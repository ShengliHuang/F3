#During process, if we terminate it, some corrupted file may be created. You cannot see the corruption from file name or size. so SUGGESTION: NEVER TERMINATE DURING PROCESSING!
#Deleting a file right after its creation may be too soon and can cause permission problem, so we should WAIT for some seconds.
#After starting the parallel processing and when the memory used is very high, do not do anything inclusing moving your cursor


import os
# 20240130, I got a similar error "C:\PythonVirtualEnv\MLHogwarts\lib\site-packages\sklearn\cluster\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning
#  warnings.warn(OpenBLAS warning: precompiled NUM_THREADS exceeded, adding auxiliary array for thread metadata. so I checked https://stackoverflow.com/questions/75619847/python-sklearn-openblas-error-for-kmeans
# and then I decided to add this part for testing----start    
default_n_threads = 8
os.environ['OPENBLAS_NUM_THREADS'] = f"{default_n_threads}"
os.environ['MKL_NUM_THREADS'] = f"{default_n_threads}"
os.environ['OMP_NUM_THREADS'] = f"{default_n_threads}"
# 20240130, I got a similar error "C:\PythonVirtualEnv\MLHogwarts\lib\site-packages\sklearn\cluster\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning
#  warnings.warn(OpenBLAS warning: precompiled NUM_THREADS exceeded, adding auxiliary array for thread metadata. so I checked https://stackoverflow.com/questions/75619847/python-sklearn-openblas-error-for-kmeans
# and then I decided to add this part for testing----end
import sys, traceback, datetime, time
import socket   #added on 20240528 to get the hostname, Ip address, and user
from datetime import date
from osgeo import gdal, ogr, osr  #need install on 20231213
import glob
import rasterio    #need install on 20231213 rasterio in arcpro after cloning the python environment of ArcGIS Pro 3.1 on 20230417
import shapefile   #need install on 20231213 shapefile in arcpro after cloning the python environmentof ArcGIS Pro 3.1 on 20230417
import pyproj
from shapely.geometry import Polygon
from rasterio.fill import fillnodata
import numpy as np  #need install on 20231213
import numpy.ma as ma
import multiprocessing
import subprocess
import math
from math import floor
from itertools import zip_longest     #This is used for raster combine
from collections import Counter   #https://www.geeksforgeeks.org/python-get-unique-values-list/
from collections import OrderedDict #https://stackoverflow.com/questions/20431270/convert-from-ordereddict-to-list
import shutil
import csv
import openpyxl   #added on 20240521 for processing excel XLSX files
import sqlite3
from PIL import Image  #need install on 20231213 but I am thinking if it really important
from PIL import ImageDraw
from PIL import ImageFont
#import stdiomask    #need installation but I may not use it, so comment out
from random import *
import random
from rasterio.plot import show
from scipy.interpolate import griddata
from scipy.stats import mode  #https://www.geeksforgeeks.org/how-to-calculate-the-mode-of-numpy-array/
from scipy import stats  #need install scipy on 20231213
import stat   #20240501 added for os.chmod() function

from scipy.ndimage import label, generate_binary_structure    #for segmentation, see https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.label.html 
from skimage import exposure   #need install scikit-image in arcpro after cloning the python environmentof ArcGIS Pro 3.1 on 20230417
from skimage.segmentation import quickshift   #can be added in ArcPRO python option
from skimage.segmentation import slic   #can be added in ArcPRO python option

import geopandas as gpd  #need install on 20231213 geopandas in arcpro after cloning the python environmentof ArcGIS Pro 3.1 on 20230417
#import GCP_CloudBucket as HuangBucket  #need installation on 20231213
#print('Below we are importing statsmodels.formula.api for StepwiseRegression---start')
import statsmodels as sm   #20210907: in virtual PC AFSPCVM07049133, (arcgispro-py3) C:\Program Files\ArcGIS\Pro\bin\Python\envs\arcgispro-py3>pip install statsmodels
import statsmodels.api as huangsm  #need install statsmodels in arcpro after cloning the python environmentof ArcGIS Pro 3.1 on 20230417
import pandas as pd
import statsmodels.graphics as smgraphics
import statsmodels.formula.api as smf  #Why not use import statsmodels.api but statsmodels.formula.api? see http://statsmodels.sourceforge.net/devel/example_formulas.html
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans  #need install scikit-learn in arcpro after cloning the python environment of ArcGIS Pro 3.1 on 20230417
#print('Below we are importing statsmodels.formula.api for StepwiseRegression---end')
from cryptography.fernet import Fernet   #https://www.geeksforgeeks.org/encrypt-and-decrypt-files-using-python/

from google.cloud import storage   #from gcloud import storage does not work, see see https://stackoverflow.com/questions/37003862/how-to-upload-a-file-to-google-cloud-storage-on-python-3
from google.cloud.storage import constants

#David work: GEE coarse segmentation takes long time; LCLUC last year; National meadow (or non Forest area such as Califnornia Meadow)
#print("https://gis.stackexchange.com/questions/324602/averaging-overlapping-rasters-with-gdal needs to be studied soon! Otherwise, we need to go back original code!")


#print("!!!!!!!!!!20230515: the ZoneStatisticsToArrayWangNing convert 2D to 1D for statistics. I think we can use array[zone=zoneID] = np.nanmean(metric[zone=zoneID]).")
#print("!!!!!!!!!!20230515: int(abs may need to change to round(abs, because I already found Area_Extent_650215.tif has 1 pixel offset. I did not do it because I am not sure if this can change others")

#https://gis.stackexchange.com/questions/23174/which-raster-format-stores-missing-strings-variable-names-multiple-bands for storing plotID for each pixel?


#Time estimation: 4 (SLTSCB) + 1.25 hour/metric * (13 + 9 x 2) NumberOfmeric * 6 Runs / (22 cores) = 14.5 hours 


#ArcPro has a Presence-only Prediction (MaxEnt) tool sutiable for invasive species prediction, see https://pro.arcgis.com/en/pro-app/latest/tool-reference/spatial-statistics/presence-only-prediction.htm
#Others incclude Forest-based Classification and Regression, generlized linear regression, geographically weight regression, and spatial pattern analysis
#print("Number of elements including the name of the program is :",len(sys.argv))
ProjectName = "F3Michigan"  #The first section of this sentence [ProjectName =] must be kept and cannot be changed, because it is used for ArcPro project creation
CWD = os.getcwd()  #get the current working directory (e.g., it will return 'D:\\f3app\\RemoteSensingYear2014' if this python code is under it)
RemoteSensingYearIndex = CWD.index("RemoteSensingYear") 
YearIndexStart = RemoteSensingYearIndex + len("RemoteSensingYear")
BaseYear = CWD[YearIndexStart:YearIndexStart+4]  #Get the BaseYear accoring where the python code resides
#print("From the current working directory, we get the BaseYear=",BaseYear)   
if len(sys.argv) == 1:   #This will only include the python itself without any additonal arguments
    Years = [2023]#,2028,2033,2038,2043,2048]#[2023] #[*range(2012,2015,1)] + [*range(2015,2075,20)]  #This shows the FVS years
    BaseMetric = "SLTSCB"
    BaseManagement = "NoMGT"
    Runs = ["Run1","Run2","Run3","Run4","Run5","Run6"] #As of 20231004, the valid parameters are Sun1 to Run6. If in the future we want more, we can change the code similarly
    Managements = ["NoMGT"] #["NoMGT"]
    Tiles = ["MichiganTile3"]#["MichiganTile1","MichiganTile2","MichiganTile3","MichiganTile4","MichiganTile5"]  #CaliforniaTile1
    
    DiscreteMetrics = ["ForType"] #We use ForType here. ForTyp is from FVS itself (see FIADB table REF_FOREST_TYPE). ForType is from Shengli's own compute. FVS standage is not good and the best one is NewAge.
    ContinuousMetrics0 = ["SLTSCB","STDAGE","STDMAI","STDCBHT","STDCBD","STDQMD","SDTCB","STDTPA","SDI1933","STDHT","STDCC","STDVOL","STDBASA"]
    ContinuousMetrics1Carbon = ["Aboveground_Total_Live","Belowground_Live","Belowground_Dead","Standing_Dead","Forest_Down_Dead_Wood","Forest_Floor","Forest_Shrub_Herb","Total_Stand_Carbon"]  #Carbon
    ContinuousMetrics2Fuel = ["Surface_Litter","Surface_Duff","Surface_lt3","Surface_3to6","Surface_6to12","Surface_ge12","Surface_Herb","Surface_Shrub","Surface_Total","Standing_Snag_lt3","Standing_Snag_ge3","Standing_Foliage","Standing_Live_lt3","Standing_Live_ge3","Standing_Total","Total_Biomass"]
    ContinuousMetrics3PotFire = ["Surf_Flame_Sev","Surf_Flame_Mod","Tot_Flame_Sev","Tot_Flame_Mod","Hard_snags_total","Soft_snags_total","Flame_Len_Sev","Flame_Len_Mod","Torch_Index","Crown_Index"]  #["litter","duff","fload_1","fload_2","fload_3","fload_4","fload_5","fload_6","fload_7","fload_8","fload_9"] can be added, but may not be necessary
    SpeciesListForImputation = ["SM","PB","WP","BF","TA","EH","JP","RN","BO","BR","CK","NC","NP","RO","SW","WO"]  #Note NC is "Not Commercial", which is weird
    ContinuousMetrics4 = ["BASA_"+k+"_0_999" for k in SpeciesListForImputation] + [k+"0and1_0_999" for k in SpeciesListForImputation] #+ ["TA0and1_0_999"]
    ContinuousMetrics5 = ["QMD_"+k+"_0_999" for k in SpeciesListForImputation]
    ContinuousMetrics6 = ["SDI1933_"+k+"_0_999" for k in SpeciesListForImputation] 
    ContinuousMetrics = ContinuousMetrics0 + ContinuousMetrics1Carbon + ContinuousMetrics2Fuel + ContinuousMetrics3PotFire + ContinuousMetrics4 + ContinuousMetrics5 + ContinuousMetrics6
    ContinuousMetrics = ContinuousMetrics0 + ContinuousMetrics4 + ContinuousMetrics5 + ContinuousMetrics6
    
    CrossValidationMetric = ["SLTSCB"]#,"QMD_15"] #["SLTSCB", "qmd_0"]   #This will list the metrics selected for crossvalidation
    F3Resolution = 30.0 #in meters
    FieldPointHeader = "RSY"+str(BaseYear)+"_MaxGap7_"   #FieldPointHeader = "Head_"
    F3InputSource = "Local" #Option are "Local" or "CloudBucket"
    EverywherePath = r'F:\CUI\fhaastf3app\F3DataEveryWhere'
    EpaEco4 = EverywherePath + os.sep + "EpaEco4" + os.sep + "us_eco_l4_no_st.shp"
    HUC8 = EverywherePath + os.sep + "NHD" + os.sep + "HUC8_US_Albers.shp"
    HUC10 = EverywherePath + os.sep + "NHD" + os.sep + "HUC10_US_Albers.shp"
    fhaastf3tilesShape =  EverywherePath + os.sep + "fhaastf3tiles.shp"
    F3ArcGISProjectCreation_TemplateFile = EverywherePath + os.sep + "F3ArcProProjectTemplate" + os.sep + "F3ArcGISProjectCreation_Template.py"
    F3ProjectAprxTemplate = EverywherePath + os.sep + "F3ArcProProjectTemplate" + os.sep + "F3ProjectTemplate.aprx"
    F3MetricExcelXLSXfile =  EverywherePath + os.sep + "F3MetricInformation.xlsx"
    SoilDrainageProductivityIndex24 = EverywherePath + os.sep + "SoilDrainageProductivityIndexes" + os.sep + "SDPI30m24.tif"  #SDPI.tif is 240m 8 class, SDPI30m8.tif is 30m 8 class, SDPI30m99.tif is 30m 99 class
    SoilDrainageProductivityIndex8 = EverywherePath + os.sep + "SoilDrainageProductivityIndexes" + os.sep + "SDPI30m8.tif"  #As of 20240411, it only covers MI. Request the US data from Frank
    EcologicalLandUnit = EverywherePath + os.sep + "EcologicalLandUnit2015" + os.sep + "World_Ecological_2015_CONUS_Albers.tif" #It is 250m classification rathen than segmentation
    SpatialMosaicProjectBoundary = r"F:\CUI\EcoregionsFVSvariants\UScounty\Michigan_Albers.shp"
    OutputUnit = "Imperial" #Options are "Imperial" or "SI". Note SI refers to "International System of Units"
    OutputGeoTifCompression = "Yes"  #Option is "Yes" or "No"
    ManualRemovePlotYearList = os.getcwd()+os.sep+"DropPlotAndInventoryYear.txt"
    HSLpath = r'D:\CUI\subplots\L48'
    Factor = -11.1
    FieldSqlitePath = r'F:\CUI\fhaastf3app\FVS\FvsDbReadyAsF3Input'  
if len(sys.argv) == 2:  #Added on 20220705, not tested yet. This will have an argument as the F3 input parameters. Please check the format of the input. 
    InputTxtFile = sys.argv[1]  #the format should be similar to F3input_20220705.txt
    if not os.path.exists(InputTxtFile):
        print("The input text file does not exist, so we cannot proceed")
        exit()
    F3InputTxtFile = open(InputTxtFile, 'r')
    Lines = F3InputTxtFile.readlines()
    Runs = []
    Tiles = []
    Managements = []
    Years = []
    DiscreteMetrics = []
    ContinuousMetrics = []
    for eachline in Lines:
        print("eachline=",eachline)
        if eachline.startswith('BaseYear ='):
           BaseYear = str(eachline.split("#")[0].split('=')[1].replace(' ','').replace('"',''))  #first remove #, then split =, then remove white space, then convert to string
        if eachline.startswith('BaseMetric ='):
           BaseMetric = str(eachline.split("#")[0].split('=')[1].replace(' ','').replace('"',''))  #first remove #, then split =, then remove white space, then convert to string
        if eachline.startswith('BaseManagement ='):
           BaseManagement = str(eachline.split("#")[0].split('=')[1].replace(' ','').replace('"',''))  #first remove #, then split =, then remove white space, then convert to string
        if eachline.startswith('FieldPointHeader ='):
           FieldPointHeader = str(eachline.split("#")[0].split('=')[1].replace(' ','').replace('"',''))  #first remove #, then split =, then remove white space, then convert to string
        if eachline.startswith('F3InputSource ='):
           F3InputSource = str(eachline.split("#")[0].split('=')[1].replace(' ','').replace('"',''))  #first remove #, then split =, then remove white space, then convert to string
        if eachline.startswith('F3Resolution ='):
           F3Resolution = float(eachline.split("#")[0].split('=')[1].replace(' ','').replace('"',''))  #first remove #, then split =, then remove white space, then convert to string
        if eachline.startswith('Run') and (("continuous" in eachline) or ("Continuous" in eachline)):
           ThisCleanLine = eachline.split("#")[0].replace(' ','').replace('"','')
           Runs.append(ThisCleanLine.split(",")[0])
           Tiles.append(ThisCleanLine.split(",")[1])
           Managements.append(ThisCleanLine.split(",")[2])
           Years.append(str(ThisCleanLine.split(",")[3]))
           ContinuousMetrics.append(ThisCleanLine.split(",")[4])
        if eachline.startswith('Run') and (("discrete" in eachline) or ("Discrete" in eachline)):
           ThisCleanLine = eachline.split("#")[0].replace(' ','').replace('"','')
           Runs.append(ThisCleanLine.split(",")[0])
           Tiles.append(ThisCleanLine.split(",")[1])
           Managements.append(ThisCleanLine.split(",")[2])
           Years.append(str(ThisCleanLine.split(",")[3]))
           DiscreteMetrics.append(ThisCleanLine.split(",")[4])
        Runs = [i for n,i in enumerate(Runs) if i not in Runs[:n]]
        Tiles = [i for n,i in enumerate(Tiles) if i not in Tiles[:n]]
        Managements = [i for n,i in enumerate(Managements) if i not in Managements[:n]]
        Years = [i for n,i in enumerate(Years) if i not in Years[:n]]
        DiscreteMetrics = [i for n,i in enumerate(DiscreteMetrics) if i not in DiscreteMetrics[:n]]
        ContinuousMetrics = [i for n,i in enumerate(ContinuousMetrics) if i not in ContinuousMetrics[:n]]
        Metrics = DiscreteMetrics + ContinuousMetrics
    F3InputTxtFile.close()
    print("BaseYear,BaseMetric,BaseManagement,Runs,Tiles,Managements,Years,DiscreteMetrics,ContinuousMetrics,Metrics,F3NoDataValue,F3ValidFillValue,F3Resolution,FieldPointHeader,F3InputSource are:")
    print(BaseYear,BaseMetric,BaseManagement,Runs,Tiles,Managements,Years,DiscreteMetrics,ContinuousMetrics,Metrics,F3NoDataValue,F3ValidFillValue,F3Resolution,FieldPointHeader,F3InputSource)
    #The return below is used for def function, which is not used here, so I comment it out
    #return BaseYear,BaseMetric,BaseManagement,Runs,Tiles,Managements,Years,DiscreteMetrics,ContinuousMetrics,Metrics,F3NoDataValue,F3ValidFillValue,F3Resolution,FieldPointHeader,F3InputSource
F3NoDataValue = -9999
F3ValidFillValue = -8888
PlotLocation = "Local" #Options are "SecuredPlace" or "Local"
F3DebugMode = "No"  #options are "Yes" and "No"
EncryptSensitiveFile = "No"
FloatToIntegerCoefficient = 100.0  #float use too much space and memory, so I decide to use Integer in the whole process. It is used in a)MetricArray, b)MetricIDW, c)RegressionCSV, d)MinMax.txt, and e)Metadata
Years = [str(k) for k in Years if int(k) > int(BaseYear)]  #added 20230505 to automatically remove those years that are older than BaseYear
Years.insert(0,BaseYear)
BaseMetric = BaseMetric.lower()
ContinuousMetrics=[i.lower() for i in ContinuousMetrics]
if BaseMetric not in ContinuousMetrics:
    ContinuousMetrics.insert(0,BaseMetric)
ContinuousMetrics.insert(0,"LT0AND1_0_999".lower())  #20240229 added to use livetree0and1 to improve stand-leve variables
DiscreteMetrics=[i.lower() for i in DiscreteMetrics]
Metrics = DiscreteMetrics + ContinuousMetrics
CrossValidationMetric = [i.lower() for i in CrossValidationMetric if i.lower() in Metrics]  #20230308 added to save this step because CrossValidation will use this tif
MosaicCandidateChosen = "Mean"  #Options are Best or Mean. 20240524: I decided we should use mean, because every step has uncertainties and we really want multiple run mean to reduce it
F3Log = os.getcwd()+os.sep+"F3Log.txt"   #This sentence must be kept and cannot be changed, because it is used for ArcPro project creation
#print("F3Log=",F3Log)




def is_file_locked(file_path):
    try:
        # Check if the file exists
        if not os.path.exists(file_path):
            return False
        # Attempt to open the file for reading
        with open(file_path, 'r'):
            pass
        # If no IOError occurred, the file is not locked
        return False
    except IOError:
        return True
    

def FindWhichPlotsUsedForSpecificPixelImputationForAllRun(Run,Tile,Management,Year,Metric,PointsTxt):
    try:
        AllRunFinalCSV = os.getcwd()+os.sep+"TilesMosaicRunAverage" + os.sep + ProjectName + os.sep + "ZoneImputationSpecificPixels_"+PointsTxt.split(os.sep)[-1].replace(".txt","")+"_AllRun.csv"
        AllRunFinalCSVFile = open(AllRunFinalCSV,'w')
        Header = "FindWhichPlotsUsedForSpecificPixelImputationForAllRun report for "+PointsTxt+"  by Dr. Shengli Huang at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n\n"
        AllRunFinalCSVFile.write(Header)
        MyPoints = []
        MyCoordinateX = []
        MyCoordinateY = []
        MyRuns = []
        MyTiles = []
        MySteps = []
        MyPlots = []
        for Run in Runs:
            for Tile in Tiles:
                for Management in [BaseManagement]:
                    for Year in [BaseYear]:
                        for Metric in [BaseMetric]:
                            FinalCSV = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"CommonShare"+os.sep+"ZoneImputationSpecificPixels_"+PointsTxt.split(os.sep)[-1].replace(".txt","")+".csv"
                            FinalCSVFile = open(FinalCSV,'r')
                            Lines = FinalCSVFile.readlines()  
                            Lines = [i.replace('\n','') for i in Lines]
                            Header = Lines[0]  #The first line indicates the input unit. Very important!
                            for Line in Lines[1:]:
                                Point = Line.split(",")[0:2]
                                CoordinateX = Line.split(",")[2]
                                CoordinateY = Line.split(",")[3]
                                Step = Line.split(",")[6]  #20240515 change Step = Line.split(",")[4] to Step = Line.split(",")[6]
                                PlotList = Line.split("------")[1].split(",")
                                MyPoints.append(Point)
                                MyCoordinateX.append(CoordinateX)
                                MyCoordinateY.append(CoordinateY)
                                MyRuns.append(Run)
                                MyTiles.append(Tile)
                                MySteps.append(Step)
                                MyPlots.append(PlotList)
        MyPointsUnique = [i for n,i in enumerate(MyPoints) if i not in MyPoints[:n]]
        kid = 0
        for k in MyPointsUnique:
            kid = kid + 1
            OriginalCoordinates = ",".join(k)
            LineContent1 = "Point " + str(kid) + " with original coordinates of " + OriginalCoordinates + "\n"
            AllRunFinalCSVFile.write(LineContent1)
            AllHerePlot = []
            for m in range(0,len(MyPoints),1):
                if MyPoints[m] == k:
                    HereCoordinateX = MyCoordinateX[m]
                    HereCoordinateY = MyCoordinateY[m]
                    HereRun = MyRuns[m]
                    HereTile = MyTiles[m]
                    HereStep = MySteps[m]
                    HerePlot = MyPlots[m]                
                    AllHerePlot = AllHerePlot + HerePlot
                    print("%%%%%%%%%%%%%%%%%%%%$$$$$$$$$$$$$$$$$$$$$$$$$$$$HerePlot=",HerePlot, file=open(F3Log, 'a'))
                    LineContent2 = "------"+ HereRun + "," + HereTile + "," + HereStep + "," + "Plot Number="+str(len(HerePlot))+":  " + ",".join(HerePlot) + "\n"
                    AllRunFinalCSVFile.write(LineContent2)
            AllHerePlotUnique = [i for n,i in enumerate(AllHerePlot) if i not in AllHerePlot[:n]]
            AllHerePlotUnique.sort()
            LineContent3 = "Summary (total number of plots="+str(len(AllHerePlotUnique))+")------" + ",".join(AllHerePlotUnique) + "\n"
            AllRunFinalCSVFile.write(LineContent3)
            if MosaicCandidateChosen == "Best":  #Options are Best or Mean
                MosaicBestMinIndex = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep + ProjectName + os.sep + "MosaicProcessingPercentageAsOrderAndReliabilityMinIndex.tif"
                ChosenRun,ChosenTile = FindRunAndTileForThisPixelBecauseMosaicCandidateChosenIsBest(MosaicBestMinIndex,HereCoordinateX,HereCoordinateY)
                LineContent4 = "Since MosaicCandidateChosen is [Best], "+ChosenRun+ " and " + ChosenTile + " was chosen!" + "\n\n"
            if MosaicCandidateChosen == "Mean":  #Options are Best or Mean  
                LineContent4 = "Since MosaicCandidateChosen is [Mean], all run and tile above was chosen!" + "\n\n"
            AllRunFinalCSVFile.write(LineContent4)
        AllRunFinalCSVFile.close()
        return AllRunFinalCSV
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"  
        #print(Content1)    
        Content2 = "The error was for FindWhichPlotsUsedForSpecificPixelImputationForAllRun with inputs of "+repr(Run)+","+repr(Tile)+","+repr(Management)+","+repr(Year)+","+repr(Metric)+","+repr(PointsTxt)+" with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog
                                           


def FindRunAndTileForThisPixelBecauseMosaicCandidateChosenIsBest(MosaicBestMinIndex,HereCoordinateX,HereCoordinateY):
    try:
        MosaicBestMinIndexArray = ReadTifToArray(MosaicBestMinIndex)
        row,col = rasterio.open(MosaicBestMinIndex).index(float(HereCoordinateX), float(HereCoordinateY))
        RunTileIndex = int(MosaicBestMinIndexArray[row,col])
        RunTileIndexID = -1
        for Run in Runs:
            for Tile in Tiles:
                RunTileIndexID = RunTileIndexID + 1
                if RunTileIndexID == RunTileIndex:
                    ChosenRun = Run
                    ChosenTile = Tile
                    break   #if necessary, check bing copilot on [python code on how to exit multiple loop using break]
        print(ChosenRun,Tile," is chosen for this pixel with X and Y =",HereCoordinateX,HereCoordinateY," and row,col=",row,col)
        return ChosenRun,ChosenTile
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"  
        #print(Content1)    
        Content2 = "The error was for FindRunAndTileForThisPixelBecauseMosaicCandidateChosenIsBest with inputs of "+repr(MosaicBestMinIndex)+repr(HereCoordinateX)+repr(HereCoordinateY)+" with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog




def lng_lat_to_albers(longitude,latitude):  #Code come from Bing Copilot [python code to use gdal to convert longitue and latitude to CONUS Albers equal area coordinates] on 04/22/2024
    try:
        print("Thus function requires [import pyproj]")
        inproj = pyproj.Proj('+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=23.0 +lon_0=-96 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs')   #Shengli defines this according to our Albers Equal Area projection parameters
        Albersx, Albersy = inproj(longitude, latitude)
        print("@@@@@@@longitude,latitude=",longitude,latitude, "converted to Albersx, Albersy=",Albersx, Albersy)
        return Albersx, Albersy
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"  
        #print(Content1)    
        Content2 = "The error was for lng_lat_to_albers with inputs of "+repr(longitude)+repr(latitude)+" with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog



def lng_lat_to_albers_Old(longitude,latitude):  #Code come from Bing Copilot [python code to use gdal to convert longitue and latitude to CONUS Albers equal area coordinates] on 04/22/2024
    try:
        print("As of 04/22/2024, the code looks OK, but there are error, so this function os not used at this time, but kept here for reference")
        nad83 = osr.SpatialReference() # Create a spatial reference for WGS 84 (latitude and longitude)
        nad83.ImportFromEPSG(4326)  # WGS84 epsg code is 4326, while NAD83 epsg code is 4269, so roiginal sentence is wgs84.ImportFromEPSG(4326)
        albers = osr.SpatialReference()  # Create a spatial reference for CONUS Albers Equal Area
        albers.ImportFromEPSG(102039)  # EPSG code for CONUS Albers Equal Area. #I do not know the difference. But we always use 5070 in our previous dataset, so I use 5070 to replace 102039 here
        #EPSG 102039 refers to the NAD 1983 USGS Contiguous USA Albers coordinate system. Let’s break down what this means:
        #Area of Use: It covers the contiguous United States (CONUS), which includes the onshore regions.
        #Projection: The projection used is Albers Equal Area Conic.
        #Datum: It is based on the North American Datum 1983 (NAD83).
        #Standard Parallels: The first standard parallel is at 29.5° North, and the second standard parallel is at 45.5° North.
        #Central Meridian: The central meridian is at 96° West.
        #Latitude of Origin: The latitude of origin is at 23° North.

        #EPSG 5070 corresponds to the NAD83 / Conus Albers coordinate system. Let’s break down what this means:
        #Area of Use: It covers the contiguous United States (CONUS), including onshore regions.
        #Projection: The projection used is the Albers Equal Area Conic.
        #Datum: It is based on the North American Datum 1983 (NAD83).
        #Standard Parallels: The first standard parallel is at 29.5° North, and the second standard parallel is at 45.5° North.
        #Central Meridian: The central meridian is at 96° West.
        #Latitude of Origin: The latitude of origin is at 23° North.
        transform = osr.CoordinateTransformation(nad83, albers)  # Create a coordinate transformation
        point = ogr.Geometry(ogr.wkbPoint)  # Create a point geometry from latitude and longitude
        point.AddPoint(longitude, latitude)
        point.TransformTo(transform)  # Transform the point to Albers Equal Area
        Albersx, Albersy = point.GetX(), point.GetY()  # Get the X and Y coordinates in meters
        print("@@@@@@@longitude,latitude=",longitude,latitude, "converted to Albersx, Albersy=",Albersx, Albersy)
        return Albersx, Albersy
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"  
        #print(Content1)    
        Content2 = "The error was for lng_lat_to_albers_Old with inputs of "+repr(longitude)+repr(latitude)+" with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog


def ConvertTheCoordinatesToAlberXY(PointsTxt):
    try:
        print("Please refer to the input example file. The first line must be [AlbersX AlbersY] or [Longitude Latitute] so that the code knows the unit of the input")
        PointsTxtFile = open(PointsTxt,'r')
        Points = PointsTxtFile.readlines()  
        Points = [i.replace('\n','') for i in Points]
        Header = Points[0]  #The first line indicates the input unit. Very important!
        CoordinatePairs = Points[1:]
        print("The number of CoordinatePairs is ",len(CoordinatePairs))

        OriginalX = []
        OriginalY = []
        AlberX = []
        AlberY = []
        for n in range(0,len(CoordinatePairs),1):
            X = float(CoordinatePairs[n].split(" ")[0].replace(",","").replace("E","").replace("°",""))
            Y = float(CoordinatePairs[n].split(" ")[1].replace(",","").replace("N","").replace("°",""))
            if (("AlbersX" in Header) or ("AlbersY" in Header) or (X < -180) or (X > 180) or (Y < -90) or (Y > 90)) :
                print("This must be Alberx coordinates, because DD will never beyond these ranges")
                print("905,150.57E 2,549,615.80N m is the standard format where the first is albers X and the second is Albers Y. This format is defined by Shengli on 04/22/2024. It can be gotton from Acrpro right clock and then [Copy Coordinates]")
                CoordinateX = X
                CoordinateY = Y
            if (("°" in Points[n]) or ("Longitude" in Header) or ("Latitute" in Header)):
                print("This must be DD, because ° will never happen in Albers coordinates, or it clearly says longitude and latitude")
                print("-84.1307605 45.1937492 is the standard format where the first is longtitude and the second is latitude. This format is defined by Frank on 04/22/2024. See teams conversation")
                CoordinateX,CoordinateY = lng_lat_to_albers(X, Y)   #Be careful of the order
            print("CoordinateX,CoordinateY = ",CoordinateX,CoordinateY)
            OriginalX.append(CoordinatePairs[n].split(" ")[0])
            OriginalY.append(CoordinatePairs[n].split(" ")[1])
            AlberX.append(CoordinateX)
            AlberY.append(CoordinateY)
        return OriginalX,OriginalY,AlberX,AlberY    #note OriginalX,OriginalY are in strings while AlberX,AlberY are floats
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"  
        #print(Content1)    
        Content2 = "The error was for ConvertTheCoordinatesToAlberXY with inputs of "+repr(PointsTxt)+" with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog



def FindWhichPlotsUsedForSpecificPixelImputation(mylock,Run,Tile,Management,Year,Metric,PointsTxt):
    try:
        if not os.path.exists(PointsTxt):
            return
        print("Let us start the plot conversion")
        OriginalX,OriginalY,AlberX,AlberY = ConvertTheCoordinatesToAlberXY(PointsTxt)
        print("AlberX=",AlberX)
        print("AlberY=",AlberY)
 
        ProcessingPercentageAsOrderAndReliability = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"Results"+os.sep+"ProcessingPercentageAsOrderAndReliability.tif"
        ZoneImputationValueLookupCSV = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"CommonShare"+os.sep+"ZoneImputationSpecificPixels_"+PointsTxt.split(os.sep)[-1].replace(".txt","")+".csv"        
        ZoneTifList = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"CommonShare"+os.sep+Management+"_"+Year+"_"+Metric+"_ZoneTifList.txt"
        ZoneTifListFile = open(ZoneTifList,'r')
        Lines = ZoneTifListFile.readlines()  
        Lines = [i.replace('\n','') for i in Lines]
        print("The number of lines is ",len(Lines))


        #This section was added on 20240425 to change the file permission from read only to written. It is not tested yet as 20240425---start
        print("Below r+ means read and append. if permission denied, make sure the file is not read only with mannual change")
        if os.path.exists(ZoneImputationValueLookupCSV):
            if os.access(ZoneImputationValueLookupCSV, os.W_OK):
                print(f"{ZoneImputationValueLookupCSV} is writable.")
            else:
                print(f"{ZoneImputationValueLookupCSV} is read-only.")
                os.chmod(ZoneImputationValueLookupCSV, stat.S_IWRITE)  #os.remove(file_name) was added when I check Bing Copilot, but I think it is not necessary
        else:
            open(ZoneImputationValueLookupCSV, 'w').close()
        #This section was added on 20240425 to change the file permission from read only to written. It is not tested yet as 20240425---end        
        
        with open(ZoneImputationValueLookupCSV, "r+") as ZoneImputationValueLookupCSVFile:   
            MyLines = ZoneImputationValueLookupCSVFile.readlines()
            MyLines = [i.replace('\n','') for i in MyLines]
            if len(MyLines) == 0:
                Header = "OriginalXinput,OriginalYinput,CoordinateX,CoordinateY,PointRow,PointColumn,StepSignSelected,ZoneTifName,PixelZone------plotlist" + "\n"
                ZoneImputationValueLookupCSVFile.write(Header)
            else:
                print("The starting AlberX are:", AlberX)
                print("The starting AlberY are:", AlberY)
                print("Below we will not do those points that have been done. This can save a lot of time (note each point may take move than one hour")
                ExistingOriginalX = []
                ExistingOriginalY = []
                for MyLine in MyLines:
                    ExistingOriginalXvalue = MyLine.split(",")[0]
                    ExistingOriginalYvalue = MyLine.split(",")[1]
                    ExistingOriginalX.append(ExistingOriginalXvalue)
                    ExistingOriginalY.append(ExistingOriginalYvalue)
                print("The starting AlberX are:", AlberX)
                print("The starting AlberY are:", AlberY)
                RemovedIndex = []
                for d in range(0,len(ExistingOriginalX),1):
                    for e in range(0,len(OriginalX),1):
                        if ((ExistingOriginalX[d] == OriginalX[e]) and (ExistingOriginalY[d] == OriginalY[e])):
                            print("---ExistingOriginalX[d],ExistingOriginalY[d]=",ExistingOriginalX[d],ExistingOriginalY[d])
                            print("---OriginalX[e],OriginalY[e]=",OriginalX[e],OriginalY[e])
                            print("---e=",e)
                            RemovedIndex.append(e)
                print("The RemovedIndex are:", RemovedIndex)
                AlberX = [v for i, v in enumerate(AlberX) if i not in RemovedIndex]
                AlberY = [v for i, v in enumerate(AlberY) if i not in RemovedIndex]
                print("The remaing AlberX are:", AlberX)
                print("The remaing AlberY are:", AlberY)
                OriginalX = [v for i, v in enumerate(OriginalX) if i not in RemovedIndex]
                OriginalY = [v for i, v in enumerate(OriginalY) if i not in RemovedIndex]
                print("The remaing OriginalX are:", OriginalX)
                print("The remaing OriginalY are:", OriginalY)                   

            YangDiBianMaFile = Lines[0].split("||")[3]
            ds2 = gdal.Open(YangDiBianMaFile, gdal.GA_ReadOnly)
            cols = ds2.RasterXSize
            rows = ds2.RasterYSize
            YangDiBianMa = ds2.GetRasterBand(1).ReadAsArray().astype(np.float64)
            YangDiBianMaNodata = ds2.GetRasterBand(1).GetNoDataValue()
            YangDiBianMa = ma.masked_values(YangDiBianMa, YangDiBianMaNodata)
            YangDiBianMaUnique = np.unique(YangDiBianMa)
            YangDiBianMaUnique = YangDiBianMaUnique[~YangDiBianMaUnique.mask]
            #print("YangDiBianMaUnique=",YangDiBianMaUnique)
            YangDiBianMaUnique = [int(x) for x in YangDiBianMaUnique if x is not None]
            #print("YangDiBianMaUnique=",YangDiBianMaUnique)

            ZoneTifArrayAll = np.full((len(Lines),YangDiBianMa.shape[0],YangDiBianMa.shape[1]), F3NoDataValue)
            
            Step = []
            StepSign = []
            ZoneTif = []
            PlotNumber = []
            LineID = -1
            for Line in Lines:
                LineID = LineID + 1
                StepSignValue = Line.split("||")[0]
                StepSign.append(StepSignValue)
                StepValue = Line.split("||")[0].split("-")[0]
                Step.append(StepValue)
                ZoneTifName = Line.split("||")[1]
                ZoneTif.append(ZoneTifName)
                PlotNumberValue = Line.split("||")[-1]
                PlotNumber.append(PlotNumberValue)
                
                ds1 = gdal.Open(ZoneTifName, gdal.GA_ReadOnly)
                ZoneArrayAAA = ds1.GetRasterBand(1).ReadAsArray().astype(np.int32)
                ZoneArrayAAANodata = ds1.GetRasterBand(1).GetNoDataValue()
                ZoneArrayAAA = ma.masked_values(ZoneArrayAAA, ZoneArrayAAANodata)
                ZoneTifArrayAll[LineID,:,:] = ZoneArrayAAA
                ds1 = None
            ZoneTifListFile.close()
            LastStep3Index = ''.join([str(k) for k in Step]).rindex('3')
            print("The index of the last step3 occurrence: ",LastStep3Index)
            
            ds = gdal.Open(ProcessingPercentageAsOrderAndReliability, gdal.GA_ReadOnly)
            OrderAndReliability = ds.GetRasterBand(1).ReadAsArray().astype(np.int32)
            OrderAndReliabilityNodata = ds.GetRasterBand(1).GetNoDataValue()
            OrderAndReliability = ma.masked_values(OrderAndReliability, OrderAndReliabilityNodata)         
            OrderAndReliabilityUnique = np.unique(OrderAndReliability)  #Get unique value
            OrderAndReliabilityUnique = OrderAndReliabilityUnique[~OrderAndReliabilityUnique.mask]
            print(OrderAndReliabilityUnique)
            print("The number of OrderAndReliabilityUnique is ",len(OrderAndReliabilityUnique))
            OrderAndReliabilityUnique.sort()
            OrderAndReliabilityUniqueList = OrderAndReliabilityUnique.tolist()
            print("The index of the last step3 occurrence: ",LastStep3Index," and its ProcessingPercentageAsOrderAndReliability value=",OrderAndReliabilityUnique[LastStep3Index])
            t00 = time.time()
            for h in range(0,len(AlberX),1):
                print("\nProcessing h=",h," out of total ",len(AlberX))
                CoordinateX = AlberX[h]
                CoordinateY = AlberY[h]
                row,col = rasterio.open(ProcessingPercentageAsOrderAndReliability).index(CoordinateX, CoordinateY)
                if ((col < 0) or (col > cols-1) or (row < 0) or (row > rows-1)):  #This means this point is beyond the image extent
                    continue
                else:
                    OriginalXinput = OriginalX[h]
                    OriginalYinput = OriginalY[h]
                    MyCoordinateX = AlberX[h]
                    MyCoordinateY = AlberY[h]
                    PointRow = row 
                    PointColumn = col
                print("Concretelly processing ",OriginalXinput,OriginalYinput,PointRow,PointColumn)
                print("Concretelly processing ",OriginalXinput,OriginalYinput,PointRow,PointColumn, file=open(F3Log, 'a'))

                t0 = time.time()
                PointValueOfOrderAndReliability = OrderAndReliability[PointRow,PointColumn]
                print("PointValueOfOrderAndReliability=",PointValueOfOrderAndReliability)   #we need a judge if PointValueOfOrderAndReliability= -- here for subsequent processing
                if np.ma.is_masked(PointValueOfOrderAndReliability):
                    LineContent = str(OriginalXinput)+","+str(OriginalYinput)+","+str(MyCoordinateX)+","+str(MyCoordinateY)+","+str(PointRow)+","+str(PointColumn)+" is not a valid pixel from imputation" + "\n"
                else:
                    OrderAndReliabilityIndex = OrderAndReliabilityUniqueList.index(PointValueOfOrderAndReliability)
                    print("OrderAndReliabilityIndex=",OrderAndReliabilityIndex)
                    if OrderAndReliabilityIndex == 0: #This is the plot Locations
                        ZoneArraySelected = YangDiBianMa
                        LineContent = str(OriginalXinput)+","+str(OriginalYinput)+","+str(MyCoordinateX)+","+str(MyCoordinateY)+","+str(PointRow)+","+str(PointColumn)+","+"1-0"+","+YangDiBianMaFile+","+"999999"+ "------" + str(int(YangDiBianMa[PointRow,PointColumn])) + "\n"
                    else:
                        StepSelected = Step[OrderAndReliabilityIndex-1]   
                        StepSignSelected = StepSign[OrderAndReliabilityIndex-1]
                        ZoneArraySelected = ZoneTifArrayAll[OrderAndReliabilityIndex-1,:,:]
                        print("ZoneArraySelected is selected from ",ZoneTif[OrderAndReliabilityIndex-1])
                        PixelZone = ZoneArraySelected[PointRow,PointColumn]
                        ZoneArraySelected_Zones = ZoneArraySelected[ZoneArraySelected == PixelZone]
                        ZoneArraySelected_ZonesID = ma.masked_values(ZoneArraySelected_Zones, F3NoDataValue)
                        ZoneArraySelected_ZonesIDUnique = np.unique(ZoneArraySelected_ZonesID).tolist()
                        ZoneArraySelected_ZonesIDUnique = [x for x in ZoneArraySelected_ZonesIDUnique if x is not None]
                        ZoneArraySelected_ZonesIDUnique = [int(i) for n,i in enumerate(ZoneArraySelected_ZonesIDUnique) if i not in ZoneArraySelected_ZonesIDUnique[:n]]
                        print("StepSignSelected=",StepSignSelected)
                        print("StepSelected=",StepSelected)
                        if StepSignSelected == "2-0":
                            print("StepSignSelected == 2-0")
                            PlotID = YangDiBianMa[ZoneArraySelected == PixelZone]
                            PlotID = ma.masked_values(PlotID, YangDiBianMaNodata)
                            PlotIDUnique = np.unique(PlotID).tolist()
                            PlotIDList = [x for x in PlotIDUnique if x is not None]
                            PlotIDListUnique = [int(i) for n,i in enumerate(PlotIDList) if i not in PlotIDList[:n]]
                            PlotJoinWithComma = ",".join([str(int(k)) for k in PlotIDListUnique])
                            LineContent = str(OriginalXinput)+","+str(OriginalYinput)+","+str(MyCoordinateX)+","+str(MyCoordinateY)+","+str(PointRow)+","+str(PointColumn)+","+StepSignSelected+","+ZoneTif[OrderAndReliabilityIndex-1]+","+str(PixelZone)+ "------" + PlotJoinWithComma + "\n"
                        if (StepSelected == "3"):
                            print("StepSelected == 3")
                            Zone1 = ZoneTifArrayAll[0,:,:][(ZoneArraySelected == PixelZone) & (~OrderAndReliability.mask) & (OrderAndReliability <= OrderAndReliabilityUniqueList[1])]
                            Zone1 = ma.masked_values(Zone1, F3NoDataValue)
                            Zone1Unique = np.unique(Zone1).tolist()
                            Zone1Unique = [x for x in Zone1Unique if x is not None]
                            Zone1Unique = [int(i) for n,i in enumerate(Zone1Unique) if i not in Zone1Unique[:n]]
                            PlotListAAA = []
                            for j in Zone1Unique:
                                PlotID = YangDiBianMa[ZoneTifArrayAll[0,:,:] == j]
                                PlotID = ma.masked_values(PlotID, YangDiBianMaNodata)
                                PlotIDUnique = np.unique(PlotID).tolist()
                                PlotListAAA.extend(PlotIDUnique)   #PlotListAAA = PlotListAAA.extend(PlotIDUnique) is wrong
                                PlotIDList = [x for x in PlotListAAA if x is not None]
                                PlotIDListUnique = [int(i) for n,i in enumerate(PlotIDList) if i not in PlotIDList[:n]]
                            PlotJoinWithComma = ",".join([str(int(k)) for k in PlotIDListUnique])
                            LineContent = str(OriginalXinput)+","+str(OriginalYinput)+","+str(MyCoordinateX)+","+str(MyCoordinateY)+","+str(PointRow)+","+str(PointColumn)+","+StepSignSelected+","+ZoneTif[OrderAndReliabilityIndex-1]+","+str(PixelZone)+ "------" + PlotJoinWithComma + "\n"
                        if (StepSelected == "4"):
                            print("StepSelected == 4")
                            print("PixelZone == ",PixelZone)
                            OrderAndReliabilityList = OrderAndReliability[(ZoneArraySelected == PixelZone) & (~OrderAndReliability.mask) & (OrderAndReliability <= OrderAndReliabilityUniqueList[LastStep3Index])]
                            OrderAndReliabilityList = ma.masked_values(OrderAndReliabilityList, F3NoDataValue)
                            OrderAndReliabilityListUnique = np.unique(OrderAndReliabilityList).tolist()
                            OrderAndReliabilityListUnique = [x for x in OrderAndReliabilityListUnique if x is not None]
                            OrderAndReliabilityListUnique = [int(i) for n,i in enumerate(OrderAndReliabilityListUnique) if i not in OrderAndReliabilityListUnique[:n]]
                            OrderAndReliabilityListUniqueIndex = [OrderAndReliabilityUniqueList.index(k) for k in OrderAndReliabilityListUnique]
                            PlotListAAA = []
                            print("OrderAndReliabilityListUniqueIndex=",OrderAndReliabilityListUniqueIndex)
                            for t in OrderAndReliabilityListUniqueIndex:
                                if t == 0:
                                    print("t==0 (i.e. t=",t,"), with processing total is",OrderAndReliabilityListUniqueIndex)
                                    PlotID = YangDiBianMa[(ZoneArraySelected == PixelZone) & (~OrderAndReliability.mask) & (OrderAndReliability <= OrderAndReliabilityUniqueList[LastStep3Index])]
                                    PlotID = ma.masked_values(PlotID, YangDiBianMaNodata)
                                    PlotIDUnique = np.unique(PlotID).tolist()
                                    PlotIDList = [x for x in PlotIDUnique if x is not None]
                                    PlotIDListUnique = [int(i) for n,i in enumerate(PlotIDList) if i not in PlotIDList[:n]]
                                    #print("PlotListAAA=",PlotListAAA)
                                    #print("PlotIDListUnique=",PlotIDListUnique)
                                    PlotListAAA.extend(PlotIDListUnique)
                                    #print("PlotListAAA=",PlotListAAA)
                                if t == 1:
                                    print("t==1 (i.e. t=",t,"), with processing total is",OrderAndReliabilityListUniqueIndex)
                                    Step2Zone = ZoneTifArrayAll[0,:,:][(ZoneArraySelected == PixelZone) & (~OrderAndReliability.mask) & (OrderAndReliability <= OrderAndReliabilityUniqueList[LastStep3Index])]
                                    LocalStep2Zone = ma.masked_values(Step2Zone, F3NoDataValue)
                                    LocalStep2ZoneUnique = np.unique(LocalStep2Zone).tolist()
                                    LocalStep2ZoneUniqueList = [x for x in LocalStep2ZoneUnique if x is not None]
                                    LocalStep3ZoneUniqueListUnique = [int(i) for n,i in enumerate(LocalStep2ZoneUniqueList) if i not in LocalStep2ZoneUniqueList[:n]]
                                    for s in LocalStep3ZoneUniqueListUnique:
                                        PlotID = YangDiBianMa[ZoneTifArrayAll[0,:,:] == s]
                                        PlotID = ma.masked_values(PlotID, YangDiBianMaNodata)
                                        PlotIDUnique = np.unique(PlotID).tolist()
                                        PlotIDList = [x for x in PlotIDUnique if x is not None]
                                        PlotIDListUnique = [int(i) for n,i in enumerate(PlotIDList) if i not in PlotIDList[:n]]
                                        #print("PlotListAAA=",PlotListAAA)
                                        #print("PlotIDListUnique=",PlotIDListUnique)
                                        PlotListAAA.extend(PlotIDListUnique)
                                if t > 1:
                                    print("t>1 (i.e. t=",t,"), with processing total is",OrderAndReliabilityListUniqueIndex)
                                    Step3Zone = ZoneTifArrayAll[t,:,:][(ZoneArraySelected == PixelZone) & (~OrderAndReliability.mask) & (OrderAndReliability <= OrderAndReliabilityUniqueList[LastStep3Index])]
                                    LocalStep3Zone = ma.masked_values(Step3Zone, F3NoDataValue)
                                    LocalStep3ZoneUnique = np.unique(LocalStep3Zone).tolist()
                                    LocalStep3ZoneUniqueList = [x for x in LocalStep3ZoneUnique if x is not None]
                                    LocalStep3ZoneUniqueListUnique = [int(i) for n,i in enumerate(LocalStep3ZoneUniqueList) if i not in LocalStep3ZoneUniqueList[:n]]
                                    #print("LocalStep3ZoneUniqueListUnique=",LocalStep3ZoneUniqueListUnique)
                                    for a in LocalStep3ZoneUniqueListUnique:
                                        Step2Zone = ZoneTifArrayAll[0,:,:][(ZoneTifArrayAll[t,:,:] == a) & (~OrderAndReliability.mask) & (OrderAndReliability <= OrderAndReliabilityUniqueList[1])]
                                        LocalStep2Zone = ma.masked_values(Step2Zone, F3NoDataValue)
                                        LocalStep2ZoneUnique = np.unique(LocalStep2Zone).tolist()
                                        LocalStep2ZoneUniqueList = [x for x in LocalStep2ZoneUnique if x is not None]
                                        LocalStep2ZoneUniqueListUnique = [int(i) for n,i in enumerate(LocalStep2ZoneUniqueList) if i not in LocalStep3ZoneUniqueList[:n]]
                                        #print("LocalStep2ZoneUniqueListUnique=",LocalStep2ZoneUniqueListUnique)
                                        for b in LocalStep2ZoneUniqueListUnique:
                                            print("step 3 a=",a, "and step 2 b=",b)
                                            PlotID = YangDiBianMa[ZoneTifArrayAll[0,:,:] == b]
                                            PlotID = ma.masked_values(PlotID, YangDiBianMaNodata)
                                            PlotIDUnique = np.unique(PlotID).tolist()
                                            PlotIDList = [x for x in PlotIDUnique if x is not None]
                                            PlotIDListUnique = [int(i) for n,i in enumerate(PlotIDList) if i not in PlotIDList[:n]]
                                            PlotListAAA.extend(PlotIDListUnique)
                            #print("heheher PlotIDList=",PlotIDList)
                            PlotIDList = [x for x in PlotListAAA if x is not None]
                            PlotIDListUnique = [int(i) for n,i in enumerate(PlotIDList) if i not in PlotIDList[:n]]
                            PlotJoinWithComma = ",".join([str(int(k)) for k in PlotIDListUnique])
                            print("PlotJoinWithComma=",PlotJoinWithComma)
                            LineContent = str(OriginalXinput)+","+str(OriginalYinput)+","+str(MyCoordinateX)+","+str(MyCoordinateY)+","+str(PointRow)+","+str(PointColumn)+","+StepSignSelected+","+ZoneTif[OrderAndReliabilityIndex-1]+","+str(PixelZone)+ "------" + PlotJoinWithComma + "\n"
                print("It took \t" + str(int((time.time() - t0)))," seconds")
                print("LineContent=",LineContent)
                ZoneImputationValueLookupCSVFile.write(LineContent)                
        print("For all ",len(AlberX)," points it took \t" + str(int((time.time() - t00)))," seconds")
        return ZoneImputationValueLookupCSVFile
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"  
        #print(Content1)    
        Content2 = "The error was for FindWhichPlotsUsedForEachPixelIputation with inputs of "+repr(Run)+","+repr(Tile)+","+repr(Management)+","+repr(Year)+","+repr(Metric)+","+repr(PointsTxt)+" with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog
     




##
##
##
##
##
##
##        
##
##
##
##
##    Step2ZoneWhereAllElementsAreMasked = []
##    Step2ZoneWhereAtLeastOneElementIsNotMasked = []
##    if k == 0: #This is for step 2
##        Step2ZoneUnique = np.unique(ZoneArrayAAA)
##        Step2ZoneUnique = Step2ZoneUnique[~Step2ZoneUnique.mask]
##        for k in Step2ZoneUnique:
##            if YangDiBianMa[ZoneArrayAAA == k].mask.all:  #Check if all elements of an array are masked
##                Step2ZoneWhereAllElementsAreMasked.append(k)
##            else:
##                Step2ZoneWhereAtLeastOneElementIsNotMasked.append(k)
##print("ZoneWhereAtLeastOneElementIsNotMasked=",Step2ZoneWhereAtLeastOneElementIsNotMasked)
##print("len(ZoneWhereAtLeastOneElementIsNotMasked)=",len(Step2ZoneWhereAtLeastOneElementIsNotMasked))
##ZoneTifArrayAll = ma.masked_values(ZoneTifArrayAll, F3NoDataValue)
##print("TotalNumberOfValidZones=",TotalNumberOfValidZones)
##
##
##
##
##PointValueOfOrderAndReliability = OrderAndReliability[PointRow,PointColumn]
##print("PointValueOfOrderAndReliability=",PointValueOfOrderAndReliability)   #we need a judge if PointValueOfOrderAndReliability= -- here for subsequent processing
##ZoneTifIndex = OrderAndReliabilityUniqueList.index(PointValueOfOrderAndReliability)
##if ZoneTifIndex is None:
##    print("We will do something saying this should be ignored or using PixelLable value")
##else:
##    print("ZoneTifIndex=",ZoneTifIndex)
##    if ZoneTifIndex == 0:
##        ZoneArray = YangDiBianMa
##        StepSelected = 1
##        ZoneArraySource = YangDiBianMaFile
##    else:
##        ZoneArray = ZoneTifArrayAll[ZoneTifIndex-1]
##        StepSelected = Step[ZoneTifIndex-1]
##        ZoneArraySource = ZoneTif[ZoneTifIndex-1]
##    print("HAHAHA StepSelected=",StepSelected)
##
##
##    print("Next we will use StepSelected to do the work")
##    if ((StepSelected == 1) or (StepSelected == 2)):
##        #Based on 1
##        ZoneID = ZoneArray[PointRow,PointColumn]
##        PlotID = YangDiBianMa[ZoneArray == ZoneID]
##        PlotID = ma.masked_values(PlotID, YangDiBianMaNodata)
##        PlotIDUnique = np.unique(PlotID).tolist()
##        PlotIDList = PlotIDList + PlotIDUnique
##        PlotIDList = [x for x in PlotIDList if x is not None]
##        print(PlotIDList)
##        PlotIDListUnique = [i for n,i in enumerate(PlotIDList) if i not in PlotIDList[:n]]
##        AllPlotID = ",".join([str(int(k)) for k in PlotIDListUnique])
##        print("AllPlotID=",AllPlotID)
##
##    if (StepSelected == 3):
##        #Based on 2
##        ZoneID = ZoneArray[PointRow,PointColumn]
##        
##        Step2ZoneIDs = ZoneTifArrayAll[1,:,:][(OrderAndReliability <= OrderAndReliabilityUnique[1]) & (ZoneArray == ZoneID)]
##        Step2ZoneIDs = Step2ZoneIDs[~Step2ZoneIDs.mask]
##        Step2ZoneIDsUnique = np.unique(Step2ZoneIDs)
##        PlotIDList = []
##        for k in range(0,len(Step2ZoneIDsUnique),1):   #Can we combine them together? Change to 1D and then [x for x in a if a in b]? or for i for j and if value in?
##            PlotID = YangDiBianMa[ZoneTifArrayAll[1,:,:] == k]
##            PlotID = ma.masked_values(PlotID, YangDiBianMaNodata)
##            PlotIDUnique = np.unique(PlotID).tolist()
##            PlotIDList = PlotIDList + PlotIDUnique
##        PlotIDList = [x for x in PlotIDList if x is not None]
##        print(PlotIDList)
##        PlotIDListUnique = [i for n,i in enumerate(PlotIDList) if i not in PlotIDList[:n]]
##        AllPlotID = ",".join([str(int(k)) for k in PlotIDListUnique])
##        print("AllPlotID=",AllPlotID)
##        
##    if (StepSelected == 4):
##        print("Do this later")
##        ZoneID = ZoneArray[PointRow,PointColumn]
##        
##        print("ZoneID=",ZoneID)
##        print("The source of is ZoneArray",ZoneArraySource)
##        print("OrderAndReliabilityUnique[LastStep3Index]=",OrderAndReliabilityUnique[LastStep3Index])
##        Step3PixelsAndOrder = OrderAndReliability[(OrderAndReliability <= OrderAndReliabilityUnique[LastStep3Index]) & (ZoneArray == ZoneID)]   #THis is still not right, but let us test
##        Step3PixelsAndOrderUnique = np.unique(Step3PixelsAndOrder[~Step3PixelsAndOrder.mask])
##        print("Step3PixelsAndOrderUnique=",Step3PixelsAndOrderUnique)
##        PlotIDList = []
##        for m in Step3PixelsAndOrderUnique: 
##            print("m=",m)
##            OrderAndReliabilityUniqueListIndex = OrderAndReliabilityUniqueList.index(m)
##            print("OrderAndReliabilityUniqueListIndex=",OrderAndReliabilityUniqueListIndex)
##            if OrderAndReliabilityUniqueListIndex == 0:
##                NewZoneArray = YangDiBianMa
##                NewZoneArraySource = YangDiBianMaFile
##            else:
##                NewZoneArray = ZoneTifArrayAll[OrderAndReliabilityUniqueListIndex-1,:,:]
##                NewZoneArraySource = ZoneTif[OrderAndReliabilityUniqueListIndex-1]
##            print("For ",m, " the NewZoneArraySource is ",NewZoneArraySource)
##
##            Step2ZoneIDs = ZoneTifArrayAll[1,:,:][(OrderAndReliability <= OrderAndReliabilityUnique[1]) & (~NewZoneArray.mask) & (OrderAndReliability == OrderAndReliabilityUnique[OrderAndReliabilityUniqueListIndex-1])]
##            Step2ZoneIDs = Step2ZoneIDs[~Step2ZoneIDs.mask]
##            Step2ZoneIDsUnique = np.unique(Step2ZoneIDs)
##            print("Step2ZoneIDsUnique AAA =",Step2ZoneIDsUnique)
##            print("len(Step2ZoneIDsUnique) AAA =",len(Step2ZoneIDsUnique))
##
##
##
##
##            Step2ZoneIDsUnique = [x for x in Step2ZoneIDsUnique if x in Step2 ZoneWhereAtLeastOneElementIsNotMasked]
##            print("Step2ZoneIDsUnique BBB =",Step2ZoneIDsUnique)
##            print("len(Step2ZoneIDsUnique) BBB =",len(Step2ZoneIDsUnique))
##
##            
##            
##            t0 = time.time()
##            for k in range(0,len(Step2ZoneIDsUnique),1):   #Can we combine them together? Change to 1D and then [x for x in a if a in b]? or for i for j and if value in?
##                PlotID = YangDiBianMa[ZoneTifArrayAll[1,:,:] == k]
##                #print("It took \t" + str(int((time.time() - t0)))," seconds")
##                PlotID = ma.masked_values(PlotID, YangDiBianMaNodata)
##                PlotIDUnique = np.unique(PlotID).tolist()
##                PlotIDList = PlotIDList + PlotIDUnique
##                
##        PlotIDList = [x for x in PlotIDList if x is not None]
##        print(PlotIDList)
##        PlotIDListUnique = [i for n,i in enumerate(PlotIDList) if i not in PlotIDList[:n]]
##        AllPlotID = ",".join([str(int(k)) for k in PlotIDListUnique])
##        print("AllPlotID=",AllPlotID)
##
##ZoneImputationValueLookupCSVFile.close()
##exit()
##
##
##
##
##ProcessingPercentageAsOrderAndReliability = r'F:\CUI\fhaastf3app\RemoteSensingYear2023\Run1\MichiganTile3\Results\ProcessingPercentageAsOrderAndReliability.tif'
##CoordinateX = 895062.79
##CoordinateY = 2479616.63
##row,col = rasterio.open(ProcessingPercentageAsOrderAndReliability).index(CoordinateX, CoordinateY)
##PointRow = row 
##PointColumn = col
##print("PointRow,PointColumn=",PointRow,PointColumn)
##
##
##print("start")
##ZoneTifList = r'F:\CUI\fhaastf3app\RemoteSensingYear2023\Run1\MichiganTile3\CommonShare\NoMGT_2023_sltscb_ZoneTifList.txt'
##ZoneTifListFile = open(ZoneTifList,'r')
##Lines = ZoneTifListFile.readlines()  
##Lines = [i.replace('\n','') for i in Lines]
##print("The number of lines is ",len(Lines))
##Step = []
##ZoneTif = []
##PlotNumber = []
##
##YangDiBianMaFile = Lines[0].split("||")[3]
##ds2 = gdal.Open(YangDiBianMaFile, gdal.GA_ReadOnly)
##YangDiBianMa = ds2.GetRasterBand(1).ReadAsArray().astype(np.float64)
##YangDiBianMaNodata = ds2.GetRasterBand(1).GetNoDataValue()
##YangDiBianMa = ma.masked_values(YangDiBianMa, YangDiBianMaNodata)
##YangDiBianMaUnique = np.unique(YangDiBianMa)
##print("YangDiBianMaUnique=",YangDiBianMaUnique)
##
##
##for Line in Lines:
##    StepValue = int(Line.split("||")[0].split("-")[0])
##    Step.append(StepValue)
##    ZoneTifName = Line.split("||")[1]
##    ZoneTif.append(ZoneTifName)
##    PlotNumberValue = Line.split("||")[-1]
##    PlotNumber.append(PlotNumberValue)
##print("Step=",Step,len(Step),"\n")    
###print("ZoneTif=",ZoneTif)
##print("The number of ZoneTif is ",len(ZoneTif))
##ZoneTifListFile.close()
##
##LastStep3Index = ''.join([str(k) for k in Step]).rindex('3')
##print("The index of the last step3 occurrence: ",LastStep3Index)
##
##    
##
##ds = gdal.Open(ProcessingPercentageAsOrderAndReliability, gdal.GA_ReadOnly)
##OrderAndReliability = ds.GetRasterBand(1).ReadAsArray().astype(np.int32)
##OrderAndReliabilityNodata = ds.GetRasterBand(1).GetNoDataValue()
##OrderAndReliability = ma.masked_values(OrderAndReliability, OrderAndReliabilityNodata)         
##OrderAndReliabilityUnique = np.unique(OrderAndReliability)  #Get unique value
##OrderAndReliabilityUnique = OrderAndReliabilityUnique[~OrderAndReliabilityUnique.mask]
##print(OrderAndReliabilityUnique)
##print("The number of OrderAndReliabilityUnique is ",len(OrderAndReliabilityUnique))
##OrderAndReliabilityUnique.sort()
##OrderAndReliabilityUniqueList = OrderAndReliabilityUnique.tolist()
##
##TotalNumberOfValidZones = 0
##ZoneTifArrayAll = np.full((len(Lines),YangDiBianMa.shape[0],YangDiBianMa.shape[1]), F3NoDataValue)
##ValidZoneID = []
##for k in range(0,len(ZoneTif),1):
##    ds1 = gdal.Open(ZoneTif[k], gdal.GA_ReadOnly)
##    ZoneArrayAAA = ds1.GetRasterBand(1).ReadAsArray().astype(np.int32)
##    ZoneArrayAAANodata = ds1.GetRasterBand(1).GetNoDataValue()
##    ZoneArrayAAA = ma.masked_values(ZoneArrayAAA, ZoneArrayAAANodata)
##    ZoneTifArrayAll[k,:,:] = ZoneArrayAAA
##    ds1 = None
##
##    ValidZoneArray1 = ZoneArrayAAA[~ZoneArrayAAA.mask]     
##    NumberOfZone1 = len(np.unique(ValidZoneArray1))
##
##    ValidZoneArray2 = ZoneArrayAAA[(~ZoneArrayAAA.mask) & (OrderAndReliability == OrderAndReliabilityUnique[k+1])]
##    ValidZoneArray2Unique = np.unique(ValidZoneArray2)
##    NumberOfZone2 = len(ValidZoneArray2Unique)
##    print("For ",ZoneTif[k]," OrderAndReliability value is ",OrderAndReliabilityUnique[k+1]," and Number Of Total and Valid Zone are ",NumberOfZone1, NumberOfZone2)
##    TotalNumberOfValidZones = TotalNumberOfValidZones + NumberOfZone2
##
##    Step2ZoneWhereAllElementsAreMasked = []
##    Step2ZoneWhereAtLeastOneElementIsNotMasked = []
##    if k == 0: #This is for step 2
##        Step2ZoneUnique = np.unique(ZoneArrayAAA)
##        Step2ZoneUnique = Step2ZoneUnique[~Step2ZoneUnique.mask]
##        for k in Step2ZoneUnique:
##            if YangDiBianMa[ZoneArrayAAA == k].mask.all:  #Check if all elements of an array are masked
##                Step2ZoneWhereAllElementsAreMasked.append(k)
##            else:
##                Step2ZoneWhereAtLeastOneElementIsNotMasked.append(k)
##print("ZoneWhereAtLeastOneElementIsNotMasked=",Step2ZoneWhereAtLeastOneElementIsNotMasked)
##print("len(ZoneWhereAtLeastOneElementIsNotMasked)=",len(Step2ZoneWhereAtLeastOneElementIsNotMasked))
##ZoneTifArrayAll = ma.masked_values(ZoneTifArrayAll, F3NoDataValue)
##print("TotalNumberOfValidZones=",TotalNumberOfValidZones)
##
##
##
##
##PointValueOfOrderAndReliability = OrderAndReliability[PointRow,PointColumn]
##print("PointValueOfOrderAndReliability=",PointValueOfOrderAndReliability)   #we need a judge if PointValueOfOrderAndReliability= -- here for subsequent processing
##ZoneTifIndex = OrderAndReliabilityUniqueList.index(PointValueOfOrderAndReliability)
##if ZoneTifIndex is None:
##    print("We will do something saying this should be ignored or using PixelLable value")
##else:
##    print("ZoneTifIndex=",ZoneTifIndex)
##    if ZoneTifIndex == 0:
##        ZoneArray = YangDiBianMa
##        StepSelected = 1
##        ZoneArraySource = YangDiBianMaFile
##    else:
##        ZoneArray = ZoneTifArrayAll[ZoneTifIndex-1]
##        StepSelected = Step[ZoneTifIndex-1]
##        ZoneArraySource = ZoneTif[ZoneTifIndex-1]
##    print("HAHAHA StepSelected=",StepSelected)
##
##
##    print("Next we will use StepSelected to do the work")
##    if ((StepSelected == 1) or (StepSelected == 2)):
##        #Based on 1
##        ZoneID = ZoneArray[PointRow,PointColumn]
##        PlotID = YangDiBianMa[ZoneArray == ZoneID]
##        PlotID = ma.masked_values(PlotID, YangDiBianMaNodata)
##        PlotIDUnique = np.unique(PlotID).tolist()
##        PlotIDList = PlotIDList + PlotIDUnique
##        PlotIDList = [x for x in PlotIDList if x is not None]
##        print(PlotIDList)
##        PlotIDListUnique = [i for n,i in enumerate(PlotIDList) if i not in PlotIDList[:n]]
##        AllPlotID = ",".join([str(int(k)) for k in PlotIDListUnique])
##        print("AllPlotID=",AllPlotID)
##
##    if (StepSelected == 3):
##        #Based on 2
##        ZoneID = ZoneArray[PointRow,PointColumn]
##        
##        Step2ZoneIDs = ZoneTifArrayAll[1,:,:][(OrderAndReliability <= OrderAndReliabilityUnique[1]) & (ZoneArray == ZoneID)]
##        Step2ZoneIDs = Step2ZoneIDs[~Step2ZoneIDs.mask]
##        Step2ZoneIDsUnique = np.unique(Step2ZoneIDs)
##        PlotIDList = []
##        for k in range(0,len(Step2ZoneIDsUnique),1):   #Can we combine them together? Change to 1D and then [x for x in a if a in b]? or for i for j and if value in?
##            PlotID = YangDiBianMa[ZoneTifArrayAll[1,:,:] == k]
##            PlotID = ma.masked_values(PlotID, YangDiBianMaNodata)
##            PlotIDUnique = np.unique(PlotID).tolist()
##            PlotIDList = PlotIDList + PlotIDUnique
##        PlotIDList = [x for x in PlotIDList if x is not None]
##        print(PlotIDList)
##        PlotIDListUnique = [i for n,i in enumerate(PlotIDList) if i not in PlotIDList[:n]]
##        AllPlotID = ",".join([str(int(k)) for k in PlotIDListUnique])
##        print("AllPlotID=",AllPlotID)
##        
##    if (StepSelected == 4):
##        print("Do this later")
##        ZoneID = ZoneArray[PointRow,PointColumn]
##        
##        print("ZoneID=",ZoneID)
##        print("The source of is ZoneArray",ZoneArraySource)
##        print("OrderAndReliabilityUnique[LastStep3Index]=",OrderAndReliabilityUnique[LastStep3Index])
##        Step3PixelsAndOrder = OrderAndReliability[(OrderAndReliability <= OrderAndReliabilityUnique[LastStep3Index]) & (ZoneArray == ZoneID)]   #THis is still not right, but let us test
##        Step3PixelsAndOrderUnique = np.unique(Step3PixelsAndOrder[~Step3PixelsAndOrder.mask])
##        print("Step3PixelsAndOrderUnique=",Step3PixelsAndOrderUnique)
##        PlotIDList = []
##        for m in Step3PixelsAndOrderUnique: 
##            print("m=",m)
##            OrderAndReliabilityUniqueListIndex = OrderAndReliabilityUniqueList.index(m)
##            print("OrderAndReliabilityUniqueListIndex=",OrderAndReliabilityUniqueListIndex)
##            if OrderAndReliabilityUniqueListIndex == 0:
##                NewZoneArray = YangDiBianMa
##                NewZoneArraySource = YangDiBianMaFile
##            else:
##                NewZoneArray = ZoneTifArrayAll[OrderAndReliabilityUniqueListIndex-1,:,:]
##                NewZoneArraySource = ZoneTif[OrderAndReliabilityUniqueListIndex-1]
##            print("For ",m, " the NewZoneArraySource is ",NewZoneArraySource)
##
##            Step2ZoneIDs = ZoneTifArrayAll[1,:,:][(OrderAndReliability <= OrderAndReliabilityUnique[1]) & (~NewZoneArray.mask) & (OrderAndReliability == OrderAndReliabilityUnique[OrderAndReliabilityUniqueListIndex-1])]
##            Step2ZoneIDs = Step2ZoneIDs[~Step2ZoneIDs.mask]
##            Step2ZoneIDsUnique = np.unique(Step2ZoneIDs)
##            print("Step2ZoneIDsUnique AAA =",Step2ZoneIDsUnique)
##            print("len(Step2ZoneIDsUnique) AAA =",len(Step2ZoneIDsUnique))
##
##
##
##
##            Step2ZoneIDsUnique = [x for x in Step2ZoneIDsUnique if x in Step2 ZoneWhereAtLeastOneElementIsNotMasked]
##            print("Step2ZoneIDsUnique BBB =",Step2ZoneIDsUnique)
##            print("len(Step2ZoneIDsUnique) BBB =",len(Step2ZoneIDsUnique))
##
##            
##            
##            t0 = time.time()
##            for k in range(0,len(Step2ZoneIDsUnique),1):   #Can we combine them together? Change to 1D and then [x for x in a if a in b]? or for i for j and if value in?
##                PlotID = YangDiBianMa[ZoneTifArrayAll[1,:,:] == k]
##                #print("It took \t" + str(int((time.time() - t0)))," seconds")
##                PlotID = ma.masked_values(PlotID, YangDiBianMaNodata)
##                PlotIDUnique = np.unique(PlotID).tolist()
##                PlotIDList = PlotIDList + PlotIDUnique
##                
##        PlotIDList = [x for x in PlotIDList if x is not None]
##        print(PlotIDList)
##        PlotIDListUnique = [i for n,i in enumerate(PlotIDList) if i not in PlotIDList[:n]]
##        AllPlotID = ",".join([str(int(k)) for k in PlotIDListUnique])
##        print("AllPlotID=",AllPlotID)
##
##exit()
##
##
##    

##
##def FindWhichFiaPlotsUsedForImputationAtTheSecificCoordinates(Xcoordinate,Ycoordinate):  #Note the Coordinates must in the same unit of the F3 projection
##    1) Giving coordinates (In ARCGIS, you can click and then copy coordinates)
##    get rows, cols = rasterio.transform.rowcol(src.transform, CoordinateX, CoordinateY)
##    In each run,
##      find the reliabilty to get the index
##      from the index, find the ZonelistImage text file
##      Get the ZoneID
##      From ZoneID, get the PlotID
##      Output text description or write to another database
##    Note when some day we need this, we can repeat for each pixel, thus for full image



def FindWhichPlotsFallenInTheGroup(mylock,Run,Tile,Management,Year,Metric):
    try:
        t0 = time.time()
        print("As of 20240426, I conclude that the processing time for [each pixel's imputation plot] is too long and thus not feasible, but we can do it for specific pixels, which is accomplished at s separate function called FindWhichPlotsUsedForSpecificPixelImputation")
        print("However, for each group, it is still meaningful to get the plot within the group; therefore this function is kept here for this purpose")         
        FinalTifname = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"CommonShare"+os.sep+"ZoneImputationValue.tif"
        ZoneImputationValueLookupCSV = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"CommonShare"+os.sep+"ZoneImputationValueLookup.csv"
        ZoneImputationPixelNumberTif = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"CommonShare"+os.sep+"ZoneImputationPixelNumber.tif"
        if not os.path.exists(FinalTifname):
            ProcessingPercentageAsOrderAndReliability = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"Results"+os.sep+"ProcessingPercentageAsOrderAndReliability.tif"
            ZoneTifList = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"CommonShare"+os.sep+Management+"_"+Year+"_"+Metric+"_ZoneTifList.txt"
            ZoneTifListFile = open(ZoneTifList,'r')
            Lines = ZoneTifListFile.readlines()  
            Lines = [i.replace('\n','') for i in Lines]
            print("The number of lines is ",len(Lines))
            Step = []
            StepSign = []
            ZoneTif = []
            PlotNumber = []

            YangDiBianMaFile = Lines[0].split("||")[3]
            ds2 = gdal.Open(YangDiBianMaFile, gdal.GA_ReadOnly)
            cols = ds2.RasterXSize
            rows = ds2.RasterYSize
            YangDiBianMa = ds2.GetRasterBand(1).ReadAsArray().astype(np.float64)
            YangDiBianMaNodata = ds2.GetRasterBand(1).GetNoDataValue()
            YangDiBianMa = ma.masked_values(YangDiBianMa, YangDiBianMaNodata)
            YangDiBianMaUnique = np.unique(YangDiBianMa)
            #print("YangDiBianMaUnique=",YangDiBianMaUnique)

            ZoneImputationValue = np.full(YangDiBianMa.shape, F3NoDataValue)
            ZoneImputationPixelNumber = np.full(YangDiBianMa.shape, F3NoDataValue) 
            print(ZoneImputationValue.shape)  
            ZoneImputationValueLookupCSVFile = open(ZoneImputationValueLookupCSV,'w')
            for Line in Lines:
                StepSignValue = Line.split("||")[0]
                StepSign.append(StepSignValue)
                StepValue = int(Line.split("||")[0].split("-")[0])
                Step.append(StepValue)
                ZoneTifName = Line.split("||")[1]
                ZoneTif.append(ZoneTifName)
                PlotNumberValue = Line.split("||")[-1]
                PlotNumber.append(PlotNumberValue)
            ZoneTifListFile.close()
            LastStep3Index = ''.join([str(k) for k in Step]).rindex('3')
            print("The index of the last step3 occurrence: ",LastStep3Index)
            
            ds = gdal.Open(ProcessingPercentageAsOrderAndReliability, gdal.GA_ReadOnly)
            OrderAndReliability = ds.GetRasterBand(1).ReadAsArray().astype(np.int32)
            OrderAndReliabilityNodata = ds.GetRasterBand(1).GetNoDataValue()
            OrderAndReliability = ma.masked_values(OrderAndReliability, OrderAndReliabilityNodata)         
            OrderAndReliabilityUnique = np.unique(OrderAndReliability)  #Get unique value
            OrderAndReliabilityUnique = OrderAndReliabilityUnique[~OrderAndReliabilityUnique.mask]
            print(OrderAndReliabilityUnique)
            print("The number of OrderAndReliabilityUnique is ",len(OrderAndReliabilityUnique))
            OrderAndReliabilityUnique.sort()
            OrderAndReliabilityUniqueList = OrderAndReliabilityUnique.tolist()

            TotalNumberOfValidZones = 0
            
            ZoneImputationValue[(~YangDiBianMa.mask)] = 10000000   #If it is YangDiBianMa pixel, we give a constant value of 10000000? or just write a special paragraph here
            
            for k in range(0,len(ZoneTif),1):
                print("ZoneTif[k]=",ZoneTif[k])
                ds1 = gdal.Open(ZoneTif[k], gdal.GA_ReadOnly)
                ZoneArrayAAA = ds1.GetRasterBand(1).ReadAsArray().astype(np.int32)  
                ZoneArrayAAANodata = ds1.GetRasterBand(1).GetNoDataValue()
                ZoneArrayAAA = ma.masked_values(ZoneArrayAAA, ZoneArrayAAANodata)
                ds1 = None
                print("ZoneArrayAAA.shape=",ZoneArrayAAA.shape)

                ValidZoneArray1 = ZoneArrayAAA[~ZoneArrayAAA.mask]     
                NumberOfZone1 = len(np.unique(ValidZoneArray1))
                print("NumberOfZone1=",NumberOfZone1)

                print("We need added a sentecne to take care of plots pixel directly. and we donot need for loop to save the time. Just directly apply and give a value of 100000000xxxxx")
                print("Does this also explained why step 4x has no plots in specific pixel function?")
                print("maybe caused by the half-pixel shift?")


                print(k,"OrderAndReliabilityUnique[k+1]=",OrderAndReliabilityUnique[k+1])
                #ValidZoneArray2 = ZoneArrayAAA[(~ZoneArrayAAA.mask) & (~OrderAndReliability.mask) & (OrderAndReliability == OrderAndReliabilityUnique[k+1])]  #20240429: it turns out (~OrderAndReliability.mask) is super important here.
                ValidZoneArray2 = ZoneArrayAAA[(~OrderAndReliability.mask) & (OrderAndReliability == OrderAndReliabilityUnique[k+1])] 

                ValidZoneArray2Unique = np.unique(ValidZoneArray2)
                ValidZoneArray2Unique = [x for x in ValidZoneArray2Unique if x is not None]
                ValidZoneArray2Unique.sort()
                print("ValidZoneArray2Unique=",ValidZoneArray2Unique)
                NumberOfZone2 = len(ValidZoneArray2Unique)
                 
                print("\n",datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),": ",ZoneTif[k],"'s OrderAndReliability is ",OrderAndReliabilityUnique[k+1]," with number of Valid Zone being ",NumberOfZone2,". It may take ",NumberOfZone2/60," minutes. Please be patient!")
                print("\n",datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),": ",ZoneTif[k],"'s OrderAndReliability is ",OrderAndReliabilityUnique[k+1]," with number of Valid Zone being ",NumberOfZone2,". It may take ",NumberOfZone2/60," minutes. Please be patient!", file=open(F3Log, 'a'))
                TotalNumberOfValidZones = TotalNumberOfValidZones + NumberOfZone2
                if TotalNumberOfValidZones >= 9999999:
                    print("TotalNumberOfValidZones=",TotalNumberOfValidZones," and it is greater than 1000000, which means we cannot get unique imputation zone, so please increase 1000000 to 10000000 in [ZoneImputationValueOutput =] sentence and rerun")
                    exit()
                pid = 0
                for p in ValidZoneArray2Unique:
                    pid = pid + 1
                    PlotIDListTotal = []
                    ZoneImputationValueOutput = 10000000 * (k + 2) + ValidZoneArray2Unique.index(p)
                    ZoneImputationValue[(~ZoneArrayAAA.mask) & (~OrderAndReliability.mask) & (OrderAndReliability == OrderAndReliabilityUnique[k+1]) & (ZoneArrayAAA == p)] = ZoneImputationValueOutput   #As of 20240416, we use 1000000 here

                    #This section detect which plots fallen within the specific group---start
                    PlotID = YangDiBianMa[(~YangDiBianMa.mask) & (~ZoneArrayAAA.mask) & (ZoneArrayAAA == p)]
                    
                    PlotID = ma.masked_values(PlotID, YangDiBianMaNodata)
                    PlotIDUnique = np.unique(PlotID).tolist()
                    PlotIDList = [x for x in PlotIDUnique if x is not None]
                    PlotIDListUnique = [int(i) for n,i in enumerate(PlotIDList) if i not in PlotIDList[:n]]
                    PlotJoinWithComma = ",".join([str(int(k)) for k in PlotIDListUnique])
                    NumberOfPlotsSelectedForThisZone = len(PlotIDListUnique)
                    LineContent = str(int(ZoneImputationValueOutput)) + ":" + PlotJoinWithComma + "\n"
                    ZoneImputationValueLookupCSVFile.write(LineContent)
                    #print(k,p,NumberOfPlotsSelectedForThisZone,LineContent)
                    #This section detect which plots fallen within the specific group---end
                        
                    ZoneImputationPixelNumber[(~ZoneArrayAAA.mask) & (~OrderAndReliability.mask) & (OrderAndReliability == OrderAndReliabilityUnique[k+1]) & (ZoneArrayAAA == p)] = NumberOfPlotsSelectedForThisZone
            print(ZoneImputationValueLookupCSV," actually took \t" + str(int((time.time() - t0)/60))," minutes")
            print(ZoneImputationValueLookupCSV," actually took \t" + str(int((time.time() - t0)/60))," minutes", file=open(F3Log, 'a'))
            ZoneImputationValueLookupCSVFile.close()
            SavedFinalTifname = Save2DArrayToTif(Run,Tile,Management,Year,Metric,ZoneImputationValue,FinalTifname)
            ZoneImputationPixelNumberTifname = Save2DArrayToTif(Run,Tile,Management,Year,Metric,ZoneImputationPixelNumber,ZoneImputationPixelNumberTif)
            return SavedFinalTifname,ZoneImputationValueLookupCSV,ZoneImputationPixelNumberTifname,
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"  
        #print(Content1)    
        Content2 = "The error was for FindWhichPlotsUsedForEachPixelIputation with inputs of "+repr(Run)+","+repr(Tile)+","+repr(Management)+","+repr(Year)+","+repr(Metric)+" with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog
     
        

def CreatePythonFileForOrganizingF3DataInArcProProject(F3ArcGISProjectCreation_NewFile):
    try:
        #This part will get the Header Part that defines the run, management, metric, and year etc., they will be used in ArcPro project---start
        CurrentPython = sys.argv[0]
        print("CurrentPython=",CurrentPython)
        CurrentPythonFile = open(CurrentPython,'r')
        Lines = CurrentPythonFile.readlines()  
        Lines = [i.replace('\n','') for i in Lines]
        LineID = -1
        for Line in Lines:
            LineID = LineID + 1
            if ((Line.startswith('ProjectName =')) or (Line.startswith('ProjectName='))):
                LineID_HeadStart = LineID
            if Line.startswith('F3Log = os.getcwd()+os.sep+"F3Log.txt"'):
                LineID_HeadEnd = LineID
        print("LineID_HeadStart,LineID_HeadEnd=",LineID_HeadStart,LineID_HeadEnd)
        HeaderContent = "\n".join(Lines[LineID_HeadStart:LineID_HeadEnd+1])
        print(HeaderContent)
        CurrentPythonFile.close()
        #This part will get the Header Part that defines the run, management, metric, and year etc., they will be used in ArcPro project---end

        with open(F3ArcGISProjectCreation_TemplateFile, 'r') as TemplateFile: #Open and read can store the entire file into a variable
            TemplateFileContent = TemplateFile.read()
        #print(TemplateFileContent)
        NewContent = TemplateFileContent.replace('###$$$F3HeadReplacement$$$',HeaderContent)

        with open(F3ArcGISProjectCreation_NewFile, 'w') as NewTemplateFile: #Open and read can store the entire file into a variable
            NewTemplateFile.write(NewContent)

        print("Note: You may need to change the arcpro python.exe path for your system. The F3ArcGISProjectCreation_NewFile is a python requiring ArcPy, which conflcits the idea of open-source, so it is special here")
        PythonRunArcProCommand = r'"C:\Program Files\ArcGIS\Pro\bin\Python\envs\arcgispro-py3\python.exe" ' + F3ArcGISProjectCreation_NewFile  #note the special command when there is a space in C:\Program Files
        print(PythonRunArcProCommand)
        os.system(PythonRunArcProCommand)
        F3ArcGISProjectCreation_NewFile_NewPlace = os.getcwd()+os.sep+"TilesMosaicRunAverage" + os.sep + ProjectName + os.sep + ProjectName + "_ArcProProjectCreation.py"
        if os.path.exists(F3ArcGISProjectCreation_NewFile_NewPlace):
            os.remove(F3ArcGISProjectCreation_NewFile_NewPlace)
        os.rename(F3ArcGISProjectCreation_NewFile,F3ArcGISProjectCreation_NewFile_NewPlace)
        return F3ArcGISProjectCreation_NewFile
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"  
        #print(Content1)    
        Content2 = "The error was for MosaicRemoteSensingWithGISshape with inputs of "+repr(F3ArcGISProjectCreation_NewFile)+" with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog




def MosaicRemoteSensingWithGISshape(mylock,Runs,Tiles, Management,Year,Metric):
    try:
        MosaicMeanOutputTifFile = os.getcwd() + os.sep + "TilesMosaicRunAverage" + os.sep + ProjectName+os.sep+"Img_"+str(Year)+"_RGB.tif"
        if not os.path.exists(MosaicMeanOutputTifFile):
            files_to_mosaic = []
            for Tile in Tiles:
                RGBFile = os.getcwd()+os.sep+"Run1"+os.sep+Tile+os.sep+"RSraster"+os.sep+"Img_"+str(Year)+"_RGB.tif"
                files_to_mosaic.append(RGBFile)
            print("files_to_mosaic=",files_to_mosaic)
            warp_options = gdal.WarpOptions(cutlineDSName=SpatialMosaicProjectBoundary, cropToCutline=False)  #20240312, change cropToCutline=True to cropToCutline=False; otherwise we have problem
            if len(files_to_mosaic) >= 1:
                g = gdal.Warp(MosaicMeanOutputTifFile, files_to_mosaic, format="GTiff", COMPRESS="LZW", TILED="YES",options=warp_options)
                g = None
                print(MosaicMeanOutputTifFile," was just created")
        return MosaicMeanOutputTifFile
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"  
        #print(Content1)    
        Content2 = "The error was for MosaicRemoteSensingWithGISshape with inputs of "+repr(Runs)+","+repr(Tile)+","+repr(Management)+","+repr(Year)+","+repr(Metric)+" with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog


def MosaicCropLayerTifFileWithGISshape(mylock,Runs,Tiles, Management,Year,Metric):
    try:
        MosaicMeanOutputTifFile = os.getcwd() + os.sep + "TilesMosaicRunAverage" + os.sep + ProjectName+os.sep+"USCropLayer20230101to20231231.tif"
        if not os.path.exists(MosaicMeanOutputTifFile):
            files_to_mosaic = []
            for Tile in Tiles:
                CropLayerFile = os.getcwd()+os.sep+"Run1"+os.sep+Tile+os.sep+"AdditionalDiscreteRaster"+os.sep+"USCropLayer20230101to20231231.tif"
                files_to_mosaic.append(CropLayerFile)
            print("files_to_mosaic=",files_to_mosaic)
            warp_options = gdal.WarpOptions(cutlineDSName=SpatialMosaicProjectBoundary, cropToCutline=False)  #20240312, change cropToCutline=True to cropToCutline=False; otherwise we have problem
            if len(files_to_mosaic) >= 1:
                g = gdal.Warp(MosaicMeanOutputTifFile, files_to_mosaic, format="GTiff", COMPRESS="LZW", TILED="YES",options=warp_options)
                g = None                               
        return MosaicMeanOutputTifFile
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"  
        #print(Content1)    
        Content2 = "The error was for MosaicCropLayerTifFileWithGISshape with inputs of "+repr(Runs)+","+repr(Tile)+","+repr(Management)+","+repr(Year)+","+repr(Metric)+" with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog



def MosaicForest1Nonforest0TifFileWithGISshape(mylock,Runs,Tiles, Management,Year,Metric):
    try:
        MosaicMeanOutputTifFile = os.getcwd() + os.sep + "TilesMosaicRunAverage" + os.sep + ProjectName+os.sep+"Forest1Nonforest0.tif"
        if not os.path.exists(MosaicMeanOutputTifFile):
            files_to_mosaic = []
            for Tile in Tiles:
                Forest1NonforestFile = os.getcwd()+os.sep+"Run1"+os.sep+Tile+os.sep+"AdditionalDiscreteRaster"+os.sep+"Forest1Nonforest0.tif"
                files_to_mosaic.append(Forest1NonforestFile)
            print("files_to_mosaic=",files_to_mosaic)
            warp_options = gdal.WarpOptions(cutlineDSName=SpatialMosaicProjectBoundary, cropToCutline=False)  #20240312, change cropToCutline=True to cropToCutline=False; otherwise we have problem
            if len(files_to_mosaic) >= 1:
                g = gdal.Warp(MosaicMeanOutputTifFile, files_to_mosaic, format="GTiff", COMPRESS="LZW", TILED="YES",options=warp_options)
                g = None                               
        return MosaicMeanOutputTifFile
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"  
        #print(Content1)    
        Content2 = "The error was for MosaicForest1Nonforest0TifFileWithGISshape with inputs of "+repr(Runs)+","+repr(Tile)+","+repr(Management)+","+repr(Year)+","+repr(Metric)+" with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog


def AddingRasterAttributeTableToForestTypeGeoTif(ForestTypeGeoTif):
    try:
        #Mosaic CDL for the mosaic extent
        #In ForestTypeGeoTif, replace nodata with CDL;
        #Using CDL value to assign the CDL land cover'
        Cropland = EverywherePath + os.sep + "USDA_NASS_Cropland_Data_Layers.xlsx"
        wb = openpyxl.load_workbook(Cropland)  # Load the workbook
        ws = wb['CropLayer'] #ws = wb.active is to Select the active worksheet, but here we select a specific worksheet. also 1) wb.sheetnames can get the worksheet names, 2) ws['A1'].value can get the cell value
        FieldLength = 0
        for cell in ws[1]:
            FieldLength = FieldLength + 1
            print("The field names are:", cell.value)
        CropValue = []
        CropClass = []
        rowid = 0
        for row in ws.iter_rows(min_row=2, values_only=True):  # Iterate through rows starting from the second row (i.e., ignore the first row which are field names
            rowid = rowid + 1
            CropValue.append(str(row[0]))
            CropClass.append(row[1])
        print(CropValue)
        print(CropClass)


        FVSINPUTDBWithForestTypeTableIncluded = r'F:\CUI\fhaastf3app\FIA\SQLite_FIADB_RI.db'
        print("https://gis.stackexchange.com/questions/40958/python-gdal-and-building-raster-attribute-tables")
        print("Please note FIADB database *.db has two tables REF_FOREST_TYPE and REF_FOREST_TYPE_GROUP. They provide the code and type")
        conn = sqlite3.connect(FVSINPUTDBWithForestTypeTableIncluded)  #https://www.sqlitetutorial.net/sqlite-python/
        
        cur= conn.cursor()
        cur.execute("SELECT * FROM REF_FOREST_TYPE_GROUP")  #Ask Marcus to give the table name consistently
        columns = [column[0] for column in cur.description]
        GRPVALUEIndex = columns.index("VALUE")
        GRPMEANINGIndex = columns.index("MEANING")   #In FVSINPUTDB (i.e.,FVS data in FIADB), the "SPECIES" refers to FIA species code
        GRProws = cur.fetchall()
        GRPValueList = []
        GRPMEANINGList = []
        GRProwid = 0
        for GRProw in GRProws:
            GRProwid = GRProwid + 1
            GRPValue = str(GRProw[GRPVALUEIndex])
            GRPValueList.append(GRPValue)
            GRPMEANING = str(GRProw[GRPMEANINGIndex])
            GRPMEANINGList.append(GRPMEANING)
        
        cur.execute("SELECT * FROM REF_FOREST_TYPE")  #Ask Marcus to give the table name consistently
        columns = [column[0] for column in cur.description]
        VALUEIndex = columns.index("VALUE")
        MEANINGIndex = columns.index("MEANING")   #In FVSINPUTDB (i.e.,FVS data in FIADB), the "SPECIES" refers to FIA species code
        TYPGRPCDIndex = columns.index("TYPGRPCD")   #In FVSINPUTDB (i.e.,FVS data in FIADB), the "SPECIES" refers to FIA species code
        rows = cur.fetchall()

        ValueList = []
        MEANINGList = []
        TYPGRPCDList = []
        TYPGRPNameList = []
        rowid = 0
        for row in rows:
            rowid = rowid + 1
            Value = str(row[VALUEIndex])
            ValueList.append(Value)
            MEANING = str(row[MEANINGIndex])
            MEANINGList.append(MEANING)
            TYPGRPCD = str(row[TYPGRPCDIndex])
            TYPGRPCDList.append(TYPGRPCD)
            for k in range(0,len(GRPValueList),1):
                if GRPValueList[k] == TYPGRPCD:
                    TYPGRPName = GRPMEANINGList[k]
            TYPGRPNameList.append(TYPGRPName)
            
        ds = gdal.Open(ForestTypeGeoTif, gdal.GA_Update)
        rat = gdal.RasterAttributeTable()
        data = ds.GetRasterBand(1).ReadAsArray()
        vals = list(np.unique(data))  #Get unique value
        rat.CreateColumn('VALUE', gdal.GFT_String, gdal.GFU_Generic)
        rat.CreateColumn('COUNT', gdal.GFT_Integer, gdal.GFU_Generic)
        rat.CreateColumn('FORTYP', gdal.GFT_String, gdal.GFU_Generic)
        rat.CreateColumn('GROUPID', gdal.GFT_String, gdal.GFU_Generic)
        rat.CreateColumn('GRPTYPE', gdal.GFT_String, gdal.GFU_Generic)
        for i in range(0,len(vals),1):
            Value = str(vals[i])
            print("\n\n")
            print("Value=",Value)
            Count = len(data[data == int(Value)])
            Found = "No"
            for j in range(0,len(ValueList),1):
                if int(float(ValueList[j]) * FloatToIntegerCoefficient) == int(Value):  #if ValueList[j] == Value is changed to include the FloatToIntegerCoefficient
                    FORTY_Code = int(ValueList[j])
                    FORTY_Des = MEANINGList[j]
                    TYPGRPCD_Des = TYPGRPCDList[j]
                    TYPGRPName_Des = TYPGRPNameList[j]
                    Found = "Yes"
            if Found == "Yes":
                FORTYPDescription = Value + ": " + FORTY_Des
                GROUPIDDescription = str(int(int(TYPGRPCD_Des) * FloatToIntegerCoefficient))
                GRPTYPEDescription = GROUPIDDescription + ": " + TYPGRPName_Des
            else:    #This indicates the nonforest area, whose land cover will come from US crop layer
                if Value in CropValue:
                    ValueIndex = CropValue.index(Value)
                    print(Value, ValueIndex, " is here")
                    FORTYPDescription = Value + ": " + "USDA crop class of " + CropClass[ValueIndex]
                    GROUPIDDescription = "USDA Cropland Data Layer"
                    GRPTYPEDescription = "USDA Cropland Data Layer"                  
                elif Value == str(F3NoDataValue):
                    FORTYPDescription = str(F3NoDataValue) + ": " + "Void Area"
                    GROUPIDDescription = "Void Area"
                    GRPTYPEDescription = "Void Area"                  
                else:
                    print(Value, " is nothing")
                    FORTYPDescription = Value + ": " + "Not Found from FVS and CropLayer, weird"
                    GROUPIDDescription = "NotFound"
                    GRPTYPEDescription = "NotFound"
            ###"20240517, I found FORTYPE=997 is not included in REF_FOREST_TYPE. This is weird. I do not know why. We have to ask FVS group for the clarification
            #print(Value)
            #print(Count)
            print(FORTYPDescription)
            print(GROUPIDDescription)
            print(GRPTYPEDescription)
            rat.SetValueAsString(i, 0, Value)   #Note the second argument is the column ID matching the field definition
            rat.SetValueAsInt(i, 1, Count)
            rat.SetValueAsString(i, 2, FORTYPDescription)
            rat.SetValueAsString(i, 3, GROUPIDDescription)
            rat.SetValueAsString(i, 4, GRPTYPEDescription)
        print("Attach the RAT to the raster band")
        rb = ds.GetRasterBand(1)
        rb.SetDefaultRAT(rat)
        print("Close the dataset")
        ds = None
        ForestTypeGeoTifMessage = ForestTypeGeoTif + " now has an attribute table added!"

        #20240521, I decided to add a csv file describing the forest type with information from FVS and from USDA crop layer---start
        ForestTypeClass = os.getcwd() + os.sep + "TilesMosaicRunAverage" + os.sep + ProjectName + os.sep + "ForestAndCropType.csv"
        with open(ForestTypeClass, 'w') as ForestTypeClassFile: #Open and read can store the entire file into a variable
            ForestTypeClassFile.write("### 1) Dr. Shengli Huang created this CSV file at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n")
            ForestTypeClassFile.write("### 2) For those areas of crop the value and meaning comes from USDA crop class at https://developers.google.com/earth-engine/datasets/catalog/USDA_NASS_CDL#bands" + "\n")
            ForestTypeClassFile.write("### 3) For those areas of forest the value and meaning comes from the associated FVS_ForestType_Code.pdf or Appendix B of FVS essential manual (but note the original value is multiplied by "+str(FloatToIntegerCoefficient)+")" + "\n")
            ForestTypeClassFile.write("### 4) Please be aware that the SIMPLE forested areas in USDA Crop Data Layer are replaced by the DETAILED F3 forest type in this product. Users are encouraged to explore other F3 data layers (e.g. species distribution and basal area and QMD etc)" + "\n")

            ForestTypeClassFile.write("\n\n")
            ForestTypeClassFile.write("Below from USDA crop layer: \n")
            for k in range(0,len(CropValue),1):
                Line = CropValue[k] + ": " + CropClass[k] + "\n"
                ForestTypeClassFile.write(Line)
            ForestTypeClassFile.write("\n\n")
            ForestTypeClassFile.write("Below from FVS forest type: \n")
            for k in range(0,len(ValueList),1):
                Line = str(int(int(ValueList[k]) * FloatToIntegerCoefficient)) + ": " + MEANINGList[k] + "\n"
                ForestTypeClassFile.write(Line)
        #20240521, I decided to add a csv file describing the forest type with information from FVS and from USDA crop layer---end
        return ForestTypeGeoTifMessage
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"  
        #print(Content1)    
        Content2 = "The error was for AddingRasterAttributeTableToForestTypeGeoTif with inputs of "+repr(ForestTypeGeoTif)+repr(FVSINPUTDBWithForestTypeTableIncluded)+" with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog



def AddingRasterAttributeTableToPixelLabelGeoTif(PixelLabelGeoTif):
    try:
        print("https://gis.stackexchange.com/questions/40958/python-gdal-and-building-raster-attribute-tables")
        print("Open your existing GeoTIFF raster")
        #PixelLabelGeoTif = r'F:\CUI\fhaastf3app\RemoteSensingYear2023\TilesMosaicRunAverage\F3Michigan\MosaicPixelLabel.tif'
        ds = gdal.Open(PixelLabelGeoTif, gdal.GA_Update)
        print("Create a new RAT")
        rat = gdal.RasterAttributeTable()
        print("Assuming 'arr' is the Numpy array with raster data")
        data = ds.GetRasterBand(1).ReadAsArray()
        vals = list(np.unique(data))  #Get unique value
        #print("vals=",vals)
        print("Add columnnps (e.g., 'VALUE' and 'COUNT')")
        rat.CreateColumn('VALUE', gdal.GFT_Integer, gdal.GFU_Generic)
        rat.CreateColumn('COUNT', gdal.GFT_Integer, gdal.GFU_Generic)
        rat.CreateColumn('LABEL', gdal.GFT_String, gdal.GFU_Generic)
        #water is 1, Perennial/permanent Ice/Snow is 2, Barren-Rock/Sand/Clay is 3, Landsat cloud/shadow/snow is 4, no remote sensing collection is 5, unmapped area is 6, nonforested area is 99, and the remaining area is 0"
        for i in range(len(vals)):
            Value = int(vals[i])
            Count = len(data[data==Value])
            if Value == -9999:
                LabelDescription = "Outside AOI"
            if Value == 0:
                LabelDescription = "Good imputation"
            if Value == 1:
                LabelDescription = "Water"
            if Value == 2:
                LabelDescription = "Perennial/permanent Ice/Snow"
            if Value == 3:
                LabelDescription = "Barren-Rock/Sand/Clay"
            if Value == 4:
                LabelDescription = "Landsat cloud/shadow/snow"
            if Value == 5:
                LabelDescription = "No remote sensing collection"
            if Value == 6:
                LabelDescription = "Unmapped area"
            if Value == 99:
                LabelDescription = "Nonforested area"
            LabelDescription = str(Value) + ": " + LabelDescription
            rat.SetValueAsInt(i, 0, Value)   #Note the second argument is the column ID matching the field definition
            rat.SetValueAsInt(i, 1, Count)
            rat.SetValueAsString(i, 2, LabelDescription)
        print("Attach the RAT to the raster band")
        rb = ds.GetRasterBand(1)
        rb.SetDefaultRAT(rat)
        print("Close the dataset")
        ds = None
        PixelLabelGeoTifMessage = PixelLabelGeoTif + " now has an attribute table added!"
        return PixelLabelGeoTifMessage
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"  
        #print(Content1)    
        Content2 = "The error was for AddingRasterAttributeTableToPixelLabelGeoTif with inputs of "+repr(PixelLabelGeoTif)+" with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog

    
def UsingShapeFileToClipRaster(ShapeFile, SourceRaster, ClipedRasterOutput):
    try:
        if not os.path.exists(ClipedRasterOutput):
            ClipedRasterOutputTemp = ClipedRasterOutput.replace(".tif","Temp.tif")
            SourceR = gdal.Open(SourceRaster, gdal.GA_ReadOnly)
            SourceRasterTrasnform = SourceR.GetGeoTransform()
            SourceRasterProjection = osr.SpatialReference() #I know SourceRasterProjection has the same projection of other raster data
            SourceRasterProjection.ImportFromWkt(SourceR.GetProjection())  #it is not GetProjectionRef() but GetProjection()
            print("SourceRasterProjection is: ",SourceRasterProjection)
            
            inDriver = ogr.GetDriverByName("ESRI Shapefile")
            shapefile_ds = inDriver.Open(ShapeFile)
            inLayer1 = shapefile_ds.GetLayer()
            for feature in inLayer1:
                print("The tile ",feature.GetField('TileName'), " has the centroid coordinates of ", feature.GetGeometryRef().Centroid().ExportToWkt())
                geom=feature.GetGeometryRef()
                env = geom.GetEnvelope()  # Get Envelope returns a tuple (minX, maxX, minY, maxY), see https://pcjericks.github.io/py-gdalogr-cookbook/geometry.html
                print("env is: ",env)
                print("minX: %d, minY: %d, maxX: %d, maxY: %d" %(env[0],env[2],env[1],env[3]))
                minX = env[0]
                minY = env[2]
                maxX = env[1]
                maxY = env[3]
            OutFile = gdal.Warp(ClipedRasterOutputTemp, SourceRaster, format='GTiff', cutlineDSName=ShapeFile, cropToCutline=True, outputBounds=[minX, minY, maxX, maxY], xRes=F3Resolution, yRes=F3Resolution, dstSRS=SourceRasterProjection, resampleAlg=gdal.GRA_NearestNeighbour)
            shapefile_ds = None
            OutFile = None # Close dataset

            #20240314: gdal.Warp above is good for mosaic, but cannot handle nodata well, this is why I added this section to improve it----start
            driverTiff = gdal.GetDriverByName('GTiff')
            ds = gdal.Open(ClipedRasterOutputTemp)
            cols = ds.RasterXSize
            rows = ds.RasterYSize
            WeUseThisProjection = ds.GetProjectionRef()
            WeUseThisGeoTransform = ds.GetGeoTransform()
            print(WeUseThisGeoTransform)
            DataArray = ds.GetRasterBand(1).ReadAsArray().astype(np.int32)
            DataArrayNodata = ds.GetRasterBand(1).GetNoDataValue()
            DataArray = ma.masked_values(DataArray, DataArrayNodata)

            driver = gdal.GetDriverByName("GTiff")
            OutputGeoTifCompression = "Yes"
            if OutputGeoTifCompression == "Yes": #Added on 20230227. LZW compression does not lose information. LZW compression is a lossless data compression algorithm, which means that the original data can be fully reconstructed from the compressed data without any loss of information.
                outdata = driver.Create(ClipedRasterOutput, cols, rows, 1, gdal.GDT_Int32, options=['COMPRESS=LZW'])   #see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
            if OutputGeoTifCompression == "No": 
                outdata = driver.Create(ClipedRasterOutput, cols, rows, 1, gdal.GDT_Int32)   #see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
            outdata.SetGeoTransform(WeUseThisGeoTransform)  ##sets same geotransform as input
            outdata.SetProjection(WeUseThisProjection)  ##sets same projection as input
            outdata.GetRasterBand(1).WriteArray(DataArray)
            outdata.GetRasterBand(1).SetNoDataValue(F3NoDataValue)  
            outdata.FlushCache() ##saves to disk!!
            outdata = None
            
            
            print("20240319: I tihnk the file is not closed after gdal.Open(ClipedRasterOutputTemp), which is why I cannot delete it with os.remove(). This is why I add ds = None below")
            ds = None  #20240320. It is important to use this to close the file, otherwise we have permission problem. Another approach may be ds.Close(). I did not test it
            time.sleep(60)  #20240319: ClipedRasterOutputTemp is deleted right after ClipedRasterOutput is created, thus we may have the error ["PermissionError: [WinError 32] The process cannot access the file because it is being used by another process], so I added a wait before this sentence
            os.remove(ClipedRasterOutputTemp)  #20240319: ClipedRasterOutputTemp is deleted right after ClipedRasterOutput is created, thus we may have the error ["PermissionError: [WinError 32] The process cannot access the file because it is being used by another process], so I added a wait before this sentence
            #20240314: gdal.Warp above is good for mosaic, but cannot handle nodata well, this is why I added this section to improve it----end

        return ClipedRasterOutput
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"  
        #print(Content1)    
        Content2 = "The error was for UsingShapeFileToClipRaster with inputs of "+repr(ShapeFile)+","+repr(SourceRaster)+","+repr(ClipedRasterOutput)+" with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog

    

def SelectF3TilesFromProjectBoundary(fhaastf3tilesShape,ProjectBoundary):
    try:
        inDriver = ogr.GetDriverByName("ESRI Shapefile")
        polygon_ds = inDriver.Open(fhaastf3tilesShape)
        polygon_layer = polygon_ds.GetLayer()
        polygon_field_names = [field.name for field in polygon_layer.schema]
        print("polygon_field_names=",polygon_field_names)

        inDriver1 = ogr.GetDriverByName("ESRI Shapefile")
        polygon_ds1 = inDriver.Open(ProjectBoundary)
        polygon_layer1 = polygon_ds1.GetLayer()
        polygon_field_names1 = [field.name for field in polygon_layer1.schema]
        print("polygon_field_names1=",polygon_field_names1)

        TileNames = []
        for polygon_feature in polygon_layer:
            polygon_geometry = polygon_feature.GetGeometryRef()  #This returns the geometry from the polygon, see spatial geometry and spatialfilter at https://pcjericks.github.io/py-gdalogr-cookbook/layers.html#spatial-filter
            for polygon_feature1 in polygon_layer1:
                polygon_geometry1 = polygon_feature1.GetGeometryRef()
                IntersectStatus = polygon_geometry.Intersection(polygon_geometry1)  #Intersection will return a <class 'osgeo.ogr.Geometry'>, so I have to convert it to string
                if str(IntersectStatus) != "POLYGON EMPTY":  #str() has to be added here
                   #print(polygon_feature.GetField("TileName"), " and ",polygon_feature1.GetField("COUNTYFP") , " has overlap area")
                   TileName = polygon_feature.GetField("TileName")
                   TileNames.append(TileName)
        TileNamesUnique = [i.lower() for n,i in enumerate(TileNames) if i not in TileNames[:n]]
        print("TileNamesUnique=",TileNamesUnique)
        return TileNamesUnique
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"  
        #print(Content1)    
        Content2 = "The error was for SelectF3TilesFromProjectBoundary with inputs of "+repr(fhaastf3tilesShape)+","+repr(ProjectBoundary)+" with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog


def SpatiallyMosaicMultiplePointGisShapeFiles(Tiles,Management,Year,Metric,ProjectName):
    try:
        MergedOutPutShape = os.getcwd() + os.sep + "TilesMosaicRunAverage" + os.sep + ProjectName + os.sep + "FiaFvsPointGIS" + os.sep + FieldPointHeader+Management+"_"+Year+"_"+Metric+".shp"
        if not os.path.exists(MergedOutPutShape):
            PointGisShapeFilesList = []
            for Tile in Tiles:
                shapeDataFile = os.getcwd()+os.sep+"Run1"+os.sep+Tile+os.sep+"FieldPoint"+os.sep+FieldPointHeader+Management+"_"+Year+"_"+Metric+".shp"
                if os.path.exists(shapeDataFile):
                    PointGisShapeFilesList.append(shapeDataFile)
            print("PointGisShapeFilesList=",PointGisShapeFilesList)
            if len(PointGisShapeFilesList) > 0:  #added on 20240531 to exclude invalid metric (e.g., NC)
                gpdList = []
                for PointGisShapeFile in PointGisShapeFilesList:
                    PointGisShapeFileGPD = gpd.read_file(PointGisShapeFile)
                    gpdList.append(PointGisShapeFileGPD)
                MergedGPD = gpd.pd.concat(gpdList)
                MergedGPD.to_file(MergedOutPutShape)
                print("MergedOutPutShape was merged from ",PointGisShapeFilesList)
        return MergedOutPutShape
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"  
        #print(Content1)    
        Content2 = "The error was for SpatiallyMosaicMultiplePointGisShapeFiles with inputs of "+repr(Tiles)+","+repr(Management)+"," + repr(Year)+","+repr(Metric)+","+repr(ProjectName)+" with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog


def TileRunBorderZshape(mylock,Run,Tile,Management,Year,Metric):  #Note Runs and Tiles, it is not Run and Tile
    try:
        print("Chicken Run,Tile=",Run,Tile,Metric, file=open(F3Log, 'a'))
        Step4OutputTif = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"Results"+os.sep+Management+"_"+Year+"_"+Metric+".tif"
        if Metric == "ProcessingPercentageAsOrderAndReliability":
            Step4OutputTif = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"Results"+os.sep+"ProcessingPercentageAsOrderAndReliability.tif"
        print("Step4OutputTif=",Step4OutputTif, file=open(F3Log, 'a'))
        if Run == "Run1":
            CorrespondingSegmentation = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R1_Y"+BaseYear+"_L1_S40_C18.tif"  #We haev different level segmentation, you can choose another one
        if Run == "Run2":
            CorrespondingSegmentation = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R2_Y"+BaseYear+"_L1_S32_C19.tif"
        if Run == "Run3":
            CorrespondingSegmentation = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R3_Y"+BaseYear+"_L1_S48_C17.tif"
        if Run == "Run4":
            CorrespondingSegmentation = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R3_Y"+BaseYear+"_L1_S48_C17.tif"  #We haev different level segmentation, you can choose another one
        if Run == "Run5":
            CorrespondingSegmentation = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R1_Y"+BaseYear+"_L1_S40_C18.tif"
        if Run == "Run6":
            CorrespondingSegmentation = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R2_Y"+BaseYear+"_L1_S32_C19.tif"     
        if os.path.exists(Step4OutputTif):
            print("Step4OutputTif=",Step4OutputTif, " exists ", file=open(F3Log, 'a'))
            Step4OutputTifBorderZshapeTif = MosaicingBorderZshape(CorrespondingSegmentation,Step4OutputTif,0.03,FloatToIntegerCoefficient)
        else:
            Step4OutputTifBorderZshapeTif = "NotAvailabe"
            print("20240214: It is understandable that the ",Step4OutputTif," does not exists (e.g., species absense), so we do not have to return here", file=open(F3Log, 'a'))
        print("Step4OutputTifBorderZshapeTif=",Step4OutputTifBorderZshapeTif)
        print("Step4OutputTifBorderZshapeTif=",Step4OutputTifBorderZshapeTif, file=open(F3Log, 'a'))
        return Step4OutputTifBorderZshapeTif
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"  
        #print(Content1)    
        Content2 = "The error was for TileRunBorderZshape with inputs of "+repr(Run)+","+repr(Tile)+","+repr(Management)+","+repr(Year)+","+","+repr(Metric)+" with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog






def MosaicMeandAndSTDWithinProjectBoundary(mylock,Runs,Tiles,Management,Year,Metric, ProjectAOI):
    try:
        MosaicMeanOutputTifFile = os.getcwd() + os.sep + "TilesMosaicRunAverage" + os.sep + ProjectName+os.sep+Management+"_"+Year+"_"+Metric+"_Mean.tif"
        MosaicMeanOutputTifFile1 = os.getcwd() + os.sep + "TilesMosaicRunAverage" + os.sep + ProjectName+os.sep+Management+"_"+Year+"_"+Metric+"_Std.tif"
        if not os.path.exists(MosaicMeanOutputTifFile):
            files_to_mosaic = []
            files_to_mosaic1 = []
            for Tile in Tiles:
                TileRunsMetricMeanTifFile = os.getcwd()+os.sep+"RunAverageZshape"+os.sep+Tile+os.sep+Management+"_"+Year+"_"+Metric+"_Mean.tif"
                files_to_mosaic.append(TileRunsMetricMeanTifFile)
                TileRunsMetricMeanTifFile1 = os.getcwd()+os.sep+"RunAverageZshape"+os.sep+Tile+os.sep+Management+"_"+Year+"_"+Metric+"_Std.tif"
                files_to_mosaic1.append(TileRunsMetricMeanTifFile1) 
            print("files_to_mosaic=",files_to_mosaic, " for ",Management,Year,Metric)
            warp_options = gdal.WarpOptions(cutlineDSName=ProjectAOI, cropToCutline=True)
            g = gdal.Warp(MosaicMeanOutputTifFile, files_to_mosaic, format="GTiff", COMPRESS="LZW", TILED="YES",options=warp_options)
            g = None
            AlsoMosaicSTD = "Yes"
            if AlsoMosaicSTD == "Yes":
                g1 = gdal.Warp(MosaicMeanOutputTifFile1, files_to_mosaic1, format="GTiff", COMPRESS="LZW", TILED="YES",options=warp_options)
                g1 = None
            return MosaicMeanOutputTifFile, MosaicMeanOutputTifFile1
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"  
        #print(Content1)    
        Content2 = "The error was for MosaicMeandAndSTDWithinProjectBoundary with inputs of "+repr(Runs)+","+repr(Tiles)+","+repr(Management)+","+repr(Year)+","+repr(Metric)+","+repr(ProjectAOI)+" with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog



def ProcessSetPriority():  #As of 20240130 not used. You can check the old F3 on how to use this function
    try:
        # On June 11, 2018, Carlos and Marcus requested setting multiprocess priority, here is some info
        # 1) Check https://stackoverflow.com/questions/23060383/lowering-process-priority-of-multiprocessing-pool-on-windows and https://www.jianshu.com/p/64e265f663f6 for multiprocess priority setting
        # 2) we can use as_dict(attrs=None, ad_value=None) to get the process info, then use if to select [python[ from a [specific user (e.g., shenglihuang], and then use [nice or GetProrityClass&SetPriorityClass] to set priority  
        # 3) But we need psutil library to implement it. In a cmd window or powershell: we can do > C:\Python27\ArcGISx6410.4\python.exe -m pip install psutil (where the python.exe is the version you want to install to.) to install it.
        # 4) Kirk wrote on June 11, 2018: it may be a good idea to set arcpy.env.parallelProcessingFactor (IN the function being sent to the pool) conservatively, perhaps 2.
     
        ###Set priority according to CPUusage. Added on June 12, 2018---start
        UserFavoritePriority = "AllAreNormal"  #Full options are "AllBelowNormal", "AllAreNormal", "AllAboveNormal", "AllFlexibleNormal". #Added on 20211102: Because GCP test has "freeze" problem, we change "AllAboveNormal" to "AllFlexibleNormal"
        CPUusedPercentage = psutil.cpu_percent(interval=1, percpu=False)
        print("CPUusedPercentage = ", CPUusedPercentage)
        if UserFavoritePriority == "AllBelowNormal":
            MyMultiprocessingPriorityIndex = 4 
        if UserFavoritePriority == "AllAreNormal":
            MyMultiprocessingPriorityIndex = 3 
        if UserFavoritePriority == "AllAboveNormal":
            MyMultiprocessingPriorityIndex = 2 
        if UserFavoritePriority == "AllFlexibleNormal":
            if CPUusedPercentage <= 20.0:
                MyMultiprocessingPriorityIndex = 1  #1 is High
            elif CPUusedPercentage <= 30.0:
                MyMultiprocessingPriorityIndex = 2  #2 is AboveNormal
            elif CPUusedPercentage <= 50.0:
                MyMultiprocessingPriorityIndex = 3  #3 is Normal
            else: 
                MyMultiprocessingPriorityIndex = 4  #4 is BelowNormal
        print("MyMultiprocessingPriorityIndex = ", MyMultiprocessingPriorityIndex)
        print(MyMultiprocessingPriority)
        print("MyMultiprocessingPriority[MyMultiprocessingPriorityIndex] is ", MyMultiprocessingPriority[MyMultiprocessingPriorityIndex])
        p = psutil.Process()
        p.nice(MyMultiprocessingPriority[MyMultiprocessingPriorityIndex])
        ###Set priority according to CPUusage. Added on June 12, 2018---end
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"  
        #print(Content1)    
        Content2 = "The error was for ProcessSetPriority with inputs of NONE with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog

    
def UserDefinedRatioCalculation():  #As of 20240130, this function has not been used but will be used
    try:
        TimesOfActualmemory = 15.0   #The actual memeory for each Tif is about 15 times. This value was calculated by Dr. Huang and can be changed in the future
        SingleTifImageMaxSizeAmongTiles = 0
        for myarea in AllImputationArea:
            LandsatRGBtif = Directoryofthiscode + myarea + os.sep + "RSraster" + os.sep + "Landsat8_"+WeightingFixForAllYear.split(":")[1]+"_RGB.tif"
            LandsatRGBtifSize = os.path.getsize(LandsatRGBtif) / 3.0  #getsize() returns the size of specified path in bytes. Here we divided by 3 because RGB tif has three bands
            print("LandsatRGBtifSize=",LandsatRGBtifSize)
            if LandsatRGBtifSize > SingleTifImageMaxSizeAmongTiles:
               SingleTifImageMaxSizeAmongTiles =  LandsatRGBtifSize
        print("SingleTifImageMaxSizeAmongTiles=",SingleTifImageMaxSizeAmongTiles)
        SingleTifImageSizeAmongTiles = SingleTifImageMaxSizeAmongTiles #SingleTifImageMaxSizeAmongTiles in bytes 
        NumberOfProcessorsOfThisComputer = int(os.cpu_count())  #20220115 used
        virtual_memory_available = psutil.virtual_memory().available   #in bytes
        RequiredMemory = SingleTifImageSizeAmongTiles * len(Years) * len(SelectedFieldMetric) * TimesOfActualmemory
        RequiredMemoryRatio = RequiredMemory / virtual_memory_available
        print("virtual_memory_available = ",virtual_memory_available," bytes")
        print("RequiredMemory in idea condition = ",RequiredMemory," bytes")
        print("RequiredMemoryRatio = RequiredMemory/virtual_memory_available = ",RequiredMemoryRatio)
        ActualRatioDesired = virtual_memory_available / (NumberOfProcessorsOfThisComputer * SingleTifImageSizeAmongTiles * TimesOfActualmemory)
        print("ActualRatioDesired=",ActualRatioDesired," but please note it can not be greater than 1.0")
        UserDefinedRatioValue = min(0.99,ActualRatioDesired)
        return UserDefinedRatioValue
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"  
        #print(Content1)    
        Content2 = "The error was for UserDefinedRatioCalculation with inputs of None with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog


def CopyFieldSqliteFromPathToEachRunAndTile(Runs,Managements,Tiles,Years, FieldPointHeader):  #20240126 added to avoid manual copy the FieldSqliteDB
    try:
        print("Let us create folders for F3")
        TilesMosaicRunAveragePath = os.getcwd() + os.sep + "TilesMosaicRunAverage"
        if not os.path.exists(TilesMosaicRunAveragePath):
            os.mkdir(TilesMosaicRunAveragePath)
            print(TilesMosaicRunAveragePath," created")
        ProjectNamePath = os.getcwd() + os.sep + "TilesMosaicRunAverage" + os.sep + ProjectName
        if not os.path.exists(ProjectNamePath):
            os.mkdir(ProjectNamePath)
            print(ProjectNamePath," created")
        ProjectNameGisPath = os.getcwd() + os.sep + "TilesMosaicRunAverage" + os.sep + ProjectName + os.sep + "FiaFvsPointGIS"
        if not os.path.exists(ProjectNameGisPath):
            os.mkdir(ProjectNameGisPath)
            print(ProjectNamePath," created")
        RunAverageZshapePath = os.getcwd() + os.sep + "RunAverageZshape"
        if not os.path.exists(RunAverageZshapePath):
            os.mkdir(RunAverageZshapePath)
            print(RunAverageZshapePath," created")
        for Tile in Tiles:
            RunAverageZshapeTile = RunAverageZshapePath + os.sep + Tile
            if not os.path.exists(RunAverageZshapeTile):
                os.mkdir(RunAverageZshapeTile)
                print(RunAverageZshapeTile," created")
        for Run in Runs:
            if ((Run == "Run1") or (Run == "Run2") or (Run == "Run3")):   # do not want to copy Run4, Run5, and Run6
                for Tile in Tiles:
                    for Management in Managements:
                        for Year in Years:     
                            SourceFieldSqlitDB = FieldSqlitePath + os.sep + Tile + os.sep + FieldPointHeader + Management + "_" + str(Year) + ".db"
                            TargetFieldSqlitDB = os.getcwd() + os.sep + Run + os.sep + Tile + os.sep + "FieldPoint" + os.sep + FieldPointHeader + Management + "_" + str(Year) + ".db"
                            if os.path.exists(SourceFieldSqlitDB):
                                if not os.path.exists(TargetFieldSqlitDB):
                                    shutil.copy(SourceFieldSqlitDB, TargetFieldSqlitDB)
                                    print(SourceFieldSqlitDB, " was copied to ",TargetFieldSqlitDB)
                                    IgnoreMetric = TargetFieldSqlitDB.replace(".db","_IgnoredMetric.txt")  #Added on 20240131 to create this txt file forst to avoid permission conflict during parallel run
                                    IgnoreMetricFile = open(IgnoreMetric, 'w') 
                                    ThisLine = "ShengliHuangIsAFakeMetric:Ignored" + "\n"
                                    IgnoreMetricFile.write(ThisLine)
                                    IgnoreMetricFile.close()
        return "SourceFieldSqlitDB copied"
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"  
        #print(Content1)    
        Content2 = "The error was for CopyFieldSqliteFromPathToEachRunAndTile with inputs of " + repr(Runs)+","+ repr(Managements)+","+ repr(Tiles)+","+ repr(Years)+","+ repr(FieldPointHeader)+" with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog


def PlotIDandXandY(ShengliHuangKeyFile,Factor):
    try:
        ShengliHuangKey = open(ShengliHuangKeyFile, "rb")
        MyBinaryLine = ShengliHuangKey.readlines()  #readline only read one line
        MyBinaryLine = [i.decode().replace('\n','') for i in MyBinaryLine]  #We had error [A bytes-like object is required, not 'str'], so We must use decode() here, see https://stackoverflow.com/questions/50829364/cannot-split-a-bytes-like-object-is-required-not-str
        plotlist = []
        xlist = []
        ylist = []
        for line in MyBinaryLine:
            if line.startswith('###'):
                if "The states Code (from FVS) spatially covered" in line:
                    StatesCodeInThisHSL = line.split(" include ")[1].split(",")  #Noth this sentence with the word [ include ] is very important
                if "The states full name spatially covered" in line:
                    StatesFullNameInThisHSL = line.split(" include ")[1].split(",")  #Noth this sentence with the word [ include ] is very important
                if "The states short name spatially covered" in line:
                    StatesShortNameInThisHSL = line.split(" include ")[1].split(",")  #Noth this sentence with the word [ include ] is very important
                if "FVS easter variants (CS, LS, NE, SN) and western variants (AK, BM, CA, CI, CR, EC, EM, IE, KT, NC, OC, OP, PN, SO, TT, UT, WC, WS) have" in line:
                    SpeciesTranslatorInThisHSL = line.split("This tile uses ")[1]  #Noth this sentence with the word [This tile uses ] is very important
            if not line.startswith('###'):  #[###] was added in the file on 20240202
                plot = round(float(line.split(",")[0]) / float(Factor))  #20230509: change int() to round(). e.g. round(2.999)=3 while int(2.999)=2
                x = float(line.split(",")[1]) / float(Factor)
                y = float(line.split(",")[2]) / float(Factor)
                plotlist.append(plot)
                xlist.append(x)
                ylist.append(y)
        ShengliHuangKey.close()
        return plotlist,xlist,ylist,StatesCodeInThisHSL,StatesFullNameInThisHSL,StatesShortNameInThisHSL,SpeciesTranslatorInThisHSL
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"  
        #print(Content1)    
        Content2 = "The error was for PlotIDandXandY with inputs of " + repr(ShengliHuangKeyFile)+","+ repr(Factor)+" with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog


def verbose_copy(src, dst):   #https://cloud.tencent.com/developer/article/2334320
    if src.endswith(".db") or src.endswith("_IgnoredMetric.txt"):   #only select those files with .db as an extension. #added on 20240312 with _IgnoredMetric.txt
        return shutil.copy2(src, dst)
def verbose_copy1(src, dst):   #https://cloud.tencent.com/developer/article/2334320
    if src.endswith("Area_Extent.dbf") or src.endswith("Area_Extent.prj") or src.endswith("Area_Extent.shp") or src.endswith("Area_Extent.shx"):   #only select those files with .db as an extension
        return shutil.copy2(src, dst)
def CrossCopyDataForThisSpecialRun(Run,Tile,BaseYear):
    try:
        print("Let us prepare Run4, 5, and 6 for more accurate F3 products")
        EmptyFolders = ["CommonShare","Intermediate","Results","ResultsAnalysis"]  #They are the empty folders
        for EmptyFolder in EmptyFolders:
            ThisEmptyFolder = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+EmptyFolder
            print("ThisEmptyFolder=",ThisEmptyFolder)
            if not os.path.exists(ThisEmptyFolder):
                os.makedirs(ThisEmptyFolder)   #Copy empty folders
        InputZoneFolder = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"   #added on 20231004: Use representative InputZoneFolder to test if all folders are empty
        if not os.path.exists(InputZoneFolder):  #https://stackoverflow.com/questions/49284015/how-to-check-if-folder-is-empty-with-python
            if Run == "Run4":
                shutil.copytree(os.getcwd()+os.sep+"Run1"+os.sep+Tile+os.sep+"AdditionalContinuousRaster", os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"AdditionalContinuousRaster")   #Copy the entire folder
                shutil.copytree(os.getcwd()+os.sep+"Run1"+os.sep+Tile+os.sep+"AdditionalDiscreteRaster", os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"AdditionalDiscreteRaster")
                shutil.copytree(os.getcwd()+os.sep+"Run1"+os.sep+Tile+os.sep+"FieldPoint", os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"FieldPoint",copy_function=verbose_copy)   #https://cloud.tencent.com/developer/article/2334320
                shutil.copytree(os.getcwd()+os.sep+"Run1"+os.sep+Tile+os.sep+"NonRSraster", os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"NonRSraster")
                shutil.copytree(os.getcwd()+os.sep+"Run1"+os.sep+Tile+os.sep+"RSraster", os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"RSraster")
                shutil.copytree(os.getcwd()+os.sep+"Run1"+os.sep+Tile+os.sep+"InputZone", os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone",copy_function=verbose_copy1)  #added on 20240312
                print("shutil.copytree is finished and we will start shutil.copy")
                shutil.copy(os.getcwd()+os.sep+"Run3"+os.sep+Tile+os.sep+"InputZone"+os.sep+"R3_Y"+BaseYear+"_L1_S48_C17.tif", os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R3_Y"+BaseYear+"_L1_S48_C17.tif")   #Copy individual file
                shutil.copy(os.getcwd()+os.sep+"Run1"+os.sep+Tile+os.sep+"InputZone"+os.sep+"R1_Y"+BaseYear+"_L2_S70_C16.tif", os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R1_Y"+BaseYear+"_L2_S70_C16.tif")
                shutil.copy(os.getcwd()+os.sep+"Run2"+os.sep+Tile+os.sep+"InputZone"+os.sep+"R2_Y"+BaseYear+"_L3_S95_C15.tif", os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R2_Y"+BaseYear+"_L3_S95_C15.tif")
                shutil.copy(os.getcwd()+os.sep+"Run1"+os.sep+Tile+os.sep+"InputZone"+os.sep+"R1_Y"+BaseYear+"_L4_S130_C12.tif", os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R1_Y"+BaseYear+"_L4_S130_C12.tif")
                shutil.copy(os.getcwd()+os.sep+"Run2"+os.sep+Tile+os.sep+"InputZone"+os.sep+"R2_Y"+BaseYear+"_L5_S300_C11.tif", os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R2_Y"+BaseYear+"_L5_S300_C11.tif")
                shutil.copy(os.getcwd()+os.sep+"Run3"+os.sep+Tile+os.sep+"InputZone"+os.sep+"R3_Y"+BaseYear+"_L6_S48.tif", os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R3_Y"+BaseYear+"_L6_S48.tif")
                print("shutil.copy is just finished")
            if Run == "Run5":
                shutil.copytree(os.getcwd()+os.sep+"Run2"+os.sep+Tile+os.sep+"AdditionalContinuousRaster", os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"AdditionalContinuousRaster")   #Copy the entire folder
                shutil.copytree(os.getcwd()+os.sep+"Run2"+os.sep+Tile+os.sep+"AdditionalDiscreteRaster", os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"AdditionalDiscreteRaster")
                shutil.copytree(os.getcwd()+os.sep+"Run2"+os.sep+Tile+os.sep+"FieldPoint", os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"FieldPoint", copy_function=verbose_copy)
                shutil.copytree(os.getcwd()+os.sep+"Run2"+os.sep+Tile+os.sep+"NonRSraster", os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"NonRSraster")
                shutil.copytree(os.getcwd()+os.sep+"Run2"+os.sep+Tile+os.sep+"RSraster", os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"RSraster")
                shutil.copytree(os.getcwd()+os.sep+"Run2"+os.sep+Tile+os.sep+"InputZone", os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone",copy_function=verbose_copy1)  #added on 20240312
                shutil.copy(os.getcwd()+os.sep+"Run1"+os.sep+Tile+os.sep+"InputZone"+os.sep+"R1_Y"+BaseYear+"_L1_S40_C18.tif", os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R1_Y"+BaseYear+"_L1_S40_C18.tif")   #Copy individual file
                shutil.copy(os.getcwd()+os.sep+"Run3"+os.sep+Tile+os.sep+"InputZone"+os.sep+"R3_Y"+BaseYear+"_L2_S78_C15.tif", os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R3_Y"+BaseYear+"_L2_S78_C15.tif")
                shutil.copy(os.getcwd()+os.sep+"Run2"+os.sep+Tile+os.sep+"InputZone"+os.sep+"R2_Y"+BaseYear+"_L3_S95_C15.tif", os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R2_Y"+BaseYear+"_L3_S95_C15.tif")
                shutil.copy(os.getcwd()+os.sep+"Run3"+os.sep+Tile+os.sep+"InputZone"+os.sep+"R3_Y"+BaseYear+"_L4_S140_C11.tif", os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R3_Y"+BaseYear+"_L4_S140_C11.tif")
                shutil.copy(os.getcwd()+os.sep+"Run2"+os.sep+Tile+os.sep+"InputZone"+os.sep+"R2_Y"+BaseYear+"_L5_S300_C11.tif", os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R2_Y"+BaseYear+"_L5_S300_C11.tif")
                shutil.copy(os.getcwd()+os.sep+"Run1"+os.sep+Tile+os.sep+"InputZone"+os.sep+"R1_Y"+BaseYear+"_L6_S40.tif", os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R1_Y"+BaseYear+"_L6_S40.tif")
            if Run == "Run6":
                shutil.copytree(os.getcwd()+os.sep+"Run3"+os.sep+Tile+os.sep+"AdditionalContinuousRaster", os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"AdditionalContinuousRaster")   #Copy the entire folder
                shutil.copytree(os.getcwd()+os.sep+"Run3"+os.sep+Tile+os.sep+"AdditionalDiscreteRaster", os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"AdditionalDiscreteRaster")
                shutil.copytree(os.getcwd()+os.sep+"Run3"+os.sep+Tile+os.sep+"FieldPoint", os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"FieldPoint", copy_function=verbose_copy)
                shutil.copytree(os.getcwd()+os.sep+"Run3"+os.sep+Tile+os.sep+"NonRSraster", os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"NonRSraster")
                shutil.copytree(os.getcwd()+os.sep+"Run3"+os.sep+Tile+os.sep+"RSraster", os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"RSraster")
                shutil.copytree(os.getcwd()+os.sep+"Run3"+os.sep+Tile+os.sep+"InputZone", os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone",copy_function=verbose_copy1)  #added on 20240312
                shutil.copy(os.getcwd()+os.sep+"Run2"+os.sep+Tile+os.sep+"InputZone"+os.sep+"R2_Y"+BaseYear+"_L1_S32_C19.tif", os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R2_Y"+BaseYear+"_L1_S32_C19.tif")   #Copy individual file
                shutil.copy(os.getcwd()+os.sep+"Run3"+os.sep+Tile+os.sep+"InputZone"+os.sep+"R3_Y"+BaseYear+"_L2_S78_C15.tif", os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R3_Y"+BaseYear+"_L2_S78_C15.tif")
                shutil.copy(os.getcwd()+os.sep+"Run1"+os.sep+Tile+os.sep+"InputZone"+os.sep+"R1_Y"+BaseYear+"_L3_S100_C14.tif", os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R1_Y"+BaseYear+"_L3_S100_C14.tif")
                shutil.copy(os.getcwd()+os.sep+"Run1"+os.sep+Tile+os.sep+"InputZone"+os.sep+"R1_Y"+BaseYear+"_L4_S130_C12.tif", os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R1_Y"+BaseYear+"_L4_S130_C12.tif")
                shutil.copy(os.getcwd()+os.sep+"Run3"+os.sep+Tile+os.sep+"InputZone"+os.sep+"R3_Y"+BaseYear+"_L5_S300_C9.tif", os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R3_Y"+BaseYear+"_L5_S300_C9.tif")
                shutil.copy(os.getcwd()+os.sep+"Run2"+os.sep+Tile+os.sep+"InputZone"+os.sep+"R2_Y"+BaseYear+"_L6_S32.tif", os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R2_Y"+BaseYear+"_L6_S32.tif")
        Message = "This is for " + Run
        print(Message)
        return Message
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"  
        #print(Content1)    
        Content2 = "The error was for CrossCopyDataForThisSpecialRun with inputs of " + repr(Run)+","+repr(Tile)+","+ repr(BaseYear)+" with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog

   

def LandscapeManagementMosaic(mylock,ManagementScenarioAOI,Tile,Year,Metric):
    try:
        #RSY, tile is used to get the LandscapeExtent, which is the TIf file depicting the mosaic extent, e.g., D:\f3app\RemoteSensingYear2012\Run1\SERAL\InputZone\Area_Extent.tif
        LandscapeTif = os.getcwd()+os.sep+"Run1"+os.sep+Tile+os.sep+"InputZone"+os.sep+"Area_Extent.tif"
        RasterMasked,ulx,uly,llx,lly,lrx,lry,urx,ury = ReadTifToArrayAndReturnExtent(LandscapeTif)
        
        if ".shp" in ManagementScenarioAOI:
            field_name = "mgtcode"  #This should be a field name in the shape file depicting the ManagementScenario code (e.g., 1 means NOMGT, 2 means Thinning etc)
            ManagementScenarioAOItif, RowMin_ForRaster,RowMax_ForRaster,ColumnMin_ForRaster,ColumnMax_ForRaster,CommonOverlay_ulx, CommonOverlay_lrx, CommonOverlay_uly, CommonOverlay_lry = ShapeAndRasterOverlayExtent(ManagementScenarioAOI,field_name,ulx,lrx,uly,lry)
        if ".tif" in ManagementScenarioAOI:
            ManagementScenarioAOItif = ManagementScenarioAOI

        driverTiff = gdal.GetDriverByName('GTiff')
        ds = gdal.Open(ManagementScenarioAOItif)
        cols = ds.RasterXSize
        rows = ds.RasterYSize
        WeUseThisProjection = ds.GetProjectionRef()
        WeUseThisGeoTransform = ds.GetGeoTransform()
        print(WeUseThisGeoTransform)
        ManagementScenarioAOIvalue = ds.GetRasterBand(1).ReadAsArray().astype(np.int64)
        ManagementScenarioAOIvalueNodata = ds.GetRasterBand(1).GetNoDataValue()
        ManagementScenarioAOIvalueMasked = ma.masked_values(ManagementScenarioAOIvalue, ManagementScenarioAOIvalueNodata)
        if ((ManagementScenarioAOIvalueMasked.shape[0] != RasterMasked.shape[0]) or  (ManagementScenarioAOIvalueMasked.shape[1] != RasterMasked.shape[1])):
            print("There might be problem because the shape file cannot be fully cover the LandscapeTif extent. Please check!")
            return
        
        LandscapeManagementMosaicArray = np.full(ManagementScenarioAOIvalue.shape, F3NoDataValue) 
        LandscapeManagementMosaicArray = ma.masked_values(LandscapeManagementMosaicArray, F3NoDataValue)

        ManagementScenarioAOIvalueMaskedUnique = np.unique(ManagementScenarioAOIvalueMasked).astype('int64')  #Make sure nodata is not in the list
        for ManagementScenarioNumber in ManagementScenarioAOIvalueMaskedUnique:   #Here ManagementScenarioNumber must match with ManagementScenarioText, which is the element of Managements list in this Python file
            if ManagementScenarioNumber == 0:
                ManagementScenarioText = "NoMGT"
            if ManagementScenarioNumber == 1:
                ManagementScenarioText = "Thin"
            if ManagementScenarioNumber == 2:
                ManagementScenarioText = "SalvagLogging"            
            TileYearMetricTif = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep+ManagementScenarioText+"_"+str(Year)+"_"+Metric+"_MosaicCellMean_Win3x3Smoothing.tif"
            driverTiff = gdal.GetDriverByName('GTiff')
            ds = gdal.Open(TileYearMetricTif)
            TileYearMetricTifArray = ds.GetRasterBand(1).ReadAsArray().astype(np.int64)
            TileYearMetricTifNodata = ds.GetRasterBand(1).GetNoDataValue()
            TileYearMetricTifArrayMasked = ma.masked_values(TileYearMetricTifArray, TileYearMetricTifNodata)
            LandscapeManagementMosaicArray[ManagementScenarioAOIvalueMasked == ManagementScenarioNumber] = TileYearMetricTifArrayMasked[ManagementScenarioAOIvalueMasked == ManagementScenarioNumber]

        LandscapeManagementMosaicArray = ma.masked_values(LandscapeManagementMosaicArray, F3NoDataValue)
        LandscapeScenarioFile = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep+"LandscapeScenario"+"_"+str(Year)+"_"+Metric+"_MosaicCellMean_Win3x3Smoothing.tif"
        MetricFinalMin = np.nanmin(LandscapeManagementMosaicArray)
        MetricFinalMax = np.nanmax(LandscapeManagementMosaicArray)
        TypeOfInterest = OutputDataType(MetricFinalMin, MetricFinalMax)
        OutputGeoTifCompression = "Yes"
        driver = gdal.GetDriverByName("GTiff")
        if OutputGeoTifCompression == "Yes": #Added on 20230227. LZW compression does not lose information. LZW compression is a lossless data compression algorithm, which means that the original data can be fully reconstructed from the compressed data without any loss of information.
            outdata = driver.Create(LandscapeScenarioFile, LandscapeManagementMosaicArray.shape[1], LandscapeManagementMosaicArray.shape[0], 1, TypeOfInterest, options=['COMPRESS=LZW'])   #see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
        if OutputGeoTifCompression == "No": 
            outdata = driver.Create(LandscapeScenarioFile, LandscapeManagementMosaicArray.shape[1], LandscapeManagementMosaicArray.shape[0], 1, TypeOfInterest)   #see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
        #print("SetGeoTransform and SetProjection usage, see http://www2.geog.ucl.ac.uk/~plewis/geogg122_local/geogg122-old/Chapter4_GDAL/GDAL_Python_bindings.html")
        outdata.SetGeoTransform(WeUseThisGeoTransform)     
        outdata.SetProjection(WeUseThisProjection)
        outdata.GetRasterBand(1).WriteArray(MetricArray)
        outdata.GetRasterBand(1).SetNoDataValue(F3NoDataValue)   
        outdata.FlushCache()  
        outdata = None
        print("---",LandscapeScenarioFile," was saved")
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)    
        Content2 = "The error was for HistoricalAnnualProductCreation with inputs of " + repr(ManagementScenarioAOI)+","+repr(Tile)+","+repr(Year)+","+","+repr(Metric)+" with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog
               


def HistoricalAnnualProductCreation(mylock,YearOfInterest,ReferenceYears,Metric,ReferencedImg,RSbins,StopPercentage,ReducedTimes):   #Originally I want to inlcude all Metrics in one function, but now I want to process only one metric at one time 
    try:
        #YearOfInterest = 2019
        #ReferenceYears = [2005, 2010, 2015, 2020]
        #ReferencedImg = "D:\\f3app\\RemoteSensingYear2014\\TilesMosaicRunAverage\\Area_Extent_650215.tif"   #We can change it later
        #Metric = "SLTSCB"

        #As of 20230513, the code works, but several problems:
        #a) Bin=3 is acceptable. When the value is higher, it take too long time (about one day);
        #b) Finer segmentation is better, but take too long time;
        #c) How to improve the computation efficiency is the most challenging problem
        #d) Can bins replaced by supervised lassification (e.g., https://www.google.com/search?q=google+earth+engine+supervised#fpstate=ive&vld=cid:4b2b1e21,vid:VMab-HAXOpw), but 3x3x3 is actually a classification, so I do not think so
        #e) How about using 5,4,3 but only with very coarse segmentation? I do not knwo the speed.

        #Some notes on 20230717:
        #a) We can map forest condition back to 1972, however, from 1972 to 1982, we can only use 'green','red','nir', because we do not have SWIR in Landsat;
        #b) If we can 'green','red','nir', please  ake sure the threshold values should be changed;
        #c) Always assure that the input reflectance are consistently scaled, because the algorthm is based on reflectance. This also means other sensors (e.g., ASTER) should also be tranformed if used

        
        t000 = time.time()
        print("In each bin, we will use each reference years")
        print("In each reference, the finer-to-coarser segmentation is used to fill the pixel in sequence. When imputed pixel % reach a threshold value, the code will stop. The purpose is to a)save the computation time; b) use finer imputation")
        print("Finally we will use the average of bin & reference pair")
         
        Reference = gdal.Open(ReferencedImg)   
        ReferenceCols = Reference.RasterXSize
        ReferenceRows = Reference.RasterYSize
        ReferenceArray = Reference.GetRasterBand(1).ReadAsArray()
        ReferenceArray = ReferenceArray[::ReducedTimes,::ReducedTimes]
        ReferenceNoDataValue = Reference.GetRasterBand(1).GetNoDataValue()
        WeUseThisProjection = Reference.GetProjectionRef()
        WeUseThisGeoTransform = Reference.GetGeoTransform()
        print(WeUseThisGeoTransform)  #This will have a new resolution 
        NewGeoTransform = [WeUseThisGeoTransform[0],WeUseThisGeoTransform[1]*ReducedTimes,WeUseThisGeoTransform[2],WeUseThisGeoTransform[3],WeUseThisGeoTransform[4],WeUseThisGeoTransform[5]*ReducedTimes]  #added in 20230623
        print(NewGeoTransform)  #This will have a new resolution 

        ##We will do something here, simiar to what we did before
        YearOfInterestImg = [
            os.path.dirname(os.getcwd())+os.sep+"Landsat_"+str(YearOfInterest)+"_red.tif",
            os.path.dirname(os.getcwd())+os.sep+"Landsat_"+str(YearOfInterest)+"_nir.tif",
            os.path.dirname(os.getcwd())+os.sep+"Landsat_"+str(YearOfInterest)+"_swir1.tif"    #we need cloud to detect the nodata 
            ]
        YearOfInterestImgQA = YearOfInterestImg[0].replace("red.tif","PixelLabel.tif")
        print("We will use this new sentence to replace the above one soon, because PixelLabel.tif is not sufficient but CloudShadowWaterSnow.tif is sufficient") #YearOfInterestImgQA = YearOfInterestImg[0].replace("red.tif","CloudShadowWaterSnow.tif")
        YearOfInterestImgQAarray = ImgRasterWithinTheExtentOfReferencedImage([YearOfInterestImgQA], ReferencedImg)
        YearOfInterestImgQAarray = YearOfInterestImgQAarray[0,:,:]  #This canot be skipped and is a must
        YearOfInterestImgQAarray = YearOfInterestImgQAarray[::ReducedTimes,::ReducedTimes]  #added on 20230623
        YearOfInterestImgArray = ImgRasterWithinTheExtentOfReferencedImage(YearOfInterestImg, ReferencedImg,YearOfInterestImgQA)
        YearOfInterestImgArray = ma.masked_values(YearOfInterestImgArray, F3NoDataValue)
        YearOfInterestImgArray = YearOfInterestImgArray[::,::ReducedTimes,::ReducedTimes]  #added on 20230623
        YearOfInterestImgArraySupposedToBeProcessed = YearOfInterestImgArray[0,:,:].count()   #This indicates how many pixels should be processed
        YearOfInterestImgArrayNew = YearOfInterestImgArray.copy()

        MetricArrayAll = np.full((len(RSbins),len(ReferenceYears),YearOfInterestImgQAarray.shape[0],YearOfInterestImgQAarray.shape[1]), F3NoDataValue)   #shape[0] is row, shape[1] is column
        MetricArrayAll = ma.masked_values(MetricArrayAll, F3NoDataValue)

        RSbinID = -1
        for RSbin in RSbins:
            RSbinID = RSbinID + 1
            YearOfInterestImgArrayNew[0,:,:] = ArrayBinnedWithConstantMinMax(YearOfInterestImgArray[0,:,:], 7400, 17000, RSbin) #For red: EndMax = 17000, EndMin = 7400. For nir, EndMax = 21000, EndMin = 11000. For swir1, EndMax = 22000, EndMin = 9300
            YearOfInterestImgArrayNew[1,:,:] = ArrayBinnedWithConstantMinMax(YearOfInterestImgArray[1,:,:], 11000, 21000, RSbin)
            YearOfInterestImgArrayNew[2,:,:] = ArrayBinnedWithConstantMinMax(YearOfInterestImgArray[2,:,:], 9300, 22000, RSbin)

            ReferenceYearID = -1
            for ReferenceYear in ReferenceYears:
                ReferenceYearID = ReferenceYearID + 1

                #This is to use Kirk's combine idea to replace the original large positive and negative value with the index for RemoteSensingSegmentationFromFineToCoarse. adopted on 20221202---start
                if RSbinID == 0:  
                    RemoteSensingSegmentationFromFineToCoarse = [   #I tried to use different year's segmentation for the reference year to "mix" the boder, but the cloud/water mask is different, so I gave up
                        #os.path.dirname(os.getcwd())+os.sep+"Run1_Y"+str(ReferenceYears[ReferenceYearID])+"_L1_S40_C18.tif",
                        #os.path.dirname(os.getcwd())+os.sep+"Run1_Y"+str(ReferenceYears[ReferenceYearID])+"_L2_S70_C16.tif",
                        #os.path.dirname(os.getcwd())+os.sep+"Run1_Y"+str(ReferenceYears[ReferenceYearID])+"_L3_S100_C14.tif",
                        #os.path.dirname(os.getcwd())+os.sep+"Run1_Y"+str(ReferenceYears[ReferenceYearID])+"_L4_S130_C12.tif",
                        #os.path.dirname(os.getcwd())+os.sep+"Run1_Y"+str(ReferenceYears[ReferenceYearID])+"_L5_S300_C10.tif"
                        
                        os.path.dirname(os.getcwd())+os.sep+"Run1_Y"+str(ReferenceYears[-1*(ReferenceYearID+1)])+"_Level1_Snic40.tif",
                        #os.path.dirname(os.getcwd())+os.sep+"Run1_Y"+str(ReferenceYears[ReferenceYearID])+"_Level2_Snic70.tif",
                        os.path.dirname(os.getcwd())+os.sep+"Run1_Y"+str(ReferenceYears[ReferenceYearID])+"_Level3_Snic100.tif",
                        #os.path.dirname(os.getcwd())+os.sep+"Run1_Y"+str(ReferenceYears[ReferenceYearID])+"_Level4_Snic130.tif",
                        #os.path.dirname(os.getcwd())+os.sep+"Run1_Y"+str(ReferenceYears[ReferenceYearID])+"_Level5_Snic400.tif",
                    
                        #os.path.dirname(os.getcwd())+os.sep+"Run2_Y"+str(ReferenceYears[ReferenceYearID])+"_Level1_Snic32.tif",
                        #os.path.dirname(os.getcwd())+os.sep+"Run2_Y"+str(ReferenceYears[ReferenceYearID])+"_Level2_Snic67.tif",
                        #os.path.dirname(os.getcwd())+os.sep+"Run2_Y"+str(ReferenceYears[ReferenceYearID])+"_Level3_Snic95.tif",
                        #os.path.dirname(os.getcwd())+os.sep+"Run2_Y"+str(ReferenceYears[ReferenceYearID])+"_Level4_Snic135.tif",
                        os.path.dirname(os.getcwd())+os.sep+"Run2_Y"+str(ReferenceYears[-1*(ReferenceYearID+1)])+"_Level5_Snic425.tif",

                        #os.path.dirname(os.getcwd())+os.sep+"Run3_Y"+str(ReferenceYears[ReferenceYearID])+"_Level1_Snic48.tif",
                        #os.path.dirname(os.getcwd())+os.sep+"Run3_Y"+str(ReferenceYears[ReferenceYearID])+"_Level2_Snic78.tif",
                        #os.path.dirname(os.getcwd())+os.sep+"Run3_Y"+str(ReferenceYears[ReferenceYearID])+"_Level3_Snic108.tif",
                        #os.path.dirname(os.getcwd())+os.sep+"Run3_Y"+str(ReferenceYears[ReferenceYearID])+"_Level4_Snic140.tif",
                        #os.path.dirname(os.getcwd())+os.sep+"Run3_Y"+str(ReferenceYears[ReferenceYearID])+"_Level5_Snic450.tif",
                        ]        
                if RSbinID == 1:
                    RemoteSensingSegmentationFromFineToCoarse = [   #I tried to use different year's segmentation for the reference year to "mix" the boder, but the cloud/water mask is different, so I gave up
                        #os.path.dirname(os.getcwd())+os.sep+"Run1_Y"+str(ReferenceYears[ReferenceYearID])+"_L1_S40_C18.tif",
                        #os.path.dirname(os.getcwd())+os.sep+"Run1_Y"+str(ReferenceYears[ReferenceYearID])+"_L2_S70_C16.tif",
                        #os.path.dirname(os.getcwd())+os.sep+"Run1_Y"+str(ReferenceYears[ReferenceYearID])+"_L3_S100_C14.tif",
                        #os.path.dirname(os.getcwd())+os.sep+"Run1_Y"+str(ReferenceYears[ReferenceYearID])+"_L4_S130_C12.tif",
                        #os.path.dirname(os.getcwd())+os.sep+"Run1_Y"+str(ReferenceYears[ReferenceYearID])+"_L5_S300_C10.tif"
                        
                        os.path.dirname(os.getcwd())+os.sep+"Run1_Y"+str(ReferenceYears[-1*(ReferenceYearID+1)])+"_Level1_Snic40.tif",
                        #os.path.dirname(os.getcwd())+os.sep+"Run1_Y"+str(ReferenceYears[ReferenceYearID])+"_Level2_Snic70.tif",
                        #os.path.dirname(os.getcwd())+os.sep+"Run1_Y"+str(ReferenceYears[ReferenceYearID])+"_Level3_Snic100.tif",
                        #os.path.dirname(os.getcwd())+os.sep+"Run1_Y"+str(ReferenceYears[ReferenceYearID])+"_Level4_Snic130.tif",
                        #os.path.dirname(os.getcwd())+os.sep+"Run1_Y"+str(ReferenceYears[ReferenceYearID])+"_Level5_Snic400.tif",
                    
                        #os.path.dirname(os.getcwd())+os.sep+"Run2_Y"+str(ReferenceYears[ReferenceYearID])+"_Level1_Snic32.tif",
                        #os.path.dirname(os.getcwd())+os.sep+"Run2_Y"+str(ReferenceYears[ReferenceYearID])+"_Level2_Snic67.tif",
                        os.path.dirname(os.getcwd())+os.sep+"Run2_Y"+str(ReferenceYears[ReferenceYearID])+"_Level3_Snic95.tif",
                        #os.path.dirname(os.getcwd())+os.sep+"Run2_Y"+str(ReferenceYears[ReferenceYearID])+"_Level4_Snic135.tif",
                        #os.path.dirname(os.getcwd())+os.sep+"Run2_Y"+str(ReferenceYears[ReferenceYearID])+"_Level5_Snic425.tif",

                        #os.path.dirname(os.getcwd())+os.sep+"Run3_Y"+str(ReferenceYears[ReferenceYearID])+"_Level1_Snic48.tif",
                        #os.path.dirname(os.getcwd())+os.sep+"Run3_Y"+str(ReferenceYears[ReferenceYearID])+"_Level2_Snic78.tif",
                        #os.path.dirname(os.getcwd())+os.sep+"Run3_Y"+str(ReferenceYears[ReferenceYearID])+"_Level3_Snic108.tif",
                        #os.path.dirname(os.getcwd())+os.sep+"Run3_Y"+str(ReferenceYears[ReferenceYearID])+"_Level4_Snic140.tif",
                        os.path.dirname(os.getcwd())+os.sep+"Run3_Y"+str(ReferenceYears[-1*(ReferenceYearID+1)])+"_Level5_Snic450.tif",
                        ]  

                if RSbinID > 1:   #RSbinID usually is <=2
                    RemoteSensingSegmentationFromFineToCoarse = [   #I tried to use different year's segmentation for the reference year to "mix" the boder, but the cloud/water mask is different, so I gave up
                        #os.path.dirname(os.getcwd())+os.sep+"Run1_Y"+str(ReferenceYears[ReferenceYearID])+"_L1_S40_C18.tif",
                        #os.path.dirname(os.getcwd())+os.sep+"Run1_Y"+str(ReferenceYears[ReferenceYearID])+"_L2_S70_C16.tif",
                        #os.path.dirname(os.getcwd())+os.sep+"Run1_Y"+str(ReferenceYears[ReferenceYearID])+"_L3_S100_C14.tif",
                        #os.path.dirname(os.getcwd())+os.sep+"Run1_Y"+str(ReferenceYears[ReferenceYearID])+"_L4_S130_C12.tif",
                        #os.path.dirname(os.getcwd())+os.sep+"Run1_Y"+str(ReferenceYears[ReferenceYearID])+"_L5_S300_C10.tif"
                        
                        os.path.dirname(os.getcwd())+os.sep+"Run1_Y"+str(ReferenceYears[-1*(ReferenceYearID+1)])+"_Level1_Snic40.tif",
                        #os.path.dirname(os.getcwd())+os.sep+"Run1_Y"+str(ReferenceYears[ReferenceYearID])+"_Level2_Snic70.tif",
                        os.path.dirname(os.getcwd())+os.sep+"Run1_Y"+str(ReferenceYears[ReferenceYearID])+"_Level3_Snic100.tif",
                        #os.path.dirname(os.getcwd())+os.sep+"Run1_Y"+str(ReferenceYears[ReferenceYearID])+"_Level4_Snic130.tif",
                        #os.path.dirname(os.getcwd())+os.sep+"Run1_Y"+str(ReferenceYears[ReferenceYearID])+"_Level5_Snic400.tif",
                    
                        #os.path.dirname(os.getcwd())+os.sep+"Run2_Y"+str(ReferenceYears[ReferenceYearID])+"_Level1_Snic32.tif",
                        #os.path.dirname(os.getcwd())+os.sep+"Run2_Y"+str(ReferenceYears[ReferenceYearID])+"_Level2_Snic67.tif",
                        #os.path.dirname(os.getcwd())+os.sep+"Run2_Y"+str(ReferenceYears[ReferenceYearID])+"_Level3_Snic95.tif",
                        #os.path.dirname(os.getcwd())+os.sep+"Run2_Y"+str(ReferenceYears[ReferenceYearID])+"_Level4_Snic135.tif",
                        #os.path.dirname(os.getcwd())+os.sep+"Run2_Y"+str(ReferenceYears[ReferenceYearID])+"_Level5_Snic425.tif",

                        #os.path.dirname(os.getcwd())+os.sep+"Run3_Y"+str(ReferenceYears[ReferenceYearID])+"_Level1_Snic48.tif",
                        #os.path.dirname(os.getcwd())+os.sep+"Run3_Y"+str(ReferenceYears[ReferenceYearID])+"_Level2_Snic78.tif",
                        #os.path.dirname(os.getcwd())+os.sep+"Run3_Y"+str(ReferenceYears[ReferenceYearID])+"_Level3_Snic108.tif",
                        #os.path.dirname(os.getcwd())+os.sep+"Run3_Y"+str(ReferenceYears[ReferenceYearID])+"_Level4_Snic140.tif",
                        os.path.dirname(os.getcwd())+os.sep+"Run3_Y"+str(ReferenceYears[-1*(ReferenceYearID+1)])+"_Level5_Snic450.tif",
                        ]  

                RemoteSensingSegmentationFromFineToCoarseArray = ImgRasterWithinTheExtentOfReferencedImage(RemoteSensingSegmentationFromFineToCoarse, ReferencedImg)
                print("AAA RemoteSensingSegmentationFromFineToCoarseArray.shape=",RemoteSensingSegmentationFromFineToCoarseArray.shape)
                RemoteSensingSegmentationFromFineToCoarseArray = RemoteSensingSegmentationFromFineToCoarseArray[::,::ReducedTimes,::ReducedTimes]  #added on 20230623
                print("BBB RemoteSensingSegmentationFromFineToCoarseArray.shape=",RemoteSensingSegmentationFromFineToCoarseArray.shape)
                for n in range(0,RemoteSensingSegmentationFromFineToCoarseArray.shape[0],1):
                    outdataNameArray = RemoteSensingSegmentationFromFineToCoarseArray[n,:,:].copy()
                    outdataNameArrayshape = outdataNameArray.shape
                    ListTifArray = []            
                    klist = outdataNameArray.flatten().tolist()  
                    ListTifArray.append(klist)  
                    dLU = {t:i+1 for i, t in enumerate(set(zip(*ListTifArray)))}
                    Final = np.array([dLU[T] for T in zip(*ListTifArray)]) #each pair has an Unique ID (0,1,2..... etc), and the ID will be given to the element
                    outdataNameArray = Final.reshape(outdataNameArrayshape)
                    RemoteSensingSegmentationFromFineToCoarseArray[n,:,:] = outdataNameArray.copy()
                    #print("outdataNameArrayUniqueValues done ", " at " + datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")) 
                #This is to use Kirk's combine idea to replace the original large positive and negative value with the index for RemoteSensingSegmentationFromFineToCoarse. adopted on 20221202---end
                RemoteSensingSegmentationFromFineToCoarseArray = ma.masked_values(RemoteSensingSegmentationFromFineToCoarseArray, F3NoDataValue)
                
                ReferenceYearImg = [
                    os.path.dirname(os.getcwd())+os.sep+"Landsat_"+str(ReferenceYear)+"_red.tif",  #The order of "red, nir, and swir1" is very important, because they correspond to the [0],[1],[2] below
                    os.path.dirname(os.getcwd())+os.sep+"Landsat_"+str(ReferenceYear)+"_nir.tif",
                    os.path.dirname(os.getcwd())+os.sep+"Landsat_"+str(ReferenceYear)+"_swir1.tif"
                    ]
                ReferenceYearImgQA = ReferenceYearImg[0].replace("red.tif","PixelLabel.tif")
                ReferenceYearImgArray = ImgRasterWithinTheExtentOfReferencedImage(ReferenceYearImg, ReferencedImg,ReferenceYearImgQA)
                ReferenceYearImgArray = ma.masked_values(ReferenceYearImgArray, F3NoDataValue)
                ReferenceYearImgArray = ReferenceYearImgArray[::,::ReducedTimes,::ReducedTimes]  #added on 20230623
                ReferenceYearImgArrayNew = ReferenceYearImgArray.copy()
                ReferenceYearImgArrayNew[0,:,:] = ArrayBinnedWithConstantMinMax(ReferenceYearImgArray[0,:,:], 7400, 17000, RSbin)  #For red: EndMax = 17000, EndMin = 7400. For nir, EndMax = 21000, EndMin = 11000. For swir1, EndMax = 22000, EndMin = 9300
                ReferenceYearImgArrayNew[1,:,:] = ArrayBinnedWithConstantMinMax(ReferenceYearImgArray[1,:,:], 11000, 21000, RSbin)
                ReferenceYearImgArrayNew[2,:,:] = ArrayBinnedWithConstantMinMax(ReferenceYearImgArray[2,:,:], 9300, 22000, RSbin)

                ReferenceYearMetric = os.path.dirname(os.getcwd())+os.sep+"RemoteSensingYear"+str(ReferenceYear)+os.sep+"TilesMosaicRunAverage"+os.sep+"NoMGT_"+str(ReferenceYear)+"_"+Metric.lower()+"_MosaicCellMean_Win3x3Smoothing.tif"
                #20230626 question: Here should we use the step 1 or 2 result (rather than step 4 results)? It maybe better by using the original field data? Note Random Forest is a not a good choice 
                #The answer is that we do not use Step1, because they are tile-based. We do not use step2, because it is tiled-based an run-based. But if we really want to use it, we can mosaic them first
                ReferenceYearMetricArrayAAA = ImgRasterWithinTheExtentOfReferencedImage([ReferenceYearMetric], ReferencedImg)   #[ReferenceYearMetric] istead of ReferenceYearMetric
                ReferenceYearMetricArrayAAA = ma.masked_values(ReferenceYearMetricArrayAAA, F3NoDataValue)
                ReferenceYearMetricArray = ReferenceYearMetricArrayAAA[0,:,:]  #This sentence is imporant to make sure the shape changef from e.g., (1, 5042, 5794) to (5042, 5794)
                ReferenceYearMetricArray = ReferenceYearMetricArray[::ReducedTimes,::ReducedTimes]  #added on 20230623

                MetricArray = np.full(YearOfInterestImgQAarray.shape, F3NoDataValue)  #MetricArray = np.full(ReferenceArray.shape, F3NoDataValue)
                MetricArray[YearOfInterestImgQAarray != 0] = F3NoDataValue
                MetricArray = ma.masked_values(MetricArray, F3NoDataValue)
                ProcessedPixel = np.full(YearOfInterestImgQAarray.shape, 0)  #ProcessedPixel = np.full(ReferenceArray.shape, 0)
                ProcessedPixel[ReferenceArray == ReferenceNoDataValue] = F3NoDataValue
                ProcessedPixel[YearOfInterestImgQAarray != 0] = F3NoDataValue ##"In the final PixelLabel.tif from GEE , water is 1, Perennial/permanent Ice/Snow is 2, Barren-Rock/Sand/Clay is 3, Landsat cloud/shadow/snow is 4, remaining value is 0"
                ProcessedPixel = ma.masked_values(ProcessedPixel, F3NoDataValue)
                ProcessedPixelTotal = ProcessedPixel.count()            

                RemoteSensingSegmentationFromFineToCoarseArrayID = -1 
                for k in range(0,RemoteSensingSegmentationFromFineToCoarseArray.shape[0],1):
                    RemoteSensingSegmentationFromFineToCoarseArrayID = RemoteSensingSegmentationFromFineToCoarseArrayID + 1
                    t0 = time.time()  
                    ThisSeg = RemoteSensingSegmentationFromFineToCoarseArray[k,:,:]
                    print("YearOfInterestImgArrayNew[0,:,:].shape=",YearOfInterestImgArrayNew[0,:,:].shape)
                    print("YearOfInterestImgArrayNew[1,:,:].shape=",YearOfInterestImgArrayNew[1,:,:].shape)
                    print("YearOfInterestImgArrayNew[2,:,:].shape=",YearOfInterestImgArrayNew[2,:,:].shape)
                    print("ThisSeg.shape=",ThisSeg.shape)
                    
                    ArrayLists0 = [YearOfInterestImgArrayNew[0,:,:],YearOfInterestImgArrayNew[1,:,:],YearOfInterestImgArrayNew[2,:,:],ThisSeg]
                    ArrayListsPath0 = os.path.dirname(os.getcwd())+os.sep+"RemoteSensingYear"+str(YearOfInterest)+os.sep+"TilesMosaicRunAverage"
                    YearOfInterestBinnedArray = RasterCombineToCreateFixedZoneValueFromArrays(ArrayLists0, ArrayListsPath0,ReferencedImg,ReducedTimes)
                    print("YearOfInterestBinnedArray.shape=",YearOfInterestBinnedArray.shape)
                    print("ProcessedPixel.shape=",ProcessedPixel.shape[0],ProcessedPixel.shape[1])
                    
                    YearOfInterestBinnedArray[ProcessedPixel == 1] = F3NoDataValue  #If already processed, we masked it to save time
                    YearOfInterestBinnedArray = ma.masked_values(YearOfInterestBinnedArray, F3NoDataValue)

                    ArrayLists1 = [ReferenceYearImgArrayNew[0,:,:],ReferenceYearImgArrayNew[1,:,:],ReferenceYearImgArrayNew[2,:,:],ThisSeg]
                    ArrayListsPath1 = os.path.dirname(os.getcwd())+os.sep+"RemoteSensingYear"+str(ReferenceYear)+os.sep+"TilesMosaicRunAverage"
                    ReferenceYearBinnedArray = RasterCombineToCreateFixedZoneValueFromArrays(ArrayLists1, ArrayListsPath1,ReferencedImg,ReducedTimes)
                    ReferenceYearBinnedArray = ma.masked_values(ReferenceYearBinnedArray, F3NoDataValue)
                    print("------","New RasterCombineToCreateFixedZoneValueFromArrays for Metric=",Metric," k=",k," took \t" + str(int((time.time() - t0)/60))," minutes", file=open(F3Log, 'a'))

                    YearOfInterestBinnedArrayUnique = np.unique(YearOfInterestBinnedArray).astype('int64')
                    YearOfInterestBinnedArrayUniqueLength = len(YearOfInterestBinnedArrayUnique)
                    Percentage = np.nansum(ProcessedPixel)/ProcessedPixelTotal*100
                    print("------","Start: Please wait! The YearOfInterestBinnedArrayUniqueLength=",YearOfInterestBinnedArrayUniqueLength," and this may take many minutes and the already-processed percentage is ", Percentage)
                    print("------","Start: Please wait! The YearOfInterestBinnedArrayUniqueLength=",YearOfInterestBinnedArrayUniqueLength," and this may take many minutes and the already-processed percentage is ", Percentage, file=open(F3Log, 'a'))
                    #if Percentage >= StopPercentage:
                    #    print("RSbinID, ReferenceYearID, RemoteSensingSegmentationFromFineToCoarseArrayID=",RSbinID, ReferenceYearID, RemoteSensingSegmentationFromFineToCoarseArrayID, " stoped with a percentage of ", Percentage, ", because it is higher than the StopPercentage of ",StopPercentage, file=open(F3Log, 'a'))
                    #    break
                    if k == 0:
                        MinimumPixelNumber = int(30/ReducedTimes)
                    else:
                        MinimumPixelNumber = int(20/ReducedTimes)
                    mid = 0
                    for m in YearOfInterestBinnedArrayUnique:
                        mid = mid + 1
                        if mid % 1000 == 0:
                            print("------","New historical mapping for Metric=",Metric,"k=",k," with progress of ", mid ,"/", YearOfInterestBinnedArrayUniqueLength, " took \t" + str(int((time.time() - t0)/60))," minutes")
                            print("------","New historical mapping for Metric=",Metric,"k=",k," with progress of ", mid ,"/", YearOfInterestBinnedArrayUniqueLength, " took \t" + str(int((time.time() - t0)/60))," minutes", file=open(F3Log, 'a'))
                        SelectPixelsFromReferenceMetric = ReferenceYearMetricArray[ReferenceYearBinnedArray == m]
                        if SelectPixelsFromReferenceMetric.count() >= MinimumPixelNumber:  #This is the minimum pixel numbers for the imputation
                            #print("We have to use np.ma.median instead of np.nanmedian, because the latter causes a UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray, which means -9999 will not be ignored")
                            #print("Also, when the number is even, it returns the mean of the middle two (e.g.,[3,5,2,4] will return 3.5]), see https://numpy.org/doc/stable/reference/generated/numpy.ma.median.html")
                            MetricArray[(YearOfInterestBinnedArray == m) & (ProcessedPixel == 0)] = np.ma.median(SelectPixelsFromReferenceMetric)   #20230626: change nanmean to np.ma.median
                    print("------","New historical mapping for Metric=",Metric,"k=",k," took \t" + str(int((time.time() - t0)/60))," minutes", file=open(F3Log, 'a'))
                    MetricArray[YearOfInterestImgQAarray != 0] = F3NoDataValue
                    MetricArray[ReferenceArray == ReferenceNoDataValue] = F3NoDataValue
                    MetricArray = ma.masked_values(MetricArray, F3NoDataValue)
                    ProcessedPixel[~MetricArray.mask] = 1
                    print("------","End: The YearOfInterestBinnedArrayUniqueLength=",YearOfInterestBinnedArrayUniqueLength," and this may take many minutes and the already-processed percentage is ", Percentage)
                    print("------","End: The YearOfInterestBinnedArrayUniqueLength=",YearOfInterestBinnedArrayUniqueLength," and this may take many minutes and the already-processed percentage is ", Percentage, file=open(F3Log, 'a'))

                #save MetricArray results here to see the difference---start
                SaveMetricArrayForDebug = "Yes"
                if SaveMetricArrayForDebug == "Yes":
                    TempFile = os.path.dirname(os.getcwd())+os.sep+"HistoricalAndActualAnnualProducts" + os.sep +  str(RSbinID) + "-" + str(ReferenceYearID) + ".tif"
                    MetricFinalMin = np.nanmin(MetricArray)
                    MetricFinalMax = np.nanmax(MetricArray)
                    TypeOfInterest = OutputDataType(MetricFinalMin, MetricFinalMax)
                    OutputGeoTifCompression = "Yes"
                    driver = gdal.GetDriverByName("GTiff")
                    if OutputGeoTifCompression == "Yes": #Added on 20230227. LZW compression does not lose information. LZW compression is a lossless data compression algorithm, which means that the original data can be fully reconstructed from the compressed data without any loss of information.
                        outdata = driver.Create(TempFile, YearOfInterestImgQAarray.shape[1], YearOfInterestImgQAarray.shape[0], 1, TypeOfInterest, options=['COMPRESS=LZW'])   #see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
                    if OutputGeoTifCompression == "No": 
                        outdata = driver.Create(TempFile, YearOfInterestImgQAarray.shape[1], YearOfInterestImgQAarray.shape[0], 1, TypeOfInterest)   #see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
                    #print("SetGeoTransform and SetProjection usage, see http://www2.geog.ucl.ac.uk/~plewis/geogg122_local/geogg122-old/Chapter4_GDAL/GDAL_Python_bindings.html")
                    outdata.SetGeoTransform(NewGeoTransform)    #outdata.SetGeoTransform(WeUseThisGeoTransform)  
                    outdata.SetProjection(WeUseThisProjection)
                    outdata.GetRasterBand(1).WriteArray(MetricArray)
                    outdata.GetRasterBand(1).SetNoDataValue(F3NoDataValue)   
                    outdata.FlushCache()  
                    outdata = None
                    print("---",TempFile," was saved")
                #save MetricArray results here to see the difference---end
                MetricArrayAll[RSbinID,ReferenceYearID,:,:] = MetricArray.copy()
        MetricFinalPath = os.path.dirname(os.getcwd())+os.sep+"RemoteSensingYear"+str(YearOfInterest)+os.sep+"TilesMosaicRunAverage"
        if not os.path.exists(MetricFinalPath):
            os.makedirs(MetricFinalPath)
        MetricFinalFile = os.path.dirname(os.getcwd())+os.sep+"HistoricalAndActualAnnualProducts" + os.sep + "NoMGT_"+str(YearOfInterest)+"_"+Metric.lower()+".tif"  #It was MetricFinalFile = MetricFinalPath + os.sep + "NoMGT_"+str(YearOfInterest)+"_"+Metric.lower()+"_MosaicCellMean_Win3x3Smoothing.tif"

        MetricFinalReshape = MetricArrayAll.reshape(MetricArrayAll.shape[0]*MetricArrayAll.shape[1],MetricArrayAll.shape[2],MetricArrayAll.shape[3])  #Originally we have two sentences as: MetricFinalAAA = np.nanmedian(MetricArrayAll,axis=0), MetricFinal = np.nanmedian(MetricFinalAAA,axis=0)
        MetricFinal = np.ma.median(MetricFinalReshape,axis=0)
        MetricFinal[YearOfInterestImgQAarray != 0] = F3NoDataValue
        MetricFinalMasked = ma.masked_values(MetricFinal, F3NoDataValue)
        YearOfInterestImgArrayActuallyBeProcessed = MetricFinalMasked.count()
        print("For ",MetricFinalFile,", ",YearOfInterestImgArrayActuallyBeProcessed, " of " , YearOfInterestImgArraySupposedToBeProcessed, " which is ", YearOfInterestImgArrayActuallyBeProcessed/YearOfInterestImgArraySupposedToBeProcessed*100, "% was processed")
        print("For ",MetricFinalFile,", ",YearOfInterestImgArrayActuallyBeProcessed, " of " , YearOfInterestImgArraySupposedToBeProcessed, " which is ", YearOfInterestImgArrayActuallyBeProcessed/YearOfInterestImgArraySupposedToBeProcessed*100, "% was processed", file=open(F3Log, 'a'))
        print("MetricArray min and max finally=",np.nanmin(MetricArray),np.nanmax(MetricArray), file=open(F3Log, 'a'))
        #We may need a 3x3 window average here later
        MetricFinalMin = np.nanmin(MetricFinal)
        MetricFinalMax = np.nanmax(MetricFinal)
        TypeOfInterest = OutputDataType(MetricFinalMin, MetricFinalMax)
        OutputGeoTifCompression = "Yes"
        driver = gdal.GetDriverByName("GTiff")
        if OutputGeoTifCompression == "Yes": #Added on 20230227. LZW compression does not lose information. LZW compression is a lossless data compression algorithm, which means that the original data can be fully reconstructed from the compressed data without any loss of information.
            outdata = driver.Create(MetricFinalFile, YearOfInterestImgQAarray.shape[1], YearOfInterestImgQAarray.shape[0], 1, TypeOfInterest, options=['COMPRESS=LZW'])   #see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
        if OutputGeoTifCompression == "No": 
            outdata = driver.Create(MetricFinalFile, YearOfInterestImgQAarray.shape[1], YearOfInterestImgQAarray.shape[0], 1, TypeOfInterest)   #see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
        print("SetGeoTransform and SetProjection usage, see http://www2.geog.ucl.ac.uk/~plewis/geogg122_local/geogg122-old/Chapter4_GDAL/GDAL_Python_bindings.html")
        outdata.SetGeoTransform(NewGeoTransform)  
        outdata.SetProjection(WeUseThisProjection)
        outdata.GetRasterBand(1).WriteArray(MetricFinal)
        outdata.GetRasterBand(1).SetNoDataValue(F3NoDataValue)   
        outdata.FlushCache()  
        outdata = None

        #This section is to calculate the uncertainty (std) of the outputs, note they are copied from above with little change---start
        MetricFinalFile = os.path.dirname(os.getcwd())+os.sep+"HistoricalAndActualAnnualProducts" + os.sep + "NoMGT_"+str(YearOfInterest)+"_"+Metric.lower()+"_std.tif"  ##20230626: change 1---add _std
        MetricFinal = np.nanstd(MetricFinalReshape,axis=0)
        MetricFinal[YearOfInterestImgQAarray != 0] = F3NoDataValue
        MetricFinalMasked = ma.masked_values(MetricFinal, F3NoDataValue)
        YearOfInterestImgArrayActuallyBeProcessed = MetricFinalMasked.count()
        print("For ",MetricFinalFile,", ",YearOfInterestImgArrayActuallyBeProcessed, " of " , YearOfInterestImgArraySupposedToBeProcessed, " which is ", YearOfInterestImgArrayActuallyBeProcessed/YearOfInterestImgArraySupposedToBeProcessed*100, "% was processed")
        print("For ",MetricFinalFile,", ",YearOfInterestImgArrayActuallyBeProcessed, " of " , YearOfInterestImgArraySupposedToBeProcessed, " which is ", YearOfInterestImgArrayActuallyBeProcessed/YearOfInterestImgArraySupposedToBeProcessed*100, "% was processed", file=open(F3Log, 'a'))
        print("MetricArray min and max finally=",np.nanmin(MetricArray),np.nanmax(MetricArray), file=open(F3Log, 'a'))
        #We may need a 3x3 window average here later
        MetricFinalMin = np.nanmin(MetricFinal)
        MetricFinalMax = np.nanmax(MetricFinal)
        TypeOfInterest = OutputDataType(MetricFinalMin, MetricFinalMax)
        OutputGeoTifCompression = "Yes"
        driver = gdal.GetDriverByName("GTiff")
        if OutputGeoTifCompression == "Yes": #Added on 20230227. LZW compression does not lose information. LZW compression is a lossless data compression algorithm, which means that the original data can be fully reconstructed from the compressed data without any loss of information.
            outdata = driver.Create(MetricFinalFile, YearOfInterestImgQAarray.shape[1], YearOfInterestImgQAarray.shape[0], 1, TypeOfInterest, options=['COMPRESS=LZW'])   #see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
        if OutputGeoTifCompression == "No": 
            outdata = driver.Create(MetricFinalFile, YearOfInterestImgQAarray.shape[1], YearOfInterestImgQAarray.shape[0], 1, TypeOfInterest)   #see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
        print("SetGeoTransform and SetProjection usage, see http://www2.geog.ucl.ac.uk/~plewis/geogg122_local/geogg122-old/Chapter4_GDAL/GDAL_Python_bindings.html")
        outdata.SetGeoTransform(NewGeoTransform)  
        outdata.SetProjection(WeUseThisProjection)
        outdata.GetRasterBand(1).WriteArray(MetricFinal)
        outdata.GetRasterBand(1).SetNoDataValue(F3NoDataValue)   
        outdata.FlushCache()  
        outdata = None
        #This section is to calculate the uncertainty (std) of the outputs, note they are copied from above with little change---end
        print("Historical Mapping for YearOfInterest,ReferenceYears,Metric,ReferencedImg,RSbins,StopPercentage,ReducedTimes=",YearOfInterest,ReferenceYears,Metric,ReferencedImg,RSbins,StopPercentage,ReducedTimes," took \t" + str(int((time.time() - t000)/60))," minutes")        
        print("Historical Mapping for YearOfInterest,ReferenceYears,Metric,ReferencedImg,RSbins,StopPercentage,ReducedTimes=",YearOfInterest,ReferenceYears,Metric,ReferencedImg,RSbins,StopPercentage,ReducedTimes," took \t" + str(int((time.time() - t000)/60))," minutes", file=open(F3Log, 'a'))
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)    
        Content2 = "The error was for HistoricalAnnualProductCreation with inputs of " + repr(YearOfInterest)+","+repr(ReferenceYears)+","+repr(Metric)+","+","+repr(ReferencedImg)+","+repr(RSbins)+","+repr(StopPercentage)+","+repr(ReducedTimes)+" with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog






"""
def ShengliHuang_HistoricalAnnualProductCreationPrioritySequence(mylock,YearOfInterest,ReferenceYears,Metric,ReferencedImg, MinimumPixelNumber, StopPercentage):   #Originally I want to inlcude all Metrics in one function, but now I want to process only one metric at one time 
    try:
        #YearOfInterest = 2019
        #ReferenceYears = [2005, 2010, 2015, 2020]
        #ReferencedImg = "D:\\f3app\\RemoteSensingYear2014\\TilesMosaicRunAverage\\Area_Extent_650215.tif"   #We can change it later
        #Metric = "SLTSCB"
        t000 = time.time()
        print("In each bin, we will use reference years and the finer-to-coarser segmentation to fill the pixel in sequence")
        print("We do not use any average mean during the imputation. When imputed pixel % reach a threshold value, the code will stop. The purpose is to save the computation time")
        print("advatage: faster; disadvantage: very noise and results look not comfortable. This is why this function is discarded as of 20230526")
        RSbins = [6,3] #The vales must be from higher to lower (e.g., finer polygon to coarser polygon), 
        Reference = gdal.Open(ReferencedImg)   #ReferenceYearTif is the last one of 
        ReferenceCols = Reference.RasterXSize
        ReferenceRows = Reference.RasterYSize
        ReferenceArray = Reference.GetRasterBand(1).ReadAsArray()
        ReferenceNoDataValue = Reference.GetRasterBand(1).GetNoDataValue()
        WeUseThisProjection = Reference.GetProjectionRef()
        WeUseThisGeoTransform = Reference.GetGeoTransform()
        YearOfInterestImg = [
            os.path.dirname(os.getcwd())+os.sep+"Landsat_"+str(YearOfInterest)+"_red.tif",
            os.path.dirname(os.getcwd())+os.sep+"Landsat_"+str(YearOfInterest)+"_nir.tif",
            os.path.dirname(os.getcwd())+os.sep+"Landsat_"+str(YearOfInterest)+"_swir1.tif"    #we need cloud to detect the nodata 
            ]
        YearOfInterestImgQA = YearOfInterestImg[0].replace("red.tif","PixelLabel.tif")
        YearOfInterestImgQAarray = ImgRasterWithinTheExtentOfReferencedImage([YearOfInterestImgQA], ReferencedImg)
        YearOfInterestImgQAarray = YearOfInterestImgQAarray[0,:,:]  #This canot be skipped and is a must
        YearOfInterestImgArray = ImgRasterWithinTheExtentOfReferencedImage(YearOfInterestImg, ReferencedImg,YearOfInterestImgQA)
        YearOfInterestImgArray = ma.masked_values(YearOfInterestImgArray, F3NoDataValue)
        YearOfInterestImgArrayNew = YearOfInterestImgArray.copy()

        MetricArray = np.full(ReferenceArray.shape, F3NoDataValue)
        MetricArray = ma.masked_values(MetricArray, F3NoDataValue)
        
        ProcessedPixel = np.full(ReferenceArray.shape, 0)
        ProcessedPixel[ReferenceArray == ReferenceNoDataValue] = F3NoDataValue
        ProcessedPixel[YearOfInterestImgQAarray != 0] = F3NoDataValue ##"In the final PixelLabel.tif from GEE , water is 1, Perennial/permanent Ice/Snow is 2, Barren-Rock/Sand/Clay is 3, Landsat cloud/shadow/snow is 4, remaining value is 0"
        ProcessedPixel = ma.masked_values(ProcessedPixel, F3NoDataValue)
        ProcessedPixelTotal = ProcessedPixel.count()
        
        RSbinID = -1
        for RSbin in RSbins:
            RSbinID = RSbinID + 1
            Percentage = np.nansum(ProcessedPixel)/ProcessedPixelTotal*100
            print(RSbinID, "RSbin level start: ProcessedPixelSum=",np.nansum(ProcessedPixel)," out of ", ProcessedPixelTotal, " with a percentage of ", Percentage, " at ",datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))            
            print(RSbinID, "RSbin level start: ProcessedPixelSum=",np.nansum(ProcessedPixel)," out of ", ProcessedPixelTotal, " with a percentage of ", Percentage, " at ",datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"), file=open(F3Log, 'a'))
            if Percentage >= StopPercentage:
                print(RSbinID, "RSbin level stoped with a percentage of ", Percentage, ", because it is higher than the StopPercentage of ",StopPercentage, file=open(F3Log, 'a'))
                break
            YearOfInterestImgArrayNew[0,:,:] = ArrayBinnedWithConstantMinMax(YearOfInterestImgArray[0,:,:], 7400, 17000, RSbin) #For red: EndMax = 17000, EndMin = 7400. For nir, EndMax = 21000, EndMin = 11000. For swir1, EndMax = 22000, EndMin = 9300
            YearOfInterestImgArrayNew[1,:,:] = ArrayBinnedWithConstantMinMax(YearOfInterestImgArray[1,:,:], 11000, 21000, RSbin)
            YearOfInterestImgArrayNew[2,:,:] = ArrayBinnedWithConstantMinMax(YearOfInterestImgArray[2,:,:], 9300, 22000, RSbin)
            
            RemoteSensingSegmentationFromFineToCoarse = [   #2012 constant? or change? will check
                #os.path.dirname(os.getcwd())+os.sep+"Run1_Y"+str(ReferenceYears[min(0,len(ReferenceYears)-1)])+"_L1_S40_C18.tif",
                #os.path.dirname(os.getcwd())+os.sep+"Run1_Y"+str(ReferenceYears[min(0,len(ReferenceYears)-1)])+"_L2_S70_C16.tif",
                #os.path.dirname(os.getcwd())+os.sep+"Run1_Y"+str(ReferenceYears[min(0,len(ReferenceYears)-1)])+"_L3_S100_C14.tif",
                #os.path.dirname(os.getcwd())+os.sep+"Run1_Y"+str(ReferenceYears[min(0,len(ReferenceYears)-1)])+"_L4_S130_C12.tif",
                #os.path.dirname(os.getcwd())+os.sep+"Run1_Y"+str(ReferenceYears[min(0,len(ReferenceYears)-1)])+"_L5_S300_C10.tif"
                
                #os.path.dirname(os.getcwd())+os.sep+"Run1_Y"+str(ReferenceYears[min(0,len(ReferenceYears)-1)])+"_Level1_Snic40.tif",
                #os.path.dirname(os.getcwd())+os.sep+"Run1_Y"+str(ReferenceYears[min(0,len(ReferenceYears)-1)])+"_Level2_Snic70.tif",
                #os.path.dirname(os.getcwd())+os.sep+"Run1_Y"+str(ReferenceYears[min(0,len(ReferenceYears)-1)])+"_Level3_Snic100.tif",
                os.path.dirname(os.getcwd())+os.sep+"Run1_Y"+str(ReferenceYears[min(RSbinID,len(ReferenceYears)-1)])+"_Level4_Snic130.tif",
                os.path.dirname(os.getcwd())+os.sep+"Run1_Y"+str(ReferenceYears[min(RSbinID,len(ReferenceYears)-1)])+"_Level5_Snic400.tif"
                ]        
            RemoteSensingSegmentationFromFineToCoarseArray = ImgRasterWithinTheExtentOfReferencedImage(RemoteSensingSegmentationFromFineToCoarse, ReferencedImg)
            
            #This is to use Kirk's combine idea to replace the original large positive and negative value with the index. adopted on 20221202---start
            for n in range(0,RemoteSensingSegmentationFromFineToCoarseArray.shape[0],1):
                outdataNameArray = RemoteSensingSegmentationFromFineToCoarseArray[n,:,:].copy()
                outdataNameArrayshape = outdataNameArray.shape
                ListTifArray = []            
                klist = outdataNameArray.flatten().tolist()  
                ListTifArray.append(klist)  
                dLU = {t:i+1 for i, t in enumerate(set(zip(*ListTifArray)))}
                Final = np.array([dLU[T] for T in zip(*ListTifArray)]) #each pair has an Unique ID (0,1,2..... etc), and the ID will be given to the element
                outdataNameArray = Final.reshape(outdataNameArrayshape)
                RemoteSensingSegmentationFromFineToCoarseArray[n,:,:] = outdataNameArray.copy()
                #print("outdataNameArrayUniqueValues done ", " at " + datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")) 
            #This is to use Kirk's combine idea to replace the original large positive and negative value with the index. adopted on 20221202---end
            RemoteSensingSegmentationFromFineToCoarseArray = ma.masked_values(RemoteSensingSegmentationFromFineToCoarseArray, F3NoDataValue)

            ReferenceYearID = -1
            for ReferenceYear in ReferenceYears:
                ReferenceYearID = ReferenceYearID + 1
                Percentage = np.nansum(ProcessedPixel)/ProcessedPixelTotal*100
                print("---",RSbinID,"RSbinID & ",ReferenceYearID, "ReferenceYear level start: ProcessedPixelSum=",np.nansum(ProcessedPixel)," out of ", ProcessedPixelTotal, " with a percentage of ", Percentage, " at ",datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
                print("---",RSbinID,"RSbinID & ",ReferenceYearID, "ReferenceYear level start: ProcessedPixelSum=",np.nansum(ProcessedPixel)," out of ", ProcessedPixelTotal, " with a percentage of ", Percentage, " at ",datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"), file=open(F3Log, 'a'))
                if Percentage >= StopPercentage:
                    print("---",RSbinID,"RSbinID & ",ReferenceYearID, "ReferenceYear level stoped with a percentage of ", Percentage, ", because it is higher than the StopPercentage of ",StopPercentage, file=open(F3Log, 'a'))                    
                    break
                ReferenceYearImg = [
                    os.path.dirname(os.getcwd())+os.sep+"Landsat_"+str(ReferenceYear)+"_red.tif",  #The order of "red, nir, and swir1" is very important, because they correspond to the [0],[1],[2] below
                    os.path.dirname(os.getcwd())+os.sep+"Landsat_"+str(ReferenceYear)+"_nir.tif",
                    os.path.dirname(os.getcwd())+os.sep+"Landsat_"+str(ReferenceYear)+"_swir1.tif"
                    ]
                ReferenceYearImgQA = ReferenceYearImg[0].replace("red.tif","PixelLabel.tif")
                ReferenceYearImgArray = ImgRasterWithinTheExtentOfReferencedImage(ReferenceYearImg, ReferencedImg,ReferenceYearImgQA)
                ReferenceYearImgArray = ma.masked_values(ReferenceYearImgArray, F3NoDataValue)
                ReferenceYearImgArrayNew = ReferenceYearImgArray.copy()
                ReferenceYearImgArrayNew[0,:,:] = ArrayBinnedWithConstantMinMax(ReferenceYearImgArray[0,:,:], 7400, 17000, RSbin)  #For red: EndMax = 17000, EndMin = 7400. For nir, EndMax = 21000, EndMin = 11000. For swir1, EndMax = 22000, EndMin = 9300
                ReferenceYearImgArrayNew[1,:,:] = ArrayBinnedWithConstantMinMax(ReferenceYearImgArray[1,:,:], 11000, 21000, RSbin)
                ReferenceYearImgArrayNew[2,:,:] = ArrayBinnedWithConstantMinMax(ReferenceYearImgArray[2,:,:], 9300, 22000, RSbin)

                ReferenceYearMetric = os.path.dirname(os.getcwd())+os.sep+"RemoteSensingYear"+str(ReferenceYear)+os.sep+"TilesMosaicRunAverage"+os.sep+"NoMGT_"+str(ReferenceYear)+"_"+Metric.lower()+"_MosaicCellMean_Win3x3Smoothing.tif"
                ReferenceYearMetricArrayAAA = ImgRasterWithinTheExtentOfReferencedImage([ReferenceYearMetric], ReferencedImg)   #[ReferenceYearMetric] istead of ReferenceYearMetric
                ReferenceYearMetricArrayAAA = ma.masked_values(ReferenceYearMetricArrayAAA, F3NoDataValue)
                ReferenceYearMetricArray = ReferenceYearMetricArrayAAA[0,:,:]  #This sentence is imporant to make sure the shape changef from e.g., (1, 5042, 5794) to (5042, 5794)
                
                RemoteSensingSegmentationFromFineToCoarseArrayID = -1 
                for k in range(0,RemoteSensingSegmentationFromFineToCoarseArray.shape[0],1):
                    RemoteSensingSegmentationFromFineToCoarseArrayID = RemoteSensingSegmentationFromFineToCoarseArrayID + 1
                    Percentage = np.nansum(ProcessedPixel)/ProcessedPixelTotal*100
                    print("------",RSbinID,"RSbinID & ",ReferenceYearID, "ReferenceYear & ",RemoteSensingSegmentationFromFineToCoarseArrayID, "RemoteSensingSegmentationFromFineToCoarseArray level start: ProcessedPixelSum=",np.nansum(ProcessedPixel)," out of ", ProcessedPixelTotal, " with a percentage of ", Percentage, " at ",datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
                    print("------",RSbinID,"RSbinID & ",ReferenceYearID, "ReferenceYear & ",RemoteSensingSegmentationFromFineToCoarseArrayID, "RemoteSensingSegmentationFromFineToCoarseArray level start: ProcessedPixelSum=",np.nansum(ProcessedPixel)," out of ", ProcessedPixelTotal, " with a percentage of ", Percentage, " at ",datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"), file=open(F3Log, 'a'))
                    if Percentage >= StopPercentage:
                        print("------",RSbinID,"RSbinID & ",ReferenceYearID, "ReferenceYear & ",RemoteSensingSegmentationFromFineToCoarseArrayID, "RemoteSensingSegmentationFromFineToCoarseArray level stoped with a percentage of ", Percentage, ", because it is higher than the StopPercentage of ",StopPercentage, file=open(F3Log, 'a'))                    
                        break
                    t0 = time.time()  
                    ThisSeg = RemoteSensingSegmentationFromFineToCoarseArray[k,:,:]

                    ArrayLists0 = [YearOfInterestImgArrayNew[0,:,:],YearOfInterestImgArrayNew[1,:,:],YearOfInterestImgArrayNew[2,:,:],ThisSeg]
                    ArrayListsPath0 = os.path.dirname(os.getcwd())+os.sep+"RemoteSensingYear"+str(YearOfInterest)+os.sep+"TilesMosaicRunAverage"
                    YearOfInterestBinnedArray = RasterCombineToCreateFixedZoneValueFromArrays(ArrayLists0, ArrayListsPath0,ReferencedImg)
                    YearOfInterestBinnedArray[ProcessedPixel == 1] = F3NoDataValue  #If already processed, we masked it to save time
                    YearOfInterestBinnedArray = ma.masked_values(YearOfInterestBinnedArray, F3NoDataValue)

                    ArrayLists1 = [ReferenceYearImgArrayNew[0,:,:],ReferenceYearImgArrayNew[1,:,:],ReferenceYearImgArrayNew[2,:,:],ThisSeg]
                    ArrayListsPath1 = os.path.dirname(os.getcwd())+os.sep+"RemoteSensingYear"+str(ReferenceYear)+os.sep+"TilesMosaicRunAverage"
                    ReferenceYearBinnedArray = RasterCombineToCreateFixedZoneValueFromArrays(ArrayLists1, ArrayListsPath1,ReferencedImg)
                    ReferenceYearBinnedArray = ma.masked_values(ReferenceYearBinnedArray, F3NoDataValue)
                    print("------","New RasterCombineToCreateFixedZoneValueFromArrays for Metric=",Metric," k=",k," took \t" + str(int((time.time() - t0)/60))," minutes", file=open(F3Log, 'a'))

                    YearOfInterestBinnedArrayUnique = np.unique(YearOfInterestBinnedArray).astype('int64')
                    YearOfInterestBinnedArrayUniqueLength = len(YearOfInterestBinnedArrayUnique)
                    print("------","Please wait! This may take ", int((YearOfInterestBinnedArrayUniqueLength/1000) * 9)," minutes and the already-processed percentage is ", Percentage)
                    mid = -1
                    for m in YearOfInterestBinnedArrayUnique:
                        mid = mid + 1
                        if mid % 1000 == 0:
                            print("------","New historical mapping for Metric=",Metric,"k=",k," with progress of ", mid ,"/", YearOfInterestBinnedArrayUniqueLength, " took \t" + str(int((time.time() - t0)/60))," minutes")
                            print("------","New historical mapping for Metric=",Metric,"k=",k," with progress of ", mid ,"/", YearOfInterestBinnedArrayUniqueLength, " took \t" + str(int((time.time() - t0)/60))," minutes", file=open(F3Log, 'a'))
                        SelectPixelsFromReferenceMetric = ReferenceYearMetricArray[ReferenceYearBinnedArray == m]
                        if SelectPixelsFromReferenceMetric.count() >= MinimumPixelNumber:  #This is the minimum pixel numbers for the imputation
                            MetricArray[(YearOfInterestBinnedArray == m) & (ProcessedPixel == 0)] = np.nanmean(SelectPixelsFromReferenceMetric)
                    print("------","New historical mapping for Metric=",Metric,"k=",k," took \t" + str(int((time.time() - t0)/60))," minutes", file=open(F3Log, 'a'))
                    MetricArray[YearOfInterestImgQAarray != 0] = F3NoDataValue
                    MetricArray[ReferenceArray == ReferenceNoDataValue] = F3NoDataValue
                    MetricArray = ma.masked_values(MetricArray, F3NoDataValue)
                    ProcessedPixel[~MetricArray.mask] = 1

                    
                    
        MetricFinalPath = os.path.dirname(os.getcwd())+os.sep+"RemoteSensingYear"+str(YearOfInterest)+os.sep+"TilesMosaicRunAverage"
        if not os.path.exists(MetricFinalPath):
            os.makedirs(MetricFinalPath)            
        MetricFinalFile = MetricFinalPath + os.sep + "NoMGT_"+str(YearOfInterest)+"_"+Metric.lower()+"_MosaicCellMean_Win3x3Smoothing.tif"
        MetricFinal = MetricArray
        print("MetricArray min and max finally=",np.nanmin(MetricArray),np.nanmax(MetricArray), file=open(F3Log, 'a'))
        #We may need a 3x3 window average here later
        MetricFinalMin = np.nanmin(MetricFinal)
        MetricFinalMax = np.nanmax(MetricFinal)
        TypeOfInterest = OutputDataType(MetricFinalMin, MetricFinalMax)
        OutputGeoTifCompression = "Yes"
        driver = gdal.GetDriverByName("GTiff")
        if OutputGeoTifCompression == "Yes": #Added on 20230227. LZW compression does not lose information. LZW compression is a lossless data compression algorithm, which means that the original data can be fully reconstructed from the compressed data without any loss of information.
            outdata = driver.Create(MetricFinalFile, ReferenceCols, ReferenceRows, 1, TypeOfInterest, options=['COMPRESS=LZW'])   #see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
        if OutputGeoTifCompression == "No": 
            outdata = driver.Create(MetricFinalFile, ReferenceCols, ReferenceRows, 1, TypeOfInterest)   #see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
        print("SetGeoTransform and SetProjection usage, see http://www2.geog.ucl.ac.uk/~plewis/geogg122_local/geogg122-old/Chapter4_GDAL/GDAL_Python_bindings.html")
        outdata.SetGeoTransform(WeUseThisGeoTransform)  
        outdata.SetProjection(WeUseThisProjection)
        outdata.GetRasterBand(1).WriteArray(MetricFinal)
        outdata.GetRasterBand(1).SetNoDataValue(F3NoDataValue)   
        outdata.FlushCache()  
        outdata = None
        print("Historical Mapping for YearOfInterest,ReferenceYears,Metric,ReferencedImg=",YearOfInterest,ReferenceYears,Metric,ReferencedImg," took \t" + str(int((time.time() - t000)/60))," minutes", file=open(F3Log, 'a'))
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for HistoricalAnnualProductCreationPrioritySequence with inputs of " + repr(YearOfInterest)+","+repr(ReferenceYears)+","+","+repr(ReferencedImg)+" with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog
"""


def ImgRasterWithinTheExtentOfReferencedImage(ImgOfInterests, ReferencedImg, QualityImage=False):
    try:
        #print("ImgOfInterests=",ImgOfInterests)
        driverTiff = gdal.GetDriverByName('GTiff')
        ds = gdal.Open(ReferencedImg)   #ReferenceYearTif is the last one of 
        dsArray = ds.GetRasterBand(1).ReadAsArray()
        dsNoDataValue = ds.GetRasterBand(1).GetNoDataValue()
        srcCols = ds.RasterXSize
        srcRows = ds.RasterYSize
        #print("srcCols,srcRows=",srcCols,srcRows)
        #print("dsArray.shape=",dsArray.shape)
        WeUseThisProjection = ds.GetProjectionRef()
        WeUseThisGeoTransform = ds.GetGeoTransform()
        upx, xres, xskew, upy, yskew, yres = WeUseThisGeoTransform
        ulx = float(upx + 0*xres + 0*xskew)
        uly = float(upy + 0*yskew + 0*yres)
        llx = float(upx + 0*xres + srcRows*xskew) 
        lly = float(upy + 0*yskew + srcRows*yres)      
        lrx = float(upx + srcCols*xres + srcRows*xskew)
        lry = float(upy + srcCols*yskew + srcRows*yres)
        urx = float(upx + srcCols*xres + 0*xskew)
        ury = float(upy + srcCols*yskew + 0*yres)
        #print("ulx,uly,lrx,lry=",ulx,uly,lrx,lry)

        ImgOfInterestArrays = np.full((len(ImgOfInterests),srcRows,srcCols), F3NoDataValue)
        ImgOfInterestID = -1
        for ImgOfInterest in ImgOfInterests:
            #print("ImgOfInterest=",ImgOfInterest)
            ImgOfInterestID = ImgOfInterestID + 1
            ds1 = gdal.Open(ImgOfInterest)
            ImgOfInterestArray = ds1.GetRasterBand(1).ReadAsArray()  
            ImgOfInterestNoDataValue = ds1.GetRasterBand(1).GetNoDataValue()
            row,col = rasterio.open(ImgOfInterest).index(ulx, uly)
            ImgOfInterestArray = ImgOfInterestArray[row:row+srcRows,col:col+srcCols]
            ImgOfInterestArray[dsArray == dsNoDataValue] = F3NoDataValue
            
            if QualityImage:
                #print("QualityImage=",QualityImage)
                ds111 = gdal.Open(QualityImage)
                QualityImageArray = ds111.GetRasterBand(1).ReadAsArray() 
                QualityImageArray = QualityImageArray[row:row+srcRows,col:col+srcCols]
                ImgOfInterestArray[QualityImageArray != 0] = F3NoDataValue ##"In the final PixelLabel.tif from GEE , water is 1, Perennial/permanent Ice/Snow is 2, Barren-Rock/Sand/Clay is 3, Landsat cloud/shadow/snow is 4, remaining value is 0"

            ImgOfInterestArray[ImgOfInterestArray == ImgOfInterestNoDataValue] = F3NoDataValue
            ImgOfInterestArray = ma.masked_values(ImgOfInterestArray, F3NoDataValue)
            ImgOfInterestArrays[ImgOfInterestID,:,:] = ImgOfInterestArray  
        return ImgOfInterestArrays
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for ImgRasterWithinTheExtentOfReferencedImage with inputs of " + repr(ImgOfInterests)+","+repr(ReferencedImg)+" with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog

           

def AutomaticAnnualProductCreation(mylock,YearsOfAnnualChange,Metric):
    try:
        #step 1
        MosaicExtentTif = os.path.dirname(os.getcwd())+os.sep+'RemoteSensingYear2012'+os.sep+'TilesMosaicRunAverage'+os.sep+'NoMGT_2012_sltscb_MosaicCellMean_Win3x3Smoothing.tif'
        driverTiff = gdal.GetDriverByName('GTiff')
        ds = gdal.Open(MosaicExtentTif)
        dsArray = ds.GetRasterBand(1).ReadAsArray()
        srcCols = ds.RasterXSize
        srcRows = ds.RasterYSize
        print("srcCols,srcRows=",srcCols,srcRows)
        print("dsArray.shape=",dsArray.shape)
        WeUseThisProjection = ds.GetProjectionRef()
        WeUseThisGeoTransform = ds.GetGeoTransform()
        upx, xres, xskew, upy, yskew, yres = WeUseThisGeoTransform
        ulx = float(upx + 0*xres + 0*xskew)
        uly = float(upy + 0*yskew + 0*yres)
        llx = float(upx + 0*xres + srcRows*xskew) 
        lly = float(upy + 0*yskew + srcRows*yres)      
        lrx = float(upx + srcCols*xres + srcRows*xskew)
        lry = float(upy + srcCols*yskew + srcRows*yres)
        urx = float(upx + srcCols*xres + 0*xskew)
        ury = float(upy + srcCols*yskew + 0*yres)
        print("ulx,uly,lrx,lry=",ulx,uly,lrx,lry)


        #step2
        AnnualChangeRasters_all = np.full((len(YearsOfAnnualChange),srcRows,srcCols), F3NoDataValue)
        p = -1
        for Year in YearsOfAnnualChange:
            print("\n Year=",Year)
            p = p + 1
            ThisYearAnnualChange = os.path.dirname(os.getcwd())+os.sep+'FVStest'+os.sep+"ChangeFrom"+str(min(Year,2020))+"0101To"+str(min(Year,2020))+"1230.tif"
            ds1 = gdal.Open(ThisYearAnnualChange)
            ThisYearAnnualChangeArray = ds1.GetRasterBand(1).ReadAsArray().astype('int64')  #we have to use astype('int64') here; otherwise,the default may be int8, then assign value > 256 will cause problem
            ThisYearAnnualChangeNoDataValue = ds1.GetRasterBand(1).GetNoDataValue()
            
            row,col = rasterio.open(ThisYearAnnualChange).index(ulx, uly)
            print("row,col=",row,col)
            ThisYearAnnualChangeArraySelect = np.full((srcRows,srcCols), F3NoDataValue).astype('int64')
            ThisYearAnnualChangeArraySelect = ThisYearAnnualChangeArray[row:row+srcRows,col:col+srcCols]
            print("ThisYearAnnualChangeArraySelectUnique=",np.unique(ThisYearAnnualChangeArraySelect))
            ThisYearAnnualChangeArraySelectMasked = ma.masked_values(ThisYearAnnualChangeArraySelect, ThisYearAnnualChangeNoDataValue)
            print("ThisYearAnnualChangeArraySelectMasked.shape=",np.unique(ThisYearAnnualChangeArraySelectMasked.shape))
            print("ThisYearAnnualChangeArraySelectMasked.max=",np.nanmax(ThisYearAnnualChangeArraySelectMasked))
            print('Datatype for ThisYearAnnualChangeArraySelectMasked is:', ThisYearAnnualChangeArraySelectMasked.dtype)
            #See https://developers.google.com/earth-engine/datasets/catalog/USFS_GTAC_LCMS_v2021-7?hl=en#bands, #1:Stable, 2:Slow Loss, 3:Fast Loss, 4:Gain, 5:Non-Processing Area Mask")
            ThisYearAnnualChangeArraySelectMasked = np.where(ThisYearAnnualChangeArraySelectMasked == 3, Year, YearsOfAnnualChange[0])  #https://stackoverflow.com/questions/38059796/can-you-use-if-else-statement-inside-braces-for-an-array-in-python
            print("ThisYearAnnualChangeArraySelectMasked.max=",np.nanmax(ThisYearAnnualChangeArraySelectMasked))
            print("ThisYearAnnualChangeArraySelectMaskedUnique=",np.unique(ThisYearAnnualChangeArraySelectMasked))
            AnnualChangeRasters_all[p,:,:] = ThisYearAnnualChangeArraySelectMasked
        print("AnnualChangeRasters_all.shape=",AnnualChangeRasters_all.shape)
    
        #step3
        SpecificYearTifList = []
        for SpecificYear in YearsOfAnnualChange:
            SpecificYearRaster = np.full((srcRows,srcCols), F3NoDataValue)
            
            SpecificYearIndex = YearsOfAnnualChange.index(SpecificYear)
            print("SpecificYearIndex=",SpecificYearIndex)
            ClosestDisturbYear = np.nanmax(AnnualChangeRasters_all[0:SpecificYearIndex+1,:,:],axis=0)
            ClosestDisturbYearUnique = np.unique(ClosestDisturbYear)
            ClosestDisturbYearUniqueMax = max(ClosestDisturbYearUnique)
            for ThisDisturbYear in ClosestDisturbYearUnique:
                print("ThisDisturbYear=",str(ThisDisturbYear))
                print("SpecificYear=",str(SpecificYear))

                print("min(ThisDisturbYear, 2014) below is a special case; it will be changed based on the maximum value of RemoteSensingYearxxxx")
                SpecificMosaic = os.path.dirname(os.getcwd())+os.sep+'RemoteSensingYear'+str(min(ThisDisturbYear, 2014))+os.sep+'TilesMosaicRunAverage'+os.sep+'NoMGT_'+str(SpecificYear)+'_'+Metric.lower()+'_MosaicCellMean_Win3x3Smoothing.tif'

                print("SpecificMosaic=",SpecificMosaic)
                ds2 = gdal.Open(SpecificMosaic)
                SpecificMosaicArray = ds2.GetRasterBand(1).ReadAsArray()
                print("SpecificMosaicArray.shape=",SpecificMosaicArray.shape)
                SpecificMosaicNoDataValue = ds2.GetRasterBand(1).GetNoDataValue()
                SpecificYearRaster[ClosestDisturbYear == ThisDisturbYear] = SpecificMosaicArray[ClosestDisturbYear == ThisDisturbYear]

            driver = gdal.GetDriverByName("GTiff")
            SpecificYearTif = os.path.dirname(os.getcwd())+os.sep+"HistoricalAndActualAnnualProducts" + os.sep + "NoMGT_"+str(SpecificYear)+"_"+Metric.lower()+".tif"  #It was SpecificYearTif = os.path.dirname(os.getcwd())+os.sep+"F3Year_"+str(SpecificYear)+Metric.lower()+".tif"
            OutputGeoTifCompression = "Yes"
            if OutputGeoTifCompression == "Yes": #Added on 20230227. LZW compression does not lose information. LZW compression is a lossless data compression algorithm, which means that the original data can be fully reconstructed from the compressed data without any loss of information.
                outdata = driver.Create(SpecificYearTif, srcCols, srcRows, 1, gdal.GDT_Int32, options=['COMPRESS=LZW'])   #see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
            if OutputGeoTifCompression == "No": 
                outdata = driver.Create(SpecificYearTif, srcCols, srcRows, 1, gdal.GDT_Int32)   #see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
            outdata.SetGeoTransform(WeUseThisGeoTransform)  ##sets same geotransform as input
            outdata.SetProjection(WeUseThisProjection)  ##sets same projection as input
            outdata.GetRasterBand(1).WriteArray(SpecificYearRaster)
            outdata.GetRasterBand(1).SetNoDataValue(F3NoDataValue)  
            outdata.FlushCache() ##saves to disk!!
            outdata = None
            SpecificYearTifList.append(SpecificYearTif)
        print("SpecificYearTifList=",SpecificYearTifList)
        return SpecificYearTifList
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for AutomaticAnnualProductCreation with inputs of " + repr(YearsOfAnnualChange)+","+repr(Metric)+" with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog


def DownloadDataFromGoogleBucketToLocalDirectory(LocalDirectory, SourceBucketName, TargetFile):
    #20230428: Based on previous work(N:\project\f3_vol2\F3ArcPro2p5Python3Since20200724OnlyChangeByShengli\GCP_CloudBucket_20230420.py), using the gsuti to transfer the data between google bucket and local computer (can be down in two ways but here only one way. Note google SDK needs to be installed first)----start
    cwd = LocalDirectory
    gsutilCommand1AAA = "gsutil cp gs://"+SourceBucketName+'/' + TargetFile + ' .'   #This is to transfer the individual specific file to the working directory
    os.system(gsutilCommand1AAA)  #This will run the gsutilCommand to download the data from google cloud bucket
    print(gsutilCommand1AAA)
    print(ThisYearAnnualChange," was downloaded from google bucket ",SourceBucketName, " to local computer at ",cwd)
    #gsutilCommand1BBB ="gsutil cp gs://"+SourceBucketName+'/*' + ' .'   #This is to transfer all files (excluding subdirectory) to the working directory, which may be useful in the future
    #20230428: Based on previous work(N:\project\f3_vol2\F3ArcPro2p5Python3Since20200724OnlyChangeByShengli\GCP_CloudBucket_20230420.py), using the gsuti to transfer the data between google bucket and local computer (can be down in two ways but here only one way. Note google SDK needs to be installed first)----en      
    return TargetFile


def WeightInZone_function(ZoneInputTif,ZoneStatisticApproach,ZoneUniqueLength,PandasGroupbyAndWangNingThresholdValue,ZoneInputTifRasterDataArray1D,MaximumZoneNumber):
    try:
        ZoneInputTifRaster = gdal.Open(ZoneInputTif)
        ZoneInputTifRaster_ncol = ZoneInputTifRaster.RasterXSize
        ZoneInputTifRaster_nrow = ZoneInputTifRaster.RasterYSize
        ZoneInputTifRaster_bands = ZoneInputTifRaster.RasterCount
        ZoneInputTifRasterData = ZoneInputTifRaster.GetRasterBand(1)
        ZoneInputTifRasterDataNoDataValue = ZoneInputTifRasterData.GetNoDataValue()
        ZoneInputTifRasterDataArray = ZoneInputTifRasterData.ReadAsArray().astype('int64') 
        ZoneInputTifRasterDataMasked = ma.masked_values(ZoneInputTifRasterDataArray, ZoneInputTifRasterDataNoDataValue)

        WeightBasisTif = ZoneInputTif.replace(ZoneInputTif.split(os.sep)[-1],"BaseManagementBaseYearBaseMetricPlotDatabase_WeightBasisBasedOnStep2Pixel.tif")
        print("WeightBasisTif=",WeightBasisTif)
        WeightBasisTifArrayAAA = ReadTifToArray(WeightBasisTif)
        WeightBasisTifArray1D = WeightBasisTifArrayAAA.flatten()
            
        WeightInZoneTif = ZoneInputTif.replace(".tif","_WeightInZone.tif")
        if os.path.exists(WeightInZoneTif):
            WeightInZoneTifRaster = gdal.Open(WeightInZoneTif)
            WeightInZoneArray2D = WeightInZoneTifRaster.GetRasterBand(1).ReadAsArray()
            WeightInZone = WeightInZoneArray2D.flatten() 
        if not os.path.exists(WeightInZoneTif):
            if (ZoneStatisticApproach.lower() == "pandasgroupyby") or ((ZoneStatisticApproach.lower() == "hybrid") and (ZoneUniqueLength < PandasGroupbyAndWangNingThresholdValue)):
                #On 20240126: an error: module 'numpy' has no attribute 'float'.`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
                #so 20240126:  All dtype=np.float was changed to dtype=np.float64
                WeightBasisSumInZone = pd.Series(WeightBasisTifArray1D).groupby(ZoneInputTifRasterDataArray1D).transform(lambda x: x.sum(skipna=True)).to_numpy(dtype=np.float64,copy=True,na_value=F3NoDataValue)  #it is float here, not int64?
            if (ZoneStatisticApproach.lower() == "wangning") or ((ZoneStatisticApproach.lower() == "hybrid") and (ZoneUniqueLength >= PandasGroupbyAndWangNingThresholdValue)):
                WeightBasisSumInZone = ZonestatisFromWangNingSum(WeightBasisTifArray1D, ZoneInputTifRasterDataArray1D, "float", MaximumZoneNumber)
            WeightInZone = WeightBasisTifArray1D / WeightBasisSumInZone
            WeightInZone_2D = WeightInZone.reshape(ZoneInputTifRaster_nrow,ZoneInputTifRaster_ncol)
            WeightInZone_2D[ZoneInputTifRasterDataMasked.mask] = F3NoDataValue
            driver = gdal.GetDriverByName("GTiff")
            if OutputGeoTifCompression == "Yes": #Added on 20230227. LZW compression does not lose information. LZW compression is a lossless data compression algorithm, which means that the original data can be fully reconstructed from the compressed data without any loss of information.
                outdata = driver.Create(WeightInZoneTif, ZoneInputTifRaster_ncol, ZoneInputTifRaster_nrow, 1, gdal.GDT_Float32, options=['COMPRESS=LZW'])   #see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
            if OutputGeoTifCompression == "No": 
                outdata = driver.Create(WeightInZoneTif, ZoneInputTifRaster_ncol, ZoneInputTifRaster_nrow, 1, gdal.GDT_Float32)   #see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
            outdata.SetGeoTransform(ZoneInputTifRaster.GetGeoTransform())  ##sets same geotransform as input
            outdata.SetProjection(ZoneInputTifRaster.GetProjection())  ##sets same projection as input
            outdata.GetRasterBand(1).WriteArray(WeightInZone_2D)
            outdata.GetRasterBand(1).SetNoDataValue(F3NoDataValue)  
            outdata.FlushCache() ##saves to disk!!
            outdata = None
        print("WeightInZoneTif=",WeightInZoneTif, " and the corresponding shape of WeightInZone array are ", WeightInZone.shape)
        print("WeightInZoneTif=",WeightInZoneTif, " and the corresponding shape of WeightInZone array are ", WeightInZone.shape,file=open(F3Log, 'a'))
        return WeightInZone
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for WeightInZone_function with inputs of " + repr(ZoneInputTif)+","+repr(ZoneStatisticApproach)+","+repr(ZoneUniqueLength)+","+repr(PandasGroupbyAndWangNingThresholdValue)+","+repr(ZoneInputTifRasterDataArray1D.shape) + ","+repr(MaximumZoneNumber) + " with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog



def RatioInZone_function(ZoneInputTif,ZoneStatisticApproach,ZoneUniqueLength,PandasGroupbyAndWangNingThresholdValue,ZoneInputTifRasterDataArray1D,MaximumZoneNumber):
    try:
        ZoneInputTifRaster = gdal.Open(ZoneInputTif)
        ZoneInputTifRaster_ncol = ZoneInputTifRaster.RasterXSize
        ZoneInputTifRaster_nrow = ZoneInputTifRaster.RasterYSize
        ZoneInputTifRaster_bands = ZoneInputTifRaster.RasterCount
        ZoneInputTifRasterData = ZoneInputTifRaster.GetRasterBand(1)
        ZoneInputTifRasterDataNoDataValue = ZoneInputTifRasterData.GetNoDataValue()
        ZoneInputTifRasterDataArray = ZoneInputTifRasterData.ReadAsArray().astype('int64') 
        ZoneInputTifRasterDataMasked = ma.masked_values(ZoneInputTifRasterDataArray, ZoneInputTifRasterDataNoDataValue)

        FieldMetricPredictedOutputFile = ZoneInputTif.replace(ZoneInputTif.split(os.sep)[-1],"BaseManagementBaseYearBaseMetricPlotDatabase_RegressionPredicted.tif")
        FieldMetricPredictedOutputFileAAA = ReadTifToArray(FieldMetricPredictedOutputFile).astype('int64')
        FieldMetricPredictedOutputArray1D = FieldMetricPredictedOutputFileAAA.flatten()
        
        RatioInZoneTif = ZoneInputTif.replace(".tif","_RatioInZone.tif")
        if os.path.exists(RatioInZoneTif):
            RatioInZoneTifRaster = gdal.Open(RatioInZoneTif)
            RatioInZoneArray2D = RatioInZoneTifRaster.GetRasterBand(1).ReadAsArray()
            RatioInZone = RatioInZoneArray2D.flatten() 
        if not os.path.exists(RatioInZoneTif):
            if (ZoneStatisticApproach.lower() == "pandasgroupyby") or ((ZoneStatisticApproach.lower() == "hybrid") and (ZoneUniqueLength < PandasGroupbyAndWangNingThresholdValue)):
                FieldMetricPredictedOutputArray1DMeanInZone = pd.Series(FieldMetricPredictedOutputArray1D).groupby(ZoneInputTifRasterDataArray1D).transform(lambda x: x.mean(skipna=True)).to_numpy(dtype=np.int64,copy=True,na_value=F3NoDataValue)
            if (ZoneStatisticApproach.lower() == "wangning") or ((ZoneStatisticApproach.lower() == "hybrid") and (ZoneUniqueLength >= PandasGroupbyAndWangNingThresholdValue)):
                FieldMetricPredictedOutputArray1DMeanInZone = ZonestatisFromWangNingMean(FieldMetricPredictedOutputArray1D, ZoneInputTifRasterDataArray1D, "int64", MaximumZoneNumber)   
            RatioInZone = FieldMetricPredictedOutputArray1D / FieldMetricPredictedOutputArray1DMeanInZone
            RatioInZone[RatioInZone > 1.5] = 1.5    #added on 20230123
            RatioInZone[RatioInZone < 0.5] = 0.5    #added on 20230123
            RatioInZone_2D = RatioInZone.reshape(ZoneInputTifRaster_nrow,ZoneInputTifRaster_ncol)
            RatioInZone_2D[ZoneInputTifRasterDataMasked.mask] = F3NoDataValue
            driver = gdal.GetDriverByName("GTiff")
            if OutputGeoTifCompression == "Yes": #Added on 20230227. LZW compression does not lose information. LZW compression is a lossless data compression algorithm, which means that the original data can be fully reconstructed from the compressed data without any loss of information.
                outdata = driver.Create(RatioInZoneTif, ZoneInputTifRaster_ncol, ZoneInputTifRaster_nrow, 1, gdal.GDT_Float32, options=['COMPRESS=LZW'])   #see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
            if OutputGeoTifCompression == "No": 
                outdata = driver.Create(RatioInZoneTif, ZoneInputTifRaster_ncol, ZoneInputTifRaster_nrow, 1, gdal.GDT_Float32)   #see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
            outdata.SetGeoTransform(ZoneInputTifRaster.GetGeoTransform())  ##sets same geotransform as input
            outdata.SetProjection(ZoneInputTifRaster.GetProjection())  ##sets same projection as input
            outdata.GetRasterBand(1).WriteArray(RatioInZone_2D)
            outdata.GetRasterBand(1).SetNoDataValue(F3NoDataValue)  
            outdata.FlushCache() ##saves to disk!!
            outdata = None
        print("RatioInZoneTif=",RatioInZoneTif, " and the corresponding shape of RatioInZone array are ", RatioInZone.shape)
        print("RatioInZoneTif=",RatioInZoneTif, " and the corresponding shape of RatioInZone array are ", RatioInZone.shape,file=open(F3Log, 'a'))
        return RatioInZone
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"   
        #print(Content1)
        Content2 = "The error was for RatioInZone_function with inputs of " +repr(ZoneInputTif)+","+repr(ZoneStatisticApproach)+","+repr(ZoneUniqueLength)+","+repr(PandasGroupbyAndWangNingThresholdValue)+","+repr(FieldMetricPredictedOutputArray1D.shape)+ ","+repr(MaximumZoneNumber) + " with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog

    

def PandasGroupbyAndWangNingThreshold(LengthOf1DArray):
    try:
        #print("It turns out that WangNing's approach is faster than PandasGroupBy after a threshold value of ZoneNumber. Before this value, WangNing's approach is slower than PandasGroupBy. This threold value changeds depending on the length of 1D array (i.e., F3 tile rows x columns)")
        #print("Therefore, this function determine the threshold value from LengthOf1DArray. The rules come from the following code that was developed by WangNing and Shengli in December 2022 in Groveland, CA")

        ###The section is the code to help the rules used for determining the threshold value from LengthOf1DArray. It is copied here as a record----start
        ##for dimension in [2000, 4000, 6000, 8000, 10000]:
        ##    #for groupsize in [6, 600, 6000, 60000, 600000, 1000000, 2000000, 4000000, 6000000, 8000000, 10000000]:  #This simuates unique group up to 10 millions
        ##    for groupsize in [6000, 10000, 20000, 40000, 60000, 80000, 100000, 200000, 300000, 400000, 500000, 600000, 1000000]:  #This simuates unique group up to 10 millions         
        ##        print("\ndimension * dimension=",dimension * dimension, " and groupsize=",groupsize)
        ##
        ##        t0 = time.time()
        ##        print("t0=",t0)
        ##        a=np.random.randint(300,size=dimension*dimension)   #This simuates an array with length about 100000000 (100 millions)  100000000
        ##        a[a < 150] = -9999
        ##        b=np.random.randint(groupsize,size=dimension*dimension)
        ##        bmax = np.max(b) + 1
        ##        #b = ma.masked_inside(b,int(groupsize/3),int(groupsize/2))
        ##        #print("a=",a)
        ##        #print("b=",b)
        ##        print("creating testing array took \t" + str(int((time.time() - t0)))," seconds")
        ##
        ##        #-----------------------------------------------------
        ##        t11 = time.time()
        ##        MAX_VALUE = 100_000_000_000
        ##        MAX_INDEX = bmax
        ##        sum_arr = [0] * MAX_INDEX
        ##        count_arr = [0] * MAX_INDEX
        ##        min_arr = [MAX_VALUE] * MAX_INDEX
        ##        max_arr = [0] * MAX_INDEX
        ##
        ##        # zip(b, a) = [(1, 3), (3, 1), (2, 2), (1, 6), (2, 5), (3, 3), (3, 4), (3, 4), (2, 8), (1, 9)]
        ##        for v in zip(b, a):
        ##            index = v[0] - 1
        ##            value = v[1]
        ##            if (value != -9999):
        ##                sum_arr[index] += value
        ##                count_arr[index] += 1
        ##                #min_arr[index] = min(min_arr[index], value)
        ##                #max_arr[index] = max(max_arr[index], value)        
        ##
        ##        #sum_res = [sum_arr[idx - 1] for idx in b]
        ##        #min_res = [min_arr[idx - 1] for idx in b]
        ##        #max_res = [max_arr[idx - 1] for idx in b]
        ##        avg_res = [sum_arr[idx - 1] / count_arr[idx - 1] if count_arr[idx - 1] > 0 else -999 for idx in b]
        ##        print("wang ning's idea took \t" + str(int((time.time() - t11)))," seconds")
        ##        WangNingTime = int((time.time() - t11))
        ##        #-----------------------------------------------------
        ##
        ##        t4 = time.time()
        ##        c = pd.Series(a).groupby(b).transform(lambda x: x.mean(skipna=True)).to_numpy(dtype=np.int64,copy=True,na_value=-9999)
        ##        print("Shengli's approach using np.mean took \t" + str(int((time.time() - t4)))," seconds")
        ##        ShengliTime = int((time.time() - t4))
        ##
        ##        if WangNingTime < ShengliTime:
        ##            print("\n\n\n")
        ##            break    
        ###The section is the code to help the rules used for determining the threshold value from LengthOf1DArray. It is copied here as a record----end

        if LengthOf1DArray < 1000 * 1000:
            PandasGroupbyAndWangNingThresholdValue = 20000
        elif ((LengthOf1DArray >= 1000 * 1000) and (LengthOf1DArray < 2000 * 2000)):
            PandasGroupbyAndWangNingThresholdValue = 30000
        elif ((LengthOf1DArray >= 2000 * 2000) and (LengthOf1DArray < 3000 * 3000)):
            PandasGroupbyAndWangNingThresholdValue = 60000        
        elif ((LengthOf1DArray >= 3000 * 3000) and (LengthOf1DArray < 4000 * 4000)):
            PandasGroupbyAndWangNingThresholdValue = 100000
        elif ((LengthOf1DArray >= 4000 * 4000) and (LengthOf1DArray < 5000 * 5000)):
            PandasGroupbyAndWangNingThresholdValue = 150000
        elif ((LengthOf1DArray >= 5000 * 5000) and (LengthOf1DArray < 6000 * 6000)):
            PandasGroupbyAndWangNingThresholdValue = 200000
        elif ((LengthOf1DArray >= 6000 * 6000) and (LengthOf1DArray < 7000 * 7000)):
            PandasGroupbyAndWangNingThresholdValue = 300000
        elif ((LengthOf1DArray >= 7000 * 7000) and (LengthOf1DArray < 8000 * 8000)):
            PandasGroupbyAndWangNingThresholdValue = 400000
        elif ((LengthOf1DArray >= 8000 * 8000) and (LengthOf1DArray < 9000 * 9000)):
            PandasGroupbyAndWangNingThresholdValue = 500000        
        elif ((LengthOf1DArray >= 9000 * 9000) and (LengthOf1DArray < 10000 * 10000)):
            PandasGroupbyAndWangNingThresholdValue = 600000
        else:
            PandasGroupbyAndWangNingThresholdValue = 700000
        #print("LengthOf1DArray and PandasGroupbyAndWangNingThresholdValue are: ",LengthOf1DArray,PandasGroupbyAndWangNingThresholdValue)
        print("LengthOf1DArray and PandasGroupbyAndWangNingThresholdValue are: ",LengthOf1DArray,PandasGroupbyAndWangNingThresholdValue,file=open(F3Log, 'a'))
        return PandasGroupbyAndWangNingThresholdValue
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for PandasGroupbyAndWangNingThreshold with inputs of "+repr(LengthOf1DArray)+" with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog


        
def ZonestatisFromWangNingMean(InputArray, ZoneArray, OutputType, MaximumZoneNumber):
    try:
        print("1 MaximumZoneNumber=",MaximumZoneNumber)
        InputArray[InputArray.mask] = F3NoDataValue  #np.ma.set_fill_value(InputArray, F3NoDataValue) is the original sentence, but the speed is very slow, so InputArray[InputArray.mask] = F3NoDataValue is used here to speed up (almost 20 times faster)
        MAX_VALUE = 100_000_000_000
        MAX_INDEX = MaximumZoneNumber   #MAX_INDEX = 10_000_000       #MAX_INDEX = np.max(ZoneArray) + 1
        sum_arr = [0] * MAX_INDEX
        count_arr = [0] * MAX_INDEX
        #min_arr = [MAX_VALUE] * MAX_INDEX
        #max_arr = [0] * MAX_INDEX
        
        for v in zip(ZoneArray, InputArray):
            index = v[0] - 1
            value = v[1]
            if (value != F3NoDataValue):
                sum_arr[index] += value
                count_arr[index] += 1
                #min_arr[index] = min(min_arr[index], value)
                #max_arr[index] = max(max_arr[index], value)        

        #sum_res = [sum_arr[idx - 1] for idx in ZoneArray]
        #min_res = [min_arr[idx - 1] for idx in ZoneArray]
        #max_res = [max_arr[idx - 1] for idx in ZoneArray]
        avg_res = [sum_arr[idx - 1] / count_arr[idx - 1] if count_arr[idx - 1] > 0 else F3NoDataValue for idx in ZoneArray]
        if ((OutputType.lower() == "float") or (OutputType.lower() == "float64")):        
            avg_res = ma.masked_values(avg_res, F3NoDataValue).astype(np.float64) #20240126: np.float to np.float64
        elif OutputType.lower() == "int64":        
            avg_res = ma.masked_values(avg_res, F3NoDataValue).astype(np.int64)       
        else:
            avg_res = ma.masked_values(avg_res, F3NoDataValue).astype(np.int32)
        print("ZonestatisFromWangNingMean has a shape of ",avg_res.shape)
        print("ZonestatisFromWangNingMean has a shape of ",avg_res.shape,file=open(F3Log, 'a'))
        return avg_res
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for ZonestatisFromWangNingMean with inputs of "+repr(InputArray.shape)+repr(ZoneArray.shape)+repr(OutputType)+repr(MaximumZoneNumber)+" with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog



def ZonestatisFromWangNingSum(InputArray, ZoneArray, OutputType, MaximumZoneNumber):
    try:
        print("2 MaximumZoneNumber=",MaximumZoneNumber)
        InputArray[InputArray.mask] = F3NoDataValue  #np.ma.set_fill_value(InputArray, F3NoDataValue) is the original sentence, but the speed is very slow, so InputArray[InputArray.mask] = F3NoDataValue is used here to speed up (almost 20 times faster)
        MAX_VALUE = 100_000_000_000
        MAX_INDEX = MaximumZoneNumber   #MAX_INDEX = 10_000_000
        sum_arr = [0] * MAX_INDEX
        count_arr = [0] * MAX_INDEX
        #min_arr = [MAX_VALUE] * MAX_INDEX
        #max_arr = [0] * MAX_INDEX
        
        for v in zip(ZoneArray, InputArray):
            index = v[0] - 1
            value = v[1]
            if (value != F3NoDataValue):
                sum_arr[index] += value
                count_arr[index] += 1
                #min_arr[index] = min(min_arr[index], value)
                #max_arr[index] = max(max_arr[index], value)        

        #min_res = [min_arr[idx - 1] for idx in ZoneArray]
        #max_res = [max_arr[idx - 1] for idx in ZoneArray]
        sum_res = [sum_arr[idx - 1] if count_arr[idx - 1] > 0 else F3NoDataValue for idx in ZoneArray]      
        if ((OutputType.lower() == "float") or (OutputType.lower() == "float64")):        
            sum_res = ma.masked_values(sum_res, F3NoDataValue).astype(np.float64) #20240126: np.float to np.float64
        elif OutputType.lower() == "int64":        
            sum_res = ma.masked_values(sum_res, F3NoDataValue).astype(np.int64)       
        else:
            sum_res = ma.masked_values(sum_res, F3NoDataValue).astype(np.int32)    
        print("ZonestatisFromWangNingSum has a shape of ",sum_res.shape)
        print("ZonestatisFromWangNingSum has a shape of ",sum_res.shape,file=open(F3Log, 'a'))
        return sum_res    
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for ZonestatisFromWangNingSum with inputs of "+repr(InputArray.shape)+repr(ZoneArray.shape)+repr(OutputType)+repr(MaximumZoneNumber)+" with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog


def EncryptFile(Input):  #https://www.geeksforgeeks.org/encrypt-and-decrypt-files-using-python/
    try:
        key = Fernet.generate_key()
        InputKeyFile = Input + "key"
        if not os.path.exists(InputKeyFile):
            with open(InputKeyFile, 'wb') as filekey:
                filekey.write(key)
        else:
            print("We do not need to create the the associated key file of ", InputKeyFile, " for the file of ",Input)
        
        # Opening the key file and opening the original file
        with open(InputKeyFile, 'rb') as filekey:
                key = filekey.read()
        fernet = Fernet(key)
        with open(Input, 'rb') as file:
                original = file.read()
        # Writing the encrypted data to the original file
        encrypted = fernet.encrypt(original)
        with open(Input, 'wb') as encrypted_file:
                encrypted_file.write(encrypted)
        print("We encrypted the original file of ", Input, " with the generated key file of ",InputKeyFile)
        return Input    
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for EncryptFile with inputs of "+repr(Input)+" with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog

    
def DecryptFile(Input):  #https://www.geeksforgeeks.org/encrypt-and-decrypt-files-using-python/
    try:
        # using the key
        InputKeyFile = Input + "key"
        if not os.path.exists(InputKeyFile):
            print("There is no associated key file called ",InputKeyFile," so we cannot proceeed. Please contact Dr. Shengli Huang (shengli.huang@usda.gov)!")
        else:
            with open(InputKeyFile, 'rb') as filekey:
                    key = filekey.read()    
        fernet = Fernet(key)   #note sure if this is correct! Where is the key from?
        with open(Input, 'rb') as enc_file:
                encrypted = enc_file.read()
        decrypted = fernet.decrypt(encrypted)
        with open(Input, 'wb') as dec_file:
                dec_file.write(decrypted)
        print("We decrypted the file of ", Input, " with its associated key file of ", InputKeyFile)
        return Input
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for DecryptFile with inputs of "+repr(Input)+" with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog

def EncryptImage(Input):  #https://www.geeksforgeeks.org/encrypt-and-decrypt-image-using-python/?ref=rp
    try:
        key = np.random.randint(1,30)
        print("key=",key)
        InputKey = Input.replace(".tif",".key")
        InputKeyFile = open(InputKey, 'w')
        InputKeyFile.write(str(key))
        InputKeyFile.close()
        
        fin = open(Input, 'rb')
        image = fin.read()
        fin.close()
        image = bytearray(image)
        for index, values in enumerate(image):
                image[index] = values ^ key
        fin = open(Input, 'wb')
        fin.write(image)
        fin.close()
        print("We encrypted the original file of ", Input, " with the key value of ", key, " recorded in ",InputKey)
        return Input
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for EncryptImage with inputs of "+repr(Input)+" with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog

def DecryptImage(Input):  #https://www.geeksforgeeks.org/encrypt-and-decrypt-image-using-python/?ref=rp
    try:
        InputKey = Input.replace(".tif",".key")
        InputKeyFile = open(InputKey, 'r')
        Content = InputKeyFile.read()
        print("Content is: ",Content)
        key = int(Content)
        print("key is: ",key)
        InputKeyFile.close()
            
        fin = open(Input, 'rb')
        image = fin.read()
        fin.close()
        image = bytearray(image)
        for index, values in enumerate(image):
                image[index] = values ^ key
        fin = open(Input, 'wb')
        fin.write(image)
        fin.close()
        return Input
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for DecryptImage with inputs of "+repr(Input)+" with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog

    
def ZonestatisFromWangNingCount(InputArray, ZoneArray, OutputType, MaximumZoneNumber):
    try:
        print("3 MaximumZoneNumber=",MaximumZoneNumber)
        InputArray[InputArray.mask] = F3NoDataValue  #np.ma.set_fill_value(InputArray, F3NoDataValue) is the original sentence, but the speed is very slow, so InputArray[InputArray.mask] = F3NoDataValue is used here to speed up (almost 20 times faster)
        MAX_VALUE = 100_000_000_000
        MAX_INDEX = MaximumZoneNumber   #MAX_INDEX = 10_000_000
        sum_arr = [0] * MAX_INDEX
        count_arr = [0] * MAX_INDEX
        #min_arr = [MAX_VALUE] * MAX_INDEX
        #max_arr = [0] * MAX_INDEX
        
        for v in zip(ZoneArray, InputArray):
            index = v[0] - 1
            value = v[1]
            if (value != F3NoDataValue):
                sum_arr[index] += value
                count_arr[index] += 1
                #min_arr[index] = min(min_arr[index], value)
                #max_arr[index] = max(max_arr[index], value)        

        #min_res = [min_arr[idx - 1] for idx in ZoneArray]
        #max_res = [max_arr[idx - 1] for idx in ZoneArray]
        count_res = [count_arr[idx - 1] if count_arr[idx - 1] > 0 else F3NoDataValue for idx in ZoneArray]
        if ((OutputType.lower() == "float") or (OutputType.lower() == "float64")):        
            count_res = ma.masked_values(count_res, F3NoDataValue).astype(np.float64)  #20240126: np.float to np.float64
        elif OutputType.lower() == "int64":        
            count_res = ma.masked_values(count_res, F3NoDataValue).astype(np.int64)       
        else:
            count_res = ma.masked_values(count_res, F3NoDataValue).astype(np.int32)
        print("ZonestatisFromWangNingCount has a shape of ",count_res.shape)
        print("ZonestatisFromWangNingCount has a shape of ",count_res.shape,file=open(F3Log, 'a'))
        return count_res  
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for ZonestatisFromWangNingCount with inputs of "+repr(InputArray.shape)+repr(ZoneArray.shape)+repr(OutputType)+repr(MaximumZoneNumber)+" with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog
    




def GeoTifMetadataUpdate(GeotifFile, MetadataFromPythonDict):
    try:
        print("20230928: I do think a HTML file is the best option, because it is easy to create and also easy to read and replace")
        print("We can create a template in HTML or XML format, and then read the file as a text string and replace() it. For example [replace $RESOLUTION$ with str(resolution)] in python. In this case, we do nto need any third-parth module to do it")
        print("see Chris Teams message on 202303/15 at 10:08 AM for https://pypi.org/project/gis-metadata-parser/. Also see his email dated Wed 3/8/2023 11:18 AM")
        
        print("\n\n$$$$$$$$$$ We can update the Geotif metadata using gdal, but the meta is not visible in ArcGIS while it is visible in QGIS$$$$$$$$$$$$")
        ##There could be several reasons why updated metadata in a GeoTIFF file using GDAL may not be visible in ArcGIS. Here are some possible explanations:
        ##ArcGIS may be reading cached metadata: ArcGIS may be reading previously cached metadata from its internal metadata store instead of directly reading the updated metadata from the GeoTIFF file. You can try clearing the metadata cache in ArcGIS to see if that resolves the issue.
        ##Different metadata schemas: GDAL and ArcGIS may be using different metadata schemas, which could cause issues with how metadata is interpreted and displayed. To ensure compatibility, it's recommended to use a common metadata standard, such as ISO 19115, and follow best practices for metadata creation and management.
        ##Incorrect metadata format: GDAL may have updated the metadata in a format that is not recognized by ArcGIS. ArcGIS may only recognize certain metadata formats or elements, so it's important to ensure that the metadata is in a format that ArcGIS can read.
        ##File locking: If the GeoTIFF file is currently open or being used by another process, ArcGIS may not be able to access the updated metadata. Make sure the file is not locked by any other process or application.
        ##Software version compatibility: It's possible that the version of GDAL and ArcGIS being used are not compatible, which could cause issues with metadata display and interpretation. Make sure you are using the latest versions of both software packages and check for any known compatibility issues.

        ##The Federal Geographic Data Committee (FGDC) has defined a set of required and optional fields for FGDC metadata.
        ##The following is a list of the required fields:
        ##idinfo/citation/citeinfo/title: The title of the dataset.
        ##idinfo/descript/purpose: A brief description of the purpose of the dataset.
        ##idinfo/timeperd/timeinfo/rngdates/begdate: The beginning date of the temporal extent of the dataset.
        ##idinfo/timeperd/timeinfo/rngdates/enddate: The ending date of the temporal extent of the dataset.
        ##dataqual/lineage: A description of the lineage of the dataset, including the source data and processing steps used to create the dataset.
        ##spatialref: The spatial reference information for the dataset.
        ##In addition to the required fields, there are many optional fields that can be included in FGDC metadata to provide additional information about the dataset. Some of the most commonly used optional fields include:
        ##idinfo/citation/citeinfo/origin: The originator of the dataset.
        ##idinfo/citation/citeinfo/pubdate: The date the dataset was published or last updated.
        ##idinfo/descript/abstract: A more detailed description of the dataset.
        ##idinfo/keywords: A list of keywords or phrases that describe the dataset.
        ##idinfo/status: The status of the dataset (e.g. completed, in progress).
        ##accconst: Access constraints on the dataset (e.g. restrictions on use or distribution).
        ##useconst: Conditions or limitations on the use of the dataset.
        ##distinfo: Information about the distribution of the dataset, including the responsible organization and contact information.
        ##It's important to note that while some fields are required by the FGDC standard, the specific requirements for metadata may vary depending on the data source, intended use, and other factors.

        """
        Here's a list of the FGDC metadata fields, separated into required and optional fields (from ChatGPT):

        Required Fields:

        Identification Information

        Title
        Abstract
        Purpose
        Credit
        Point of Contact
        Maintenance
        Keywords
        Theme
        Place Keywords
        Temporal Keywords
        Access Constraints
        Use Constraints
        Data Set Language
        Data Quality Information

        Positional Accuracy
        Attribute Accuracy
        Logical Consistency
        Completeness
        Lineage
        Spatial Data Organization Information

        Direct Spatial Reference Method
        Spatial Reference Information
        Grid Coordinate System
        Topological Consistency
        Spatial Reference Information

        Spatial Reference System
        Map Projection
        Grid Coordinate System
        Geographic Extent
        Entity and Attribute Information

        Detailed Description
        Entity Type
        Attribute
        Attribute Label
        Attribute Definition
        Attribute Domain Values
        Distribution Information

        Distribution Format
        Distributor
        Transfer Options
        Online Resource
        Offline Resource
        Distribution Liability
        Metadata Reference Information

        Metadata Standard
        Metadata Time Stamp
        Contact
        Metadata Access Constraints
        Optional Fields:

        Identification Information

        Native Data Set Environment
        Supplemental Information
        Data Quality Information

        Positional Accuracy Explanation
        Attribute Accuracy Explanation
        Logical Consistency Explanation
        Completeness Explanation
        Horizontal Positional Accuracy
        Vertical Positional Accuracy
        Point Positional Accuracy
        Lineage Statements
        Process Step
        Source Citation
        Spatial Data Organization Information

        Spatial Representation Type
        Vector Information
        Geometric Objects
        Geometric Object Count
        Entity and Attribute Information

        Attribute Measurement Frequency
        Attribute Measurement Type
        Attribute Accuracy Assessment
        Entity and Attribute Overview
        Distribution Information

        Standard Order Process
        Digital Transfer Options
        Metadata Reference Information

        Metadata Review Date
        Metadata Contact Role
        Metadata Metadata Standard Version
        Metadata Profile Version
        These fields provide a standardized way to describe geospatial data and ensure that important information is included in metadata records.
        """


        """
        print("Below is the code showing how to use dict for FGDC in geotif")
        print("\n20230223 notes: 1) FGDC is one kind of metadata; 2) Sometimes meta data updated by gdal is not visible in ArcGIS with the reason of version and compatible: 3)Gdal itself also different versions supporting different functions")
        print("gdal version is ",gdal.VersionInfo())
        MyFile = "D:\f3app\HuangTest2\TilesMosaicRunAverage\MosaicPixelLabel.tif"

        print("\ngdalinfo below---------------------------------------")
        gdalinfo_output = subprocess.check_output(["gdalinfo", MyFile])
        gdalinfo_output = gdalinfo_output.decode("utf-8")
        print(gdalinfo_output)
        
        print("\nbandinfo below---------------------------------------")        
        dataset = gdal.Open(MyFile, gdal.GA_Update) #dataset.SetMetadataDomain('FGDC')  # Error is [no attribute 'SetMetadataDomain']. The SetMetadataDomain method is only available in GDAL version 3.3.0 or later. To resolve this issue, you can either upgrade your GDAL version to 3.3.0 or later, or you can use a different method to set the metadata domain. In earlier versions of GDAL, you can set the metadata domain using the SetMetadataItem method. 
        band = dataset.GetRasterBand(1)
        band.SetMetadataItem('Description', 'This is the first band from Shengli')
        print(band.GetMetadata())

        # Get metadata for a specific domain
        image_structure_metadata = dataset.GetMetadata("IMAGE_STRUCTURE")
        print("image_structure_metadata=",image_structure_metadata)

        print("\nGetDescription below---------------------------------------")
        MyDescription = dataset.GetDescription()
        print(MyDescription)

        print("\nhahahah meta below1---------------------------------------")  
        dataset.SetMetadataItem('Developer', 'Huang Shengli')  #set a metadata item named "Developer" to "Huang Shengli"
        dataset.SetMetadataItem('FGDC', 'This is the FGDC metadata')

        MetaDataBeforeEdit = dataset.GetMetadata()
        print("MetaDataBeforeEdit is:",MetaDataBeforeEdit)

        print("\nFGDC meta below1---------------------------------------")        
        MaoShi = dataset.GetMetadataItem('FGDC')  #metadata = dataset.GetMetadata('xml:FGDC') does not work
        print("MaoShi is:",MaoShi)

        print("\nSet FGDC metadata below-----------------")
        MyTile = 'F3 Raster Dataset produced by Dr. Helen'
        Beef = {
            'title': MyTile,
            'description': 'This is Jacey',
            'Huang Family': 'a)Come from China for a life in the U.S.; \n b) starting life is hard; \n c) But become better'
        }
        print(len(Beef))
        print(Beef.items())
        print(Beef.keys())
        print(Beef.values())
        print(Beef.get('title', 'This value does not exist'))
        print("***********************")
        for x in Beef:
          print(x)
        print("***********************")
        for x in Beef:
          print(Beef[x])
        print("***********************")
        for x in Beef.values():
          print(x)
        print("***********************")
        for x, y in Beef.items():
          print(x, y) 
        print("***********************")
        dataset.SetMetadata(Beef)

        MetaDataAfterEdit = dataset.GetMetadata()
        print("MetaDataAfterEdit is:",MetaDataAfterEdit)

        print("\nDuck  meta below1---------------------------------------")        
        Duck = dataset.GetMetadataItem('Huang Family')  #metadata = dataset.GetMetadata('xml:FGDC') does not work
        print("Duck is:",Duck)

        dataset = None
        """
        

    
        #Find the required field names of FGDC; 2) add \n for multiple lines (tested OK); 3) Talk to Chris for the metadata work; 4) FIA credentials; 5) Marcus and Laura excel file
        dataset = gdal.Open(GeotifFile, gdal.GA_Update)

        
        MyTile = 'F3 Raster Dataset produced by Dr. Helen'
        MetadataFromPythonDict = {
            'title': MyTile,
            'description': 'This is Jacey',
            'Huang Family': 'a)Come from China for a life in the U.S.; \n b) starting life is hard; \n c) But become better'
        }
        

        dataset.SetMetadata(MetadataFromPythonDict)
        dataset = None
        #FDGC-->XML-->txt-->HTML
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for GeoTifMetadataUpdate with inputs of "+repr(GeotifFile)+repr(len(MetadataFromPythonDict))+" with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog
    





def ZoneStatisticsToArrayWangNing(ZoneInputTif,Metric,MetricArray,StatisticType,PixelNumberTif,RequiredMinimumPixelNumberYesOrNo,MinimumNumberOfInputPixel):  #ZoneInputTif is Zone in TIF, MetricArray is numpy array
    try:
        ZoneStatisticApproach = "Hybrid" #options are "PandasGroupyBy", "WangNing", or "Hybrid"
        t0 = time.time()
        if Metric in DiscreteMetrics:
            MetricArray = MetricArray.astype('int64')  #20221026: Metric may come from ReadTifToArray whose return is float. Here for discrete, we will use mode() majority, float does not make sense
        #print("\n\n\nZoneInputTif=",ZoneInputTif," for ",Metric," at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
        print("\n\n\nZoneInputTif=",ZoneInputTif," for ",Metric," at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"), file=open(F3Log, 'a'))

        #print("ma.is_masked(MetricArray)=",ma.is_masked(MetricArray))
        if PixelNumberTif == False:
            if RequiredMinimumPixelNumberYesOrNo == "Yes":
                print("You want to consider PixNumber without giving the PixNumberTif (i.e., YangDiBianMa.tif); this is impossible. Please redo")
                print(GouPi)  #This is to trigger the error report on purpose by printing a non-existing variable 
            else:
                print("No PixelNumberTif is given, so we assign a empty array")
                PixelNumberArray =  np.full(MetricArray.shape, F3NoDataValue).astype('int64')
                PixelNumberArray = ma.masked_values(PixelNumberArray, F3NoDataValue)
        else:
            print("PixelNumberTif is given, so we read the tif from ",PixelNumberTif)
            PixelNumberArray = ReadTifToArray(PixelNumberTif).astype('int64')   #20240429: note PlotIDTif type in not integer but float, should we not use int64 here? As of 20240429, I think this is not a problem. GDAL float64 should be OK to convert to int64 
            
        #print("------ZoneStatisticsToArray start")
        ZoneInputTifRaster = gdal.Open(ZoneInputTif)
        ZoneInputTifRaster_ncol = ZoneInputTifRaster.RasterXSize
        ZoneInputTifRaster_nrow = ZoneInputTifRaster.RasterYSize
        ZoneInputTifRaster_bands = ZoneInputTifRaster.RasterCount
        #print("------The ncol,nrow,bands are: ", ZoneInputTifRaster_ncol,ZoneInputTifRaster_nrow,ZoneInputTifRaster_bands)
        ZoneInputTifRasterData = ZoneInputTifRaster.GetRasterBand(1)
        ZoneInputTifRasterDataNoDataValue = ZoneInputTifRasterData.GetNoDataValue()
        #print("------ZoneInputTifRasterDataNoDataValue=",ZoneInputTifRasterDataNoDataValue)
        ZoneInputTifRasterDataArray = ZoneInputTifRasterData.ReadAsArray().astype('int64') 
        ZoneInputTifRasterDataMasked = ma.masked_values(ZoneInputTifRasterDataArray, ZoneInputTifRasterDataNoDataValue)
        #print(ZoneInputTifRasterDataMasked)
        ZoneUnique = np.unique(ZoneInputTifRasterDataArray)
        ZoneUniqueLength = len(ZoneUnique)
        print(Metric," AAA The number of unique zone is: ",ZoneUniqueLength)
        print(Metric," AAA The number of unique zone is: ",ZoneUniqueLength, file=open(F3Log, 'a'))
        #ZoneInputTifRaster = None   #Since ZoneInputTifRaster will be used later, we have to comment this out, because = None means it is cleared
        #print(Metric," AAA The number of unique zone it took (since start) \t" + str(int((time.time() - t0)/60))," minutes"," for ",ZoneInputTif,Metric," at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
        print(Metric," AAA The number of unique zone it took (since start) \t" + str(int((time.time() - t0)/60))," minutes"," for ",ZoneInputTif,Metric," at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"), file=open(F3Log, 'a'))
        ZoneInputTifRasterDataArray1D = ZoneInputTifRasterDataArray.flatten()   

        ##If the number of FIA plots is less than a threshold value (e.g., 2), then the imputation is discarded---start
        #print("Tested at the end of Dec 2022 in Groveland, CA with Wang Ning: Under a specifc dimension, when groupsize < Threshold, WangNing is slower than PandasGroupBy; when groupsize > Threshold, WangNing is faster than PandasGroupBy! Here threshold is determined by the function PandasGroupbyAndWangNingThreshold",file=open(F3Log, 'a'))
        MaximumZoneNumber = ZoneUniqueLength + 100000   #Usually MaximumZoneNumber = ZoneUniqueLength should be good enough, but here we allow extra 1000 for conservative purpose. 20240403, I changed 1000 to 100000 because we had an error of [index out of range] 
        if ZoneStatisticApproach.lower() == "hybrid":
            LengthOf1DArray = ZoneInputTifRaster_ncol * ZoneInputTifRaster_nrow
            PandasGroupbyAndWangNingThresholdValue = PandasGroupbyAndWangNingThreshold(LengthOf1DArray)
            if ZoneUniqueLength < PandasGroupbyAndWangNingThresholdValue:
                HybridChosen = "pandasgroupyby"
            if ZoneUniqueLength >= PandasGroupbyAndWangNingThresholdValue:
                HybridChosen = "wangning"

        NumberOfPlotInZoneInputTif = ZoneInputTif.replace(".tif","_PlotNumber.tif")
        #print("NumberOfPlotInZoneInputTif=",NumberOfPlotInZoneInputTif)
        if not os.path.exists(NumberOfPlotInZoneInputTif):
            t1 = time.time()
            PixelNumberArray1D = PixelNumberArray.flatten()
            if (ZoneStatisticApproach.lower() == "pandasgroupyby") or ((ZoneStatisticApproach.lower() == "hybrid") and (ZoneUniqueLength < PandasGroupbyAndWangNingThresholdValue)):
                NumberOfPlotInZone = pd.Series(PixelNumberArray1D).groupby(ZoneInputTifRasterDataArray1D).transform(lambda x: x.count()).to_numpy(dtype=np.int64,copy=True,na_value=F3NoDataValue)
            if (ZoneStatisticApproach.lower() == "wangning") or ((ZoneStatisticApproach.lower() == "hybrid") and (ZoneUniqueLength >= PandasGroupbyAndWangNingThresholdValue)):
                NumberOfPlotInZone = ZonestatisFromWangNingCount(PixelNumberArray1D, ZoneInputTifRasterDataArray1D, "int64", MaximumZoneNumber) 
            NumberOfPlotInZone = ma.masked_values(NumberOfPlotInZone, F3NoDataValue)
            NumberOfPlotInZone2D = NumberOfPlotInZone.reshape(ZoneInputTifRaster_nrow,ZoneInputTifRaster_ncol)

            #Added on 20230201 to change the output datatype---start
            NumberOfPlotInZoneMin = np.nanmin(NumberOfPlotInZone)
            NumberOfPlotInZoneMax = np.nanmax(NumberOfPlotInZone)
            TypeOfInterest = OutputDataType(NumberOfPlotInZoneMin, NumberOfPlotInZoneMax)
            #Added on 20230201 to change the output datatype---end

            driver = gdal.GetDriverByName("GTiff")
            if OutputGeoTifCompression == "Yes": #Added on 20230227. LZW compression does not lose information. LZW compression is a lossless data compression algorithm, which means that the original data can be fully reconstructed from the compressed data without any loss of information.
                outdata = driver.Create(NumberOfPlotInZoneInputTif, ZoneInputTifRaster_ncol, ZoneInputTifRaster_nrow, 1, TypeOfInterest, options=['COMPRESS=LZW'])   #original is gdal.GDT_Int32, see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
            if OutputGeoTifCompression == "No": 
                outdata = driver.Create(NumberOfPlotInZoneInputTif, ZoneInputTifRaster_ncol, ZoneInputTifRaster_nrow, 1, TypeOfInterest)   #original is gdal.GDT_Int32, see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
            outdata.SetGeoTransform(ZoneInputTifRaster.GetGeoTransform())   ##sets same geotransform as input
            outdata.SetProjection(ZoneInputTifRaster.GetProjection())   ##sets same projection as input
            outdata.GetRasterBand(1).WriteArray(NumberOfPlotInZone2D)
            outdata.GetRasterBand(1).SetNoDataValue(F3NoDataValue) 
            outdata.FlushCache() ##saves to disk!!
            outdata = None
            print(NumberOfPlotInZoneInputTif," is the PlotNumberTif file and just created")
            print(NumberOfPlotInZoneInputTif," was created and it took (since start) \t" + str(int((time.time() - t1)/60))," minutes")                
        if os.path.exists(NumberOfPlotInZoneInputTif):
            print("read tif and 1D flatten here")
            NumberOfPlotInZone0 = ReadTifToArray(NumberOfPlotInZoneInputTif).astype('int32')
            NumberOfPlotInZone = NumberOfPlotInZone0.flatten()
        if RequiredMinimumPixelNumberYesOrNo == "Yes":                
            ZoneInputTifRasterDataArray1D[NumberOfPlotInZone < MinimumNumberOfInputPixel] = F3NoDataValue   #note here NumberOfPlotInZone < MinimumNumberOfInputPixel not NumberOfPlotInZone <= MinimumNumberOfInputPixel
        if RequiredMinimumPixelNumberYesOrNo == "No":   #added on 20230123
            ZoneInputTifRasterDataArray1D[NumberOfPlotInZone == 0] = F3NoDataValue 
        ZoneUnique = np.unique(ZoneInputTifRasterDataArray1D)
        ZoneUniqueLength = len(ZoneUnique)
        print(Metric," BBB The number of unique zone is: ",ZoneUniqueLength)
        print(Metric," BBB The number of unique zone is: ",ZoneUniqueLength, file=open(F3Log, 'a'))
        ##If the number of FIA plots is less than a threshold value (e.g., 2), then the imputation is discarded---end
        print(Metric," BBB The number of unique zone it took (since start) \t" + str(int((time.time() - t0)/60))," minutes"," for ",ZoneInputTif,Metric," at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
        print(Metric," BBB The number of unique zone it took (since start) \t" + str(int((time.time() - t0)/60))," minutes"," for ",ZoneInputTif,Metric," at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"), file=open(F3Log, 'a'))
        
        print("ma.is_masked(ZoneInputTifRasterDataArray1D)=",ma.is_masked(ZoneInputTifRasterDataArray1D))
        print("ZoneInputTifRasterDataArray1D.min(): ", ZoneInputTifRasterDataArray1D.min())
        MetricArrayMasked = ma.masked_values(MetricArray, F3NoDataValue)
        MetricArray1D = MetricArrayMasked.flatten()
        print("ma.is_masked(MetricArray1D)=",ma.is_masked(MetricArray1D))
        print("MetricArray1D.min(): ", MetricArray1D.min())
        print("Start at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
        print("see PD statistics function at https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.count.html")

        #print("Tested at the end of Dec 2022 in Groveland, CA with Wang Ning: Under a specifc dimension, when groupsize < Threshold, WangNing is slower than PandasGroupBy; when groupsize > Threshold, WangNing is faster than PandasGroupBy! Here threshold is determined by the function PandasGroupbyAndWangNingThreshold",file=open(F3Log, 'a'))
        MaximumZoneNumber = ZoneUniqueLength + 100000   #Usually MaximumZoneNumber = ZoneUniqueLength shuld be good enough, but here we allow extra 1000 for conservative purpose. 20240403, I changed 1000 to 100000 because we had an error of [index out of range] 
        if ZoneStatisticApproach.lower() == "hybrid":
            LengthOf1DArray = ZoneInputTifRaster_ncol * ZoneInputTifRaster_nrow
            PandasGroupbyAndWangNingThresholdValue = PandasGroupbyAndWangNingThreshold(LengthOf1DArray)
            print("ZoneInputTifRaster_ncol=",ZoneInputTifRaster_ncol, " and ZoneInputTifRaster_nrow=",ZoneInputTifRaster_nrow, " and ZoneUniqueLength=",ZoneUniqueLength, " and PandasGroupbyAndWangNingThresholdValue=",PandasGroupbyAndWangNingThresholdValue)
            print("ZoneInputTifRaster_ncol=",ZoneInputTifRaster_ncol, " and ZoneInputTifRaster_nrow=",ZoneInputTifRaster_nrow, " and ZoneUniqueLength=",ZoneUniqueLength, " and PandasGroupbyAndWangNingThresholdValue=",PandasGroupbyAndWangNingThresholdValue,file=open(F3Log, 'a'))
            if ZoneUniqueLength < PandasGroupbyAndWangNingThresholdValue:
                HybridChosen = "pandasgroupyby"
            if ZoneUniqueLength >= PandasGroupbyAndWangNingThresholdValue:
                HybridChosen = "wangning"
            print("Here groupsize=",ZoneUniqueLength," vs. PandasGroupbyAndWangNingThresholdValue=",PandasGroupbyAndWangNingThresholdValue," ZoneStatisticApproach=Hybrid, so HybridChosen=",HybridChosen," (depending groupsize > or < PandasGroupbyAndWangNingThresholdValue) at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
            print("Here groupsize=",ZoneUniqueLength," vs. PandasGroupbyAndWangNingThresholdValue=",PandasGroupbyAndWangNingThresholdValue," ZoneStatisticApproach=Hybrid, so HybridChosen=",HybridChosen," (depending groupsize > or < PandasGroupbyAndWangNingThresholdValue) at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),file=open(F3Log, 'a'))
        else:
            print("Here groupsize=",ZoneUniqueLength," ZoneStatisticApproach=",ZoneStatisticApproach,". Also note ZoneInputTifRaster_ncol=",ZoneInputTifRaster_ncol, " and ZoneInputTifRaster_nrow=",ZoneInputTifRaster_nrow," at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))            
            print("Here groupsize=",ZoneUniqueLength," ZoneStatisticApproach=",ZoneStatisticApproach,". Also note ZoneInputTifRaster_ncol=",ZoneInputTifRaster_ncol, " and ZoneInputTifRaster_nrow=",ZoneInputTifRaster_nrow," at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),file=open(F3Log, 'a'))            

        if ((StatisticType.lower() == "meanandweightedmean") or (StatisticType.lower() == "allfour")):
            MetricPerZoneAAA_allfour = np.full((4,len(MetricArray1D)), F3NoDataValue)  #here the first length is 4
            
            #This is mean for allfour assigned to MetricPerZoneAAA_allfour[0,:]---start
            if (ZoneStatisticApproach.lower() == "pandasgroupyby") or ((ZoneStatisticApproach.lower() == "hybrid") and (ZoneUniqueLength < PandasGroupbyAndWangNingThresholdValue)):
                MetricPerZoneAAA_allfour[0,:] = pd.Series(MetricArray1D).groupby(ZoneInputTifRasterDataArray1D).transform(lambda x: x.mean(skipna=True)).to_numpy(dtype=np.int64,copy=True,na_value=F3NoDataValue)            
            if (ZoneStatisticApproach.lower() == "wangning") or ((ZoneStatisticApproach.lower() == "hybrid") and (ZoneUniqueLength >= PandasGroupbyAndWangNingThresholdValue)):
                MetricPerZoneAAA_allfour[0,:] = ZonestatisFromWangNingMean(MetricArray1D, ZoneInputTifRasterDataArray1D, "int64", MaximumZoneNumber)
            #This is mean for allfour assigned to MetricPerZoneAAA_allfour[0,:]---end

            #This is weightedmean for allfour assigned to MetricPerZoneAAA_allfour[1,:]---start
            WeightInZone = WeightInZone_function(ZoneInputTif,ZoneStatisticApproach,ZoneUniqueLength,PandasGroupbyAndWangNingThresholdValue,ZoneInputTifRasterDataArray1D,MaximumZoneNumber)
            MetricValueTimesWeight = MetricArray1D * WeightInZone  #MetricValueTimesWeight = np.multiply(MetricArray1D, np.divide(WeightBasisTifArray1D, WeightBasisSumInZone))
            if (ZoneStatisticApproach.lower() == "pandasgroupyby") or ((ZoneStatisticApproach.lower() == "hybrid") and (ZoneUniqueLength < PandasGroupbyAndWangNingThresholdValue)):
                MetricPerZoneAAA_allfour[1,:] = pd.Series(MetricValueTimesWeight).groupby(ZoneInputTifRasterDataArray1D).transform(lambda x: x.sum(skipna=True)).to_numpy(dtype=np.int64,copy=True,na_value=F3NoDataValue)
            if (ZoneStatisticApproach.lower() == "wangning") or ((ZoneStatisticApproach.lower() == "hybrid") and (ZoneUniqueLength >= PandasGroupbyAndWangNingThresholdValue)):
                MetricPerZoneAAA_allfour[1,:] = ZonestatisFromWangNingSum(MetricValueTimesWeight, ZoneInputTifRasterDataArray1D, "int64", MaximumZoneNumber) 
            #This is weightedmean for allfour assigned to MetricPerZoneAAA_allfour[1,:]---end

            if StatisticType.lower() == "meanandweightedmean":
                #This is the average of mean (i.e., MetricPerZoneAAA_allfour[0,:]) and weightedmean (i.e., MetricPerZoneAAA_allfour[1,:])---start
                MetricPerZoneAAA = np.nanmean(MetricPerZoneAAA_allfour[0:2,:],axis=0)  #added on 20221122
                #This is the average of mean (i.e., MetricPerZoneAAA_allfour[0,:]) and weightedmean (i.e., MetricPerZoneAAA_allfour[1,:])---end
                
            if StatisticType.lower() == "allfour":
                #This is meantimesregressionratio assigned to MetricPerZoneAAA_allfour[2,:] and weightedmeantimesregressionratio assigned to MetricPerZoneAAA_allfour[3,:]---start
                RatioInZone = RatioInZone_function(ZoneInputTif,ZoneStatisticApproach,ZoneUniqueLength,PandasGroupbyAndWangNingThresholdValue,ZoneInputTifRasterDataArray1D,MaximumZoneNumber)
                MetricPerZoneAAA_allfour[2,:] = MetricPerZoneAAA_allfour[0,:] * RatioInZone #you can use np.multiply() and np.divide() here too    
                MetricPerZoneAAA_allfour[3,:] = MetricPerZoneAAA_allfour[1,:] * RatioInZone  #you can use np.multiply() and np.divide() here too    
                #This is meantimesregressionratio and weightedmeantimesregressionratio for allfour assigned to MetricPerZoneAAA_allfour[2,:] and MetricPerZoneAAA_allfour[3,:]---end
                MetricPerZoneAAA = np.nanmean(MetricPerZoneAAA_allfour,axis=0)
                
        if ((StatisticType.lower() == "weightedmean") or (StatisticType.lower() == "weightedmeantimesregressionratio")):
            WeightInZone = WeightInZone_function(ZoneInputTif,ZoneStatisticApproach,ZoneUniqueLength,PandasGroupbyAndWangNingThresholdValue,ZoneInputTifRasterDataArray1D,MaximumZoneNumber)
            MetricValueTimesWeight = MetricArray1D * WeightInZone  #MetricValueTimesWeight = np.multiply(MetricArray1D, np.divide(WeightBasisTifArray1D, WeightBasisSumInZone))
            if (ZoneStatisticApproach.lower() == "pandasgroupyby") or ((ZoneStatisticApproach.lower() == "hybrid") and (ZoneUniqueLength < PandasGroupbyAndWangNingThresholdValue)):
                MetricPerZoneAAA = pd.Series(MetricValueTimesWeight).groupby(ZoneInputTifRasterDataArray1D).transform(lambda x: x.sum(skipna=True)).to_numpy(dtype=np.int64,copy=True,na_value=F3NoDataValue)
            if (ZoneStatisticApproach.lower() == "wangning") or ((ZoneStatisticApproach.lower() == "hybrid") and (ZoneUniqueLength >= PandasGroupbyAndWangNingThresholdValue)):
                MetricPerZoneAAA = ZonestatisFromWangNingSum(MetricValueTimesWeight, ZoneInputTifRasterDataArray1D, "int64", MaximumZoneNumber)
   
        if ((StatisticType.lower() == "mean") or (StatisticType.lower() == "meantimesregressionratio")):
            if (ZoneStatisticApproach.lower() == "pandasgroupyby") or ((ZoneStatisticApproach.lower() == "hybrid") and (ZoneUniqueLength < PandasGroupbyAndWangNingThresholdValue)):
                MetricPerZoneAAA = pd.Series(MetricArray1D).groupby(ZoneInputTifRasterDataArray1D).transform(lambda x: x.mean(skipna=True)).to_numpy(dtype=np.int64,copy=True,na_value=F3NoDataValue)            
            if (ZoneStatisticApproach.lower() == "wangning") or ((ZoneStatisticApproach.lower() == "hybrid") and (ZoneUniqueLength >= PandasGroupbyAndWangNingThresholdValue)):
                MetricPerZoneAAA = ZonestatisFromWangNingMean(MetricArray1D, ZoneInputTifRasterDataArray1D, "int64", MaximumZoneNumber)

        if ((StatisticType.lower() == "weightedmeantimesregressionratio") or (StatisticType.lower() == "meantimesregressionratio")):
            RatioInZone = RatioInZone_function(ZoneInputTif,ZoneStatisticApproach,ZoneUniqueLength,PandasGroupbyAndWangNingThresholdValue,ZoneInputTifRasterDataArray1D,MaximumZoneNumber)
            MetricPerZoneAAA = MetricPerZoneAAA * RatioInZone  #you can use np.multiply() and np.divide() here too    
        if StatisticType.lower() == "max":
            MetricPerZoneAAA = pd.Series(MetricArray1D).groupby(ZoneInputTifRasterDataArray1D).transform(lambda x: x.max(skipna=True)).to_numpy(dtype=np.int64,copy=True,na_value=F3NoDataValue)
        if StatisticType.lower() == "min":
            MetricPerZoneAAA = pd.Series(MetricArray1D).groupby(ZoneInputTifRasterDataArray1D).transform(lambda x: x.min(skipna=True)).to_numpy(dtype=np.int64,copy=True,na_value=F3NoDataValue)
        if StatisticType.lower() == "median":
            MetricPerZoneAAA = pd.Series(MetricArray1D).groupby(ZoneInputTifRasterDataArray1D).transform(lambda x: x.median(skipna=True)).to_numpy(dtype=np.int64,copy=True,na_value=F3NoDataValue)
        if StatisticType.lower() == "std":
            MetricPerZoneAAA = pd.Series(MetricArray1D).groupby(ZoneInputTifRasterDataArray1D).transform(lambda x: x.std(skipna=True)).to_numpy(dtype=np.int64,copy=True,na_value=F3NoDataValue)
        if StatisticType.lower() == "var":
            MetricPerZoneAAA = pd.Series(MetricArray1D).groupby(ZoneInputTifRasterDataArray1D).transform(lambda x: x.var(skipna=True)).to_numpy(dtype=np.int64,copy=True,na_value=F3NoDataValue)
        if StatisticType.lower() == "sum":
            MetricPerZoneAAA = pd.Series(MetricArray1D).groupby(ZoneInputTifRasterDataArray1D).transform(lambda x: x.sum(skipna=True)).to_numpy(dtype=np.int64,copy=True,na_value=F3NoDataValue)
        if StatisticType.lower() == "mode":  #a=np.random.randint(5,size=20)-->mode(a)[0]--->mode(a)[0][0] can get the mode value from a python array
            #print("We cannot use x.mode(skipna=True) or x.mode(dropna=True). We can use x.mode(dropna=True)[0]; however, an error occurs when the mode is empty. Finally, I have to do it myself based on my understanding as below")
            #print("https://stackoverflow.com/questions/66647301/get-values-from-pandas-core-groupby-generic-dataframegroupby-object")
            #print("https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.transform.html")
            #print("https://stackoverflow.com/questions/66647301/get-values-from-pandas-core-groupby-generic-dataframegroupby-object")
            #print("https://github.com/pandas-dev/pandas/issues/11562")
            #print("pandas dataframe mode, see https://www.w3schools.com/python/pandas/ref_df_mode.asp#:~:text=Pandas%20DataFrame%20mode%20%28%29%20Method%201%20Definition%20and,to%20the%20original%20DataFrame%20object.%20%E2%9D%AE%20DataFrame%20Reference")
            MetricPerZoneAAA = np.full(len(MetricArray1D), F3NoDataValue, dtype="int64")  
            PandasSeries = pd.Series(MetricArray1D).groupby(ZoneInputTifRasterDataArray1D)  #This is a pandas series object, which is actually a list of tuples
            for group in PandasSeries:
                if group[0] == F3NoDataValue:   #This was added on 20230128. When the groupvalue (i.e., ZoneValue) is F3NoDataValue, we just assign a value. This would increase the speed a lot.
                    MetricPerZoneAAA[group[1].index] = F3NoDataValue
                elif group[1].mode().empty:  #If the majority is empty, we give a F3NoDataValue for the corresponding indexes
                    MetricPerZoneAAA[group[1].index] = F3NoDataValue
                else:
                    MetricPerZoneAAA[group[1].index] = group[1].mode()[0]  ##If the majority is not empty, we give the mode value for the corresponding indexes
        print(Metric," StatisticType=",StatisticType," for ZoneStatisticsToArray it took (since start) \t" + str(int((time.time() - t0)/60))," minutes"," for ",ZoneInputTif,Metric," at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
        print(Metric," StatisticType=",StatisticType," for ZoneStatisticsToArray it took (since start) \t" + str(int((time.time() - t0)/60))," minutes"," for ",ZoneInputTif,Metric," at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"), file=open(F3Log, 'a'))

        MetricPerZoneAAA[np.isnan(MetricPerZoneAAA)] = F3NoDataValue
        MetricPerZoneAAA[ZoneInputTifRasterDataArray1D == ZoneInputTifRasterDataNoDataValue] = F3NoDataValue
        MetricPerZoneAAA[ZoneInputTifRasterDataArray1D == F3NoDataValue] = F3NoDataValue   #added on 20230123

        MetricPerZone = MetricPerZoneAAA.copy()
        MetricPerZone = MetricPerZone.reshape(ZoneInputTifRaster_nrow,ZoneInputTifRaster_ncol)

        print("Finish at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
        print(Metric," ZoneStatisticsToArray5 it took (since start) \t" + str(int((time.time() - t0)/60))," minutes"," for ",ZoneInputTif,Metric," at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
        print(Metric," ZoneStatisticsToArray5 it took (since start) \t" + str(int((time.time() - t0)/60))," minutes"," for ",ZoneInputTif,Metric," at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"), file=open(F3Log, 'a'))

        MetricPerZone[ZoneInputTifRasterData==ZoneInputTifRasterDataNoDataValue] = F3NoDataValue
        MetricPerZoneMasked = ma.masked_values(MetricPerZone, F3NoDataValue)
        print(Metric," ZoneStatisticsToArray6 it took (since start) \t" + str(int((time.time() - t0)/60))," minutes"," for ",ZoneInputTif,Metric," at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
        print(Metric," ZoneStatisticsToArray6 it took (since start) \t" + str(int((time.time() - t0)/60))," minutes"," for ",ZoneInputTif,Metric," at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"), file=open(F3Log, 'a'))
        
        return MetricPerZoneMasked
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for ZoneStatisticsToArray with inputs of " + repr(ZoneInputTif)+","+repr(Metric)+","+repr(MetricArray.shape)+","+repr(StatisticType)+","+repr(PixelNumberTif)+","+repr(RequiredMinimumPixelNumberYesOrNo) + ","+repr(MinimumNumberOfInputPixel) + " with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog



def Array3x3MovingAverageAndLowHighBound(Input2DArray, Metric, Type, LowEnd, HighEnd, NoDataValue):
    try:
        #print("Local moving window for averaging, std, median, low/high-pass filter for an array")
        data = ma.masked_values(Input2DArray, NoDataValue)
        rows = Input2DArray.shape[0]
        cols = Input2DArray.shape[1]
        #print("vectorize moving window idea come from https://opensourceoptions.com/blog/vectorize-moving-window-grid-operations-on-numpy-arrays/")
        #print("Element-wise mean by ignoring nan come from https://stackoverflow.com/questions/18826422/python-element-wise-means-of-multiple-matrices-with-numpy")
        MovingWindowArrayList = np.ma.array([data[1:-1,1:-1], data[:-2,1:-1], data[2:,1:-1], data[1:-1,:-2], data[1:-1,2:], data[2:,2:], data[:-2,:-2], data[2:,:-2], data[:-2,2:]])  #20230214: np.array does not work because NoDataValue (i.e. -9999) cannot be ignored. We must use np.ma.array() here
        outData = np.full(data.shape, NoDataValue)
        if ((Metric in ContinuousMetrics) or (Metric == "ProcessingPercentageAsOrderAndReliability")):
            ##This part use a pixel-wise loop to calcluate the moving window. It works but slow, so it is replaced by using vectorize moving window technique---start
            #for i in range(1, rows-1,1): # skipping first & last because it is 3x3 window
            #    if i%50 == 0:
            #        print("Local 3x3 window at i=",i," out of ",rows-1)
            #    for j in range(1, cols-1,1):
            #        Win3x3Array = data[i-1:i+2,j-1:j+2]  #Win3x3Array = np.array([data[i-1,j-1],data[i-1,j],data[i-1,j+1],data[i,j-1],data[i,j],data[i,j+1],data[i+1,j-1],data[i+1,j],data[i+1,j+1]])
            #        Win3x3ArrayMasked = ma.masked_values(Win3x3Array, NoDataValue)
            #        NumberOfValidPixel = Win3x3ArrayMasked.count()  #if the array is not a maksed array, then use np.count_nonzero(np.isnan(ARRAY))
            #        #print("NumberOfValidPixel=",NumberOfValidPixel)
            #        if NumberOfValidPixel != 0:
            #            if Type == "mean":
            #                outData[i,j] = np.nanmean(Win3x3ArrayMasked)  #This will ignore the NAN values when calculating statistics
            #            if Type == "median": 
            #                outData[i,j] = np.nanmedian(Win3x3ArrayMasked)  #This will ignore the NAN values when calculating statistics
            #            if Type == "max":
            #                outData[i,j] = np.nanmax(Win3x3ArrayMasked)  #This will ignore the NAN values when calculating statistics
            #            if Type == "min":
            #                outData[i,j] = np.nanmin(Win3x3ArrayMasked)  #This will ignore the NAN values when calculating statistics
            #            if Type == "sum":
            #                outData[i,j] = np.nansum(Win3x3ArrayMasked)  #This will ignore the NAN values when calculating statistics
            #            if Type == "std":
            #                outData[i,j] = np.nanstd(Win3x3ArrayMasked)  #This will ignore the NAN values when calculating statistics
            #            if Type == "var":
            #                outData[i,j] = np.nanvar(Win3x3ArrayMasked)  #This will ignore the NAN values when calculating statistics
            #            if Type == "ptp":  #question this as 20220920, ptp returns Range = max value – min value, check https://www.geeksforgeeks.org/numpy-ptp-in-python/
            #                outData[i,j] = np.ptp(Win3x3Array)  #This will ignore the NAN values when calculating statistics
            #            if Type == "count":  
            #                outData[i,j] = Win3x3ArrayMasked.count()  #This will ignore the NAN values when calculating statistics. Is there () at the end?
            ##This part use a pixel-wise loop to calcluate the moving window. It works but slow, so it is replaced by using vectorize moving window technique---end
            t0 = time.time()
            if Type.lower() == "mean":
                #print("Metric, Type, LowEnd, HighEnd, NoDataValue=",Metric, Type, LowEnd, HighEnd, NoDataValue," and MovingWindowArrayList.shape=",MovingWindowArrayList.shape)
                outData[1:-1, 1:-1] = np.nanmean(MovingWindowArrayList,axis=0)  #This return the mean by ignoring the nan element. 20240221: For unknown reason, there is a [RuntimeWarning: invalid value encountered in cast]
            if Type.lower() == "median":
                print("We have to use np.ma.median instead of np.nanmedian, because the latter causes a UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray, which means -9999 will not be ignored")
                outData[1:-1, 1:-1] = np.ma.median(MovingWindowArrayList,axis=0)  #This return the median by ignoring the nan element
            if Type.lower() == "max":
                outData[1:-1, 1:-1] = np.nanmax(MovingWindowArrayList,axis=0)  #This return the max by ignoring the nan element
            if Type.lower() == "min":
                outData[1:-1, 1:-1] = np.nanmin(MovingWindowArrayList,axis=0)  #This return the min by ignoring the nan element
            if Type.lower() == "sum":
                outData[1:-1, 1:-1] = np.nansum(MovingWindowArrayList,axis=0)  #This return the sum by ignoring the nan element
            if Type.lower() == "std":
                outData[1:-1, 1:-1] = np.nanstd(MovingWindowArrayList,axis=0)  #This return the std by ignoring the nan element
            if Type.lower() == "var":
                outData[1:-1, 1:-1] = np.nanvar(MovingWindowArrayList,axis=0)  #This return the var by ignoring the nan element
            if LowEnd >= 0:  #For GAP continuous metric such as QMD20, we assign the value to be zero or lowend with the separation threshold value of half lowend
                outData[outData <= 0.5*LowEnd] = 0
                outData[(outData > 0.5*LowEnd) & (outData <= LowEnd)] = LowEnd
            if LowEnd < 0:
                outData[outData <= LowEnd] = LowEnd
            outData[outData >= HighEnd] = HighEnd
            #print(Metric," is continuous metric and the Array3x3MovingAverageAndLowHighBound took \t" + str(int((time.time() - t0)/60))," minutes at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
            #print(Metric," is continuous metric and the Array3x3MovingAverageAndLowHighBound took \t" + str(int((time.time() - t0)/60))," minutes at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"), file=open(F3Log, 'a'))
        if ((Metric in DiscreteMetrics) or (Type.lower() == "mode")):
            ##This part use a pixel-wise loop to calcluate the moving window. It works but slow, so it is replaced by using vectorize moving window technique and scipy.stats.mode---start
            #for i in range(1, rows-2,1): # skipping first & last because it is 3x3 window
            #    for j in range(1, cols-2,1):
            #        Win3x3Array = data[i-1:i+2,j-1:j+2].flatten()  #Win3x3Array = np.array([data[i-1,j-1],data[i-1,j],data[i-1,j+1],data[i,j-1],data[i,j],data[i,j+1],data[i+1,j-1],data[i+1,j],data[i+1,j+1]])
            #        Win3x3ArrayMasked = ma.masked_values(Win3x3Array, NoDataValue)
            #        outData[i,j] = mode(Win3x3ArrayMasked)[0][0]  #This will return majority, because we have from scipy.stats import mode
            ##This part use a pixel-wise loop to calcluate the moving window. It works but slow, so it is replaced by using vectorize moving window technique and scipy.stats.mode---end
            t0 = time.time()
            print("Check mode at https://stackoverflow.com/questions/62748195/how-to-take-the-mode-across-elements-in-multiple-numpy-arrays-of-1-d. NAN is ignored")
            outData[1:-1,1:-1] = mode(MovingWindowArrayList,axis=0,nan_policy='omit',keepdims=True).mode[0]  #mode[0] is the same as mode[0,:,:]. Also outData[1:-1,1:-1] = mode(MovingWindowArrayList,axis=0).count[0,:,:] can be used for count; This sentence may change in the future, depending on scipy version
            print(Metric," is discrete metric and the Array3x3MovingAverageAndLowHighBound took \t" + str(int((time.time() - t0)/60))," minutes at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
            print(Metric," is discrete metric and the Array3x3MovingAverageAndLowHighBound took \t" + str(int((time.time() - t0)/60))," minutes at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"), file=open(F3Log, 'a'))
            print("As of 20230203, Dr. Huang realize discrete metric Array3x3MovingAverageAndLowHighBound took about 2 hours. We will watch the np.nanmode progress and imporve it. Please noe np.nanmode() is already avaialble in numpy 1.15 or higher")
            print("As of 20230203, Dr. Huang realize discrete metric Array3x3MovingAverageAndLowHighBound took about 2 hours. We will watch the np.nanmode progress and imporve it", file=open(F3Log, 'a'))
        outData[data.mask] = NoDataValue
        outData = ma.masked_values(outData, NoDataValue)
        
        return outData
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for Array3x3MovingAverageAndLowHighBound with inputs of "+repr(Input2DArray.shape)+","+repr(Metric)+","+repr(Type)+","+repr(LowEnd)+","+repr(HighEnd)+","+repr(NoDataValue)+" with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog

    

def F3RasterMovingAverageAndLowHighBound(ScrTif, Type, LowEnd, HighEnd):   #This function has not been used
    try:
        driverTiff = gdal.GetDriverByName('GTiff')
        ds = gdal.Open(SrcTif)
        cols = ds.RasterXSize
        rows = ds.RasterYSize
        WeUseThisProjection = ds.GetProjectionRef()
        WeUseThisGeoTransform = ds.GetGeoTransform()
        print(WeUseThisGeoTransform)
        band1 = ds.GetRasterBand(1).ReadAsArray().astype(np.int64)
        NoDataValue = ds.GetRasterBand(1).GetNoDataValue()
        data = ma.masked_values(Input2DArray, NoDataValue)
        rows = Input2DArray.shape[0]
        cols = Input2DArray.shape[1]
        MovingWindowArrayList = np.array([data[1:-1,1:-1], data[:-2,1:-1], data[2:,1:-1], data[1:-1,:-2], data[1:-1,2:], data[2:,2:], data[:-2,:-2], data[2:,:-2], data[:-2,2:]])

        outData = np.full(data.shape, NoDataValue)
        if Metric in ContinuousMetrics:
            if Type.lower() == "mean":
                outData[1:-1, 1:-1] = np.nanmean(MovingWindowArrayList,axis=0)  #This return the mean by ignoring the nan element
            if Type.lower() == "median":
                print("We have to use np.ma.median instead of np.nanmedian, because the latter causes a UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray, which means -9999 will not be ignored")
                outData[1:-1, 1:-1] = np.ma.median(MovingWindowArrayList,axis=0)  #This return the median by ignoring the nan element
            if Type.lower() == "max":
                outData[1:-1, 1:-1] = np.nanmax(MovingWindowArrayList,axis=0)  #This return the max by ignoring the nan element
            if Type.lower() == "min":
                outData[1:-1, 1:-1] = np.nanmin(MovingWindowArrayList,axis=0)  #This return the min by ignoring the nan element
            if Type.lower() == "sum":
                outData[1:-1, 1:-1] = np.nansum(MovingWindowArrayList,axis=0)  #This return the sum by ignoring the nan element
            if Type.lower() == "std":
                outData[1:-1, 1:-1] = np.nanstd(MovingWindowArrayList,axis=0)  #This return the std by ignoring the nan element
            if Type.lower() == "var":
                outData[1:-1, 1:-1] = np.nanvar(MovingWindowArrayList,axis=0)  #This return the var by ignoring the nan element
            if LowEnd >= 0:  #For GAP continuous metric such as QMD20, we assign the value to be zero or lowend with the separation threshold value of half lowend
                outData[outData <= 0.5*LowEnd] = 0
                outData[(outData > 0.5*LowEnd) & (outData <= LowEnd)] = LowEnd
            if LowEnd < 0:
                outData[outData <= LowEnd] = LowEnd
            outData[outData >= HighEnd] = HighEnd
        if Metric in DiscreteMetrics:
            outData[1:-1,1:-1] = mode(MovingWindowArrayList,axis=0).mode[0,:,:]  #outData[1:-1,1:-1] = mode(MovingWindowArrayList,axis=0).count[0,:,:] can be used for count; This sentence may change in the future, depending on scipy version
        outData[data.mask] = NoDataValue
        
        outData = ma.masked_values(outData, NoDataValue)

        #Added on 20230201 to change the output datatype---start
        outDataMin = np.nanmin(outData)
        outDataMax = np.nanmax(outData)
        TypeOfInterest = OutputDataType(outDataMin, outDataMax)
        #Added on 20230201 to change the output datatype---end
        
        driver = gdal.GetDriverByName("GTiff")
        F3FinalTif = ScrTif.replace(".tif","Win3x3.tif")
        if OutputGeoTifCompression == "Yes": #Added on 20230227. LZW compression does not lose information. LZW compression is a lossless data compression algorithm, which means that the original data can be fully reconstructed from the compressed data without any loss of information.
            myoutdata = driver.Create(F3FinalTif, ds.RasterXSize, ds.RasterYSize,1, TypeOfInterest, options=['COMPRESS=LZW'])   #Original is gdal.GDT_Int32, see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
        if OutputGeoTifCompression == "No": 
            myoutdata = driver.Create(F3FinalTif, ds.RasterXSize, ds.RasterYSize,1, TypeOfInterest)   #Original is gdal.GDT_Int32, see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
        myoutdata.SetGeoTransform(ds.GetGeoTransform())  ##sets same geotransform as input
        myoutdata.SetProjection(ds.GetProjectionRef())   ##sets same projection as input
        myoutdata.GetRasterBand(1).WriteArray(outData)
        myoutdata.GetRasterBand(1).SetNoDataValue(F3NoDataValue) 
        myoutdata.FlushCache() ##saves to disk!!
        myoutdata = None
        print(F3FinalTif, "was finished")
        return F3FinalTif
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"  
        #print(Content1)
        Content2 = "The error was for F3RasterMovingAverageAndLowHighBound with inputs of " +repr(ScrTif)+","+repr(Type)+","+repr(LowEnd)+","+repr(HighEnd)+ " with with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog



def forward_selected(data, response):  # Copy from http://planspace.org/20150423-forward_selection_with_statsmodels/
    try:
        """Linear model designed by forward selection.
        Parameters:
        -----------
        data : pandas DataFrame with all possible predictors and response
        response: string, name of response column in data
        Returns:
        --------
        model: an "optimal" fitted statsmodels linear model with an intercept selected by forward selection evaluated by adjusted R-squared
        """
        print("zzzzzzzzzzzzzzzzzzzzzzzzzzzz_come to forward_selected section")
        remaining = set(data.columns)
        remaining.remove(response)
        #print('remaining is:', remaining)  #I have check this and found the remaining order is random. THis is because set() means "Unordered collections of unique elements" (see https://docs.python.org/2/library/sets.html)
        selected = []
        current_score, best_new_score = 0.0, 0.0
        Mystep = 0
        while remaining and current_score == best_new_score:
            Mystep = Mystep + 1
            scores_with_candidates = []  
            for candidate in remaining:
                #print('candidate and remaining are ', candidate, '----', remaining)
                formula = "{} ~ {} + 1".format(response, ' + '.join(selected + [candidate]))  # Check formula at http://statsmodels.sourceforge.net/devel/example_formulas.html, and check "Intercept handling (i.e. 1 here)" at http://patsy.readthedocs.org/en/latest/formulas.html
                #print('formula is:', formula)
                score = smf.ols(formula, data, missing='drop').fit().rsquared_adj  # THis stepwise is conducted by maximizing the adjust-R2. Also check missing values information (missing='drop') at http://stackoverflow.com/questions/22234589/ignoring-missing-values-in-multiple-ols-regression-with-statsmodels. Note the missing value is nan not -inf or null
                R2score = smf.ols(formula, data, missing='drop').fit().rsquared
                scores_with_candidates.append((score, candidate))
                #print('scores_with_candidates is:', scores_with_candidates)
            scores_with_candidates.sort()  # Sort the items of the list in placefrom low to high (sse https://docs.python.org/2/tutorial/datastructures.html)
            #print('After sorted, scores_with_candidates is:', scores_with_candidates)
            best_new_score, best_candidate = scores_with_candidates.pop()  #If no index is specified, a.pop() removes and returns the last item in the list (see https://docs.python.org/2/tutorial/datastructures.html)
            if current_score < best_new_score:
                remaining.remove(best_candidate)
                selected.append(best_candidate)
                current_score = best_new_score
            #print('Step:', Mystep, ' selected:',selected, ' remaining:',remaining, 'rsquared:', R2score, 'rsquared_adj:', score)
            #print('Mystep = ', Mystep)
            if Mystep % 100 == 0:
               print(('Mystep = ', Mystep))
            if Mystep == 1000: break   #On June 5, 2017, I found the iteration may not be terminated and the loop is forever, so I added this sentence to stop the looping.
        #print('The final regressors automatically selected by stepwise regression are: ', selected)
        scores_with_candidates.sort()  # Sort from low to high
        #print('The final sorted scores_with_candidates is:', scores_with_candidates)
        if len(scores_with_candidates) > 0:
           LastBestCandidate = scores_with_candidates.pop()
        else:
           LastBestCandidate = scores_with_candidates
        if len(LastBestCandidate) > 0:
           print(('The last best one in final sorted scores_with_candidates is:', LastBestCandidate, ' and the candidate name is: ', LastBestCandidate[1], ' and its score is: ', LastBestCandidate[0])) # .pop() select the highest one
        else:
           print('LastBestCandidate is empty')
        # If you want to force a specific variable to be included in the regressors (e.g., NDVI here), then we can add the following sentence--start
        ForceNDVIinclude = "no" # Another option is "no"
        if "NDVI" in selected:
            print('NDVI is already included in regressors')
        else:
            if ForceNDVIinclude == "yes":
               selected.append("NDVI")
            print(('The final regressors, including what you just specified, are: ', selected))
        # If you want to force a specific variable to be included in the regressors (e.g., NDVI here), then we can add the following sentence--end
        # Sometimes if the number of explanatory variable is too less (e.g. < 2, means only one), then we can add the last best candidate--start 
        if ((len(selected) < 2) & (len(LastBestCandidate) > 0)):
           selected.append(LastBestCandidate[1]) 
        # Sometimes if the number of explanatory variable is too less (e.g. < 2, means only one), then we can add the last best candidate--end
        formula = "{} ~ {} + 1".format(response, ' + '.join(selected))         
        FinalRegreesionType = "OrdinaryLeastSquare" # Another option is "RobustRegression"
        if FinalRegreesionType == "OrdinaryLeastSquare":
           StepWiseRegressionModel = smf.ols(formula, data, missing='drop').fit()  # Originally I used ordinary least square (OLS), but I change it to robust linear model (RLM) on June 17, 2015. Also it is possibel to identify outliers from OLS, please refer to http://stackoverflow.com/questions/10231206/can-scipy-stats-identify-and-mask-obvious-outliers 
        if FinalRegreesionType == "RobustRegression":
           StepWiseRegressionModel = smf.rlm(formula, data, M=sm.robust.norms.AndrewWave()).fit() # Originally I used ordinary least square (OLS), but I change it to robust linear model (RLM) on June 17, 2015. Also check RLM M-Estimators at http://statsmodels.sourceforge.net/devel/examples/notebooks/generated/robust_models.html and http://statsmodels.sourceforge.net/stable/examples/notebooks/generated/robust_models_1.html and more information at https://en.wikipedia.org/wiki/M-estimator
        return StepWiseRegressionModel
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for forward_selected with inputs of data, response with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog

    
def StepwiseRegression(InputFile,Metric):  #This is an excel csv file. The first row is field names; the first column is independant variable (e.g., SLTSCB) while other columns are dependant variable (e.g., Remote sensing bands...)
    try:
        # Command example:  C:\Anaconda3\python.exe D:\ShengliKama\AnacondaStepwiseRegression.py D:\ShengliKama\P40R36Reflectance\LT50400362006155-SC20141104191215\LT50400362006155PAC01_FieldPlotsMeasurements_MoreInfo_Selected_TotalLiveT.csv
        #pd.set_option('use_inf_as_null', True)   # See the reason at http://stackoverflow.com/questions/22234589/ignoring-missing-values-in-multiple-ols-regression-with-statsmodels
        print('ZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZThe stepwise regression developed from statsmodels worked well')  # Note python 2.7 has different format for print
        FieldmetricandRSdata = pd.read_csv(InputFile)
        FieldMetric = Metric   #FieldMetric = InputFile.split("__")[-1].split(".")[0] is the old version. 
        MyStepRegreesionModel = forward_selected(FieldmetricandRSdata, FieldMetric)
        #print(MyStepRegreesionModel.summary())  #Check http://statsmodels.sourceforge.net/0.5.0/generated/statsmodels.regression.linear_model.OLSResults.html for more OLS result info; Go to http://www.datarobot.com/blog/ordinary-least-squares-in-python/ and http://statsmodels.sourceforge.net/devel/examples/generated/example_ols.html to find the interpration of the fit result
        ### This section is to identify the outliers, which may be useful in the future---start
        ###print('FieldmetricandRSdata is: ', FieldmetricandRSdata)
        ##print('The shape FieldmetricandRSdata is: ', FieldmetricandRSdata.shape)
        ##DataValues = FieldmetricandRSdata.get_values()  # see http://pandas.pydata.org/pandas-docs/dev/generated/pandas.DataFrame.html for more information on Pandas DataFrame
        ##print('The values of FieldmetricandRSdata is: ',DataValues, 'and the shape is', DataValues.shape)
        ##print('The first row of values of FieldmetricandRSdata is: ',DataValues[0,:])
        ##print('The first column of values of FieldmetricandRSdata is: ',DataValues[:,0])
        ##MyY = DataValues[:,0]  # The Y value come from the first column
        ##MyX = DataValues[:,1:] # The X value come from the remaining columns
        ##print('The Y of values of FieldmetricandRSdata is: ',MyY)
        ##print('The X of values of FieldmetricandRSdata is: ',MyX)
        ##OutlierTest = MyStepRegreesionModel.outlier_test()  # See http://statsmodels.sourceforge.net/0.5.0/generated/statsmodels.regression.linear_model.OLSResults.html for OLS result information
        ##outliers = ((MyX[i],MyY[i]) for i,t in enumerate(OutlierTest.icol(2)) if t < 0.5)
        ##print('Outliers: ', list(outliers))
        ### This section is to identify the outliers, which may be useful in the future---end
        StepwiseRegressionResult = InputFile.replace(".csv", "__StepwiseRegreesionResult.txt")
        print(StepwiseRegressionResult)
        if not os.path.exists(StepwiseRegressionResult):  #added on 20240320 for permission problem
            StepwiseRegressionResultFile = open(StepwiseRegressionResult, 'w')
            Y = MyStepRegreesionModel.model.formula.split("~")[0]
            print(('Y is: ', Y))
            X = MyStepRegreesionModel.model.formula.split("~")[1].split("+")
            i = -1
            RegressorSeries = ";"
            for Regressor in X:
                i = i + 1
                if i == len(X)-1:
                   print(('Intercept is: ', MyStepRegreesionModel.params[0]))
                else:
                   print(('Regressor is: ', Regressor, 'and its coefficient is: ', MyStepRegreesionModel.params[i+1]))
                   RegressorSeries = RegressorSeries + Regressor.replace(" ","") + ":" + str(MyStepRegreesionModel.params[i+1])+";"
            #print('R2 is: ', MyStepRegreesionModel.rsquared)   #OLS has attribute of rsquared but RLM does not have, so comment out this sentence here
            FinalResult = "Y:" + Y.replace(" ","") + RegressorSeries + "Intercept:" + str(MyStepRegreesionModel.params[0]) + ";R^2:" + str(MyStepRegreesionModel.rsquared)+"\n"  #OLS has attribute of rsquared but RLM does not have, so comment out this sentence here
            #FinalResult = "Y:" + Y.replace(" ","") + RegressorSeries + "Intercept:" + str(MyStepRegreesionModel.params[0]) + ";R^2: NoValueForRLM" + "\n"  #OLS has attribute of rsquared but RLM does not have, so this is a new sentence on June 15, 2015.
            #print('Final result sentence written to file\n ', StepwiseRegressionResult, '\nis:\n ', FinalResult)
            StepwiseRegressionResultFile.write(FinalResult)
            StepwiseRegressionResultFile.write("\nThe summary of the regression can be found below:\n")
            StepwiseRegressionResultFile.write(str(MyStepRegreesionModel.summary()))
            StepwiseRegressionResultFile.close()
            # Note we can change the data to DataCsvFile and the response to totalbiomass
            ##    ## The following information is important to extedn our work for the future, so I keep it here although I do not use them--start 
            ##    # Technically, we can use different regression style as shown below; however, the negative values should be "nan" for LN or SQRT, which is hard, so I do not consider in our work--start    
            ##    FormulaStyle = "Y~Ln(X)" # Full options are ["Y~X", "Y~Ln(X)", "Ln(Y)~X", "Ln(Y)~Ln(X)","Sqrt(Y)~X"]
            ##    if FormulaStyle == "Y~X":                 
            ##       formula = "{} ~ {} + 1".format(response, ' + '.join(selected))  # Formular for Y and X
            ##    if FormulaStyle == "Y~Ln(X)": 
            ##       formula = "{} ~ {} + 1".format(response, ' + '.join("np.log(" + VarString + ")" for VarString in selected))  # Formular for Y and Ln(X)
            ##    if FormulaStyle == "Ln(Y)~X": 
            ##       formula = "{} ~ {} + 1".format("np.log(" + response + ")", ' + '.join(selected))  # Formular for Ln(Y) and X
            ##    if FormulaStyle == "Ln(Y)~Ln(X)": 
            ##       formula = "{} ~ {} + 1".format("np.log(" + response + ")", ' + '.join("np.log(" + VarString + ")" for VarString in selected)) # Formular for Ln(Y) and Ln(X)
            ##    if FormulaStyle == "Sqrt(Y)~X": 
            ##       formula = "{} ~ {} + 1".format("np.sqrt(" + response + ")", ' + '.join(selected))  # Formular for SQRT(Y) and X
            ##    print('FormulaStyle is: ', FormulaStyle,' and Formula is:', formula)
            ##    # Technically, we can use different regression style as shown below; however, the negative values should be "nan" for LN or SQRT, which is hard, so I do not consider in our work--end  
            ##    ## The following information is important to extedn our work for the future, so I keep it here although I do not use them--end
        return StepwiseRegressionResult
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)     ,
        Content2 = "The error was for StepwiseRegression with inputs of " +repr(InputFile)+","+repr(Metric)+ " with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog

    
def FindTheFirstTableNameWhereMetricExists(Metric,SqliteDB):
    try:
        TableWhereMetricIsFound = []
        conn_src = sqlite3.connect(SqliteDB)  #Using the first one to copy the sqlite database structure
        conn_srcCursor = conn_src.cursor()
        for line in conn_src.iterdump():  #This is to copy the structure but do not copy the data. The code comes from ChatGPT on 20230404
            #print(line)
            if ('INSERT INTO' not in line) and ('CREATE TABLE' in line):
                #print(Metric,"%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%",line)
                for WholeWord1 in line.split():  #We need wholeword (e.g., DBH and DBH_class are different), see https://stackoverflow.com/questions/4154961/find-substring-in-string-but-only-if-whole-words
                    for WholeWord2 in WholeWord1.split(","):   #note split(" ") and split() are different
                        if WholeWord2.lower() == Metric.lower():
                            ThisTable = line.split()[2].split("(")[0]   #Sometimes it is "CREATE TABLE FVS_Compute(CaseID" but sometimes it is "CREATE TABLE FVS_Compute (CaseID"
                            NotStandLevelTable = ["fvs_treelist","fvs_atrtlist","fvs_cutlist","fvs_cases"]  #20231012 added to exclude those table that are not stand specific
                            if ThisTable.lower() not in NotStandLevelTable:
                                print(Metric," is in table of ", ThisTable)   
                                TableWhereMetricIsFound.append(ThisTable)
        conn_src.close()
        print("For metric=",Metric," TableWhereMetricIsFound=",TableWhereMetricIsFound," in SqliteDB=",SqliteDB)
        print(Metric, " was found in the tables ",TableWhereMetricIsFound, " from the SQLITE of ",SqliteDB, file=open(F3Log, 'a'))
        if len(TableWhereMetricIsFound) >= 1:
            if "FVS_Compute" in TableWhereMetricIsFound:
                TheFirstTableNameWhereMetricExists = "FVS_Compute" #20240126: We put FVS_Compute as a priority, because we can control it. Also other system-generated table is not stable but FVS_Compute is stable 
            else:
                TheFirstTableNameWhereMetricExists = TableWhereMetricIsFound[0]   #A metric may appear in several tables but their values should be identical, so we choose the first one
        else:
            TheFirstTableNameWhereMetricExists = "NotFound"
        return TheFirstTableNameWhereMetricExists
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n" 
        #print(Content1)     ,
        Content2 = "The error was for FindTheFirstTableNameWhereMetricExists with inputs of " +repr(Metric)+","+repr(SqliteDB)+ " with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog




def PlotSymbolInQuicklook(NewGeoTransform,band1,Metric,MinimumBoundValue,MaximumBoundValue,ShengliHuangKeyFile,FieldPlotData,F3NoDataValue):
    try:
        print("Here we have rows, columns, resolutions, extent, minimumnound, and maximumbound, we just need to add the original dB and coordinates?")
        cols = band1.shape[1]
        rows = band1.shape[0]
        MinX = NewGeoTransform[0]
        MaxX = NewGeoTransform[0] + NewGeoTransform[1] * cols
        MinY = NewGeoTransform[3] + NewGeoTransform[5] * rows
        MaxY = NewGeoTransform[3]
        print("MinX,MaxX,MinY,MaxY=",MinX,MaxX,MinY,MaxY)
        FuzzyLocation = "Yes"   #Another option is "No". This indicates if you want to use actual corrdinates to locate the symbol. We always use "Yes" here
        PlotMetricValueRectangle = np.full((rows,cols), F3NoDataValue)
        plotlist,xlist,ylist,StatesCodeInThisHSL,StatesFullNameInThisHSL,StatesShortNameInThisHSL,SpeciesTranslatorInThisHSL = PlotIDandXandY(ShengliHuangKeyFile,Factor)  #20240125: plotlist is integer (from round function), xlist is float,and ylist is flaot too        
        MetricValuePositionXList = []
        MetricValuePositionYList = []
        MetricValueTextList = []
        for FieldSqlite in FieldPlotData:
            conn = sqlite3.connect(FieldSqlite)  #https://www.sqlitetutorial.net/sqlite-python/
            cur= conn.cursor()
            #20230504: add another function to determine which table should be chosen for this metric---start
            Table = FindTheFirstTableNameWhereMetricExists(Metric,FieldSqlite)
            if Table != "NotFound":
                TableQuery = "SELECT * FROM " + Table
                cur.execute(TableQuery)  
            #20230504: add another function to determine which table should be chosen for this metric---end
            columns = [column[0].lower() for column in cur.description]
            FIADB_PLOTIndex = columns.index("FIADB_PLOT".lower())
            if Metric not in columns:
                print("------This metric does not exist:",Metric)
                continue
            else:
                MetricIndex = columns.index(Metric)
                print("------MetricIndex=",MetricIndex)
            rowsAAA = cur.fetchall()
            FIADB_PLOTCode = []
            MetricMax = -100000000000000
            MetricMin =  100000000000000
            rowid = 0
            for row in rowsAAA:
                rowid = rowid + 1                    
                FIADB_PLOT = int(row[FIADB_PLOTIndex])

                if row[MetricIndex] is None:  #20240214 added because We have an error at MetricValue = float(row[MetricIndex]): "TypeError: float() argument must be a string or a real number, not 'NoneType'
                    MetricValue0 = 0
                else:
                    MetricValue0 = float(row[MetricIndex])

                MetricValue = int(MetricValue0 * FloatToIntegerCoefficient) 
                PlotIndexInplotlist = plotlist.index(FIADB_PLOT)
                CoordinateX = xlist[PlotIndexInplotlist]
                CoordinateY = ylist[PlotIndexInplotlist]
                if (CoordinateX < MinX) or (CoordinateX > MaxX) or (CoordinateY < MinY) or (CoordinateY > MaxY): #outside, then quit
                    #print("This plot is outside of the range, so discarded")
                    continue
                else:
                    CellX = int((CoordinateX - MinX) / NewGeoTransform[1])
                    CellY = int((MaxY - CoordinateY) / abs(NewGeoTransform[5]))
                    #print("CellX,CellY=",CellX,CellY)
                    if FuzzyLocation == "Yes":
                       FuzzyDistance = 1600.0  #Here 1600 is in meters equal to 1 mile. The location is fuzzied in 1 mile = FIA 1 mile
                       CellX = min(max(CellX + randint(-1*int(FuzzyDistance/abs(NewGeoTransform[1])),int(FuzzyDistance/abs(NewGeoTransform[1]))),0),cols)
                       CellY = min(max(CellY + randint(-1*int(FuzzyDistance/abs(NewGeoTransform[5])),int(FuzzyDistance/abs(NewGeoTransform[5]))),0),rows)
                SmallestThickness = 4
                LargestThickness = 14
                RectangeBorderThickness = 1
                if MetricValue == 0:
                    RectangeRadius = SmallestThickness
                    colorcode = 10   #This is the color for value=0
                else:
                    RectangeRadius =  int(SmallestThickness + (MetricValue-MinimumBoundValue)/(MaximumBoundValue-MinimumBoundValue) * (LargestThickness-SmallestThickness))
                    colorcode = 200   #This is the color for value!=0
                print("RectangeRadius=",RectangeRadius)
                CellXstart = max(0,CellX-RectangeRadius)
                CellXend = min(CellX+RectangeRadius,cols)
                CellYstart = max(0,CellY-RectangeRadius)
                CellYend = min(CellY+RectangeRadius,rows)
                
                MetricValuePositionX = int(CellX)
                MetricValuePositionY = int(CellY)
                MetricValueText = MetricValue
                MetricValuePositionXList.append(MetricValuePositionX)
                MetricValuePositionYList.append(MetricValuePositionY)
                MetricValueTextList.append(str(MetricValueText))
                
                print("CellXstart,CellXend,CellYstart,CellYend=",CellXstart,CellXend,CellYstart,CellYend)
                PlotMetricValueRectangle[CellXstart:CellXend,CellYstart:CellYend] = colorcode  #This will be solid rectange
                RectangleEmptyCenterCellXstart = max(CellXstart+RectangeBorderThickness,0)
                RectangleEmptyCenterCellXend = min(max(CellXend-RectangeBorderThickness,0),cols)
                RectangleEmptyCenterCellYstart = max(CellYstart+RectangeBorderThickness,0)
                RectangleEmptyCenterCellYend = min(max(CellYend-RectangeBorderThickness,0),rows)
                print("RectangleEmptyCenterCellXstart,RectangleEmptyCenterCellXend,RectangleEmptyCenterCellYstart,RectangleEmptyCenterCellYend=",RectangleEmptyCenterCellXstart,RectangleEmptyCenterCellXend,RectangleEmptyCenterCellYstart,RectangleEmptyCenterCellYend)
                PlotMetricValueRectangle[RectangleEmptyCenterCellXstart:RectangleEmptyCenterCellXend,RectangleEmptyCenterCellYstart:RectangleEmptyCenterCellYend] = F3NoDataValue  #to make the rectange empty
        PlotMetricValueRectangle = ma.masked_values(PlotMetricValueRectangle, F3NoDataValue)
        band1[~PlotMetricValueRectangle.mask] = PlotMetricValueRectangle[~PlotMetricValueRectangle.mask] 
        return band1,MetricValuePositionXList,MetricValuePositionYList,MetricValueTextList
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n" 
        #print(Content1)     ,
        Content2 = "The error was for PlotSymbolInQuicklook with inputs of " +repr(NewGeoTransform)+","+repr(band1.shape)+","+repr(Metric)+","+repr(MinimumBoundValue)+","+repr(MaximumBoundValue)+","+repr(ShengliHuangKeyFile)+","+repr(FieldPlotData)+","+repr(F3NoDataValue)+ " with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog





def ContinuousSingleBandQuickLookGeotifPseudoColorImage(SrcTif,ReducedTimes,MinMaxSource,MinimumBound,MaximumBound,Metric):
    try:
        MetricShortName,MetricFullName,MetricDefinition,SpeciesScienticName,USDAPlantCode,FVSKeyword,MetricUnit_US,MetricUnit_SI,UStoSIconversion,MetricShortNameIGivenBy,MetricFullNameIGivenBy,AdditionalNotes = MetricInformationFromXLSX(Metric)
        if OutputUnit == "Imperial":
           ThisUnit = MetricUnit_US
        if OutputUnit == "SI":
           ThisUnit =  MetricUnit_SI
                    
        Quicklookfile = SrcTif.replace(".tif","")+"_Purple"+str(int(MinimumBound))+"Red"+str(int(MaximumBound))+"_QuickLook"+str(int(ReducedTimes))+".tif"
        if not os.path.exists(Quicklookfile):    
            if os.path.exists(SrcTif):
                driverTiff = gdal.GetDriverByName('GTiff')
                ds = gdal.Open(SrcTif)
                cols = ds.RasterXSize
                rows = ds.RasterYSize
                WeUseThisProjection = ds.GetProjectionRef()
                WeUseThisGeoTransform = ds.GetGeoTransform()
                print(WeUseThisGeoTransform)
                NewGeoTransform = [WeUseThisGeoTransform[0],WeUseThisGeoTransform[1]*ReducedTimes,WeUseThisGeoTransform[2],WeUseThisGeoTransform[3],WeUseThisGeoTransform[4],WeUseThisGeoTransform[5]*ReducedTimes]
                print(NewGeoTransform)  #This will have a new resolution 

                band1 = ds.GetRasterBand(1).ReadAsArray()
                NoDataValue = ds.GetRasterBand(1).GetNoDataValue()
                band1 = ma.masked_values(band1, NoDataValue)
                if MinMaxSource == "ImageItSelf":
                    MinimumBoundValue = max(band1.mean()-band1.std(),band1.min())
                    MaximumBoundValue = min(band1.mean()+band1.std(),band1.max())
                if MinMaxSource == "CommandArgument":  #Someday, we will use the metrics max and min values
                    MinimumBoundValue = MinimumBound  #This value shoud get from F3 input database; if not, then MEAN-STD is proposed
                    MaximumBoundValue = MaximumBound   #This value shoud get from F3 input database; if not, then MEAN+STD is proposed
                print("Below we use multiple where to do : if >max, 255; if < min, 0; else interploted from 0 to 255")
                band1AAA = np.where(band1 >= MaximumBoundValue, 254, np.where(band1 <= MinimumBoundValue, 1, 254.0*(band1-MinimumBoundValue)*1.0/(MaximumBoundValue-MinimumBoundValue)))
                band1AAA[band1.mask] = 0  #added 20230210 to set the nodata area as 0
                band1 = band1AAA  #added 20230210 to set the nodata area as 0
                band1 = band1.astype(int)   #convert to unsigned 8 bit integer
                band1 = band1[::ReducedTimes,::ReducedTimes]  #This is to resample the array with interval of ReducedTimes, see https://www.w3schools.com/python/numpy/numpy_array_slicing.asp
                newrows = band1.shape[0]  
                newcols = band1.shape[1]
                print("band1.shape[1] columns, band1.shape[0] rows=",band1.shape[1], band1.shape[0])

                AddingPlotMetricValueAndSymbol = "No"
                if AddingPlotMetricValueAndSymbol == "Yes":
                    #ShengliHuangKeyFile = r"O:\inventory\fastemap\ShengliHuangTrue.sec"
                    FieldPlotData = ["D:\\f3app\\HuangTest2\\Run1\\SERAL\\FieldPoint\\Head_NoMGT_2019.db"]   #This is just a placeholder
                    band1,MetricValuePositionXList,MetricValuePositionYList,MetricValueTextList = PlotSymbolInQuicklook(NewGeoTransform,band1,Metric,MinimumBoundValue,MaximumBoundValue,ShengliHuangKeyFile,FieldPlotData,F3NoDataValue)
                
                #Add legend color---start
                LegendRows = 1000  #20230202: I think we can use a fixed height but ignore width
                Legendcols = newcols
                FontSize = 60
                LegendArray = np.full((LegendRows,Legendcols), 0) #0.1 and 0.9 is the heigh of the legend (from 10% to 90%)
                LegendStartRow = int(LegendRows * 0.2) 
                LegendEndRow = int(LegendRows * 0.7) 
                LegendStartCol = int(Legendcols * 0.01) #0.1 and 0.3 is the width of the legend (from 10% to 30%)
                LegendEndCol = int(Legendcols * 0.15)
                for i in range(LegendStartRow,LegendEndRow):
                    myvalue = int(254.0 / (LegendEndRow-LegendStartRow) * (i-LegendStartRow))
                    LegendArray[i,LegendStartCol:LegendEndCol] = myvalue
                LegendArray[LegendStartRow,LegendStartCol:LegendEndCol] = 255  #These are the top border, give a value of 255
                LegendArray[LegendEndRow,LegendStartCol:LegendEndCol] = 255  #These are the bottom border, give a value of 255
                LegendArray[LegendStartRow:LegendEndRow,LegendStartCol] = 255   #These are the left border, give a value of 255
                LegendArray[LegendStartRow:LegendEndRow,LegendEndCol] = 255  #These are the right border, give a value of 255
                LegendMinimumPositionX = LegendStartCol
                LegendMinimumPositionY = LegendStartRow - FontSize - 5    
                LegendMinimumText = str(int(MinimumBoundValue)) + " ("+ThisUnit+")"
                LegendMaximumPositionX = LegendStartCol
                LegendMaximumPositionY = LegendEndRow + 3        
                LegendMaximumText = str(int(MaximumBoundValue)) + " ("+ThisUnit+")"
                
                ScalebarRowStart = int(LegendRows * 0.3)
                ScalebarRowEnd = ScalebarRowStart + 20
                ScalebarColStart = int(Legendcols * 0.5)
                ScalebarColEnd = int(Legendcols * 0.95)
                HalfScale = int((ScalebarColEnd-ScalebarColStart)/2)
                ScalebarTextPositionX = ScalebarColStart + HalfScale - 20
                ScalebarTextPositionY = LegendStartRow
                ScalebarText = str(int((ScalebarColEnd - ScalebarColStart) * F3Resolution * ReducedTimes / 1000.0)) + " KM"
                print("ScalebarTextPositionX,ScalebarTextPositionY,ScalebarText=",ScalebarTextPositionX,ScalebarTextPositionY,ScalebarText)       
                LegendArray[ScalebarRowStart:ScalebarRowEnd,ScalebarColStart:ScalebarColEnd] = 255  #This is for adding a scale bar

                TitleTextPositionX = LegendStartCol
                TitleTextPositionY = 15
                if Metric in ["fortyp","fortype"]:
                    TitleText = SrcTif.split(os.sep)[-1].replace(".tif","") + " check ForestAndCropType.csv"
                else:
                    TitleText = SrcTif.split(os.sep)[-1].replace(".tif","") + " (/100 for actual values)"
                
                CreatorTextPositionX = 15
                CreatorTextPositionY = LegendEndRow + FontSize + 30
                CreatorText = "Produced with the F3 script developed by Dr. Shengli Huang (shengli.huang@usda.gov) at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")

                NorthArrowTif = os.getcwd()+os.sep+"TilesMosaicRunAverage" + os.sep + "NorthArrow.tif"
                driverTiff = gdal.GetDriverByName('Tiff')
                NorthArrowds = gdal.Open(NorthArrowTif)
                NorthArrowcols = NorthArrowds.RasterXSize
                NorthArrowrows = NorthArrowds.RasterYSize
                NorthArrowband = NorthArrowds.GetRasterBand(1).ReadAsArray()
                print("rows and columns of north arrow = ",NorthArrowrows,NorthArrowcols)
                RowsReduceTimes = max(1,int(np.ceil(NorthArrowrows*1.0/(LegendEndRow-ScalebarRowEnd))))
                ColsReduceTimes = max(1,int(np.ceil(NorthArrowcols*1.0/(ScalebarColEnd-ScalebarColStart))))
                NorthArrowReduceTimes = max(RowsReduceTimes,ColsReduceTimes)
                print("RowsReduceTimes,ColsReduceTimes,ReduceTimes=",RowsReduceTimes,ColsReduceTimes,NorthArrowReduceTimes)
                NorthArrowArray = NorthArrowband[::NorthArrowReduceTimes,::NorthArrowReduceTimes]
                print("NorthArrowArray.shape=",NorthArrowArray.shape)
                SpaceBetweenScaleBarAndNorthArrow = 50  #we saw an error ValueError: could not broadcast input array from shape (265,215) into shape (265,189) for the following sentence
                a1 = ScalebarRowEnd+SpaceBetweenScaleBarAndNorthArrow
                a2 = ScalebarRowEnd+SpaceBetweenScaleBarAndNorthArrow+NorthArrowArray.shape[0]
                b1 = ScalebarColStart+HalfScale-int(0.5*NorthArrowArray.shape[1])  #20230316 revised 
                b2 = b1 + NorthArrowArray[:,:].shape[1]  #b2 = ScalebarColStart+HalfScale+int(0.5*NorthArrowArray.shape[1]) may have 1 offset
                print("a1,a2,b1,b2=",a1,a2,b1,b2)
                print("a1,a2,b1,b2=",a1,a2,b1,b2, file=open(F3Log, 'a'))
                LegendArray[a1:a2,b1:b2] = NorthArrowArray[:,:]

                band1andlegend = np.vstack((band1,LegendArray))   #use vstack to combine the two array, see https://numpy.org/doc/stable/reference/generated/numpy.vstack.html
                #Add legend color---start

                driver = gdal.GetDriverByName("GTiff")
                if OutputGeoTifCompression == "Yes": #Added on 20230227. LZW compression does not lose information. LZW compression is a lossless data compression algorithm, which means that the original data can be fully reconstructed from the compressed data without any loss of information.
                    outdata = driver.Create(Quicklookfile, band1andlegend.shape[1], band1andlegend.shape[0], 1, gdal.GDT_Byte, options=['COMPRESS=LZW'])  #New cols and rows are necessary, see datatype at https://gis.stackexchange.com/questions/122806/create-8bit-unsigned-geotiff-with-gdal and https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
                if OutputGeoTifCompression == "No": 
                    outdata = driver.Create(Quicklookfile, band1andlegend.shape[1], band1andlegend.shape[0], 1, gdal.GDT_Byte)  #New cols and rows are necessary, see datatype at https://gis.stackexchange.com/questions/122806/create-8bit-unsigned-geotiff-with-gdal and https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
                outdata.SetGeoTransform(NewGeoTransform)  #Need to use new GeoTransform
                outdata.SetProjection(WeUseThisProjection)  ##sets same projection as input
                outdata.GetRasterBand(1).WriteArray(band1andlegend)
                outdata.GetRasterBand(1).SetNoDataValue(F3NoDataValue)  
                outdata.FlushCache() ##saves to disk!!
                outdata = None
              
                ds1 = gdal.Open(Quicklookfile, 1)
                band2 = ds1.GetRasterBand(1)
                print("for CreateColorRamp, see https://gdal.org/doxygen/classGDALColorTable.html and https://gis.stackexchange.com/questions/354650/gdal-colorramp-for-float-based-values")
                print("for discrete color like colors.SetColorEntry(4, (194, 140, 124)), see https://gis.stackexchange.com/questions/325615/store-geotiff-with-color-table-python")
                colors = gdal.ColorTable()  #Algorithm behind it is to interpolate the start-end for R,G,B
                colors.SetColorEntry(0, (255,255,255))      #Black is R0G0B0 while white is R255G255B255
                colors.CreateColorRamp(1, (199,36,177), 50, (0,0,255))  # purple to blue
                colors.CreateColorRamp(51, (0,0,255), 100, (0,255,0))  #blue-green
                colors.CreateColorRamp(101, (0,255,0), 150, (255,255,0))  #green-yellow
                colors.CreateColorRamp(151, (255,255,0), 200, (255, 165, 0)) #Yellow-orange
                colors.CreateColorRamp(201, (255, 165, 0), 255, (255,0,0))   #orange-red
                colors.SetColorEntry(F3NoDataValue, (0, 0, 0)) #Not sure if this sentence (giving a color to NAN pixels) is necessary here
                colors.SetColorEntry(255, (0,0,0))   #Black is R0G0B0 while white is R255G255B255
                colors_size = colors.GetCount()  #print("The number of colors is: ",colors_size)
                for k in range(colors_size):
                    entry = colors.GetColorEntry(k)
                    #print("k=",k, " and entry is: ", entry)
                band2.SetRasterColorTable(colors)
                band2.SetRasterColorInterpretation(gdal.GCI_PaletteIndex)
                del band2, ds1

                #Adding text to an image, see https://fedingo.com/how-to-add-text-to-image-in-python/---start        
                img = Image.open(Quicklookfile)
                I1 = ImageDraw.Draw(img)
                FontDatabase = os.getcwd()+os.sep+"TilesMosaicRunAverage" + os.sep + "Verdana.ttf"
                if not os.path.exists(FontDatabase):
                    FontDatabase = 'C:\Windows\Fonts\Verdana.ttf'  #This may be customized for the specific OS
                myFont = ImageFont.truetype(FontDatabase, FontSize)  #For windows user, font files in C:\WINDOWS\Fonts, see https://stackoverflow.com/questions/41382116/oserror-cannot-open-resource-while-trying-to-use-imagefont-py
                print("ScalebarTextPositionX, ScalebarTextPositionY+newrows), ScalebarText=",ScalebarTextPositionX, ScalebarTextPositionY+newrows, ScalebarText)
                I1.text((ScalebarTextPositionX, ScalebarTextPositionY+newrows), ScalebarText, font=myFont, fill =(0, 0, 255))   
                print("TitleTextPositionX, TitleTextPositionY+newrows), TitleText=",TitleTextPositionX, TitleTextPositionY+newrows, TitleText)
                I1.text((TitleTextPositionX, TitleTextPositionY+newrows), TitleText, font=myFont, fill =(0, 0, 255))  #If you want to choosee fonttype, you need to install or download font database, see https://fedingo.com/how-to-add-text-to-image-in-python/ 
                I1.text((LegendMinimumPositionX, LegendMinimumPositionY+newrows), LegendMinimumText, font=myFont, fill =(0, 0, 255))  #If you want to choosee fonttype, you need to install or download font database, see https://fedingo.com/how-to-add-text-to-image-in-python/ 
                I1.text((LegendMaximumPositionX, LegendMaximumPositionY+newrows), LegendMaximumText, font=myFont, fill =(0, 0, 255))  #If you want to choosee fonttype, you need to install or download font database, see https://fedingo.com/how-to-add-text-to-image-in-python/         
                CreatorFont = ImageFont.truetype('C:\Windows\Fonts\Verdana.ttf', int(FontSize*0.8))
                I1.text((CreatorTextPositionX, CreatorTextPositionY+newrows), CreatorText, font=CreatorFont, fill =(0, 0, 255))  #If you want to choosee fonttype, you need to install or download font database, see https://fedingo.com/how-to-add-text-to-image-in-python/         

                AddingWaterMark = "Yes" #Options are "Yes", "No"
                if AddingWaterMark == "Yes":  #added on 20230301
                    WaterMarkFont1 = ImageFont.truetype('C:\Windows\Fonts\Verdana.ttf', int(FontSize*np.random.randint(3,10)))
                    WaterMarkText1PositionX = np.random.randint(1, int(0.3 * newcols))
                    WaterMarkText1PositionY = np.random.randint(1, int(0.9 * newrows))
                    WaterMarkText1 = "F3 PRODUCTS"
                    #WaterMarkText1_rotated = WaterMarkText1.rotate(45, expand=1)  #rotate the text by degrees. We set expand=1 to ensure that the rotated text fits inside the original image.
                    I1.text((WaterMarkText1PositionX, WaterMarkText1PositionY), WaterMarkText1, font=WaterMarkFont1, fill =(0, 0, 255))  #fill =(np.random.randint(1,254),np.random.randint(1,254),np.random.randint(1,254))

                    WaterMarkFont2 = ImageFont.truetype('C:\Windows\Fonts\Verdana.ttf', int(FontSize*np.random.randint(4,10)))
                    WaterMarkText2PositionX = np.random.randint(1, int(0.3 * newcols))
                    WaterMarkText2PositionY = np.random.randint(1, int(0.9 * newrows))
                    WaterMarkText2 = "Dr. SHENGLI HUANG"
                    #WaterMarkText2_rotated = WaterMarkText2.rotate(45, expand=1)  #rotate the text by degrees. We set expand=1 to ensure that the rotated text fits inside the original image.
                    I1.text((WaterMarkText2PositionX, WaterMarkText2PositionY), WaterMarkText2, font=WaterMarkFont2, fill =(0, 0, 255))  #if if not (0, 0, 255), then 'ValueError: cannot allocate more than 256 colors

                    WaterMarkFont3 = ImageFont.truetype('C:\Windows\Fonts\Verdana.ttf', int(FontSize*np.random.randint(5,10)))
                    WaterMarkText3PositionX = np.random.randint(1, int(0.3 * newcols))
                    WaterMarkText3PositionY = np.random.randint(1, int(0.9 * newrows))
                    WaterMarkText3 = "shengli.huang@usda.gov"
                    #WaterMarkText3_rotated = WaterMarkText3.rotate(45, expand=1)  #rotate the text by degrees. We set expand=1 to ensure that the rotated text fits inside the original image.
                    I1.text((WaterMarkText3PositionX, WaterMarkText3PositionY), WaterMarkText3, font=WaterMarkFont3, fill =(0, 0, 255))  

                    WaterMarkFont4 = ImageFont.truetype('C:\Windows\Fonts\Verdana.ttf', int(FontSize*np.random.randint(4,10)))
                    WaterMarkText4PositionX = np.random.randint(1, int(0.3 * newcols))
                    WaterMarkText4PositionY = np.random.randint(1, int(0.9 * newrows))
                    WaterMarkText4 = "916-6401258"
                    #WaterMarkText4_rotated = WaterMarkText4.rotate(45, expand=1)  #rotate the text by degrees. We set expand=1 to ensure that the rotated text fits inside the original image.
                    I1.text((WaterMarkText4PositionX, WaterMarkText4PositionY), WaterMarkText4, font=WaterMarkFont4, fill =(0, 0, 255))  
                if AddingPlotMetricValueAndSymbol == "Yes":
                    for i in range(0,len(MetricValuePositionXList),1):  #This is to add MetricValue into quicklook
                        I1.text((MetricValuePositionXList[i], MetricValuePositionYList[i]), MetricValueTextList[i], font=myFont, fill =(0, 0, 255))
                img.save(Quicklookfile)
                #Adding text to an image, see https://fedingo.com/how-to-add-text-to-image-in-python/---end
        return Quicklookfile
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"   
        #print(Content1)      
        Content2 = "The error was for ContinuousSingleBandQuickLookGeotifPseudoColorImage with inputs of "+repr(SrcTif)+","+repr(ReducedTimes)+","+repr(MinMaxSource)+","+repr(MinimumBound)+","+repr(MaximumBound)+","+repr(Metric)+ " with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog

    

def DiscreteSingleBandQuickLookGeotifPseudoColorImage(SrcTif,ReducedTimes,MinMaxSource,MinimumBound,MaximumBound):
    try:
        #SrcTif = r'C:\F3LinuxGui2_backup20220630\F3unix\Testout\Landsat8_2019_NIR.tif'
        #ReducedTimes = 20  #It is a integer. This means the new image is reduced by X times.
        #MinMaxSource = "ImageItSelf"  #Options are "ImageItSelf" or "CommandArgument"

        driverTiff = gdal.GetDriverByName('GTiff')
        ds = gdal.Open(SrcTif)
        cols = ds.RasterXSize
        rows = ds.RasterYSize
        WeUseThisProjection = ds.GetProjectionRef()
        WeUseThisGeoTransform = ds.GetGeoTransform()
        print(WeUseThisGeoTransform)
        NewGeoTransform = [WeUseThisGeoTransform[0],WeUseThisGeoTransform[1]*ReducedTimes,WeUseThisGeoTransform[2],WeUseThisGeoTransform[3],WeUseThisGeoTransform[4],WeUseThisGeoTransform[5]*ReducedTimes]
        print(NewGeoTransform)  #This will have a new resolution 

        band1 = ds.GetRasterBand(1).ReadAsArray().astype(np.int64)
        NoDataValue = ds.GetRasterBand(1).GetNoDataValue()
        band1 = ma.masked_values(band1, NoDataValue)
        if MinMaxSource == "ImageItSelf":
            MinimumBoundValue = max(band1.mean()-band1.std(),band1.min())
            MaximumBoundValue = min(band1.mean()+band1.std(),band1.max())
        if MinMaxSource == "CommandArgument":  #Someday, we will use the metrics max and min values
            MinimumBoundValue = MinimumBound  #This value shoud get from F3 input database; if not, then MEAN-STD is proposed
            MaximumBoundValue = MaximumBound   #This value shoud get from F3 input database; if not, then MEAN+STD is proposed
        print("Below we use multiple where to do : if >max, 255; if < min, 0; else interploted from 0 to 255")
        #band1 = np.where(band1 >= MaximumBoundValue, MaximumBoundValue, np.where(band1 <= MinimumBoundValue, 0, 255.0*(band1-MinimumBoundValue)*1.0/(MaximumBoundValue-MinimumBoundValue)))
        #band1 = band1.astype(int)   #convert to unsigned 8 bit integer
        band1 = band1[::ReducedTimes,::ReducedTimes]  #This is to resample the array with interval of ReducedTimes, see https://www.w3schools.com/python/numpy/numpy_array_slicing.asp
        newrows = band1.shape[0]  
        newcols = band1.shape[1]         
        driver = gdal.GetDriverByName("GTiff")
        Quicklookfile = SrcTif.replace(".tif","_DiscreteColor.tif")
        if OutputGeoTifCompression == "Yes": #Added on 20230227. LZW compression does not lose information. LZW compression is a lossless data compression algorithm, which means that the original data can be fully reconstructed from the compressed data without any loss of information.
            outdata = driver.Create(Quicklookfile, newcols, newrows, 1, gdal.GDT_Int32, options=['COMPRESS=LZW'])  #New cols and rows are nccessary, see datatype at https://gis.stackexchange.com/questions/122806/create-8bit-unsigned-geotiff-with-gdal and https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
        if OutputGeoTifCompression == "No": 
            outdata = driver.Create(Quicklookfile, newcols, newrows, 1, gdal.GDT_Int32)  #New cols and rows are nccessary, see datatype at https://gis.stackexchange.com/questions/122806/create-8bit-unsigned-geotiff-with-gdal and https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
        outdata.SetGeoTransform(NewGeoTransform)  #Need to use new GeoTransform
        outdata.SetProjection(WeUseThisProjection)##sets same projection as input
        outdata.GetRasterBand(1).WriteArray(band1)
        outdata.GetRasterBand(1).SetNoDataValue(F3NoDataValue)  ##if you want these values transparent
        outdata.FlushCache() ##saves to disk!!
        outdata = None

        ds1 = gdal.Open(Quicklookfile, 1)
        band2 = ds1.GetRasterBand(1)
        print("for CreateColorRamp, see https://gdal.org/doxygen/classGDALColorTable.html and https://gis.stackexchange.com/questions/354650/gdal-colorramp-for-float-based-values")
        print("for discrete color like colors.SetColorEntry(4, (194, 140, 124)), see https://gis.stackexchange.com/questions/325615/store-geotiff-with-color-table-python")
        colors = gdal.ColorTable()  #Algorithm behind it is to interpolate the start-end for R,G,B

        DiscreteClassUnique = np.unique(band1)
        for DiscreteVale in DiscreteClassUnique:
            colors.SetColorEntry(DiscreteVale, (randint(0, 255), randint(0, 255), randint(0, 255)))
        colors.SetColorEntry(F3NoDataValue, (0, 0, 0))
        colors_size = colors.GetCount()  #print("The number of colors is: ",colors_size)
        for k in range(colors_size):
            entry = colors.GetColorEntry(k)
            #print("k=",k, " and entry is: ", entry)
        band2.SetRasterColorTable(colors)
        band2.SetRasterColorInterpretation(gdal.GCI_PaletteIndex)
        del band2, ds1
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)   
        Content2 = "The error was for DiscreteSingleBandQuickLookGeotifPseudoColorImage with inputs of " +repr(SrcTif)+","+repr(ReducedTimes)+","+repr(MinMaxSource)+","+repr(MinimumBound)+","+repr(MaximumBound)+ " with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog



def GifAnimation(TifList, AnimationOutput):   #https://www.blog.pythonlibrary.org/2021/06/23/creating-an-animated-gif-with-python/
    try:
        print("TifList=",TifList, file=open(F3Log, 'a'))
        frames = [Image.open(image) for image in TifList]
        frame_one = frames[0]
        frame_one.save(AnimationOutput, format="GIF", append_images=frames, save_all=True, duration=100, loop=0)
        print(AnimationOutput, " was created. You can open it with a internet browser", file=open(F3Log, 'a'))
        return AnimationOutput
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)   
        Content2 = "The error was for GifAnimation with inputs of "+repr(TifList)+repr(AnimationOutput)+" with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog

 


def FinalStatisticsReportForMetricAndTimeSeriesCurve(mylock,MetricOfInterest):
    try:
        ##https://www.geeksforgeeks.org/how-to-merge-multiple-csv-files-into-a-single-pandas-dataframe/
        ##https://realpython.com/pandas-groupby/
        ##https://www.askpython.com/python-modules/pandas/pandas-groupby-function
        ##https://stackoverflow.com/questions/55788963/using-groupby-function-with-a-dataframe-from-a-csv-file-and-plotting-the-result
        ##https://www.geeksforgeeks.org/pandas-groupby-multiple-values-and-plotting-results/
        ##https://www.geeksforgeeks.org/plot-the-size-of-each-group-in-a-groupby-object-in-pandas/

        FinalStatisticsReportCSV = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep+MetricOfInterest +"_FinalStatistic.csv"
        StatisticsReportCSVcombined = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep+"F3_"+MetricOfInterest+"_Final.csv"
        if not os.path.exists(FinalStatisticsReportCSV):
            StatisticsReportCSV = glob.glob(os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep+"*_"+MetricOfInterest+"_Final_*.csv")
            print("StatisticsReportCSV=",StatisticsReportCSV, file=open(F3Log, 'a'))
            StatisticsReportCSV_df = pd.concat(map(pd.read_csv, StatisticsReportCSV), ignore_index=True)  #https://www.geeksforgeeks.org/how-to-merge-multiple-csv-files-into-a-single-pandas-dataframe/
            print("StatisticsReportCSV_df=",StatisticsReportCSV_df, file=open(F3Log, 'a'))
            print("StatisticsReportCSV_df.dtypes=",StatisticsReportCSV_df.dtypes, file=open(F3Log, 'a'))
            print("StatisticsReportCSV_df.info()=",StatisticsReportCSV_df.info(), file=open(F3Log, 'a'))
            print("StatisticsReportCSVcombined = ",StatisticsReportCSVcombined, file=open(F3Log, 'a'))  #https://www.geeksforgeeks.org/saving-a-pandas-dataframe-as-a-csv/
            StatisticsReportCSV_df.to_csv(StatisticsReportCSVcombined)  #This will create one csv file for easy analysis
            shutil.copy(StatisticsReportCSVcombined, FinalStatisticsReportCSV) #make a copy
        if os.path.exists(StatisticsReportCSVcombined):   #https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html, https://www.geeksforgeeks.org/python-read-csv-using-pandas-read_csv/
            ColumnOfInterest = ["Management","Year","Metric","MetricUnit","ZoneName","ZonePixelsMean","F3category","STDmeanInThisZoneAsUncertainty"]
            print("ColumnOfInterest=",ColumnOfInterest, file=open(F3Log, 'a'))
            StatisticsReportCSVcombinedDF = pd.read_csv(
                                                            filepath_or_buffer=StatisticsReportCSVcombined,
                                                            header=0,
                                                            usecols=ColumnOfInterest,   #Note the last item has no , at the end
                                                        )
            #print("StatisticsReportCSVcombinedDF=",StatisticsReportCSVcombinedDF, file=open(F3Log, 'a'))
            #print("StatisticsReportCSVcombinedDF.tail=",StatisticsReportCSVcombinedDF.tail(), file=open(F3Log, 'a'))
            #print("StatisticsReportCSVcombinedDF.info()=",StatisticsReportCSVcombinedDF.info(), file=open(F3Log, 'a'))
            print("count, mean, max, min, sum, std etc. can be calculated below. also check https://stackoverflow.com/questions/37984736/pandas-return-a-dataframe-after-groupby for return dataframe by using as_index=False")
            print("see advanced groupby usage at https://realpython.com/pandas-groupby/ and https://stackoverflow.com/questions/47666438/how-to-groupby-aggregate-on-multiple-columns-and-rename-the-multi-index-in-pan")
            ZoneNameMetricManagementYearGroup = StatisticsReportCSVcombinedDF.groupby(["ZoneName","Metric","MetricUnit","Management","Year","F3category"], as_index=False).agg({'ZonePixelsMean': ['mean','median'],'STDmeanInThisZoneAsUncertainty': ['mean','median']})
            ZoneNameMetricManagementYearGroup.columns = ZoneNameMetricManagementYearGroup.columns.map('_'.join)  #rename the column
            ZoneNameMetricManagementYearGroup = ZoneNameMetricManagementYearGroup.rename(columns={'ZoneName_': 'ZoneName', 'Metric_': 'Metric', 'MetricUnit_': 'MetricUnit', 'Management_': 'Management','Year_': 'Year', 'F3category_': 'F3category'})            
            print("ZoneNameMetricManagementYearGroup=",ZoneNameMetricManagementYearGroup)
            print("ZoneNameMetricManagementYearGroup=",ZoneNameMetricManagementYearGroup, file=open(F3Log, 'a'))
            print("ZoneNameMetricManagementYearGroup.dtypes=",ZoneNameMetricManagementYearGroup.dtypes)
            print("ZoneNameMetricManagementYearGroup.dtypes=",ZoneNameMetricManagementYearGroup.dtypes, file=open(F3Log, 'a'))
            #for Zone in ZoneNameMetricManagementYearGroup.ZoneName.unique()[5:10]:  #This is for testing
            for Zone in ZoneNameMetricManagementYearGroup.ZoneName.unique():  #https://www.geeksforgeeks.org/get-unique-values-from-a-column-in-pandas-dataframe/, #https://www.geeksforgeeks.org/how-to-get-cell-value-from-pandas-dataframe/
                for Metric in ZoneNameMetricManagementYearGroup.Metric.unique():
                    
                   #added on 20230222 to add unit in figure Y-axis---start
                    MetricShortName,MetricFullName,MetricDefinition,SpeciesScienticName,USDAPlantCode,FVSKeyword,MetricUnit_US,MetricUnit_SI,UStoSIconversion,MetricShortNameIGivenBy,MetricFullNameIGivenBy,AdditionalNotes = MetricInformationFromXLSX(Metric)
                    if OutputUnit == "Imperial":
                       ThisUnit = MetricUnit_US
                    if OutputUnit == "SI":
                       ThisUnit =  MetricUnit_SI
                    #added on 20230222 to add unit in figure Y-axis---end
                    
                    for Management in ZoneNameMetricManagementYearGroup.Management.unique():
                        for F3category in ZoneNameMetricManagementYearGroup.F3category.unique():
                            SelectedRows = ZoneNameMetricManagementYearGroup[(ZoneNameMetricManagementYearGroup['ZoneName'] == Zone) & (ZoneNameMetricManagementYearGroup['Metric'] == Metric) & (ZoneNameMetricManagementYearGroup['Management'] == Management) & (ZoneNameMetricManagementYearGroup['F3category'] == F3category)] ##https://www.geeksforgeeks.org/selecting-rows-in-pandas-dataframe-based-on-conditions/
                            print(Zone,Metric,Management,F3category,SelectedRows)
                            print(Zone,Metric,Management,F3category,SelectedRows, file=open(F3Log, 'a'))
                            #https://pandas.pydata.org/pandas-docs/stable/user_guide/visualization.html#visualization-errorbars   
                            SelectedRows.plot(kind = 'bar',    #kind = 'line' may be good. https://www.geeksforgeeks.org/how-to-plot-a-dataframe-using-pandas/, https://www.geeksforgeeks.org/pandas-groupby-multiple-values-and-plotting-results/
                                                x = 'Year',   #https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.html
                                                y = "ZonePixelsMean_mean",  #how to emove this from plot? do not know yet
                                                xlabel="Years",  #https://stackoverflow.com/questions/63650646/add-labels-and-title-to-a-plot-made-using-pandas
                                                ylabel="Mean "+Metric+" ("+ThisUnit+")",   #Someday we will add the unit here automatically by calling the dataframe
                                                title="Zone="+Zone+","+"Metric="+Metric+","+"Management="+Management,
                                                yerr = "STDmeanInThisZoneAsUncertainty_mean",  #https://pandas.pydata.org/pandas-docs/stable/user_guide/visualization.html#visualization-errorbars
                                                color = 'red'
                                              )
                            plt.legend(['Mean value of '+Metric+' (pls divide by '+str(FloatToIntegerCoefficient)+' to get the actual value)'],loc='upper left')  #if this sentence does not exist, the legend is "ZonePixelsMean_mean", https://www.statology.org/pandas-plot-legend/#:~:text=You%20can%20use%20the%20following%20basic%20syntax%20to,Pandas%20Suppose%20we%20have%20the%20following%20pandas%20DataFrame%3A
                            #https://stackoverflow.com/questions/13030488/using-pandas-to-plot-barplots-with-error-bars
                            #https://stackoverflow.com/questions/35562556/plotting-error-bars-matplotlib-using-pandas-data-frame
                            #plt.show()  #We comment out this because we want to automatically save the fugure without showing
                            FigureName = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep+"Timeseries_"+Zone.replace(" ","")+"_"+Metric+"_"+Management+".png"  #"png" is also OK here
                            plt.savefig(FigureName) 
                            #plt.pause(3) # https://stackoverflow.com/questions/27693039/matplotlib-for-loop-to-show-save-and-redraw-all-plots
        return FinalStatisticsReportCSV
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)   
        Content2 = "The error was for FinalStatisticsReportForMetricAndTimeSeriesCurve with inputs of "+repr(mylock)+repr(MetricOfInterest)+" with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog


def TimeSeriesPixelWiseStatistics(mylock,Management,Years,Metric):
    try:
        FinalPixelTifMean = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep+Management+"_"+Years[0]+"to"+Years[-1]+"_"+Metric+"_MosaicCellMean_Win3x3Smoothing_PixelWiseMean.tif"
        if not os.path.exists(FinalPixelTifMean):
            SrcTifList = glob.glob(os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep+Management+"_*_"+Metric+"_MosaicCellMean_Win3x3Smoothing.tif")
            print("SrcTifList = ",SrcTifList, file=open(F3Log, 'a'))
            DataSource = gdal.Open(SrcTifList[0])
            ncol = DataSource.RasterXSize
            nrow = DataSource.RasterYSize
            FinalPixelArray = np.full((len(SrcTifList),nrow,ncol), F3NoDataValue)   #https://stackoverflow.com/questions/5891410/numpy-array-initialization-fill-with-identical-values

            k = -1
            for SrcTif in SrcTifList:
                k = k + 1
                print("k=",k, file=open(F3Log, 'a'))
                PixelWiseTifRaster = gdal.Open(SrcTif)
                PixelWiseTifRaster_bands = PixelWiseTifRaster.RasterCount
                PixelWiseTifRasterData = PixelWiseTifRaster.GetRasterBand(1)
                PixelWiseTifRasterDataNoDataValue = PixelWiseTifRasterData.GetNoDataValue()
                PixelWiseTifRasterDataArray = PixelWiseTifRasterData.ReadAsArray().astype('int64') 
                PixelWiseTifRasterDataMasked = ma.masked_values(PixelWiseTifRasterDataArray, PixelWiseTifRasterDataNoDataValue)
                FinalPixelArray[k,:,:] = PixelWiseTifRasterDataMasked
                
            FinalPixelArrayMasked = ma.masked_values(FinalPixelArray, F3NoDataValue)
            for PixelWiseStatisticsType in ["Mean","Min","Max","Std","Sum","Var","Ptp","Count"]:
                print("PixelWiseStatisticsType=",PixelWiseStatisticsType, file=open(F3Log, 'a'))
                if PixelWiseStatisticsType.lower() == "mean":
                    FinalPixelArraySpecific = np.nanmean(FinalPixelArrayMasked,axis=0)
                if PixelWiseStatisticsType.lower() == "std":
                    FinalPixelArraySpecific = np.nanstd(FinalPixelArrayMasked,axis=0)
                if PixelWiseStatisticsType.lower() == "sum":
                    FinalPixelArraySpecific = np.nansum(FinalPixelArrayMasked,axis=0)
                if PixelWiseStatisticsType.lower() == "min":
                    FinalPixelArraySpecific = np.nanmin(FinalPixelArrayMasked,axis=0)
                if PixelWiseStatisticsType.lower() == "max":
                    FinalPixelArraySpecific = np.nanmax(FinalPixelArrayMasked,axis=0)
                if PixelWiseStatisticsType.lower() == "var":
                    FinalPixelArraySpecific = np.nanvar(FinalPixelArrayMasked,axis=0)
                if PixelWiseStatisticsType.lower() == "ptp":  #numpy.ptp()function plays an important role in statistics by finding out Range of given numbers. Range = max value – min value.
                    FinalPixelArraySpecific = np.ptp(FinalPixelArrayMasked,axis=0)
                if PixelWiseStatisticsType.lower() == "count":
                   FinalPixelArraySpecific = np.count_nonzero(~np.isnan(FinalPixelArrayMasked),axis=0)  #Count how many valid. It is not checked, may not work, if work, then save it to a tif file, see http://www.kasimte.com/2020/02/13/how-do-i-count-numpy-nans.html           
                if PixelWiseStatisticsType.lower() == "slope":
                    print("placerholder1")
                if PixelWiseStatisticsType.lower() == "Hotspot":
                    print("placerholder2")
                FinalPixelArraySpecific = ma.masked_values(FinalPixelArraySpecific, F3NoDataValue)
                FinalPixelTif = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep+Management+"_"+Years[0]+"to"+Years[-1]+"_"+Metric+"_MosaicCellMean_Win3x3Smoothing_PixelWise"+PixelWiseStatisticsType+".tif"
                print("FinalPixelTif=",FinalPixelTif, file=open(F3Log, 'a'))
                driver = gdal.GetDriverByName("GTiff")
                outDataMin = np.nanmin(FinalPixelArraySpecific)
                outDataMax = np.nanmax(FinalPixelArraySpecific)
                TypeOfInterest = OutputDataType(outDataMin, outDataMax)
                if OutputGeoTifCompression == "Yes": #Added on 20230227. LZW compression does not lose information. LZW compression is a lossless data compression algorithm, which means that the original data can be fully reconstructed from the compressed data without any loss of information.
                    outdata = driver.Create(FinalPixelTif, ncol, nrow, 1, TypeOfInterest, options=['COMPRESS=LZW'])   #see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
                if OutputGeoTifCompression == "No": 
                    outdata = driver.Create(FinalPixelTif, ncol, nrow, 1, TypeOfInterest)   #see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
                outdata.SetGeoTransform(DataSource.GetGeoTransform())   ##sets same geotransform as input
                outdata.SetProjection(DataSource.GetProjection())   ##sets same projection as input
                outdata.GetRasterBand(1).WriteArray(FinalPixelArraySpecific)
                outdata.GetRasterBand(1).SetNoDataValue(F3NoDataValue) 
                outdata.FlushCache() ##saves to disk!!
                outdata = None
            print(FinalPixelTif, "raster for F3 TimeSeriesPixelWiseStatistics just finished")
        return FinalPixelTifMean
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)   
        Content2 = "The error was for TimeSeriesPixelWiseStatistics with inputs of "+repr(Management)+repr(Years)+repr(Metric)+" with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog        


def ManagementYearsMetricAnimation(mylock,Management,Years,Metric):
    try:
        AnimationOutput = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep+Management+"_"+Years[0]+"to"+Years[-1]+"_"+Metric+"_MosaicCellMean_Win3x3Smoothing_Animation.gif"
        if not os.path.exists(AnimationOutput):
            MosaicCellMeanQuickLookTifList = []
            SrcTifList = glob.glob(os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep+Management+"_*_"+Metric+"_MosaicCellMean_Win3x3Smoothing.tif")
            print("SrcTifList=",SrcTifList, file=open(F3Log, 'a'))
            for SrcTif in SrcTifList:
                print("SrcTif=",SrcTif,file=open(F3Log, 'a'))
                MinimumBound, MaximumBound = F3EntireMetricMinMaxForLegend(Metric)
                print("MinimumBound, MaximumBound = ",MinimumBound, MaximumBound, file=open(F3Log, 'a'))
                ReducedTimes = 3  #This is the times for reduction
                MinMaxSource = "CommandArgument"
                MosaicCellMeanQuickLookTif = ContinuousSingleBandQuickLookGeotifPseudoColorImage(SrcTif,ReducedTimes,MinMaxSource,MinimumBound,MaximumBound,Metric)
                print("MosaicCellMeanQuickLookTif=",MosaicCellMeanQuickLookTif, file=open(F3Log, 'a'))
                MosaicCellMeanQuickLookTifList.append(MosaicCellMeanQuickLookTif)
            print("MosaicCellMeanQuickLookTifList = ",MosaicCellMeanQuickLookTifList, file=open(F3Log, 'a'))
            AnimationFile = GifAnimation(MosaicCellMeanQuickLookTifList,AnimationOutput)
            print("AnimationFile=",AnimationFile, file=open(F3Log, 'a'))
        return AnimationOutput
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)   
        Content2 = "The error was for ManagementYearsMetricAnaimation with inputs of "+repr(Management)+repr(Years)+repr(Metric)+" with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog

def SendingEmailWithPython():
    try:
       #import smtplib, ssl
       print("https://realpython.com/python-send-email/ to see how to use python to send email")
       print("We had error: smtplib.SMTPAuthenticationError: (535, b'5.7.8 Username and Password not accepted). So I had to change the gmail account settings, see https://stackoverflow.com/questions/16512592/login-credentials-not-working-with-gmail-smtp")
       print("[https://myaccount.google.com/u/1/lesssecureapps?pli=1&pageId=none] is the website to change the settings")
       print("If you don’t want your password to show on your screen when you type it, you can import the getpass module and use .getpass() instead for blind input of your password.")
       print("We can add attachement at some day")
       print("We can use csv or code to Sending Multiple Personalized Emails")
       print("We will make this function more fancy in the future. But now let us use it in a simple way--as of 20220222")
       print("Someday when I have time, I can use Python to send sms, too")
       EmailOption = "SMTP_SSL"  #Another option is "starttls"

       if EmailOption == "SMTP_SSL":
           print("I am using SMTP_SSL to send Email with Python---start")
           port = 465  # For SSL
           smtp_server = "smtp.gmail.com"
           sender_email = "shengli.huang0086@gmail.com"  # Enter your address
           receiver_email = "jenny_huang0086@hotmail.com"  # Enter receiver address. #shengli.huang@usda.gov is problematic (due to security?)
           password = input("Type your password and press enter: ")
           message = """\
           Subject: Hi there

           This message is sent from Python."""
           context = ssl.create_default_context()
           with smtplib.SMTP_SSL(smtp_server, port, context=context) as server:
               server.login(sender_email, password)
               server.sendmail(sender_email, receiver_email, message)
           print("I am using SMTP_SSL to send Email with Python---end")
       if EmailOption == "starttls":
           print("I am using Using starttls to send Email with Python---start")
           port = 587  # For starttls
           smtp_server = "smtp.gmail.com"
           sender_email = "shengli.huang0086@gmail.com"
           receiver_email = "jenny_huang0086@hotmail.com"    #shengli.huang@usda.gov is problematic (due to security?)
           password = input("Type your password and press enter:")
           message = """\
           Subject: Hi there

           This message is sent from Python."""

           context = ssl.create_default_context()
           with smtplib.SMTP(smtp_server, port) as server:
               server.ehlo()  # Can be omitted
               server.starttls(context=context)
               server.ehlo()  # Can be omitted
               server.login(sender_email, password)
               server.sendmail(sender_email, receiver_email, message)
           print("I am using Using starttls to send Email with Python---end")
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)   
        Content2 = "The error was for SendingEmailWithPython with inputs of "+repr(Metric)+" with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog



def MetricInformationFromXLSX(Metric):
    try:
        #ExcelXLSXfile = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep+"F3MetricInformation20231220.xlsx"
        print("F3MetricExcelXLSXfile in Excel XLSX format (not CSV format) is: ",F3MetricExcelXLSXfile)
        MetricDF = pd.read_excel(F3MetricExcelXLSXfile)  #https://www.geeksforgeeks.org/reading-excel-file-using-python/
        #print(MetricDF.dtypes)        
        print("https://stackoverflow.com/questions/22245171/how-to-lowercase-a-pandas-dataframe-string-column-if-it-has-missing-values and https://stackoverflow.com/questions/40312128/how-to-lower-all-the-elements-in-a-pandas-dataframe")
        ThisMetricInfo = MetricDF.loc[MetricDF['MetricShortName'].str.lower() == Metric.lower()]  #https://www.geeksforgeeks.org/how-to-select-rows-from-pandas-dataframe/
        #print("ThisMetricInfo=",ThisMetricInfo)
        #print("ThisMetricInfo.shape[0]=",ThisMetricInfo.shape[0])
        if ThisMetricInfo.shape[0] == 0: # Gives number of rows, count_col = df.shape[1] will gives number of columns, see https://stackoverflow.com/questions/15943769/how-do-i-get-the-row-count-of-a-pandas-dataframe
            print("The metric ", Metric, " cannot be found in the database of F3MetricInformation.xlsx")
            print("In the future, we will add the function SendingEmailWithPython (seee above) to notify Marcus/Laura about the missing automatically")
        else:
            MetricShortName = str(ThisMetricInfo.iat[0, ThisMetricInfo.columns.get_loc("MetricShortName")].lower())  #https://www.geeksforgeeks.org/how-to-select-multiple-columns-in-a-pandas-dataframe/
            MetricFullName = str(ThisMetricInfo.iat[0, ThisMetricInfo.columns.get_loc("MetricFullName")])  #https://statisticsglobe.com/get-specific-element-from-pandas-dataframe-python#:~:text=In%20this%20example%2C%20I%E2%80%99ll%20show%20how%20to%20print,attribute%20print%28data_cell_2%29%20%23%20Print%20extracted%20value%20%23%20b
            SpeciesScienticName = str(ThisMetricInfo.iat[0, ThisMetricInfo.columns.get_loc("SpeciesScienticName")])
            MetricDefinition = str(ThisMetricInfo.iat[0, ThisMetricInfo.columns.get_loc("MetricDefinition")])
            USDAPlantCode = str(ThisMetricInfo.iat[0, ThisMetricInfo.columns.get_loc("USDAPlantCode")])
            FVSKeyword = str(ThisMetricInfo.iat[0, ThisMetricInfo.columns.get_loc("FVSKeyword")])
            MetricUnit_US = str(ThisMetricInfo.iat[0, ThisMetricInfo.columns.get_loc("MetricUnit_US")])
            MetricUnit_SI = str(ThisMetricInfo.iat[0, ThisMetricInfo.columns.get_loc("MetricUnit_SI")])
            UStoSIconversion = float(ThisMetricInfo.iat[0, ThisMetricInfo.columns.get_loc("UStoSIconversion")])  #https://stackoverflow.com/questions/48000347/converting-pandas-dataframe-to-float
            MetricShortNameIGivenBy = str(ThisMetricInfo.iat[0, ThisMetricInfo.columns.get_loc("MetricShortNameIGivenBy")])
            MetricFullNameIGivenBy = str(ThisMetricInfo.iat[0, ThisMetricInfo.columns.get_loc("MetricFullNameIGivenBy")])
            AdditionalNotes = str(ThisMetricInfo.iat[0, ThisMetricInfo.columns.get_loc("AdditionalNotes")])

            #We may add something to take care of NA    
            if Metric in DiscreteMetrics:
                MetricUnit_US = "Unitless"
                MetricUnit_SI = "Unitless"
                UStoSIconversion = 1.0

            #print("MetricShortName=",MetricShortName)
            #print("UStoSIconversion=",UStoSIconversion)
            print(MetricShortName,MetricFullName,MetricDefinition,SpeciesScienticName,USDAPlantCode,FVSKeyword,MetricUnit_US,MetricUnit_SI,UStoSIconversion,MetricShortNameIGivenBy,MetricFullNameIGivenBy,AdditionalNotes)
            return MetricShortName,MetricFullName,MetricDefinition,SpeciesScienticName,USDAPlantCode,FVSKeyword,MetricUnit_US,MetricUnit_SI,UStoSIconversion,MetricShortNameIGivenBy,MetricFullNameIGivenBy,AdditionalNotes
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)   
        Content2 = "The error was for MetricInformationFromXLSX with inputs of "+repr(Metric)+" with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog




def ClipShapeBasedOnCustmizedPolygon(InputShape, PolygonVertices):   #Note this InputShape must be in the folder of "TilesMosaicRunAverage"
    #https://www.earthdatascience.org/courses/use-data-open-source-python/intro-vector-data-python/vector-data-processing/clip-vector-data-in-python-geopandas-shapely/
    #https://stackoverflow.com/questions/44976231/python-only-using-part-of-a-shapefile
    #http://geospatialpython.com/2010/12/subsetting-shapefile-by-attributes.html
    #https://geopandas.org/en/stable/gallery/plot_clip.html
    try:
        #if "TilesMosaicRunAverage" not in InputShape:   #20240202: I commented out this section
        #    print("To avoid conflicts, we require that the InputShape must be in the folder of TilesMosaicRunAverage. Please redo!")
        #    return
        print("PolygonVertices=",PolygonVertices)
        PolyPerimeter = str(int((abs(PolygonVertices[0][0]-PolygonVertices[2][0]) + abs(PolygonVertices[0][1]-PolygonVertices[2][1])) * 2))  #We use the rectangle perimeter as the unique shape
        print("PolyPerimeter=",PolyPerimeter)
        OutputShape = InputShape.replace(".shp","_"+PolyPerimeter+".shp")
        print("OutputShape=",OutputShape)
        if not os.path.exists(OutputShape):
            InputShapeGPD = gpd.read_file(InputShape)
            print("InputShape=",InputShape)
            ClipPolygon_geom = Polygon(PolygonVertices)   ##PolygonVertices = [(0, 0), (0, 90), (180, 90), (180, 0), (0, 0)]
            print("1111111111111111111111111")
            polygon = gpd.GeoDataFrame(index=[0], geometry=[ClipPolygon_geom], crs=InputShapeGPD.crs)
            print("222222222222222222222222222")
            OutputShapeGeoDataFrame = gpd.clip(InputShapeGPD, polygon)  #https://geopandas.org/en/stable/docs/reference/api/geopandas.GeoDataFrame.clip.html says the clip() returns "GeoDataFrame"
            print("3333333333333333333333333333")
            print("https://gis.stackexchange.com/questions/147156/making-shapefile-from-pandas-dataframe#:~:text=To%20dump%20this%20GeoDataFrame%20into%20a%20shapefile%2C%20use,GeoJSON%20should%20also%20work%29%3A%20df.to_file%20%28%27MyGeometries.shp%27%2C%20driver%3D%27ESRI%20Shapefile%27%29")
            print("20230414, I had the same error as below, but please see https://stackoverflow.com/questions/75994612/invalidversion-error-returned-when-writting-an-esri-shp-file-geopandas-geodata")
            OutputShapeGeoDataFrame.to_file(OutputShape, driver='ESRI Shapefile')  #http://geospatialpython.com/2010/12/subsetting-shapefile-by-attributes.html how to save the clipped one?
            print(OutputShape," was created; It is a subset with boundary being the ratser extent")
        return OutputShape
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)   
        Content2 = "The error was for ClipShapeBasedOnCustmizedPolygon with inputs of "+repr(InputShape)+repr(PolygonVertices)+" with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog                
                        



def StatisticsReportFromRastersAndShapeField(mylock,Management,Year,Metric,StatisticsShapeAndFieldPair):
    try:
        #This section is ptocessing MosaicCellMean_Win3x3Smoothing.tif---start
        TwoRasters = [
                      os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep+Management+"_"+Year+"_"+Metric+"_MosaicCellMean_Win3x3Smoothing.tif",
                      os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep+Management+"_"+Year+"_"+Metric+"_MosaicCellStd_Win3x3Smoothing.tif"
                     ]
        for Raster in TwoRasters:
            print("This raster is: ",Raster)
            print("This raster is: ",Raster,file=open(F3Log, 'a'))
            RasterMasked,ulx,uly,llx,lly,lrx,lry,urx,ury = ReadTifToArrayAndReturnExtent(Raster)

            ShapeFile = StatisticsShapeAndFieldPair.split("||")[0]
            field_name = StatisticsShapeAndFieldPair.split("||")[1]
            print("ShapeFile=",ShapeFile,file=open(F3Log, 'a'))
            print("field_name=",field_name,file=open(F3Log, 'a'))
            
            output_tiff, RowMin_ForRaster,RowMax_ForRaster,ColumnMin_ForRaster,ColumnMax_ForRaster,CommonOverlay_ulx, CommonOverlay_lrx, CommonOverlay_uly, CommonOverlay_lry = ShapeAndRasterOverlayExtent(ShapeFile,field_name,ulx,lrx,uly,lry)
            RasterArrayMasked = RasterMasked[RowMin_ForRaster:RowMax_ForRaster,ColumnMin_ForRaster:ColumnMax_ForRaster]
            print("RowMin_ForRaster,RowMax_ForRaster,ColumnMin_ForRaster,ColumnMax_ForRaster=",RowMin_ForRaster,RowMax_ForRaster,ColumnMin_ForRaster,ColumnMax_ForRaster,file=open(F3Log, 'a'))
            ShapeWithFieldNameTif = output_tiff
            ShapeMasked,Shapeulx,Shapeuly,Shapellx,Shapelly,Shapelrx,Shapelry,Shapeurx,Shapeury = ReadTifToArrayAndReturnExtent(ShapeWithFieldNameTif)
            ColumnMin_ForShape = int(abs(CommonOverlay_ulx - Shapeulx) / F3Resolution)  #If the upperleft corner does not align perfectly, we may have problem here. Need to think it over 
            ColumnMax_ForShape = int(abs(CommonOverlay_lrx - Shapeulx) / F3Resolution)  #We may +1 here? see https://opensourceoptions.com/blog/zonal-statistics-algorithm-with-python-in-4-steps/
            RowMin_ForShape = int(abs(CommonOverlay_uly - Shapeuly) / F3Resolution)
            RowMax_ForShape = int(abs(CommonOverlay_lry - Shapeuly) / F3Resolution)   #We may +1 here? but I prefer not, because this is just Raster, I do not care of missin gone pixel
            ShapeArrayMasked = ShapeMasked[RowMin_ForShape:RowMax_ForShape,ColumnMin_ForShape:ColumnMax_ForShape]
            print("ColumnMin_ForShape,ColumnMax_ForShape,RowMin_ForShape,RowMax_ForShape=",ColumnMin_ForShape,ColumnMax_ForShape,RowMin_ForShape,RowMax_ForShape,file=open(F3Log, 'a'))

            if ((RasterArrayMasked.shape[0] != ShapeArrayMasked.shape[0]) or (RasterArrayMasked.shape[1] != ShapeArrayMasked.shape[1])):
                print("There are errors here, because these two array are supposed to have the same shape (i.e., row and column)")
                print("There are errors here, because these two array are supposed to have the same shape (i.e., row and column)",file=open(F3Log, 'a'))
            else:
                print("RasterArrayMasked.shape[0]=", RasterArrayMasked.shape[0], " and RasterArrayMasked.shape[1]=",RasterArrayMasked.shape[1])
                print("RasterArrayMasked.shape[0]=", RasterArrayMasked.shape[0], " and RasterArrayMasked.shape[1]=",RasterArrayMasked.shape[1],file=open(F3Log, 'a'))
                
            UniqueZoneID = np.unique(ShapeArrayMasked).astype(np.int32)
            UniqueZoneID = UniqueZoneID[~(np.isnan(UniqueZoneID))]   #https://www.geeksforgeeks.org/how-to-remove-nan-values-from-a-given-numpy-array/
            UniqueZoneID = [k for k in UniqueZoneID if k != '--']  #I found the element may be '--', which is problematic
            print("UniqueZoneID=",UniqueZoneID)
            
            #Read the field_name_values_unique and their corresponding values (i.e. their index) for statitics report---start
            output_tiff_zone = ShapeWithFieldNameTif.replace(".tif","_Zone.txt")
            output_tiff_zoneFile = open(output_tiff_zone,'r')
            Lines = output_tiff_zoneFile.readlines()  
            Lines = [i.replace('\n','') for i in Lines]  
            field_name_values = []
            field_name_values_zone = []
            for Line in Lines: 
                field_name_values.append(Line.split(",")[0])
                field_name_values_zone.append(int(Line.split(",")[1]))
            output_tiff_zoneFile.close()
            print("field_name_values=",field_name_values)
            print("field_name_values_zone=",field_name_values_zone)
            #Read the field_name_values_unique and their corresponding values (i.e. their index) for statitics report---en

            if "MosaicCellMean_Win3x3Smoothing.tif" in Raster:
                ShapeWithFieldNameCSV = os.sep.join(ShapeWithFieldNameTif.split(os.sep)[:-1])+os.sep+Management+"_"+Year+"_"+Metric+"_CellMean_"+ShapeWithFieldNameTif.split(os.sep)[-1].replace(".tif",".csv")
            if "MosaicCellStd_Win3x3Smoothing.tif" in Raster:
                ShapeWithFieldNameCSV = os.sep.join(ShapeWithFieldNameTif.split(os.sep)[:-1])+os.sep+Management+"_"+Year+"_"+Metric+"_CellStd_"+ShapeWithFieldNameTif.split(os.sep)[-1].replace(".tif",".csv")
            print("ShapeWithFieldNameCSV=",ShapeWithFieldNameCSV)
            print("We are creating the statistic report of ", ShapeWithFieldNameCSV)
            print("We are creating the statistic report of ", ShapeWithFieldNameCSV,file=open(F3Log, 'a'))
            if not os.path.exists(ShapeWithFieldNameCSV):

                #added on 20230222 to provide unit in excel file---start
                MetricShortName,MetricFullName,MetricDefinition,SpeciesScienticName,USDAPlantCode,FVSKeyword,MetricUnit_US,MetricUnit_SI,UStoSIconversion,MetricShortNameIGivenBy,MetricFullNameIGivenBy,AdditionalNotes = MetricInformationFromXLSX(Metric)
                if OutputUnit == "Imperial": 
                    MetricUnit = MetricUnit_US
                if OutputUnit == "SI":
                    MetricUnit = MetricUnit_SI
                #added on 20230222 to provide unit in excel file---end
                
                ShapeWithFieldNameCSVFile = open(ShapeWithFieldNameCSV,'w')
                LineHeader = "StatisticSourceTif"+","+"Management"+","+"Year"+","+"Metric"+","+"MetricUnit"+","+"StatisticTime"+","+"ZoneTifFile"+","+"ZoneTxtFile"+","+"Author"+","+"OriginalShapeFile"+","+"Field"+","+"Zone"+","+"ZoneName"+","+"ZonePixelsMean"+","+"ZonePixelsStd"+","+"ZonePixelsSum"+","+"ZonePixelsMin"+","+"ZonePixelsMax"+","+"ZonePixelsVar"+","+"ZonePixelsPtp"+","+"ZonePixelsCount"+","+"F3category"+","+"Notes"+"\n"
                ShapeWithFieldNameCSVFile.write(LineHeader)
                #print("ZonePixelsMean below is the average values in this zone from the tif of Management_Year_Metric_MosaicCellMean_Win3x3Smoothing.tif. It indicates the metric variation, not important")
                #print("STDmeanInThisZone below is the average values in this zone from the tif of Management_Year_Metric_MosaicCellStd_Win3x3Smoothing.tif. It indicates the F3 imputation uncerntainity, very important")
                LineFirstPart = Raster+","+Management+","+Year+","+Metric+","+MetricUnit+","+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")+","+ShapeWithFieldNameTif+","+ShapeWithFieldNameTif.replace(".tif","_Zone.txt")+","+"Dr. Shengli Huang"+","+ShapeFile+","+field_name+","
                RasterArrayMasked = RasterArrayMasked.flatten()
                ShapeArrayMasked = ShapeArrayMasked.astype(np.int32).flatten()
                for Zone in UniqueZoneID:
                    ZoneName = field_name_values[field_name_values_zone.index(int(Zone))]
                    print("Zone=",Zone," and ZoneName=",ZoneName)
                    RasterArrayMaskedForThisZone = RasterArrayMasked[ShapeArrayMasked == int(Zone)]
                    #print("Check if al elements in an array are nan:",ma.count_masked(RasterArrayMaskedForThisZone),len(RasterArrayMaskedForThisZone),np.isnan(RasterArrayMaskedForThisZone).all(),file=open(F3Log, 'a')) #np.isnan().all() returns False but no True, strange, but ignore it now
                    if ma.count_masked(RasterArrayMaskedForThisZone) == len(RasterArrayMaskedForThisZone): #[if np.isnan(RasterArrayMaskedForThisZone).all()] does not work. Surprised! #Check if all pixels are masked value, see https://www.pythonprogramming.in/how-to-check-all-elements-are-nan-in-a-numpy-array-in-python.html. 
                        mymean = F3NoDataValue
                        mystd = F3NoDataValue
                        mysum = F3NoDataValue
                        mymin = F3NoDataValue
                        mymax = F3NoDataValue
                        myvar = F3NoDataValue
                        myptp = F3NoDataValue
                        mycount = F3NoDataValue
                        F3Category = "F3Core"   #Late we may have "DRAST" etc
                    else:                    
                        mymean = np.nanmean(RasterArrayMaskedForThisZone)
                        mystd = np.nanstd(RasterArrayMaskedForThisZone)
                        mysum = np.nansum(RasterArrayMaskedForThisZone)
                        mymin = np.nanmin(RasterArrayMaskedForThisZone)
                        mymax = np.nanmax(RasterArrayMaskedForThisZone)
                        myvar = np.nanvar(RasterArrayMaskedForThisZone)
                        myptp = np.ptp(RasterArrayMaskedForThisZone)
                        mycount = RasterArrayMasked[ShapeArrayMasked == int(Zone)].count()
                        F3Category = "F3Core"   #Late we may have "DRAST" etc. This will help analysis
                    Notes = "Pls /" + str(FloatToIntegerCoefficient)
                    LineContent = LineFirstPart+str(Zone)+","+ZoneName+","+str(mymean)+","+str(mystd)+","+str(mysum)+","+str(mymin)+","+str(mymax)+","+str(myvar)+","+str(myptp)+","+str(mycount)+","+str(F3Category)+","+str(Notes)+"\n"
                    ShapeWithFieldNameCSVFile.write(LineContent)
                ShapeWithFieldNameCSVFile.close()
                print(ShapeWithFieldNameCSV," was created")
            else:
                print(ShapeWithFieldNameCSV," was already created, so skipped") 
        #This section is ptocessing MosaicCellMean_Win3x3Smoothing.tif---end        



  
        #Regarding Python CSV module, see https://docs.python.org/3/library/csv.html
        #https://www.codevscolor.com/python-read-csv-column#:~:text=Below%20is%20the%20method%20used%20to%20read%20column,column_list%20is%20the%20list%20of%20all%20column%20names.
        ShapeWithFieldNameCSVmean = os.sep.join(ShapeWithFieldNameTif.split(os.sep)[:-1])+os.sep+Management+"_"+Year+"_"+Metric+"_CellMean_"+ShapeWithFieldNameTif.split(os.sep)[-1].replace(".tif",".csv")
        ShapeWithFieldNameCSVstd = os.sep.join(ShapeWithFieldNameTif.split(os.sep)[:-1])+os.sep+Management+"_"+Year+"_"+Metric+"_CellStd_"+ShapeWithFieldNameTif.split(os.sep)[-1].replace(".tif",".csv")
        ShapeWithFieldNameCSVfinal = ShapeWithFieldNameCSVstd.replace("_CellStd_","_Final_")
        print("ShapeWithFieldNameCSVfinal=",ShapeWithFieldNameCSVfinal)

        ShapeWithFieldNameCSVmeanFile = open(ShapeWithFieldNameCSVmean,'r')
        ShapeWithFieldNameCSVmeanLines = ShapeWithFieldNameCSVmeanFile.readlines()  
        ShapeWithFieldNameCSVmeanLines = [i.replace('\n','') for i in ShapeWithFieldNameCSVmeanLines]
            
        ShapeWithFieldNameCSVstdFile = open(ShapeWithFieldNameCSVstd,'r')
        ShapeWithFieldNameCSVstdLines = ShapeWithFieldNameCSVstdFile.readlines()  
        ShapeWithFieldNameCSVstdLines = [i.replace('\n','') for i in ShapeWithFieldNameCSVstdLines]
            
        ShapeWithFieldNameCSVfinalFile = open(ShapeWithFieldNameCSVfinal,'w')
        ShapeWithFieldNameCSVfinalFile.write(ShapeWithFieldNameCSVmeanLines[0] + "," + "STDmeanInThisZoneAsUncertainty" + "\n")  #This is Header

        ZoneNameIndex = ShapeWithFieldNameCSVmeanLines[0].split(",").index("ZoneName")  #https://www.geeksforgeeks.org/python-list-index/
        STDmeanInThisZoneAsUncertaintyIndex = ShapeWithFieldNameCSVstdLines[0].split(",").index("ZonePixelsMean")
        for ShapeWithFieldNameCSVmeanLine in ShapeWithFieldNameCSVmeanLines[1:]:
            for ShapeWithFieldNameCSVstdLine in ShapeWithFieldNameCSVstdLines[1:]:
                if str(F3NoDataValue) not in ShapeWithFieldNameCSVmeanLine:  #added on 20230215 to skip those lines with -9999 (i.e., all NAN in the zone)
                        if ((ShapeWithFieldNameCSVmeanLine.split(",")[ZoneNameIndex]) == (ShapeWithFieldNameCSVstdLine.split(",")[ZoneNameIndex])):  #11 is the index of ZoneName (i.e., ZoneName is the 12th column)
                            ShapeWithFieldNameCSVfinalLine = ShapeWithFieldNameCSVmeanLine + "," + str(ShapeWithFieldNameCSVstdLine.split(",")[STDmeanInThisZoneAsUncertaintyIndex]) + "\n"  #12 is the index of ZonePixelsMean (i.e., ZonePixelsMean is the 13th column)
                            print("ShapeWithFieldNameCSVfinalLine=",ShapeWithFieldNameCSVfinalLine,file=open(F3Log, 'a'))
                            ShapeWithFieldNameCSVfinalFile.write(ShapeWithFieldNameCSVfinalLine)
        ShapeWithFieldNameCSVmeanFile.close()        
        ShapeWithFieldNameCSVstdFile.close()        
        ShapeWithFieldNameCSVfinalFile.close()                         
                        
        return ShapeWithFieldNameCSVfinal
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)   
        Content2 = "The error was for StatisticsReportFromRastersAndShapeField with inputs of "+repr(mylock)+repr(Management)+repr(Year)+repr(Metric)+repr(StatisticsShapeAndFieldPair)+" with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog

    
    





#This part is zonestatistics from Gdal, copied from https://opensourceoptions.com/blog/zonal-statistics-algorithm-with-python-in-4-steps/ ---start
def boundingBoxToOffsets(bbox, geot):
    col1 = int((bbox[0] - geot[0]) / geot[1])
    col2 = int((bbox[1] - geot[0]) / geot[1]) + 1
    row1 = int((bbox[3] - geot[3]) / geot[5])
    row2 = int((bbox[2] - geot[3]) / geot[5]) + 1
    return [row1, row2, col1, col2]
def geotFromOffsets(row_offset, col_offset, geot):
    new_geot = [
    geot[0] + (col_offset * geot[1]),
    geot[1],
    0.0,
    geot[3] + (row_offset * geot[5]),
    0.0,
    geot[5]
    ]
    return new_geot
def setFeatureStats(fid, min, max, mean, median, sd, sum, count, names=["min", "max", "mean", "median", "sd", "sum", "count", "id"]):
    featstats = {
    names[0]: min,
    names[1]: max,
    names[2]: mean,
    names[3]: median,
    names[4]: sd,
    names[5]: sum,
    names[6]: count,
    names[7]: fid,
    }
    return featstats
def ZonalStatisticsToCSV(fn_raster,fn_zones,fn_csv):
    try:
        #fn_raster = "C:/pyqgis/raster/USGS_NED_13_n45w116_IMG.img"
        #fn_zones = "C:/temp/zonal_stats/zones.shp"
        #fn_csv = "C:/temp/zonal_stats/zstats.csv" 
        mem_driver = ogr.GetDriverByName("Memory")
        mem_driver_gdal = gdal.GetDriverByName("MEM")
        shp_name = "temp"
        r_ds = gdal.Open(fn_raster)
        p_ds = ogr.Open(fn_zones)
        lyr = p_ds.GetLayer()
        geot = r_ds.GetGeoTransform()
        nodata = r_ds.GetRasterBand(1).GetNoDataValue()
        zstats = []
        p_feat = lyr.GetNextFeature()
        niter = 0
        while p_feat:
            if p_feat.GetGeometryRef() is not None:
                if os.path.exists(shp_name):
                    mem_driver.DeleteDataSource(shp_name)
                tp_ds = mem_driver.CreateDataSource(shp_name)
                tp_lyr = tp_ds.CreateLayer('polygons', None, ogr.wkbPolygon)
                tp_lyr.CreateFeature(p_feat.Clone())
                offsets = boundingBoxToOffsets(p_feat.GetGeometryRef().GetEnvelope(), geot)
                new_geot = geotFromOffsets(offsets[0], offsets[2], geot)
                #tr_ds = mem_driver_gdal.Create("", offsets[3] - offsets[2], offsets[1] - offsets[0], 1, gdal.GDT_Byte)  
                tr_ds = mem_driver_gdal.Create("", offsets[3] - offsets[2], offsets[1] - offsets[0], 1, gdal.GDT_Int32)  
                tr_ds.SetGeoTransform(new_geot)
                gdal.RasterizeLayer(tr_ds, [1], tp_lyr, burn_values=[1])
                tr_array = tr_ds.ReadAsArray()
                r_array = r_ds.GetRasterBand(1).ReadAsArray(offsets[2], offsets[0], offsets[3] - offsets[2], offsets[1] - offsets[0])
                id = p_feat.GetFID()
                if r_array is not None:
                    maskarray = np.ma.MaskedArray(r_array, maskarray=np.logical_or(r_array==nodata, np.logical_not(tr_array)))
                    if maskarray is not None:
                        zstats.append(setFeatureStats(\
                        id,\
                        maskarray.min(),\
                        maskarray.max(),\
                        maskarray.mean(),\
                        np.ma.median(maskarray),\
                        maskarray.std(),\
                        maskarray.sum(),\
                        maskarray.count()))
                    else:
                        zstats.append(setFeatureStats(\
                        id,\
                        nodata,\
                        nodata,\
                        nodata,\
                        nodata,\
                        nodata,\
                        nodata,\
                        nodata))
                else:
                    zstats.append(setFeatureStats(\
                        id,\
                        nodata,\
                        nodata,\
                        nodata,\
                        nodata,\
                        nodata,\
                        nodata,\
                        nodata))
                tp_ds = None
                tp_lyr = None
                tr_ds = None
                p_feat = lyr.GetNextFeature()
        col_names = zstats[0].keys()
        with open(fn_csv, 'w', newline='') as csvfile:
            writer = csv.DictWriter(csvfile, col_names)
            writer.writeheader()
            writer.writerows(zstats)
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for ZonalStatisticsToCSV with inputs of "+repr(fn_raster)+","+repr(fn_zones)+","+repr(fn_csv)+" with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog
#This part is zonestatistics from Gdal, copied from https://opensourceoptions.com/blog/zonal-statistics-algorithm-with-python-in-4-steps/ ---end
        



def PolygonToRaster1(PolygonShape, FieldName):  #PolygonShape may be for example a national forest polygon; FieldName may be the code for each national forest
    try:
        print("As of 20220523, I have not made it work, but check these two")
        print("https://gis.stackexchange.com/questions/212795/rasterizing-shapefiles-with-gdal-and-python")
        print("https://gdal.org/programs/gdal_rasterize.html#cmdoption-gdal_rasterize-tr")
        print("The output can be considered as Zone for zonestatistics, but make sure the dimension are the same")
        MyPoly = ogr.Open(PolygonShape)
        MyLayer = MyPoly.GetLayer()
        PolygonTif = PolygonShape.replace(".shp",".tif")
        cmd = r'gdal_rasterize -tr F3Resolution F3Resolution -a FieldName -a_nodata F3NoDataValue -l MyLayer PolygonShape PolygonTif'
        os.system(cmd)
        MyPoly = None
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for PolygonToRaster1 with inputs of " +repr(PolygonShape)+","+repr(FieldName)+" with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog

    
        
def PolygonToRaster2(input_shp0, output_tiff, cellsize, field_name=False, NoData_value=F3NoDataValue):  #copy from https://www.programcreek.com/python/example/101827/gdal.RasterizeLayer
    try:
        """ Converts a shapefile into a raster. e.g., polygon to ratser or point to raster"""
        # Input
        orig_data_source_driver = ogr.GetDriverByName('ESRI Shapefile')
        orig_data_source = orig_data_source_driver.Open(input_shp0)  # Make a copy of the layer's data source because we'll need to modify its attributes table
        inp_source = ogr.GetDriverByName("Memory").CopyDataSource(orig_data_source, "")  #see https://stackoverflow.com/questions/2220749/rasterizing-a-gdal-layer
        
        inp_lyr = inp_source.GetLayer()
        inp_lyr_Count = inp_lyr.GetFeatureCount()  #This return the number of records
        inp_srs = inp_lyr.GetSpatialRef()
        x_min, x_max, y_min, y_max = inp_lyr.GetExtent()    # get the Extent of the shape file

        if field_name:
            NewFieldName = field_name+"code"
            new_field_defn = ogr.FieldDefn(NewFieldName, ogr.OFTInteger) #new_field_defn = ogr.FieldDefn(NewFieldName, ogr.OFTReal), see https://gis.stackexchange.com/questions/7436/adding-attribute-field-to-existing-shapefile-via-python-without-arcgis  #https://stackoverflow.com/questions/39982877/python-crashes-when-adding-a-field-to-a-shapefile-with-ogr
            new_field_defn.SetWidth(50)
            new_field_defn.SetPrecision(11)
            inp_lyr.CreateField(new_field_defn)
            layerDefinition = inp_lyr.GetLayerDefn()
            field_names = [m.name for m in inp_lyr.schema]  #https://gis.stackexchange.com/questions/220844/get-field-names-of-shapefiles-using-gdal
            print("field_names=",field_names)
            field_index1 = layerDefinition.GetFieldIndex(field_name)
            field_index2 = layerDefinition.GetFieldIndex(NewFieldName)
            print("field_index1 = ", field_index1)
            print("field_index2 = ", field_index2)

            field_name_values = []
            for feature in inp_lyr:
                field_name_values.append(feature.GetField(field_name))
            inp_lyr.ResetReading()
            print("The length of field_name_values=",len(field_name_values))
            field_name_values_unique = np.unique(field_name_values).tolist()
            print("field_name_values_unique=",field_name_values_unique)
            print("The length of field_name_values_unique=",len(field_name_values_unique))
            
            for feature in inp_lyr:  #You can get a specific feature by passing its ID to the layer.GetFeature(id) method, see https://gis.stackexchange.com/questions/328210/how-to-change-the-field-value-of-a-specific-feature-in-a-shapefile-using-gdal-og
                field_name_value = feature.GetField(field_name)
                print("for field_name of ", field_name, "its value from feature.GetField(field_name) = ",field_name_value)
                NewFieldNameValue = field_name_values_unique.index(field_name_value)
                print("field_name_values_unique.index(field_name_value) (i.e. NewFieldNameValue) = ",NewFieldNameValue)
                feature.SetField(field_index2, NewFieldNameValue)   #https://gis.stackexchange.com/questions/328210/how-to-change-the-field-value-of-a-specific-feature-in-a-shapefile-using-gdal-og
                inp_lyr.SetFeature(feature)
            inp_lyr.ResetReading()  #go back to the beginning after the loop

        x_ncells = int((x_max - x_min) / cellsize)
        y_ncells = int((y_max - y_min) / cellsize)
        # Output
        out_driver = gdal.GetDriverByName('GTiff')
        if os.path.exists(output_tiff):
            out_driver.Delete(output_tiff)
        out_source = out_driver.Create(output_tiff, x_ncells, y_ncells, 1, gdal.GDT_Int32, options=['COMPRESS=LZW'])  #20240403 add options=['COMPRESS=LZW'] to compress the output tif
        out_source.SetGeoTransform((x_min, cellsize, 0, y_max, 0, -cellsize))
        out_source.SetProjection(inp_srs.ExportToWkt())
        out_lyr = out_source.GetRasterBand(1)
        out_lyr.SetNoDataValue(NoData_value)
        # Rasterize
        if field_name:
            #gdal.RasterizeLayer(out_source, [1], inp_lyr, burn_values=[kid], where='field_name="{myvalue}"'.format(myvalue=k))
            #https://stackoverflow.com/questions/44658399/gdal-rasterizelayer-using-the-where-parameter
            OPTIONS = ["ATTRIBUTE={0}".format(NewFieldName)]
            gdal.RasterizeLayer(out_source, [1], inp_lyr, options=OPTIONS)   #This is the original one
        else:
            gdal.RasterizeLayer(out_source, [1], inp_lyr, burn_values=[1])  #burn a constant value of 1 here. you can use burn_values=[8888] to have a value of 8888 etc., see https://gis.stackexchange.com/questions/263161/gdal-rasterizelayer-constant-value
        # Save and/or close the data sources
        inp_source = None
        out_source = None

        #Save the field_name_values_unique and their corresponding values (i.e. their index) for future use---start
        if field_name:
            output_tiff_zone = output_tiff.replace(".tif","_Zone.txt")
            print("output_tiff_zone=",output_tiff_zone)
            output_tiff_zoneFile = open(output_tiff_zone,'w')
            kid = -1
            for k in field_name_values_unique:
                kid = kid + 1
                if "," in str(k):
                    LineContent = str(k).replace(","," ")+","+str(kid)+"\n"  #The comma in zone name may cause a lot of problem, so I remove it here              
                else:
                    LineContent = str(k)+","+str(kid)+"\n"
                output_tiff_zoneFile.write(LineContent)
            output_tiff_zoneFile.close()        
        #Save the field_name_values_unique and their corresponding values (i.e. their index) for future use---end
        
        # Return
        return output_tiff
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for PolygonToRaster2 with inputs of "+repr(input_shp0)+","+repr(output_tiff)+","+repr(cellsize)+","+repr(field_name)+","+repr(NoData_value)+" with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog

        
def RemoteSensingYearFunction(RSYstring):  #This function return the remote sensing year which is a four digits immediatelly followig "rsy" from a long string 
    try:    
        for i in range(0,len(RSYstring)-4,1):  #rls is 3 letters plus the index is -1, so here using -4
            if RSYstring[i:i+3].lower() == "rsy":
                RemoteSensingYear = RSYstring[i+3:i+7]  #because year occupies four digits
                break   #The first appearce of rsy is processed
        return RemoteSensingYear     
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for RemoteSensingYear with inputs of "+repr(RSYstring)+" with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog

def FindValidMetrics(MetricsList,FieldSqlite,Run,Tile,Management,Year,Metric):
    try:  
        ValidMetricsList = CheckMetricIgnoredNew(MetricsList,FieldSqlite,Run,Tile,Management,Year,Metric)  
        return ValidMetricsList
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for FindValidMetrics with inputs of "+repr(MetricsList)+","+repr(FieldSqlite)+","+repr(Run)+","+repr(Tile)+","+repr(Management)+","+repr(Year)+","+repr(Metric)+" with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog
        


def RunTileInput(Run,Tile,Management,Year,Metric):
    try:    
        #print("------RunTileInput start")
        FieldSqlite = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"FieldPoint"+os.sep+FieldPointHeader+Management+"_"+Year+".db"
        print(Run,Tile,Management,Year,Metric,"$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$",FieldSqlite)
        print("The DB can have shifted colmn and rows only with PlotID. Also the TIF does not need projection/coordinates (i.e. in tif not in geotif). We can add it at the end of processing")
        print("In this case, there is no any FIA coordinates in cloud! but how to spatially mosaic? We can have the upperleft coordinates in a separate confiential file?")
        CloudWaterShadowMask = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"RSraster"+os.sep+"CloudShadowWaterSnow.tif" #We need to prepare this tif and find cloud,water,shadow, image edge,meadow, ice, snow, InvoidArea and so on. 

        InputRemoteSensingImagesPixelLabel = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"RSraster"+os.sep+"Img_"+BaseYear+"_PixelLabel.tif"
        
        InputRemoteSensingImagesReal = [
            os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"RSraster"+os.sep+"Img_"+BaseYear+"_swir1.tif",
            os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"RSraster"+os.sep+"Img_"+BaseYear+"_nir.tif",
            os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"RSraster"+os.sep+"Img_"+BaseYear+"_red.tif"
            ]

        InputRemoteSensingImagesPseudo = [
            os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"NonRSraster"+os.sep+"Annualmeantemperature.tif",
            os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"NonRSraster"+os.sep+"Annualprecipitation.tif",
            os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"NonRSraster"+os.sep+"Meantemperatureofwarmestquarter.tif",
            os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"NonRSraster"+os.sep+"Precipitationofdriestquarter.tif"
            ]

        if Run == "Run1":
            RemoteSensingSegmentationFromFineToCoarse = [
                os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R1_Y"+BaseYear+"_L1_S40_C18.tif",
                os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R1_Y"+BaseYear+"_L2_S70_C16.tif",
                os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R1_Y"+BaseYear+"_L3_S100_C14.tif",
                os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R1_Y"+BaseYear+"_L4_S130_C12.tif",
                os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R1_Y"+BaseYear+"_L5_S300_C10.tif",
                os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R1_Y"+BaseYear+"_L6_S40.tif"
                ]        
        if Run == "Run2":
            RemoteSensingSegmentationFromFineToCoarse = [
                os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R2_Y"+BaseYear+"_L1_S32_C19.tif",
                os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R2_Y"+BaseYear+"_L2_S67_C17.tif",
                os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R2_Y"+BaseYear+"_L3_S95_C15.tif",
                os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R2_Y"+BaseYear+"_L4_S135_C13.tif",
                os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R2_Y"+BaseYear+"_L5_S300_C11.tif",
                os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R2_Y"+BaseYear+"_L6_S32.tif"
                ]
        if Run == "Run3":
            RemoteSensingSegmentationFromFineToCoarse = [
                os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R3_Y"+BaseYear+"_L1_S48_C17.tif",
                os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R3_Y"+BaseYear+"_L2_S78_C15.tif",
                os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R3_Y"+BaseYear+"_L3_S108_C13.tif",
                os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R3_Y"+BaseYear+"_L4_S140_C11.tif",
                os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R3_Y"+BaseYear+"_L5_S300_C9.tif",
                os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R3_Y"+BaseYear+"_L6_S48.tif"
                ]        

        #Added on 20231002 to add more runs for more smoothy products. In reality, if the computation is not a problem, Run4, Run5, and Run6 are suggested. This indicates the segmentation data---start
        if Run == "Run4":
            SegmentationForThisRun = CrossCopyDataForThisSpecialRun("Run4",Tile,BaseYear)  
            RemoteSensingSegmentationFromFineToCoarse = [
                os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R3_Y"+BaseYear+"_L1_S48_C17.tif",   #from 3
                os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R1_Y"+BaseYear+"_L2_S70_C16.tif",   #from 1
                os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R2_Y"+BaseYear+"_L3_S95_C15.tif",   #from 2
                os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R1_Y"+BaseYear+"_L4_S130_C12.tif",   #from 1
                os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R2_Y"+BaseYear+"_L5_S300_C11.tif",   #from 2
                os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R3_Y"+BaseYear+"_L6_S48.tif"   #from 3
                ]        
        if Run == "Run5":
            SegmentationForThisRun = CrossCopyDataForThisSpecialRun("Run5",Tile,BaseYear)
            RemoteSensingSegmentationFromFineToCoarse = [
                os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R1_Y"+BaseYear+"_L1_S40_C18.tif",   #from 1
                os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R3_Y"+BaseYear+"_L2_S78_C15.tif",   #from 3
                os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R2_Y"+BaseYear+"_L3_S95_C15.tif",   #from 2
                os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R3_Y"+BaseYear+"_L4_S140_C11.tif",   #from 3
                os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R2_Y"+BaseYear+"_L5_S300_C11.tif",   #from 2
                os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R1_Y"+BaseYear+"_L6_S40.tif"   #from 1
                ]
        if Run == "Run6":
            SegmentationForThisRun = CrossCopyDataForThisSpecialRun("Run6",Tile,BaseYear)
            RemoteSensingSegmentationFromFineToCoarse = [
                os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R2_Y"+BaseYear+"_L1_S32_C19.tif",   #from 2
                os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R3_Y"+BaseYear+"_L2_S78_C15.tif",   #from 3
                os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R1_Y"+BaseYear+"_L3_S100_C14.tif",   #from 1
                os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R1_Y"+BaseYear+"_L4_S130_C12.tif",   #from 1
                os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R3_Y"+BaseYear+"_L5_S300_C9.tif",   #from 3
                os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R2_Y"+BaseYear+"_L6_S32.tif"   #from 2
                ]
        #Added on 20231002 to add more runs for more smoothy products. In reality, if the computation is not a problem, Run4, Run5, and Run6 are suggested. This indicates the segmentation data---end

        if ((Run == "Run1") or (Run == "Run4")):
            AdditionalDiscreteRaster = [
                os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"AdditionalDiscreteRaster"+os.sep+"LandFireBPS.tif",
                os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"AdditionalDiscreteRaster"+os.sep+"BioClimateZone.tif",
                os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"AdditionalDiscreteRaster"+os.sep+"PhenologyKmeans9.tif",
                #os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"AdditionalDiscreteRaster"+os.sep+"LiDAR5class.tif"
                ]
        if ((Run == "Run2") or (Run == "Run5")):
            AdditionalDiscreteRaster = [
                os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"AdditionalDiscreteRaster"+os.sep+"LandFireBPS.tif",
                os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"AdditionalDiscreteRaster"+os.sep+"BioClimateZone.tif",
                os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"AdditionalDiscreteRaster"+os.sep+"PhenologyKmeans11.tif",
                #os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"AdditionalDiscreteRaster"+os.sep+"LiDAR5class.tif"
                ]
        if ((Run == "Run3") or (Run == "Run6")):
            AdditionalDiscreteRaster = [
                os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"AdditionalDiscreteRaster"+os.sep+"LandFireBPS.tif",
                os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"AdditionalDiscreteRaster"+os.sep+"BioClimateZone.tif",
                os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"AdditionalDiscreteRaster"+os.sep+"PhenologyKmeans13.tif",
                #os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"AdditionalDiscreteRaster"+os.sep+"LiDAR5class.tif"
                ]
        AdditionalContinuousRaster = [
            os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"AdditionalContinuousRaster"+os.sep+"Dem30m.tif"
            ]


        #Added on 20230501: Download data from google bucket, but I decide not to use it here because the data in bucket has not been processed for each individual tile---start
        F3InputSource == "CloudBucket"
        InputRasterImages = InputRemoteSensingImagesReal + InputRemoteSensingImagesPseudo + RemoteSensingSegmentationFromFineToCoarse + AdditionalDiscreteRaster + AdditionalContinuousRaster
        InputRasterImages.insert(0,InputRemoteSensingImagesPixelLabel)
        InputRasterImages.insert(0,CloudWaterShadowMask)
        if F3InputSource == "CloudBucket": #Option are "Local" or "CloudBucket"
            for InputRasterImage in InputRasterImages:
                if not os.path.exists(InputRasterImage):
                    LocalDirectory = os.sep.join(InputRasterImage.split(os.sep)[:-2])
                    TargetFile = DownloadDataFromGoogleBucketToLocalDirectory(LocalDirectory, "f3seral", InputRasterImage)
        #Added on 20230501: Download data from google bucket, but I decide not to use it here because the data in bucket has not been processed for each individual tile---end


        InputRemoteSensingImagesReal = [k for k in InputRemoteSensingImagesReal if os.path.exists(k)]
        InputRemoteSensingImagesPseudo = [k for k in InputRemoteSensingImagesPseudo if os.path.exists(k)]
        RemoteSensingSegmentationFromFineToCoarse = [k for k in RemoteSensingSegmentationFromFineToCoarse if os.path.exists(k)]
        AdditionalDiscreteRaster = [k for k in AdditionalDiscreteRaster if os.path.exists(k)]
        AdditionalContinuousRaster = [k for k in AdditionalContinuousRaster if os.path.exists(k)]
        InputRasterImages = InputRemoteSensingImagesReal + InputRemoteSensingImagesPseudo + RemoteSensingSegmentationFromFineToCoarse + AdditionalDiscreteRaster + AdditionalContinuousRaster
        if InputRemoteSensingImagesPixelLabel not in InputRasterImages:  #20230928 added: This sentence may be duplicate because we have it in the [if F3InputSource == "CloudBucket":] part
            InputRasterImages.insert(0,InputRemoteSensingImagesPixelLabel)   
        if CloudWaterShadowMask not in InputRasterImages:
            InputRasterImages.insert(0,CloudWaterShadowMask)   #20230928 added: This sentence may be duplicate because we have it in the [if F3InputSource == "CloudBucket":] part

        gdalDS = gdal.Open(CloudWaterShadowMask)
        gdalDSArray = gdalDS.GetRasterBand(1).ReadAsArray()
        ##20230417, I had a new error after Nathan upgrade arcpro. I can see there is a warning "verison mismatch, so I had to install all modules again after cloning the python envieonment
        #[2:06 PM] Huang, Shengli (CTR) - FS, CA
        #did you upgrade arcpro in 06 computer?
        #[2:07 PM] Huang, Shengli (CTR) - FS, CA
        #gdalDSArray = gdalDS.GetRasterBand(1).ReadAsArray()\n', '  File "C:\\Users\\shenglihuang\\AppData\\Local\\ESRI\\conda\\envs\\arcgispro-py3-clone\\lib\\site-packages\\osgeo\\gdal.py", line 3671, in ReadAsArray\n    from osgeo import gdal_array\n', '  File "C:\\Users\\shenglihuang\\AppData\\Local\\ESRI\\conda\\envs\\arcgispro-py3-clone\\lib\\site-packages\\osgeo\\gdal_array.py", line 13, in <module>\n    from . import _gdal_array\n', 'ImportError: DLL load failed: The specified procedure could not be found.\n']
        #[2:08 PM] Huang, Shengli (CTR) - FS, CA
        #I have this new error. I never saw this before and wondering why
        gdalDSNoDataValue = gdalDS.GetRasterBand(1).GetNoDataValue()
        gdalDSArrayMasked = ma.masked_values(gdalDSArray, gdalDSNoDataValue)
        MaximumTargetPixelNumber = gdalDSArrayMasked.count()

        CheckRasterProjectionAndDimension(InputRasterImages)

        AdditionContinuousRasterIncluded = "No"  #option is "Yes" or "No". Note: This sentence is added here for flexibility. It is your responsibilty to correctly setup the input raster
        print("20230111: the following Step2IntensifyingPlotsBin and Step3IterativeImputationBinValueFromHighToLow is not easy to determine as the input RS images are quite different. This is not good")
        print("20230111: In the future, if this is not feasible, we can use the same RS image input for Run1, Run2, and Run3 (i.e., InputRemoteSensingImagesReal is identical)")
        print("20240305: The FIA density is quite different for different states. I am thinking of the values change according to density, which is the number of plots divided by the tile area")
        if Run == "Run1":
            #Step2IntensifyingPlotsBin = [25]  
            #Step3IterativeImputationBinValueFromHighToLow = [10, 7, 4] #too wide # try [19, 18, 17] #try [13, 11, 10] bad #original [11, 9, 7]  #important: value order is from high to low, meaning the binning result is from fine to coarse
            Step2IntensifyingPlotsBin = [40]  
            Step3IterativeImputationBinValueFromHighToLow = [19, 12, 6] #too wide # try [19, 18, 17] #try [13, 11, 10] bad #original [11, 9, 7]  #important: value order is from high to low, meaning the binning result is from fine to coarse
            if AdditionContinuousRasterIncluded == "Yes": 
                Step2IntensifyingPlotsBin = [8] 
                Step3IterativeImputationBinValueFromHighToLow = [7, 5, 3]         
        if Run == "Run2":
            Step2IntensifyingPlotsBin = [38] 
            Step3IterativeImputationBinValueFromHighToLow = [20, 13, 7] #Reasonable #original [10, 8, 6]
            if AdditionContinuousRasterIncluded == "Yes":
                Step2IntensifyingPlotsBin = [6] 
                Step3IterativeImputationBinValueFromHighToLow = [5, 4, 3]  
        if Run == "Run3":
            Step2IntensifyingPlotsBin = [35]
            Step3IterativeImputationBinValueFromHighToLow = [18, 11, 6] #too narrow   #original [11, 8, 10]
            if AdditionContinuousRasterIncluded == "Yes":
                Step2IntensifyingPlotsBin = [7] 
                Step3IterativeImputationBinValueFromHighToLow = [6, 5, 4]

        #Added on 20231002 to add more runs for more smoothy products. In reality, if the computation is not a problem, Run4, Run5, and Run6 are suggested---start
        if Run == "Run4":
            #Step2IntensifyingPlotsBin = [25]  
            #Step3IterativeImputationBinValueFromHighToLow = [10, 7, 4] #too wide # try [19, 18, 17] #try [13, 11, 10] bad #original [11, 9, 7]  #important: value order is from high to low, meaning the binning result is from fine to coarse
            Step2IntensifyingPlotsBin = [43]  
            Step3IterativeImputationBinValueFromHighToLow = [17, 10, 5] #too wide # try [19, 18, 17] #try [13, 11, 10] bad #original [11, 9, 7]  #important: value order is from high to low, meaning the binning result is from fine to coarse
            if AdditionContinuousRasterIncluded == "Yes": 
                Step2IntensifyingPlotsBin = [7] 
                Step3IterativeImputationBinValueFromHighToLow = [8, 5, 3]         
        if Run == "Run5":
            Step2IntensifyingPlotsBin = [41] 
            Step3IterativeImputationBinValueFromHighToLow = [23, 11, 6] #Reasonable #original [10, 8, 6]
            if AdditionContinuousRasterIncluded == "Yes":
                Step2IntensifyingPlotsBin = [6] 
                Step3IterativeImputationBinValueFromHighToLow = [7, 5, 3]  
        if Run == "Run6":
            Step2IntensifyingPlotsBin = [39]
            Step3IterativeImputationBinValueFromHighToLow = [17, 9, 5] #too narrow   #original [11, 8, 10]
            if AdditionContinuousRasterIncluded == "Yes":
                Step2IntensifyingPlotsBin = [6] 
                Step3IterativeImputationBinValueFromHighToLow = [5, 4, 3]
        #Added on 20231002 to add more runs for more smoothy products. In reality, if the computation is not a problem, Run4, Run5, and Run6 are suggested---end

        #print("------InputRemoteSensingImagesReal=",InputRemoteSensingImagesReal)

                

        #20240307: This section is to prepare SoilDrainageProductivityIndex24 according to the suggestion from Frank and Bill---start
        ShapeFile = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"Area_Extent.shp"
        SourceRaster = SoilDrainageProductivityIndex24
        ClipedRasterOutput = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"CommonShare"+os.sep+"SDPI24.tif"  #note in the void area, they use a value of 0
        SoilDrainageProductivityIndex24File = UsingShapeFileToClipRaster(ShapeFile, SourceRaster, ClipedRasterOutput)
        #Step4RemainingPixelFillingRaster.append(SoilDrainageProductivityIndex24File)
        #20240307: This section is to prepare SoilDrainageProductivityIndex24 according to the suggestion from Frank and Bill---end

        #20240411: This section is to prepare SoilDrainageProductivityIndex8 according to the suggestion from Frank and Bill---start
        ShapeFile = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"Area_Extent.shp"
        SourceRaster = SoilDrainageProductivityIndex8
        ClipedRasterOutput = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"CommonShare"+os.sep+"SDPI8.tif"  #note in the void area, they use a value of 0
        SoilDrainageProductivityIndex8File = UsingShapeFileToClipRaster(ShapeFile, SourceRaster, ClipedRasterOutput)
        #Step4RemainingPixelFillingRaster.append(SoilDrainageProductivityIndex8File)
        #20240411: This section is to prepare SoilDrainageProductivityIndex8 according to the suggestion from Frank and Bill---end
        
                
        print("------RunTileInput finished")
        return CloudWaterShadowMask,InputRemoteSensingImagesPixelLabel,MaximumTargetPixelNumber,InputRemoteSensingImagesReal,InputRemoteSensingImagesPseudo,RemoteSensingSegmentationFromFineToCoarse,AdditionalDiscreteRaster,AdditionalContinuousRaster,Step2IntensifyingPlotsBin,Step3IterativeImputationBinValueFromHighToLow,FieldSqlite  #https://stackoverflow.com/questions/19469697/return-multiple-lists-in-python-function
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for RunTileInput with inputs of "+repr(Run)+","+repr(Tile)+","+repr(Management)+","+repr(Year)+","+repr(Metric)+" with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog


def ImageSegmentationBasedOnClassifiedImage(InputTif):  
    try:
        print("The following website shws scipy.ndimage.label is good for labeling classification into sementatiob, but this function only take binary (1/0), so we customie it to non-binary input")
        #https://www.programcreek.com/python/example/52894/scipy.ndimage.label
        #https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.label.html
        #https://stackoverflow.com/questions/48996148/algorithm-behind-scipy-ndimage-measurements-label
        #https://stackoverflow.com/questions/65631673/how-to-use-scipy-label-on-a-non-binary-image
        print("ImageSegmentation start")
        print("InputTif=",InputTif)
        driverTiff = gdal.GetDriverByName('GTiff')
        ds = gdal.Open(InputTif)
        band = ds.GetRasterBand(1).ReadAsArray()
        NoDataValue = ds.GetRasterBand(1).GetNoDataValue()
        band = ma.masked_values(band, NoDataValue)
        bandMin = np.nanmin(band)
        bandMax = np.nanmax(band)
        if bandMin <= 0:  #if there is negative or 0 in classification, we use shift to make all values into positive; for NoDataValue, we assign originalmax + shift + 1
            shift = abs(bandMin) + 1      
            band[band != NoDataValue] = band[band != NoDataValue] + shift
            band[band == NoDataValue] = bandMax + shift + 1
        #band = band[30:40,50:60]  #this is obly used for testing, so comment out here but keep it for future testing if necessary

        UniqueClassID = np.unique(band)
        np.random.shuffle(UniqueClassID) #https://numpy.org/doc/stable/reference/random/generated/numpy.random.shuffle.html
        print("UniqueClassID=",UniqueClassID)
        Connection = [[1,1,1], [1,1,1], [1,1,1]]  #Connection = [[0,1,0], [1,1,1], [0,1,0]] is for four direction  ##Connection = [[1,1,1], [1,1,1], [1,1,1]], which is 8-direction and equivalent to Connection = generate_binary_structure(2,2)
        cum_num = 0
        segments = np.zeros_like(band)
        for IndividualClassID in UniqueClassID:  #https://stackoverflow.com/questions/65631673/how-to-use-scipy-label-on-a-non-binary-image, with little change because we do not have 0
            labeled_array, num_features = label((band==IndividualClassID).astype(np.int32), structure=Connection)  #https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.label.html
            segments += np.where(labeled_array > 0, labeled_array + cum_num, 0).astype(segments.dtype)
            cum_num += num_features
        print("cum_num=",cum_num)
        
        segments_fn = InputTif.replace(".tif","_segmentation.tif")
        segments_ds = driverTiff.Create(segments_fn, ds.RasterXSize, ds.RasterYSize,1, gdal.GDT_Int32) 
        segments_ds.SetGeoTransform(ds.GetGeoTransform())
        segments_ds.SetProjection(ds.GetProjectionRef())
        segments_ds.GetRasterBand(1).WriteArray(segments)
        segments_ds = None
        print("ImageSegmentation finished")
        return segments_fn
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for ImageSegmentation with inputs of " + repr(InputTif) + " with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog



def ImageSegmentation(InputTifList):
    try:
        #https://pyimagesearch.com/2014/07/28/a-slic-superpixel-tutorial-using-python/
        #https://towardsdatascience.com/object-based-land-cover-classification-with-python-cbe54e9c9e24
        #https://scikit-image.org/skimage-tutorials/lectures/4_segmentation.html#:~:text=Segmentation%20%E2%80%94%20Image%20analysis%20in%20Python%20Segmentation%20Separating,from%20one%20image%20and%20place%20them%20into%20another.
        #https://scikit-image.org/docs/stable/auto_examples/segmentation/plot_segmentations.html#:~:text=Quickshift%20image%20segmentation&text=Quickshift%20has%20two%20main%20parameters,%2Dspace%2C%20given%20by%20ratio%20.
        #As of 20220520, this works but a) need to test the segementation parameters and datatype, b) output file name etc.
        print("ImageSegmentation start")
        band_data = []
        for InputTif in InputTifList:
            print("InputTif=",InputTif)
            driverTiff = gdal.GetDriverByName('GTiff')
            ds = gdal.Open(InputTif)
            band = ds.GetRasterBand(1).ReadAsArray()
            NoDataValue = ds.GetRasterBand(1).GetNoDataValue()
            band = ma.masked_values(band, NoDataValue)
            MinimumBoundValue = max(band.mean()-band.std(),band.min())
            MaximumBoundValue = min(band.mean()+band.std(),band.max())
            band = np.where(band >= MaximumBoundValue, MaximumBoundValue, np.where(band <= MinimumBoundValue, 0, 255.0*(band-MinimumBoundValue)*1.0/(MaximumBoundValue-MinimumBoundValue)))
            band = band.astype(int)   #convert to unsigned 8 bit integer
            band_data.append(band)
        band_data = np.dstack(band_data)
        img = exposure.rescale_intensity(band_data)  #20220809, I am not sure what is this, but we can rescale ourselves using our own algorthm
        print(type(img))
        print(img.shape)
        print("starting segementation at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
        # do segmentation, different options with quickshift and slic (only use one of the next two lines)
        SegmentationMethod = "slic" #Options are "quickshift" or "slic"
        if SegmentationMethod == "quickshift":
            for ratio in range(1,10,2):
                for max_dist in range(5,50,5):
                    segments = quickshift(img, ratio=ratio, max_dist=max_dist, convert2lab=False)
                    segments_fn = InputTifList[0].replace("RSraster","CommonShare").replace("NonRSraster","CommonShare").replace("AdditionalContinuousRaster","CommonShare").replace(InputTifList[0].split(os.sep)[-1],"Seg_"+SegmentationMethod+"_R"+str(ratio)+"_"+"D"+str(max_dist)+".tif")
                    segments_ds = driverTiff.Create(segments_fn, ds.RasterXSize, ds.RasterYSize,1, gdal.GDT_Int32) 
                    segments_ds.SetGeoTransform(ds.GetGeoTransform())
                    segments_ds.SetProjection(ds.GetProjectionRef())
                    segments_ds.GetRasterBand(1).WriteArray(segments)
                    segments_ds = None
                    print("ImageSegmentation quickshift finished")
        if SegmentationMethod == "slic":
            for n_segments in range(5000,6000,1000):   #larger values result in more detailed segmentation
                for compactness in np.arange(1,50,5):
                    segments = slic(img, n_segments=n_segments, sigma=3, compactness=compactness, convert2lab=True)  #https://pyimagesearch.com/2014/07/28/a-slic-superpixel-tutorial-using-python/
                    segments_fn = InputTifList[0].replace("RSraster","CommonShare").replace("NonRSraster","CommonShare").replace("AdditionalContinuousRaster","CommonShare").replace(InputTifList[0].split(os.sep)[-1],"Seg_"+SegmentationMethod+"_N"+str(n_segments)+"_"+"C"+str(compactness)+".tif")
                    segments_ds = driverTiff.Create(segments_fn, ds.RasterXSize, ds.RasterYSize,1, gdal.GDT_Int32) 
                    segments_ds.SetGeoTransform(ds.GetGeoTransform())
                    segments_ds.SetProjection(ds.GetProjectionRef())
                    segments_ds.GetRasterBand(1).WriteArray(segments)
                    segments_ds = None
                    print("ImageSegmentation slic finished")
        return segments_fn
        print('segments complete at ', datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
         

    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for ImageSegmentation with inputs of " + repr(InputTifList) + " with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog

        

def MosaicingBorderZshape(SegmentationTif,ToBeMosaicedTif,InwardBufferPercent,FloatToIntegerCoefficient):  #e.g., InwardBufferPercent = 0.1 mean 10%
    try:
        print("MosaicingBorderZshape start")
        t0 = time.time()
        MosaicingBorderZshapeTif = ToBeMosaicedTif.replace(".tif","_Zshaped.tif")
        print("SegmentationTif=",SegmentationTif)
        print("ToBeMosaicedTif=",ToBeMosaicedTif)
        print("InwardBufferPercent=",InwardBufferPercent)
        print("MosaicingBorderZshapeTif=",MosaicingBorderZshapeTif)
        if (os.path.exists(SegmentationTif) and os.path.exists(ToBeMosaicedTif)):
            print("MosaicingBorderZshapeTif=",MosaicingBorderZshapeTif)
            if not os.path.exists(MosaicingBorderZshapeTif):
                print("ToBeMosaicedTif=",ToBeMosaicedTif)
                #if ((BaseManagement in ToBeMosaicedTif) and (BaseYear in ToBeMosaicedTif) and (BaseMetric in ToBeMosaicedTif)):
                if ((BaseManagement in ToBeMosaicedTif) and (BaseYear in ToBeMosaicedTif) and (BaseMetric in ToBeMosaicedTif)) or ("ProcessingPercentageAsOrderAndReliability.tif" in ToBeMosaicedTif):  #20240514 add or ("ProcessingPercentageAsOrderAndReliability.tif" in ToBeMosaicedTif) 
                    src = gdal.Open(SegmentationTif)
                    print("SegmentationTif=",SegmentationTif)
                    cols = src.RasterXSize
                    rows = src.RasterYSize
                    print("MosaicingBorderZshape startAAA")
                    upx, xres, xskew, upy, yskew, yres = src.GetGeoTransform()  #https://gis4programmers.wordpress.com/2017/01/06/using-gdal-to-get-raster-extent/, note GetGeoTransform not GetGeotransform
                    ulx = upx + 0*xres + 0*xskew
                    uly = upy + 0*yskew + 0*yres
                    llx = upx + 0*xres + rows*xskew
                    lly = upy + 0*yskew + rows*yres
                    lrx = upx + cols*xres + rows*xskew
                    lry = upy + cols*yskew + rows*yres
                    urx = upx + cols*xres + 0*xskew
                    ury = upy + cols*yskew + 0*yres
                    print("MosaicingBorderZshape startBBB")
                    SegmentationTifArray = src.GetRasterBand(1).ReadAsArray()
                    SegmentationTifNoDataValue = src.GetRasterBand(1).GetNoDataValue()
                    SegmentationArray = ma.masked_values(SegmentationTifArray, SegmentationTifNoDataValue)
                    print("MosaicingBorderZshape startCCC")    

                    #I know the actual situation is much more complex, but here we just assume the raster is a rectangle for the following calculation
                    x1 = 0 + int(cols*InwardBufferPercent)
                    y1 = 0 + int(rows*InwardBufferPercent)
                    x2 = cols - int(cols*InwardBufferPercent)
                    y2 = rows - int(rows*InwardBufferPercent)
                    print("x1,x2,y1,y2=",x1,x2,y1,y2) 
                    NorthBorder = SegmentationArray[y1,x1:x2].flatten().tolist()
                    WestBorder = SegmentationArray[y1:y2,x1].flatten().tolist()
                    SouthBorder = SegmentationArray[y2,x1:x2].flatten().tolist()
                    EastBorder = SegmentationArray[y1:y2,x2].flatten().tolist()
                    SegmentationArrayAlongFourSidesWithNone = NorthBorder + WestBorder + SouthBorder + EastBorder #is for list not for array
                    #print("The length of SegmentationArrayAlongFourSidesWithNone=",len(SegmentationArrayAlongFourSidesWithNone))
                    SegmentationArrayAlongFourSides = list(filter(None, SegmentationArrayAlongFourSidesWithNone)) # using filter() to remove None values in list, see https://www.geeksforgeeks.org/python-remove-none-values-from-list/
                    #print("The length of SegmentationArrayAlongFourSides=",len(SegmentationArrayAlongFourSides))
                    SegmentationArrayAlongFourSidesUnique = np.unique(SegmentationArrayAlongFourSides)
                    #print("The SegmentationArrayAlongFourSidesUnique=",SegmentationArrayAlongFourSidesUnique)

                    SelectedPixels = np.full((rows,cols), F3NoDataValue)
                    for m in SegmentationArrayAlongFourSidesUnique:
                        SelectedPixels[SegmentationArray == m] = 1   #SelectedPixels[np.where(SegmentationArray == m)] = 1   is also OK
                    SelectedPixels[y1:y2,x1:x2] = 1         
                else:  #20240424: There was a NOT after if, I do not know why, so I deleted it
                    print(ToBeMosaicedTif,"come here")
                    src = gdal.Open(SegmentationTif)
                    print("SegmentationTif 111=",SegmentationTif)
                    cols = src.RasterXSize
                    rows = src.RasterYSize
                    #ZshapedTif = ToBeMosaicedTif.replace(ToBeMosaicedTif.split(os.sep)[-1],BaseManagement+"_"+str(BaseYear)+"_"+BaseMetric+"_Zshaped.tif")
                    ZshapedTif = ToBeMosaicedTif.replace("Intermediate","Results").replace(ToBeMosaicedTif.split(os.sep)[-1],BaseManagement+"_"+str(BaseYear)+"_"+BaseMetric+"_Zshaped.tif")   #20240226 added .replace("Intermediate","Results") for IDW zshape
                    print(BaseManagement)
                    print(BaseYear)
                    print(BaseMetric)
                    print("ZshapedTif=",ZshapedTif," is supposed to be the ",BaseManagement,"_",BaseYear,"_",BaseMetric+"_Zshaped.tif")
                    ZshapedTifRaster = gdal.Open(ZshapedTif)
                    ZshapedTifRasterData = ZshapedTifRaster.GetRasterBand(1)
                    ZshapedTifRasterDataArray = ZshapedTifRasterData.ReadAsArray()  
                    ZshapedTifRasterDataNoDataValue = ZshapedTifRasterData.GetNoDataValue()
                    ZshapedTifRasterDataMasked = ma.masked_values(ZshapedTifRasterDataArray, ZshapedTifRasterDataNoDataValue)
                    print("The ZshapedTifRasterDataNoDataValue = ", ZshapedTifRasterDataNoDataValue)
                    ZshapedTifRasterDataMasked[~ZshapedTifRasterDataMasked.mask] = 1  #20231006: make sure it is almost the same as the SelectedPixels below. 
                    SelectedPixels = np.full((rows,cols), F3NoDataValue)
                    SelectedPixels[~ZshapedTifRasterDataMasked.mask] = 1  

                src1 = gdal.Open(ToBeMosaicedTif)    
                ToBeMosaicedTifArray = src1.GetRasterBand(1).ReadAsArray()
                ToBeMosaicedTifNoDataValue = src1.GetRasterBand(1).GetNoDataValue()    
                ToBeMosaicedArray = ma.masked_values(ToBeMosaicedTifArray, ToBeMosaicedTifNoDataValue)
                ToBeMosaicedArray[ToBeMosaicedArray == ToBeMosaicedTifNoDataValue] = F3NoDataValue
                ToBeMosaicedArray[np.where(SelectedPixels == F3NoDataValue)] = F3NoDataValue  #https://stackoverflow.com/questions/59206103/how-to-modify-the-value-of-numpy-array-based-on-another-array
                #print(ToBeMosaicedTifArray.shape)
                #print(ToBeMosaicedArray.shape)
                ToBeMosaicedArrayMin = np.nanmin(ToBeMosaicedArray)
                ToBeMosaicedArrayMax = np.nanmax(ToBeMosaicedArray)
                TypeOfInterest = OutputDataType(ToBeMosaicedArrayMin, ToBeMosaicedArrayMax)

                
                driver = gdal.GetDriverByName("GTiff")
                if OutputGeoTifCompression == "Yes": #Added on 20230227. LZW compression does not lose information. LZW compression is a lossless data compression algorithm, which means that the original data can be fully reconstructed from the compressed data without any loss of information.
                    outdata = driver.Create(MosaicingBorderZshapeTif, cols, rows, 1, TypeOfInterest, options=['COMPRESS=LZW'])   #Original is  gdal.GDT_Int32, see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
                if OutputGeoTifCompression == "No": 
                    outdata = driver.Create(MosaicingBorderZshapeTif, cols, rows, 1, TypeOfInterest)   #Original is  gdal.GDT_Int32, see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
                outdata.SetGeoTransform(src1.GetGeoTransform())  ##sets same geotransform as input
                outdata.SetProjection(src1.GetProjection())  ##sets same projection as input
                #outdata.GetRasterBand(1).WriteArray(SelectedPixels)
                outdata.GetRasterBand(1).WriteArray(ToBeMosaicedArray)
                outdata.GetRasterBand(1).SetNoDataValue(F3NoDataValue)  
                outdata.FlushCache() ##saves to disk!!
                outdata = None
            #print("MosaicingBorderZshape for ToBeMosaicedTif=",ToBeMosaicedTif, " it took \t" + str(int((time.time() - t0)/60))," minutes at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
            #print("MosaicingBorderZshape for ToBeMosaicedTif=",ToBeMosaicedTif, " it took \t" + str(int((time.time() - t0)/60))," minutes at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"), file=open(F3Log, 'a'))
        return MosaicingBorderZshapeTif
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for MosaicingBorderZshape with inputs of "+repr(SegmentationTif)+","+repr(ToBeMosaicedTif)+","+repr(InwardBufferPercent)+" with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog


def CheckMetricIgnoredNew(MetricList,FieldSqlite,Run,Tile,Management,Year,Metric):
    try:
        #This section was added on 20240229 to skip the CheckMetricIgnoredNew function if already done. This can save a lot of time---start
        IgnoreMetric = FieldSqlite.replace(".db","_IgnoredMetric.txt")

        #This section was added on 20240425 to change the file permission from read only to written. It is not tested yet as 20240425---start
        print("Below r+ means read and append. if permission denied, make sure the file is not read only with mannual change")
        if os.access(IgnoreMetric, os.W_OK):
            print(f"{IgnoreMetric} is writable.")
        else:
            print(f"{IgnoreMetric} is read-only.")
            os.chmod(IgnoreMetric, stat.S_IWRITE)  #os.remove(file_name) was added when I check Bing Copilot, but I think it is not necessary
        #This section was added on 20240425 to change the file permission from read only to written. It is not tested yet as 20240425---end        
        
        with open(IgnoreMetric, "r+") as IgnoreMetricFile:   
            Lines = IgnoreMetricFile.readlines()
            Lines = [i.replace('\n','') for i in Lines]  
            ExistingMetricNameList = []
            ExistingMetricIgnored = []
            ExistingMetricNotIgnored = []
            for Line in Lines:
                ExistingMetricName = Line.split(":")[0]
                ExistingMetricNameList.append(ExistingMetricName)
                MetricStatus = Line.split(":")[1]
                if MetricStatus == "Ignored":
                    ExistingMetricIgnored.append(Line.split(":")[0])
                if MetricStatus == "NotIgnored":
                    ExistingMetricNotIgnored.append(Line.split(":")[0])            
            MetricList = [k for k in MetricList if k not in ExistingMetricNameList]
            #This section was added on 20240229 to skip the CheckMetricIgnoredNew function if already done. This can save a lot of time---end

            
            #print("MetricList=",MetricList)
            #print("MetricList=",MetricList, file=open(F3Log, 'a'))
            #print("FieldSqlite=",FieldSqlite)
            #print("FieldSqlite=",FieldSqlite, file=open(F3Log, 'a'))
            MetricList = [i.lower() for n,i in enumerate(MetricList) if i not in MetricList[:n]]  #Unique
            conn = sqlite3.connect(FieldSqlite)  #https://www.sqlitetutorial.net/sqlite-python/
            cur= conn.cursor()
            MetricIgnored = []
            MetricNotIgnored = []
            for MyMetric in MetricList:
                #20230504: add another function to determine which table should be chosen for this metric---start
                Table = FindTheFirstTableNameWhereMetricExists(MyMetric,FieldSqlite)
                #print(MyMetric, " was found in Table=",Table)
                #print(MyMetric, " was found in Table=",Table, file=open(F3Log, 'a'))
                if Table == "NotFound":
                    MetricIgnored.append(MyMetric)
                else:
                    MetricNotIgnored.append(MyMetric)
                    TableQuery = "SELECT * FROM " + Table
                    cur.execute(TableQuery)
                    
                    columns = [column[0].lower() for column in cur.description]
                    #print(FieldSqlite, "has columns=",columns)
                    print(FieldSqlite, "has columns=",columns, file=open(F3Log, 'a'))
                    MetricIndex = columns.index(MyMetric)
                    #print(MyMetric," found in Table=", Table, " with MetricIndex=", MetricIndex)
                    print(MyMetric," found in Table=", Table, " with MetricIndex=", MetricIndex, file=open(F3Log, 'a'))
                    rows = cur.fetchall()
                    MetricValueList = []   
                    rowid = 0
                    for row in rows:
                        rowid = rowid + 1
                        #print("row[MetricIndex]=",row[MetricIndex])
                        #print("row[MetricIndex]=",row[MetricIndex], file=open(F3Log, 'a'))
                        if row[MetricIndex] is None:  #20240214 added because We have an error at MetricValue = float(row[MetricIndex]): "TypeError: float() argument must be a string or a real number, not 'NoneType'
                            MetricValue = 0
                        else:
                            MetricValue = float(row[MetricIndex])
                        #print("MetricValue=",MetricValue)
                        MetricValueList.append(MetricValue)
                    #print("MetricValueList=",MetricValueList)
                    if min(MetricValueList) == max(MetricValueList):
                       MetricIgnored.append(MyMetric)
                       MetricNotIgnored.remove(MyMetric)
                    #print("2",MetricIgnored)
                    #print("2",MetricNotIgnored)
                #20230504: add another function to determine which table should be chosen for this metric---end
            #if len(MetricIgnored) >= 1:
            Content1 = ""
            for k in MetricNotIgnored:
                ThisLine = k + ":" + "NotIgnored"+ "\n"
                Content1 = Content1 + ThisLine
            print("Content1=",Content1)
            Content2 = ""
            for k in MetricIgnored:
                ThisLine = k + ":" + "Ignored"+ "\n"
                Content2 = Content2 + ThisLine
            print("Content2=",Content2)
            Content = Content1 + Content2
            print("Content=",Content," for ",Management,Year,Metric)
            if ((Management in [BaseManagement]) and (Year in [BaseYear]) and (Metric in [BaseMetric])):  #20240320: I have [Errno 13] Permission denied indicating writing into IgnoreMetric.txt is problematic, so I add this condition
                print("BaseManagement,BaseYear,BaseMetric, so we will write and save")
                IgnoreMetricFile.write(Content)
        
        MetricNotIgnored = MetricNotIgnored + [k for k in ExistingMetricNotIgnored if k not in MetricNotIgnored]        
        return MetricNotIgnored
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for CheckMetricIgnoredNew with inputs of " + repr(MetricList)+","+repr(FieldSqlite)+","+repr(Run)+","+repr(Tile)+","+repr(Management)+","+repr(Year)+","+repr(Metric) + " with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog


def FilePermissionConflictDuringMultipleProcess(FileName, Content):   #20240320: This function is discarded 
    try:
        print("$$$$$$$$$$$$$$$$$$$$$$$$$FileName, Content=",FileName, Content)
        ##As of 20240201 working: This is the approach, but I thought it is with risk of permission conflict---start
        FileNameFile = open(FileName, 'a')  #20240130, I change the 'w' to 'a', because w has permission problem.
        FileNameFile.write(Content)
        FileNameFile.close()
        ##As of 20240201 working: This is the approach, but I thought it is with risk of permission conflict---end

        ###As of 20240201 not working: This is the new approach trying to solve permission conflict during multiple process. Check https://stackoverflow.com/questions/55789178/python-locking-and-unlocking-file-from-multiple-processes---start
        #from filelock import FileLock   #[pip install filelock] is the module is not installed
        #with FileLock(FileName):
        #    FileNameFile = open(FileName, 'a')              
        #    FileNameFile.write(Content)
        #    FileNameFile.close()
        ###As of 20240201 not working:This is the new approach trying to solve permission conflict during multiple process. Check https://stackoverflow.com/questions/55789178/python-locking-and-unlocking-file-from-multiple-processes---end
        return FileName
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for CheckRasterProjectionAndDimension with inputs of " + repr(FileName) + "," + repr(len(Content)) + " with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog
        

def CheckRasterProjectionAndDimension(InputTifList):  #InputTifList is a python list
    try:
        print("------CheckRasterProjectionAndDimension start")
        #print("------https://rdrr.io/cran/raster/man/compare.html is a good source")
        print("------InputTifList=",InputTifList)
        print("------InputTifList[0]=",InputTifList[0])
        TifRaster = gdal.Open(InputTifList[0])
        ncol = TifRaster.RasterXSize
        nrow = TifRaster.RasterYSize
        bands = TifRaster.RasterCount
        NoDataValue = TifRaster.GetRasterBand(1).GetNoDataValue()
        #print("------ncol,nrow,bands,NoDataValue=",ncol,nrow,bands,NoDataValue)
        for K in InputTifList[1:]:
            print("K=",K)
            TifRaster = gdal.Open(K)
            col = TifRaster.RasterXSize
            row = TifRaster.RasterYSize
            band = TifRaster.RasterCount
            NoData = TifRaster.GetRasterBand(1).GetNoDataValue()
            if ((col != ncol) or (row != nrow) or (band != bands) or (NoData != NoDataValue)):  #We will turn this back
                print("------we cannot proceed, because ", K, " has different rows, columns, or NoData as: ",col,row,NoData)
            else:
                print("------we can proceed, because ", K, " has same rows, columns, or NoData as: ",col,row,NoData)
        #print("------CheckRasterProjectionAndDimension finished")
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for CheckRasterProjectionAndDimension with inputs of " + repr(InputTifList) + " with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog
    

def SegmentationRevalue(CloudWaterShadowMask,SegmentationTifList): #This convert the very large negative and positive GEE segmentation values into normal values, but it is no use used here, because I used in preprocessing part
    try:
        src = gdal.Open(CloudWaterShadowMask)
        Cols = src.RasterXSize
        Rows = src.RasterYSize
        CloudWaterShadowMaskArray = src.GetRasterBand(1).ReadAsArray()
        CloudWaterShadowMaskNoDataValue = src.GetRasterBand(1).GetNoDataValue()
        #print("CloudWaterShadowMaskNoDataValue=",CloudWaterShadowMaskNoDataValue)
        for SegmentationTif in SegmentationTifList:
            OutFile = SegmentationTif.replace(".tif","_test.tif")
            if not os.path.exists(OutFile):
                print("\n Processing ",OutFile)
                MyRaster = gdal.Open(SegmentationTif)
                TifArray = MyRaster.GetRasterBand(1).ReadAsArray()
                TifArrayUniqueValues = np.unique(TifArray).tolist()  #tolist is required here because index() can only be applied to list
                #print("TifArrayUniqueValues=",TifArrayUniqueValues)

                for ElementValue in TifArrayUniqueValues:
                    ElementIndex = TifArrayUniqueValues.index(ElementValue)
                    TifArray[TifArray == ElementValue] = ElementIndex
                                       
                TifArray[CloudWaterShadowMaskArray == CloudWaterShadowMaskNoDataValue] = F3NoDataValue
                driver = gdal.GetDriverByName("GTiff")
                if OutputGeoTifCompression == "Yes": #Added on 20230227. LZW compression does not lose information. LZW compression is a lossless data compression algorithm, which means that the original data can be fully reconstructed from the compressed data without any loss of information.
                    outdata = driver.Create(OutFile, Cols, Rows, 1, gdal.GDT_Int32, options=['COMPRESS=LZW'])   #see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
                if OutputGeoTifCompression == "No": 
                    outdata = driver.Create(OutFile, Cols, Rows, 1, gdal.GDT_Int32)   #see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
                outdata.SetGeoTransform(src.GetGeoTransform())  ##sets same geotransform as input
                outdata.SetProjection(src.GetProjection())   ##sets same projection as input
                outdata.GetRasterBand(1).WriteArray(TifArray)
                outdata.GetRasterBand(1).SetNoDataValue(F3NoDataValue)
                outdata.FlushCache() ##saves to disk!!
                outdata = None
        Message = "Shengli is successful in revalue segmentation at " + datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        return Message
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for SegmentationRevalue with inputs of " + repr(CloudWaterShadowMask)+","+repr(SegmentationTifList) + " with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog



def OutputDataType(MinValue0, MaxValue):  #Added on 20230201 to change the output datatype---start
    try:
        #20230227: I was wondering if the nagative value can be -9999 in a Geotif where the data is always positive, and here is the answer from chatGPT [can gdal nodatavalue be negative in geotif if it is in 8-bit integer]
        #In an 8-bit integer GeoTIFF, the valid range of pixel values is typically from 0 to 255. Therefore, it is not possible to assign a negative value as a NoData value using an 8-bit integer data type. 
        #If you need to represent negative values as NoData in a GeoTIFF, you may need to use a different data type such as signed 16-bit integer or floating-point, depending on the range and precision of your data. With these data types, you can set the NoData value to a negative value if it is appropriate for your data. 
        #When using GDAL to work with GeoTIFF files, it is important to ensure that the data type and NoData value are correctly specified in order to avoid data loss or incorrect analysis results.

        #20240126: >>> import osgeo.gdal  >>> osgeo.gdal.VersionInfo() >>> '3040300', see https://stackoverflow.com/questions/3233674/how-can-i-get-the-installed-gdal-ogr-version-from-python
        #20240126: >>> from osgeo import gdal, ogr, osr   >>> a = gdal.GDT_UInt32 is ok   b = gdal.GDT_UInt64 does not work. This means UInt64 is not supported by this GDAL
        #20240126: https://gis.stackexchange.com/questions/313991/how-to-create-a-raster-in-gdal-with-int64-datatype-rasterizing-a-vector-layer-w
        #>>> c = gdal.GDT_Float32 and >>> c = gdal.GDT_Float64 are ok. According to 
        MinValue = min(MinValue0,F3NoDataValue)
        print("MinValue=",MinValue, file=open(F3Log, 'a'))
        print("MaxValue=",MaxValue, file=open(F3Log, 'a'))
        if ((MinValue >= 0) and (MaxValue <= 256)):
            TypeOfInterest = gdal.GDT_Byte  #see GDAL Types at https://gist.github.com/CMCDragonkai/ac6289fa84bcc8888035744d7e00e2e6
        elif ((MinValue >= 0) and (MaxValue <= 65535)):
            TypeOfInterest = gdal.GDT_UInt16
        elif ((MinValue >= -32768) and (MaxValue <= 32768)):
            TypeOfInterest = gdal.GDT_Int16
        elif ((MinValue >= 0) and (MaxValue <= 4294967296)):
            TypeOfInterest = gdal.GDT_UInt32
        elif ((MinValue >= -2147483648) and (MaxValue <= 2147483648)):
            TypeOfInterest = gdal.GDT_Int32
        else:
            TypeOfInterest = gdal.GDT_Float64  #20240126: The FIADB_PLOT is a big number like 12002421376854, which is larger than the 2147483648. GDAL does not support gdal.GDT_Int64, so I use gdal.GDT_Float64 here (note before 20240418, it was gdal.GDT_Float32, which caused trouble: FIADB plotID is totally different), see https://stackoverflow.com/questions/1835787/what-is-the-range-of-values-a-float-can-have-in-python
        print("TypeOfInterest=",TypeOfInterest, file=open(F3Log, 'a'))
        return TypeOfInterest
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for OutputDataType with inputs of " + repr(MinValue)+","+repr(MaxValue) + " with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog


def RasterCombineToCreateFixedZoneValueFromArrays(ArrayLists, ArrayListsPath, ReferencedImg, ReducedTimes):  #ArrayLists is a list of arrays. When producing annual historic maps, we need consistent zone value, which is why we have this function here
    try:
        #print("------RasterCombine start")
        t0 = time.time()
        Reference = gdal.Open(ReferencedImg)   #ReferenceYearTif is the last one of 
        ReferenceCols = Reference.RasterXSize
        ReferenceRows = Reference.RasterYSize
        ReferenceArray = Reference.GetRasterBand(1).ReadAsArray()
        ReferenceNoDataValue = Reference.GetRasterBand(1).GetNoDataValue()
        ReferenceArray = ReferenceArray[::ReducedTimes,::ReducedTimes]
        WeUseThisProjection = Reference.GetProjectionRef()
        WeUseThisGeoTransform = Reference.GetGeoTransform()
        NewGeoTransform = [WeUseThisGeoTransform[0],WeUseThisGeoTransform[1]*ReducedTimes,WeUseThisGeoTransform[2],WeUseThisGeoTransform[3],WeUseThisGeoTransform[4],WeUseThisGeoTransform[5]*ReducedTimes]  #added in 20230623
        print(NewGeoTransform)  #This will have a new resolution 

        Mins = "-".join([str(np.nanmin(k)) for k in ArrayLists])
        Means = "-".join([str(int(np.nanmean(k))) for k in ArrayLists])
        Maxs = "-".join([str(np.nanmax(k)) for k in ArrayLists])
        OutFile = ArrayListsPath+os.sep+Mins+"_"+Means+"_"+Maxs+"HM.tif"   #HM means Historical Mapping. 
        #print("------OutFile=",OutFile, file=open(F3Log, 'a'))
        if os.path.exists(OutFile):
            #print("------we already have OutFile=",OutFile, file=open(F3Log, 'a'))
            Final2D = ReadTifToArray(OutFile)
            Final2D[ReferenceArray == ReferenceNoDataValue] = F3NoDataValue
            Final2D = ma.masked_values(Final2D, F3NoDataValue)
            #print("and the existing Final2DMin,Final2DMax=",np.nanmin(Final2D),np.nanmax(Final2D), file=open(F3Log, 'a'))
        if not os.path.exists(OutFile):
            Kid = 0
            LastMyRasterArray = np.full((ReferenceArray.shape[0], ReferenceArray.shape[1]), 0)
            for k in ArrayLists:
                Kid = Kid + 1
                MyRasterArray = ma.masked_values(k, F3NoDataValue)
                MyRasterArrayMax = np.nanmax(MyRasterArray)
                ShiftCoefficient = len(str(int(MyRasterArrayMax)))  #ShiftCoefficient = int(math.log10(MyRasterArrayMax)) + 1   #https://stackoverflow.com/questions/2189800/how-to-find-length-of-digits-in-an-integer)
                #print("Now MyRasterArrayMin,MyRasterArrayMax,ShiftCoefficient=",np.nanmin(MyRasterArray),np.nanmax(MyRasterArray),ShiftCoefficient, file=open(F3Log, 'a'))
                MyRasterArray = np.add(LastMyRasterArray * pow(10,ShiftCoefficient), MyRasterArray)

                LastMyRasterArray = MyRasterArray.copy()
                LastMyRasterArrayMin = np.nanmin(LastMyRasterArray)
                LastMyRasterArrayMax = np.nanmax(LastMyRasterArray)
                #print("Now LastMyRasterArrayMin,LastMyRasterArrayMax=",LastMyRasterArrayMin,LastMyRasterArrayMax, file=open(F3Log, 'a'))
            Final2D = LastMyRasterArray.copy()
            Final2D[ReferenceArray == ReferenceNoDataValue] = F3NoDataValue
            Final2D = ma.masked_values(Final2D, F3NoDataValue)

            #Added on 20230201 to change the output datatype---start
            Final2D = ma.masked_values(Final2D, F3NoDataValue)
            Final2DMin = np.nanmin(Final2D)
            Final2DMax = np.nanmax(Final2D)
            TypeOfInterest = OutputDataType(Final2DMin, Final2DMax)
            #print("Now Final2DMin,Final2DMax=",np.nanmin(Final2D),np.nanmax(Final2D), file=open(F3Log, 'a'))
            #Added on 20230201 to change the output datatype---end
            
            driver = gdal.GetDriverByName("GTiff")
            if OutputGeoTifCompression == "Yes": #Added on 20230227. LZW compression does not lose information. LZW compression is a lossless data compression algorithm, which means that the original data can be fully reconstructed from the compressed data without any loss of information.
                outdata = driver.Create(OutFile, ReferenceArray.shape[1], ReferenceArray.shape[0], 1, TypeOfInterest, options=['COMPRESS=LZW'])   #original is gdal.GDT_Int32. see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
            if OutputGeoTifCompression == "No": 
                outdata = driver.Create(OutFile, ReferenceArray.shape[1], ReferenceArray.shape[0], 1, TypeOfInterest)   #original is gdal.GDT_Int32. see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
            outdata.SetGeoTransform(NewGeoTransform)    #outdata.SetGeoTransform(WeUseThisGeoTransform)  ##sets same geotransform as input
            outdata.SetProjection(WeUseThisProjection)  ##sets same projection as input
            outdata.GetRasterBand(1).WriteArray(Final2D)
            outdata.GetRasterBand(1).SetNoDataValue(F3NoDataValue) 
            outdata.FlushCache() ##saves to disk!!
            outdata = None
            #print("------Image combined from: ", InputTifList)
            #print("------The output image is: ", OutFile)

        #print("------RasterCombine is done")
        #print("RasterCombineToCreateFixedZoneValueFromArrays it took \t" + str(int((time.time() - t0)/60))," minutes")
        #print("------RasterCombine finished with output of ", OutFile, file=open(F3Log, 'a'))        
        return Final2D
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"    
        #print(Content1)
        Content2 = "The error was for RasterCombineToCreateFixedZoneValueFromArrays with inputs of "+repr(len(ArrayLists))+"," + repr(ArrayListsPath)+"," + repr(ReferencedImg)+"," + repr(ReducedTimes) + " with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog

    

def RasterCombineToCreateFixedZoneValueFromImages(InputTifList):  #not used by F3, but if needed, we need to revise it according to RasterCombineToCreateFixedZoneValueFromArrays concept
    print("During revision, we may a)convert the InputTifList to ArrayLists, and b) call the RasterCombineToCreateFixedZoneValueFromArrays function. In this case, it is easier to maintain the code")
    try:
        #print("------RasterCombine start")
        t0 = time.time()
        InputTifListNameOnly = [k.split(os.sep)[-1].replace(".tif","") for k in InputTifList]
        filename = "".join(InputTifListNameOnly)
        OutFile = os.sep.join(InputTifList[0].split(os.sep)[:-2])+os.sep+"CommonShare"+os.sep+filename+"HM.tif"   #HM means Historical Mapping
        #print("------OutFile=",OutFile)
        if not os.path.exists(OutFile):
            src = gdal.Open(InputTifList[0])
            Cols = src.RasterXSize
            Rows = src.RasterYSize
            CloudWaterShadowMaskArray = src.GetRasterBand(1).ReadAsArray()
            CloudWaterShadowMaskNoDataValue = src.GetRasterBand(1).GetNoDataValue()
            #print("CloudWaterShadowMaskNoDataValue=",CloudWaterShadowMaskNoDataValue)

            #print(time.time())
            Kid = 0
            LastCoefficient = 0
            LastMyRasterArray = np.full((Rows, Cols), F3NoDataValue)
            for k in InputTifList:
                Kid = Kid + 1
                MyRaster = gdal.Open(k)
                MyRasterArray = MyRaster.GetRasterBand(1).ReadAsArray()
                MyRasterArrayNoDataValue = MyRaster.GetRasterBand(1).GetNoDataValue()
                MyRasterArray = ma.masked_values(MyRasterArray, MyRasterArrayNoDataValue)
                MyRasterArray[CloudWaterShadowMaskArray == CloudWaterShadowMaskNoDataValue] = F3NoDataValue
                MyRasterArray = ma.masked_values(MyRasterArray, F3NoDataValue)
                MyRasterArray = np.add(lastMyRasterArray * pow(10,LastCoefficient), MyRasterArray)
                LastMyRasterArrayMax = np.nanmax(LastMyRasterArray)
                LastCoefficient = int(math.log10(LastMyRasterArrayMax)) + 1
                LastMyRasterArray = MyRasterArray.copy()
                
            Final2D = lastMyRasterArray.copy()    
            Final2D[CloudWaterShadowMaskArray == CloudWaterShadowMaskNoDataValue] = F3NoDataValue  #added on 20220908

            #Added on 20230201 to change the output datatype---start
            Final2D = ma.masked_values(Final2D, F3NoDataValue)
            Final2DMin = np.nanmin(Final2D)
            Final2DMax = np.nanmax(Final2D)
            TypeOfInterest = OutputDataType(Final2DMin, Final2DMax)
            #Added on 20230201 to change the output datatype---end

            driver = gdal.GetDriverByName("GTiff")
            if OutputGeoTifCompression == "Yes": #Added on 20230227. LZW compression does not lose information. LZW compression is a lossless data compression algorithm, which means that the original data can be fully reconstructed from the compressed data without any loss of information.
                outdata = driver.Create(OutFile, Cols, Rows, 1, TypeOfInterest, options=['COMPRESS=LZW'])   #original is gdal.GDT_Int32. see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
            if OutputGeoTifCompression == "No": 
                outdata = driver.Create(OutFile, Cols, Rows, 1, TypeOfInterest)   #original is gdal.GDT_Int32. see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
            outdata.SetGeoTransform(src.GetGeoTransform())  ##sets same geotransform as input
            outdata.SetProjection(src.GetProjection())  ##sets same projection as input
            outdata.GetRasterBand(1).WriteArray(Final2D)
            outdata.GetRasterBand(1).SetNoDataValue(F3NoDataValue) 
            outdata.FlushCache() ##saves to disk!!
            outdata = None
            #print("------Image combined from: ", InputTifList)
            #print("------The output image is: ", OutFile)
        #print("------RasterCombine is done")
        print("RasterCombine it took \t" + str(int((time.time() - t0)/60))," minutes")
        #print("------RasterCombine finished with output of ", OutFile)        
        return OutFile
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for RasterCombineToCreateFixedZoneValueFromImages with inputs of "+repr(InputTifList) + " with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog

    
def RasterCombine(CloudWaterShadowMask,InputTifList):  #InputTifList is a python list
    try:
        #print("------RasterCombine start")
        t0 = time.time()
        InputTifListNameOnly = [k.split(os.sep)[-1].replace(".tif","") for k in InputTifList]
        filename = "".join(InputTifListNameOnly)
        OutFile = os.sep.join(CloudWaterShadowMask.split(os.sep)[:-2])+os.sep+"CommonShare"+os.sep+filename+".tif"
        #print("------OutFile=",OutFile)
        if not os.path.exists(OutFile):
            src = gdal.Open(CloudWaterShadowMask)
            Cols = src.RasterXSize
            Rows = src.RasterYSize
            CloudWaterShadowMaskArray = src.GetRasterBand(1).ReadAsArray()
            CloudWaterShadowMaskNoDataValue = src.GetRasterBand(1).GetNoDataValue()
            #print("CloudWaterShadowMaskNoDataValue=",CloudWaterShadowMaskNoDataValue)

            #print(time.time())
            ListTifArray = []
            for k in InputTifList:
                #print("------k=",k)
                MyRaster = gdal.Open(k)
                klist = MyRaster.GetRasterBand(1).ReadAsArray().flatten().tolist()  
                ListTifArray.append(klist)  #here it is not [] but ()

            ##This is Kirk's approach for raster combine. It works very well, but speed is slow sometimes (maybe due to computer itself), so I may replace with with zip_longest function---start
            dLU = {t:i+1 for i, t in enumerate(set(zip(*ListTifArray)))}
            Final = np.array([dLU[T] for T in zip(*ListTifArray)]) #each pair has an Unique ID (0,1,2..... etc), and the ID will be given to the element
            ##This is Kirk's approach for raster combine. It works very well, but speed is slow sometimes (maybe due to computer itself), so I may replace with with zip_longest function---end

            ###This is Shengli's approach for raster combine. Idea comes from #https://gis.stackexchange.com/questions/59375/is-it-possible-to-use-gdal-to-combine-rather-than-mosaic-rasters---start
            #z=list(zip_longest(*ListTifArray))  #zip_longest usage, see https://www.geeksforgeeks.org/python-itertools-zip_longest/. Note here it is *ListTifArray not ListTifArray, see #https://www.geeksforgeeks.org/args-kwargs-python/#:~:text=What%20is%20Python%20%2Aargs%20%3F%20The%20special%20syntax,to%20pass%20a%20non-key%20worded%2C%20variable-length%20argument%20list.
            #zUnique = list(set(z))
            #FinalList =[zUnique.index(k) for k in z]
            #Final =np.array(FinalList)
            ##Final =np.array([list(set(z)).index(k) for k in z])  #combined from: zUnique = list(set(z)); FinalList =[zUnique.index(k) for k in z]; Final =np.array(FinalList). But this is super slow as of 20220912.
            #print("still under test as  of 20220911, and Final shape is ", Final.shape, " and at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
            ###This is Shengli's approach for raster combine. Idea comes from #https://gis.stackexchange.com/questions/59375/is-it-possible-to-use-gdal-to-combine-rather-than-mosaic-rasters---end
     
            Final2D = Final.reshape((Rows, Cols))
            Final2D[CloudWaterShadowMaskArray == CloudWaterShadowMaskNoDataValue] = F3NoDataValue  #added on 20220908

            #Added on 20230201 to change the output datatype---start
            Final2D = ma.masked_values(Final2D, F3NoDataValue)
            Final2DMin = np.nanmin(Final2D)
            Final2DMax = np.nanmax(Final2D)
            TypeOfInterest = OutputDataType(Final2DMin, Final2DMax)
            #Added on 20230201 to change the output datatype---end

            driver = gdal.GetDriverByName("GTiff")
            if OutputGeoTifCompression == "Yes": #Added on 20230227. LZW compression does not lose information. LZW compression is a lossless data compression algorithm, which means that the original data can be fully reconstructed from the compressed data without any loss of information.
                outdata = driver.Create(OutFile, Cols, Rows, 1, TypeOfInterest, options=['COMPRESS=LZW'])   #original is gdal.GDT_Int32. see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
            if OutputGeoTifCompression == "No": 
                outdata = driver.Create(OutFile, Cols, Rows, 1, TypeOfInterest)   #original is gdal.GDT_Int32. see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
            outdata.SetGeoTransform(src.GetGeoTransform())  ##sets same geotransform as input
            outdata.SetProjection(src.GetProjection())  ##sets same projection as input
            outdata.GetRasterBand(1).WriteArray(Final2D)
            outdata.GetRasterBand(1).SetNoDataValue(F3NoDataValue) 
            outdata.FlushCache() ##saves to disk!!
            outdata = None
            #print("------Image combined from: ", InputTifList)
            #print("------The output image is: ", OutFile)
        #print("------RasterCombine is done")
        print("RasterCombine it took \t" + str(int((time.time() - t0)/60))," minutes")
        #print("------RasterCombine finished with output of ", OutFile)        
        return OutFile
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for RasterCombine with inputs of " + repr(CloudWaterShadowMask)+","+repr(InputTifList) + " with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog


def CreateBaseLineFileList():
    try:
        #Here, we 1) Generate a txt file using os.glob to list all required files for future run; 2)add read only permission for these files 
        #There are consideration of OS and 0o etc when changing file permission, see  https://stackoverflow.com/questions/16249440/changing-file-permission-in-python
        #Although Windows supports chmod(), you can only set the file’s read-only flag with it. All other bits are ignored. See https://stackoverflow.com/questions/15607903/python-module-os-chmodfile-664-does-not-change-the-permission-to-rw-rw-r-bu    
        #os.chmod(FieldMetricFinal1FileInGCPxPath, 0o444)  #Note 0o444 is read permission while 0o777 is full permission, https://stackoverflow.com/questions/15607903/python-module-os-chmodfile-664-does-not-change-the-permission-to-rw-rw-r-bu; https://www.geeksforgeeks.org/python-os-chmod-method/; http://www.w3big.com/python/os-chmod.html
        F3BaseLine = os.getcwd()+os.sep+"BaseLineFiles.txt"
        if not os.path.exists(F3BaseLine):
            CurrentTimeInFloat = time.time()
            F3BaseLineFile = open(F3BaseLine, 'w')
            F3BaseLineHead1 = "#This file was created by Dr. Shengli Huang with the F3 python code version of " + sys.argv[0] + " at " + datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
            F3BaseLineHead2 = "#The file lists all the essential files that are created during Baseline run, which is based on BaseManagement, BaseYear, and BaseMetric" + "\n"
            F3BaseLineHead3 = "#The purpose is to give a reference for future runs in case the run has to be done separatelly or the data have been moved" + "\n"
            F3BaseLineHead4 = "#These reference files were create for Managements = " + ",".join(Managements) + "\n"
            F3BaseLineHead5 = "#These reference files were create for Years = " + ",".join(Years) + "\n"
            F3BaseLineHead6 = "#These reference files were create for Metrics = " + ",".join(Metrics) + "\n"
            F3BaseLineFile.write(F3BaseLineHead1 + F3BaseLineHead2 + F3BaseLineHead3 + F3BaseLineHead4 + F3BaseLineHead5 + F3BaseLineHead6)

            #AllFilesRun1 = glob.glob(os.getcwd()+os.sep+"Run1"+os.sep+'*', recursive = True)
            AllFilesRun1 = glob.glob(os.getcwd() + os.sep + "Run1" + os.sep + '**' + os.sep + '*', recursive=True)  #refer to glob.glob('d:/temp/**/*', recursive=True), see https://stackoverflow.com/questions/14798220/how-can-i-search-sub-folders-using-glob-glob-module
            AllFilesRun2 = glob.glob(os.getcwd() + os.sep + "Run2" + os.sep + '**' + os.sep + '*', recursive=True)  #refer to glob.glob('d:/temp/**/*', recursive=True), see https://stackoverflow.com/questions/14798220/how-can-i-search-sub-folders-using-glob-glob-module
            AllFilesRun3 = glob.glob(os.getcwd() + os.sep + "Run3" + os.sep + '**' + os.sep + '*', recursive=True)  #refer to glob.glob('d:/temp/**/*', recursive=True), see https://stackoverflow.com/questions/14798220/how-can-i-search-sub-folders-using-glob-glob-module
            AllFilesTilesMosaicRunAverage = glob.glob(os.getcwd() + os.sep + "TilesMosaicRunAverage" + os.sep + '**' + os.sep + '*', recursive=True)  #refer to glob.glob('d:/temp/**/*', recursive=True), see https://stackoverflow.com/questions/14798220/how-can-i-search-sub-folders-using-glob-glob-module
            AllFiles = AllFilesRun1 + AllFilesRun2 + AllFilesRun3 + AllFilesTilesMosaicRunAverage
            print("The length of AllFiles with folder and files is ",len(AllFiles))
            AllFiles = [f for f in AllFiles if os.path.isfile(f)]  #This will filter out the path and only keep files
            print("The length of AllFiles with only files is ",len(AllFiles))            
            MetricsExceptBaseMetrics = [k for k in Metrics if k != BaseMetric]
            for OneFile in AllFiles:
                print("OneFile=",OneFile)
                for MetricsExceptBaseMetric in MetricsExceptBaseMetrics:
                    if MetricsExceptBaseMetric in OneFile:
                        print("The file of ", OneFile, " is not considered a baseline file")
                        AllFiles.remove(OneFile)
            TotalSizeInMgbyte = 0
            NumberOfBaseLineFile = 0
            for OneFile in AllFiles:
                NumberOfBaseLineFile = NumberOfBaseLineFile + 1
                print("The file of ", OneFile, " is considered a baseline file because it was created during BaseManagement, BaseYear, and BaseMetric run")
                os.chmod(OneFile, 0o444)
                OneFileSizeInMgbyte = os.path.getsize(OneFile) / 1000000 #https://www.geeksforgeeks.org/how-to-get-file-size-in-python/
                TotalSizeInMgbyte = TotalSizeInMgbyte + OneFileSizeInMgbyte
                OneFileCreatedTimeInFloat = os.path.getctime(OneFile)  #https://www.geeksforgeeks.org/how-to-get-file-creation-and-modification-date-or-time-in-python/
                OneFileCreatedTimeInDate = time.ctime(OneFileCreatedTimeInFloat)
                if OneFileCreatedTimeInFloat <= CurrentTimeInFloat: 
                    OneFileLine = str(NumberOfBaseLineFile) + ": " + OneFile + ", with size of " + str(OneFileSizeInMgbyte) + " Mg, which was created at " + str(OneFileCreatedTimeInDate) + " and its float format since EPOCH is " + str(OneFileCreatedTimeInFloat) +  ", earlier than CurrentTimeInFloat of " + str(CurrentTimeInFloat) + " (Great!)" + "\n"
                if OneFileCreatedTimeInFloat > CurrentTimeInFloat: 
                    OneFileLine = str(NumberOfBaseLineFile) + ": " + OneFile + ", with size of " + str(OneFileSizeInMgbyte) + " Mg, which was created at " + str(OneFileCreatedTimeInDate) + " and its float format since EPOCH is " + str(OneFileCreatedTimeInFloat) +  ", later than CurrentTimeInFloat of " + str(CurrentTimeInFloat) + " (Suspicious!)" + "\n"
                F3BaseLineFile.write(OneFileLine)
            F3BaseLineFile.write("#The total size of all the baseline files is " + str(TotalSizeInMgbyte) + " Mg (i.e."+ str(TotalSizeInMgbyte/1000) +" G!)")
            F3BaseLineFile.close()
        return F3BaseLine
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for CreateBaseLineFileList with inputs of " + repr(CloudWaterShadowMask)+","+repr(InputTifList) + " with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog




def ManualRemovePlotYear(ManualRemovePlotYearList):
    try:
        if os.path.exists(ManualRemovePlotYearList):
           DropPlotAndInventoryYearTxtFile = open(ManualRemovePlotYearList, 'r')
           DropPlotAndInventoryYearTxtRecord = DropPlotAndInventoryYearTxtFile.readlines()
           DropPlotAndInventoryYearTxtRecord = [i.replace('\n','') for i in DropPlotAndInventoryYearTxtRecord]
           DropPlotAndInventoryYearTxtFile.close()
        else:
           DropPlotAndInventoryYearTxtRecord = []
        return DropPlotAndInventoryYearTxtRecord   #note each element in this list is like "78802&2016"
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for ManualRemovePlotYear with inputs of " + repr(ManualRemovePlotYearList) + " with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog

    

def ModifyDBtoIncludeTifRowColumn(Run,Tile,Management,Year,Metric):
    try:
        ShengliHuangKeyFile = HSLpath + os.sep + Tile + ".hsl"  #20240212 added
        if Metric == BaseMetric:
            #print("------CreateMetricArray start")
            CloudWaterShadowMask = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"RSraster"+os.sep+"CloudShadowWaterSnow.tif"
            src = rasterio.open(CloudWaterShadowMask)
            srcCols = src.width
            srcRows = src.height
            srcextent = src.bounds
            #print("------srcCols,srcRows=",srcCols,srcRows)
            #print("------srcextent=",srcextent)  #BoundingBox(left=358485.0, bottom=4028985.0, right=590415.0, top=4265115.0), https://gis.stackexchange.com/questions/104362/how-to-get-extent-out-of-geotiff
               
            #print("------Let us prepare the input parameters for Plot--start")
            ShengliHuangKeyFile = DecryptFile(ShengliHuangKeyFile)  #20230206 added to decrypt the input file
            plotlist,xlist,ylist,StatesCodeInThisHSL,StatesFullNameInThisHSL,StatesShortNameInThisHSL,SpeciesTranslatorInThisHSL = PlotIDandXandY(ShengliHuangKeyFile,Factor)  #20240125: plotlist is integer (from round function), xlist is float,and ylist is flaot too
            FieldSqlite = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"FieldPoint"+os.sep+FieldPointHeader+Management+"_"+Year+".db"
            FieldSqliteOriginalCopy = FieldSqlite.replace(".db","_OriginalCopy.db")
            shutil.copy(FieldSqlite, FieldSqliteOriginalCopy)
            
            conn = sqlite3.connect(FieldSqlite)  #https://www.sqlitetutorial.net/sqlite-python/
            cur= conn.cursor()
            cur.execute("SELECT * FROM FVS_Compute")  #Ask Marcus to give the table name consistently
            columns = [column[0].lower() for column in cur.description]
            #print(columns)


            # Add a new column Row to Fvs_RESULTS table, see https://www.geeksforgeeks.org/how-to-alter-a-sqlite-table-using-python/
            new_RowColumn = "ALTER TABLE FVS_Compute ADD COLUMN TifRow INTEGER"  #Column type, see see https://stackoverflow.com/questions/69152237/get-column-type-of-returned-row-in-python-sqlite3
            cur.execute(new_RowColumn)
            # Add a new column Column to Fvs_RESULTS table
            new_ColumnColumn = "ALTER TABLE FVS_Compute ADD TifCOLUMN Column INTEGER"
            cur.execute(new_ColumnColumn)
            conn.commit()

            
            FIADB_PLOTIndex = columns.index("FIADB_PLOT".lower())
            if Metric not in columns:
                print("------This metric does not exist:",Metric)
            else:
                MetricIndex = columns.index(Metric)
                print("------MetricIndex=",MetricIndex)
                
            rows = cur.fetchall()
            FIADB_PLOTCode = []
            rowid = 0

            for row in rows:
                rowid = rowid + 1
                    
                FIADB_PLOT = int(row[FIADB_PLOTIndex])
                
                PlotIndexInplotlist = plotlist.index(FIADB_PLOT)
                CoordinateX = xlist[PlotIndexInplotlist]
                CoordinateY = ylist[PlotIndexInplotlist]

                rows, cols = rasterio.transform.rowcol(src.transform, CoordinateX, CoordinateY)  #https://gis.stackexchange.com/questions/299787/finding-pixel-location-in-raster-using-coordinates
                if ((rows >= 0) and (rows < srcRows) and (cols >= 0) and (cols < srcCols)):  #need more attantion if we need a -1 here or use = here
                    #print("------FIADB_PLOT,X,Y,MetricValue,rows,cols=",FIADB_PLOT,CoordinateX,CoordinateY,MetricValue,rows,cols)
                    cur.execute('UPDATE FVS_Compute SET TifRow=? WHERE FIADB_PLOT=?',[(rows, FIADB_PLOT)])  #not sure if it works, see https://stackoverflow.com/questions/60821674/how-to-update-row-by-row-using-python-function-in-sqlite3
                    cur.execute('UPDATE FVS_Compute SET TifCOLUMN=? WHERE FIADB_PLOT=?',[(cols, FIADB_PLOT)])
                else:
                    cur.execute('DELETE FROM table FVS_Compute WHERE FIADB_PLOT=?',[(FIADB_PLOT)])  #delete this record
                conn.commit()
            DeleteColumnFIADB_PLOT = "Yes"
            if DeleteColumnFIADB_PLOT == "Yes":
                cur.execute('ALTER TABLE FVS_Compute DROP COLUMN FIADB_PLOT')
                conn.commit()
            conn.close()
            return FieldSqlite
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for ModifyDBtoIncludeTifRowColumn with inputs of "+repr(Run)+","+repr(Tile)+","+repr(Management)+","+repr(Year)+","+repr(Metric)+" with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog
    

def CreateRGBimage(RGBInThisOrder):  #https://gis.stackexchange.com/questions/223910/using-rasterio-or-gdal-to-stack-multiple-bands-without-using-subprocess-commands
    try:
        print("RGBInThisOrder=",RGBInThisOrder)
        RGBfile = RGBInThisOrder[0].replace(RGBInThisOrder[0].split(os.sep)[-1].split("_")[-1],"RGB.tif")
        if not os.path.exists(RGBfile):
            #print("RGBfile=",RGBfile)
            RGBInThisOrderChange = [RGBInThisOrder[0],RGBInThisOrder[1],RGBInThisOrder[2]]
            array_list = []
            # Read arrays
            for file in RGBInThisOrderChange:
                #print("file=",file)
                src = gdal.Open(file)
                geotransform = src.GetGeoTransform() # Could be done more elegantly outside the for loop
                projection = src.GetProjectionRef()
                band = src.GetRasterBand(1).ReadAsArray()
                bandNoDataValue = src.GetRasterBand(1).GetNoDataValue()
                band = ma.masked_values(band, bandNoDataValue)
                MinimumBoundValue = max(band.mean()-band.std(),band.min())
                MaximumBoundValue = min(band.mean()+band.std(),band.max())
                #print("Below we use multiple where to do : if >max, 255; if < min, 0; else interploted from 0 to 255")
                band = np.where(band >= MaximumBoundValue, MaximumBoundValue, np.where(band <= MinimumBoundValue, 0, 255.0*(band-MinimumBoundValue)*1.0/(MaximumBoundValue-MinimumBoundValue)))
                band = band.astype(int)   #convert to unsigned 8 bit integer
                array_list.append(band)
                src = None
            # Stack arrays
            stacked_array = np.stack(array_list, axis=0)
            array_list = None
            # Write to disk
            driver = gdal.GetDriverByName('GTiff')
            n, rows, cols = stacked_array.shape
            if OutputGeoTifCompression == "Yes": #Added on 20230227. LZW compression does not lose information. LZW compression is a lossless data compression algorithm, which means that the original data can be fully reconstructed from the compressed data without any loss of information.
                dataset = driver.Create(RGBfile, cols, rows, n, gdal.GDT_Byte, options=['COMPRESS=LZW'])
            if OutputGeoTifCompression == "No": 
                dataset = driver.Create(RGBfile, cols, rows, n, gdal.GDT_Byte)
            dataset.SetGeoTransform(geotransform)
            dataset.SetProjection(projection)
            for b in range(1,n+1):
                band = dataset.GetRasterBand(b) # GetRasterBand is not zero indexed
                band.WriteArray(stacked_array[b-1]) # Numpy is zero indexed
            dataset = None
            stacked_array = None
            print("We create the RGB file of ", RGBfile)
        return RGBfile
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for CreateRGBimage with inputs of " + repr(RGBInThisOrder) + " with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog


def PlotIDFuzzyBufferArrayFunction(Tiles, MosaicArrayFinalFile, PlotFuzzyDistance, ResampledTargetResolution,Metric):  #PlotFuzzyDistance in meters, it is 1 mile (e.g., 1600 m) for ACCEL; ResampledTargetResolution is also in meter, for ACCEL, it is 300 
    #To prevent end users from using reverse-engineering technology to get the confientail FIA plot location, within the fuzzy area, we reduce the resolution and also adjust the values
    try:
        MosaicArrayFinalFileMixResolution = MosaicArrayFinalFile.replace(".tif","_MixResolution.tif")
        print(MosaicArrayFinalFileMixResolution," exists?")
        if not os.path.exists(MosaicArrayFinalFileMixResolution):   #added on 20240412 to avoid duplication if the file exists
            print(MosaicArrayFinalFileMixResolution," does not exist yet!")
            ShengliHuangKeyFiles = [HSLpath+os.sep+Tile+".hsl" for Tile in Tiles]  #20240223 added 
            FinalMetricArray = ReadTifToArray(MosaicArrayFinalFile)
            FinalMetricArray = ma.masked_values(FinalMetricArray, F3NoDataValue)
            FinalMetricArrayMin = np.nanmin(FinalMetricArray)   
            print("FinalMetricArray shape[0] is ", FinalMetricArray.shape[0], file=open(F3Log, 'a'))

            src = rasterio.open(MosaicArrayFinalFile)
            InputTifRaster = gdal.Open(MosaicArrayFinalFile)
            WeUseThisProjection = InputTifRaster.GetProjectionRef()
            WeUseThisGeoTransform = InputTifRaster.GetGeoTransform()
            band = InputTifRaster.GetRasterBand(1)
            DataType = band.DataType
            srcCols = InputTifRaster.RasterXSize
            srcRows = InputTifRaster.RasterYSize
            upx, xres, xskew, upy, yskew, yres = InputTifRaster.GetGeoTransform()  #https://gis4programmers.wordpress.com/2017/01/06/using-gdal-to-get-raster-extent/, note GetGeoTransform not GetGeotransform
            ulx = float(upx + 0*xres + 0*xskew)
            uly = float(upy + 0*yskew + 0*yres)
            llx = float(upx + 0*xres + srcRows*xskew)
            lly = float(upy + 0*yskew + srcRows*yres)
            lrx = float(upx + srcCols*xres + srcRows*xskew)
            lry = float(upy + srcCols*yskew + srcRows*yres)
            urx = float(upx + srcCols*xres + 0*xskew)
            ury = float(upy + srcCols*yskew + 0*yres)

            PlotIDFuzzyBufferTif = MosaicArrayFinalFile.replace(MosaicArrayFinalFile.split(os.sep)[-1],"PlotIDFuzzyBuffer.tif")
            if os.path.exists(PlotIDFuzzyBufferTif):
                PlotIDFuzzyBufferArray = ReadTifToArray(PlotIDFuzzyBufferTif).astype('int32')
            if not os.path.exists(PlotIDFuzzyBufferTif):
                PlotFuzzyPixelSize = int(PlotFuzzyDistance / F3Resolution)            
                PlotIDFuzzyBufferArray = np.full((srcRows, srcCols), F3NoDataValue)            

                for ShengliHuangKeyFile in ShengliHuangKeyFiles:
                    plotlist,xlist,ylist,StatesCodeInThisHSL,StatesFullNameInThisHSL,StatesShortNameInThisHSL,SpeciesTranslatorInThisHSL = PlotIDandXandY(ShengliHuangKeyFile,Factor)  #20240125: plotlist is integer (from round function), xlist is float,and ylist is flaot too
                    for k in range(0,len(plotlist),1):
                        x = xlist[k]
                        y = ylist[k]
                        if ((x>=llx) and (x<=lrx) and (y>=lly) and (y<=uly)):  
                            rows, cols = rasterio.transform.rowcol(src.transform, x, y)  #https://gis.stackexchange.com/questions/299787/finding-pixel-location-in-raster-using-coordinates
                            if ((rows >= 0) and (rows < srcRows) and (cols >= 0) and (cols < srcCols)):
                                bufferRowsStart = min(max(0, rows - PlotFuzzyPixelSize), srcRows)
                                bufferRowsEnd = min(max(0, rows + PlotFuzzyPixelSize), srcRows)
                                bufferColsStart = min(max(0, cols - PlotFuzzyPixelSize), srcCols)
                                bufferColsEnd = min(max(0, cols + PlotFuzzyPixelSize), srcCols)
                                for i in range(bufferRowsStart,bufferRowsEnd,1):
                                    for j in range(bufferColsStart,bufferColsEnd,1):
                                        DistanceToCenter = math.sqrt((i-rows)*(i-rows) + (j-cols)*(j-cols))
                                        if DistanceToCenter >= 1.0 * PlotFuzzyPixelSize:  #outside of 1.0 radius circle area
                                           PlotIDFuzzyBufferArray[i,j] = F3NoDataValue 
                                        elif DistanceToCenter <= 0.8 * PlotFuzzyPixelSize: #inside of 0.8 radius
                                           PlotIDFuzzyBufferArray[i,j] = 1
                                        else:  #between 0.8 and 1.0 radius area
                                           PlotIDFuzzyBufferArray[i,j] = random.choice([1,F3NoDataValue])
                
                driver = gdal.GetDriverByName("GTiff")
                if OutputGeoTifCompression == "Yes": #Added on 20230227. LZW compression does not lose information. LZW compression is a lossless data compression algorithm, which means that the original data can be fully reconstructed from the compressed data without any loss of information.
                    outdata = driver.Create(PlotIDFuzzyBufferTif, srcCols, srcRows, 1, gdal.GDT_Int32, options=['COMPRESS=LZW'])   #see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
                if OutputGeoTifCompression == "No": 
                    outdata = driver.Create(PlotIDFuzzyBufferTif, srcCols, srcRows, 1, gdal.GDT_Int32)   #see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
                print("SetGeoTransform and SetProjection usage, see http://www2.geog.ucl.ac.uk/~plewis/geogg122_local/geogg122-old/Chapter4_GDAL/GDAL_Python_bindings.html")
                outdata.SetGeoTransform(WeUseThisGeoTransform)  
                outdata.SetProjection(WeUseThisProjection)
                outdata.GetRasterBand(1).WriteArray(PlotIDFuzzyBufferArray)
                outdata.GetRasterBand(1).SetNoDataValue(F3NoDataValue)   
                outdata.FlushCache()  
                outdata = None
                print("PlotIDFuzzyBufferTif was created at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"), file=open(F3Log, 'a'))

                           
            print("PlotIDFuzzyBufferArray shape[0] is ", PlotIDFuzzyBufferArray.shape[0], file=open(F3Log, 'a'))
            print("FinalMetricArray shape[0] is ", FinalMetricArray.shape[0], file=open(F3Log, 'a'))
            print("FinalMetricArray shape[1] is ", FinalMetricArray.shape[1], file=open(F3Log, 'a'))
            #Added on 20230417 to get the data at 300m resolution within fuzzy plot 1 mile area but keep 30m in the remainign area---start
            ResampledInterval = int(ResampledTargetResolution / F3Resolution)
            
            FinalMetricArrayCopy = FinalMetricArray.copy()   #https://stackoverflow.com/questions/16096753/python-array-slicing-how-can-2d-array-slicing-be-implemented
            FinalMetricArrayResampled = FinalMetricArray.copy()
            NewFinalMetricArrayResampled = FinalMetricArrayCopy[::ResampledInterval,::ResampledInterval]  #[::ResampledInterval,::ResampledInterval] is wrong
            print("NewFinalMetricArrayResampled.shape=",NewFinalMetricArrayResampled.shape,file=open(F3Log, 'a'))
            for i in range(0, NewFinalMetricArrayResampled.shape[0],1):     #shape[0] is the number of rows while shape[0] is the number of columns
                for j in range(0, NewFinalMetricArrayResampled.shape[1],1):
                    istart = i*ResampledInterval
                    iend = i*ResampledInterval+ResampledInterval
                    jstart = j*ResampledInterval
                    jend = j*ResampledInterval+ResampledInterval
                    LocalWindowArray = FinalMetricArrayCopy[istart:iend:1,jstart:jend:1]
                    print("As of 20240530, I need to talk with Frank about how to resample for the best result of species distribution. Do we really need to set up the minimum value pixels as Nodata?")
                    if ((NewFinalMetricArrayResampled[i,j] != F3NoDataValue) or (NewFinalMetricArrayResampled[i,j] == FinalMetricArrayMin)):
                        print("added on 20240530 to make sure the Nodata pixel (e.g., nonforest area) or MinValue pixel (e.g., species is zero or CanopyBaseHeight=-1) will keep their original values") 
                        print("Do we need to remove those small isolated pixels? because I found any sinle pixel in the LocalWindowArray has influence on the distribution. I will talk to Frank in the future. Also need to think Gap continuous and CanopyBaseHeight  -1 value. They cannot be directly mean")
                        if Metric in DiscreteMetrics:  #20240530 added for discrete calculation
                            #ModeValue = mode(LocalWindowArray,nan_policy='omit',axis=None).mode[0]   #ModeValue = mode(LocalWindowArray,nan_policy='omit').mode[0] will the mode values for each column in the 2D array. axis=None will give the overall mode value
                            ModeValue = mode(LocalWindowArray,nan_policy='omit',axis=None).mode  #The above mode[0] has an error [IndexError: invalid index to scalar variable], but mode works here
                            FinalMetricArrayResampled[istart:iend:1,jstart:jend:1] = ModeValue   
                            NewFinalMetricArrayResampled[i,j] = ModeValue   
                        if Metric in ContinuousMetrics:
                            if ma.count(LocalWindowArray) > 0:  #https://numpy.org/doc/stable/reference/routines.ma.html, you can get many to use masked arrays
                                WindowMean = np.nanmean(LocalWindowArray)
                            if ma.count(LocalWindowArray) == 0:  #ma.count() Counts the non-masked elements of the array along the given axis
                                WindowMean = F3NoDataValue
                            ResampleInLocalWindowArray = "WindowMean"  #Options are WindowMean or RandomMean
                            if ResampleInLocalWindowArray == "WindowMean":
                                FinalMetricArrayResampled[istart:iend:1,jstart:jend:1] = WindowMean
                                NewFinalMetricArrayResampled[i,j] = WindowMean  
                            if ResampleInLocalWindowArray == "RandomMean":
                                for m in range(istart,iend,1):
                                    for n in range(jstart,jend,1):
                                        if ((m < FinalMetricArrayResampled.shape[0]-1) and (n < FinalMetricArrayResampled.shape[1]-1)):
                                            #print("m,n=",m,n,file=open(F3Log, 'a'))
                                            FinalMetricArrayResampled[m,n] = WindowMean * np.random.randint(90, 110) / 100.0  #To keep the variation, the value is randomly assigned as 0.7~1.2 times of the mean
                                            NewFinalMetricArrayResampled[i,j] = WindowMean * np.random.randint(90, 110) / 100.0 
            FinalMetricArrayResampled[FinalMetricArray.mask] = F3NoDataValue
            NewFinalMetricArrayResampledSave = "Yes" #Options are "Yes" or "No"
            if NewFinalMetricArrayResampledSave == "Yes":
                NewFinalMetricArrayResampledHuang = MosaicArrayFinalFile.replace(".tif","_Resampled"+str(int(ResampledTargetResolution))+".tif")
                driver = gdal.GetDriverByName("GTiff")
                if OutputGeoTifCompression == "Yes": #Added on 20230227. LZW compression does not lose information. LZW compression is a lossless data compression algorithm, which means that the original data can be fully reconstructed from the compressed data without any loss of information.
                    outdata = driver.Create(NewFinalMetricArrayResampledHuang, NewFinalMetricArrayResampled.shape[1], NewFinalMetricArrayResampled.shape[0], 1, gdal.GDT_Int32, options=['COMPRESS=LZW'])   #see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
                if OutputGeoTifCompression == "No":    #FinalMetricArrayResampledTemp.shape[1], FinalMetricArrayResampledTemp.shape[0] is cols and rows
                    outdata = driver.Create(NewFinalMetricArrayResampledHuang, NewFinalMetricArrayResampled.shape[1], NewFinalMetricArrayResampled.shape[0], 1, gdal.GDT_Int32)   #see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
                print("SetGeoTransform and SetProjection usage, see http://www2.geog.ucl.ac.uk/~plewis/geogg122_local/geogg122-old/Chapter4_GDAL/GDAL_Python_bindings.html")
                NewGeoTransform = [WeUseThisGeoTransform[0],WeUseThisGeoTransform[1]*ResampledInterval,WeUseThisGeoTransform[2],WeUseThisGeoTransform[3],WeUseThisGeoTransform[4],WeUseThisGeoTransform[5]*ResampledInterval]  #added in 20230623
                print(NewGeoTransform)  #This will have a new resolution 
                outdata.SetGeoTransform(NewGeoTransform)  
                outdata.SetProjection(WeUseThisProjection)
                outdata.GetRasterBand(1).WriteArray(NewFinalMetricArrayResampled)
                outdata.GetRasterBand(1).SetNoDataValue(F3NoDataValue)   
                outdata.FlushCache()  
                outdata = None
                if ((Metric.lower() == "fortyp") or (Metric.lower() == "fortype")):  #added on 20240604
                    ForestTypeGeoTifMessage = AddingRasterAttributeTableToForestTypeGeoTif(NewFinalMetricArrayResampledHuang)
            FinalMetricArrayCopy[PlotIDFuzzyBufferArray==1] = FinalMetricArrayResampled[PlotIDFuzzyBufferArray==1]
            MosaicArrayFinalFileMixResolution = MosaicArrayFinalFile.replace(".tif","_MixResolution.tif")
            driver = gdal.GetDriverByName("GTiff")
            if OutputGeoTifCompression == "Yes": #Added on 20230227. LZW compression does not lose information. LZW compression is a lossless data compression algorithm, which means that the original data can be fully reconstructed from the compressed data without any loss of information.
                outdata = driver.Create(MosaicArrayFinalFileMixResolution, srcCols, srcRows, 1, gdal.GDT_Int32, options=['COMPRESS=LZW'])   #see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
            if OutputGeoTifCompression == "No": 
                outdata = driver.Create(MosaicArrayFinalFileMixResolution, srcCols, srcRows, 1, gdal.GDT_Int32)   #see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
            print("SetGeoTransform and SetProjection usage, see http://www2.geog.ucl.ac.uk/~plewis/geogg122_local/geogg122-old/Chapter4_GDAL/GDAL_Python_bindings.html")
            outdata.SetGeoTransform(WeUseThisGeoTransform)  
            outdata.SetProjection(WeUseThisProjection)
            outdata.GetRasterBand(1).WriteArray(FinalMetricArrayCopy)
            outdata.GetRasterBand(1).SetNoDataValue(F3NoDataValue)   
            outdata.FlushCache()  
            outdata = None
            if ((Metric.lower() == "fortyp") or (Metric.lower() == "fortype")):  #added on 20240604
                ForestTypeGeoTifMessage = AddingRasterAttributeTableToForestTypeGeoTif(MosaicArrayFinalFileMixResolution)
            print("MosaicArrayFinalFileMixResolution was created at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"), file=open(F3Log, 'a'))
        return MosaicArrayFinalFileMixResolution
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')  
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for PlotIDFuzzyBufferArrayFunction with inputs of "+repr(Tiles)+","+repr(MosaicArrayFinalFile)+","+repr(PlotFuzzyDistance)+","+repr(ResampledTargetResolution)+","+repr(Metric)+" with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog



def MinAndCutThreshValue(Run,Tile,Management,Year,Metric):
    try:
        FieldSqlite = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"FieldPoint"+os.sep+FieldPointHeader+Management+"_"+Year+".db"
        FieldMetricPercentileTxt = FieldSqlite.replace(".db", "_"+Metric+"Percentile.txt") 
        FieldMetricPercentileTxtFile = open(FieldMetricPercentileTxt, 'r')
        FieldMetricPercentileTxtLines = FieldMetricPercentileTxtFile.readlines()   #readlines() not readline()
        FieldMetricPercentileTxtLines = [i.replace('\n','') for i in FieldMetricPercentileTxtLines]
        print("FieldMetricPercentileTxtLines[4]=",FieldMetricPercentileTxtLines[4])
        MetricMinValue = float(FieldMetricPercentileTxtLines[4].split(",")[0])  #The first column of the 5th line is the Metric Min Value
        HalfOfCutthresholdMinusMin = float(FieldMetricPercentileTxtLines[4].split(",")[1])   #The second column of the 5th line is the HalfOfCutthresholdMinusMin
        Cutthreshold = float(FieldMetricPercentileTxtLines[4].split(",")[2])  #The third column of the 5th line is the Cutthreshold
        MetricMaxValue = float(FieldMetricPercentileTxtLines[4].split(",")[3])
        FieldMetricPercentileTxtFile.close()
        #print(">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>The MetricMinValue is ", MetricMinValue)
        #print(">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>The CutThreshValue is ", CutThreshValue)
        return MetricMinValue, HalfOfCutthresholdMinusMin, Cutthreshold, MetricMaxValue
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for CutThreshValue with inputs of "+repr(Run)+","+repr(Tile)+","+repr(Management)+","+repr(Year)+","+repr(Metric)+" with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog

def MetricMinMaxPercentile(Run,Tile,Management,Year,Metric,FloatToIntegerCoefficient):
    try:
        ShengliHuangKeyFile = HSLpath + os.sep + Tile + ".hsl"  #20240212 added
        FieldSqlite = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"FieldPoint"+os.sep+FieldPointHeader+Management+"_"+Year+".db"
        FieldMetricMinMaxTxt = FieldSqlite.replace(".db", "_"+Metric+"MinMax.txt")
        if os.path.exists(FieldMetricMinMaxTxt):
            MetricMin,MetricMax = MetricMinAndMax(Run,Tile,Management,Year,Metric)
        else:        
            DropPlotAndInventoryYearTxtRecord = ManualRemovePlotYear(ManualRemovePlotYearList) #20230315 added to manually remove those plots that we know bad
            print("MMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMM------CreateMetricArray start")
            CloudWaterShadowMask = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"RSraster"+os.sep+"CloudShadowWaterSnow.tif"
            src = rasterio.open(CloudWaterShadowMask)
            srcCols = src.width
            srcRows = src.height
            srcextent = src.bounds    
            gdalDS = gdal.Open(CloudWaterShadowMask)
            upx, xres, xskew, upy, yskew, yres = gdalDS.GetGeoTransform()  #https://gis4programmers.wordpress.com/2017/01/06/using-gdal-to-get-raster-extent/, note GetGeoTransform not GetGeotransform
            ulx = float(upx + 0*xres + 0*xskew)
            uly = float(upy + 0*yskew + 0*yres)
            llx = float(upx + 0*xres + srcRows*xskew)
            lly = float(upy + 0*yskew + srcRows*yres)
            lrx = float(upx + srcCols*xres + srcRows*xskew)
            lry = float(upy + srcCols*yskew + srcRows*yres)
            urx = float(upx + srcCols*xres + 0*xskew)
            ury = float(upy + srcCols*yskew + 0*yres)        
                       
            #print("------Let us prepare the input parameters for Plot--start")
            plotlist,xlist,ylist,StatesCodeInThisHSL,StatesFullNameInThisHSL,StatesShortNameInThisHSL,SpeciesTranslatorInThisHSL = PlotIDandXandY(ShengliHuangKeyFile,Factor)  #20240125: plotlist is integer (from round function), xlist is float,and ylist is flaot too
            FieldSqlite = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"FieldPoint"+os.sep+FieldPointHeader+Management+"_"+Year+".db"
            conn = sqlite3.connect(FieldSqlite)  #https://www.sqlitetutorial.net/sqlite-python/
            cur= conn.cursor()
            #cur.execute("SELECT * FROM FVS_Compute")  #Ask Marcus to give the table name consistently

            #20230504: add another function to determine which table should be chosen for this metric---start
            Table = FindTheFirstTableNameWhereMetricExists(Metric,FieldSqlite)
            if Table != "NotFound":
                TableQuery = "SELECT * FROM " + Table
                cur.execute(TableQuery)  
            #20230504: add another function to determine which table should be chosen for this metric---end

            columns = [column[0].lower() for column in cur.description]
            #print(columns)

            FIADB_PLOTIndex = columns.index("FIADB_PLOT".lower())
            if Metric not in columns:
                print("------This metric does not exist:",Metric)
                return
            else:
                MetricIndex = columns.index(Metric)
                print("------MetricIndex=",MetricIndex)

            if ((Management == BaseManagement) and (Year == BaseYear)):
                FieldPlotInThisTileList = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"FieldPoint"+os.sep+Management+"_"+Year+"_"+Metric+"_FieldPlotInThisTileList.txt"
                FieldPlotInThisTileListFile = open(FieldPlotInThisTileList, 'w')
            rows = cur.fetchall()
            FIADB_PLOTCode = []
            MetricMax = -100000000000000
            MetricMin =  100000000000000
            rowid = 0
            CoordinateXlist = []
            CoordinateYlist = []
            MetricValuelist = []
            MetricValuelistForPercentileCalculation = []   #added on 20231220
            for row in rows:
                rowid = rowid + 1
                #print("rowid=",rowid)
                
                FIADB_PLOT = int(row[FIADB_PLOTIndex])
                if FIADB_PLOT in [int(k.split("&")[0]) for k in DropPlotAndInventoryYearTxtRecord]:  #20230315 added to manually remove those plots that we know bad
                    continue
                #print("FIADB_PLOT=",FIADB_PLOT)
                if row[MetricIndex] is None:  #20240214 added because We have an error at MetricValue0 = float(row[MetricIndex]): "TypeError: float() argument must be a string or a real number, not 'NoneType'
                    MetricValue0 = 0
                else:
                    MetricValue0 = float(row[MetricIndex])
                #print("MetricValue0=",MetricValue0)
                MetricValue = int(MetricValue0 * FloatToIntegerCoefficient) 
                #print("MetricValue=",MetricValue)
                
                PlotIndexInplotlist = plotlist.index(FIADB_PLOT)
                CoordinateX = xlist[PlotIndexInplotlist]
                CoordinateY = ylist[PlotIndexInplotlist]
                CoordinateXlist.append(CoordinateX)
                CoordinateYlist.append(CoordinateY)
                MetricValuelist.append(MetricValue)

                rows, cols = rasterio.transform.rowcol(src.transform, CoordinateX, CoordinateY)  #https://gis.stackexchange.com/questions/299787/finding-pixel-location-in-raster-using-coordinates
                #print("rows, cols=",rows, cols)
                if ((rows >= 0) and (rows < srcRows) and (cols >= 0) and (cols < srcCols)):  #need more attantion if we need a -1 here or use = here
                    if ((Management == BaseManagement) and (Year == BaseYear)):
                        FieldPlotInThisTileListContent = str(int(FIADB_PLOT)) + "," + str(int(rows)) + "," + str(int(cols)) + "," + str(int(MetricValue)) + "\n"
                        #print("%%%%%%%%%%%%%%%%%%%FieldPlotInThisTileListContent=",FieldPlotInThisTileListContent)
                        FieldPlotInThisTileListFile.write(FieldPlotInThisTileListContent)
                    if (MetricValue < MetricMin):  
                        MetricMin = MetricValue    
                    if (MetricValue > MetricMax):
                        MetricMax = MetricValue
                    MetricValuelistForPercentileCalculation.append(MetricValue)   #added on 20231220
            if ((Management == BaseManagement) and (Year == BaseYear)):
                FieldPlotInThisTileListFile.close()
            print("#####MetricMax,MetricMin=",MetricMax,MetricMin)

            FieldMetricMinMaxTxt = FieldSqlite.replace(".db", "_"+Metric+"MinMax.txt")   
            if not os.path.exists(FieldMetricMinMaxTxt):
                FieldMetricMinMaxTxtFile = open(FieldMetricMinMaxTxt, 'w')
                FieldMetricMinMaxTxtFile.write(str(MetricMin))
                FieldMetricMinMaxTxtFile.write(",")
                FieldMetricMinMaxTxtFile.write(str(MetricMax))
                FieldMetricMinMaxTxtFile.write("\n")
                FieldMetricMinMaxTxtFile.close()

            #FieldMetricPercentileTxt is added on 20231221 to solve the local zero-inflation problem---start
            FieldMetricPercentileTxt = FieldSqlite.replace(".db", "_"+Metric+"Percentile.txt")   #added on 20231220
            print("FieldMetricPercentileTxt=",FieldMetricPercentileTxt)
            MetricValuelistForPercentileCalculation.sort()  #Sort the items of the list in place from low to high (sse https://docs.python.org/2/tutorial/datastructures.html)
            PercentileStep = 2   #PercentileStep value should be 1,2,4 or 5, because 100 can be integerally divided by them
            PercentileMetricValueList = []
            if not os.path.exists(FieldMetricPercentileTxt):
                FieldMetricPercentileTxtFile = open(FieldMetricPercentileTxt, 'w')
                PercentileHead1 = "###Dr. Shengli Huang calculate percentile for "+ Run + " " + Tile + " "+Management + " " + str(Year) + " " + Metric + " " + str(FloatToIntegerCoefficient) + " with percentile interval of " + str(PercentileStep) + " at " + datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                FieldMetricPercentileTxtFile.write(PercentileHead1+"\n")
                PercentileHead2 = "###The first line without comment sign at the begining is percentiles"
                FieldMetricPercentileTxtFile.write(PercentileHead2+"\n")
                PercentileHead3 = "###The second line without comment sign are min, 1/2 *(Cutthreshold-min), and Cutthreshold. Rules are: a) if <1/2 *(Cutthreshold-min), then min; b) if >1/2 *(Cutthreshold-min), then Cutthreshold; c) if all three are identical, then no adjust"
                FieldMetricPercentileTxtFile.write(PercentileHead3+"\n")
                for percentile in range(0,101,PercentileStep):   
                    PercentileMetricValue = MetricValuelistForPercentileCalculation[int((len(MetricValuelistForPercentileCalculation)-1)*percentile/100.0)]
                    PercentileMetricValueList.append(PercentileMetricValue)
                if percentile != 100:  #This makes sure that last one is the maximum value
                    The100PercentileValue = MetricValuelistForPercentileCalculation[-1]
                    PercentileMetricValueList.append(The100PercentileValue)
                PercentileMetricValueListTxt = [str(k) for k in PercentileMetricValueList]
                PercentileContent = ",".join(PercentileMetricValueListTxt)
                FieldMetricPercentileTxtFile.write(PercentileContent+"\n")

                Min = MetricValuelistForPercentileCalculation[0]
                Max = MetricValuelistForPercentileCalculation[-1]
                if ("CBHT".lower() in Metric) or ("Torch_Index" in Metric) or ("Crown_Index" in Metric):  #Canopy Base Height, -1 no, and then 0 and upper. Values of –1 are printed for canopy base height, torching index and crowning index if canopy fuels are so sparse that the canopy base height is undefined
                    MinValue = int(-1 * FloatToIntegerCoefficient)
                    Cutthreshold = 0
                    HalfOfCutthresholdMinusMin = int(0.5 * MinValue)
                elif "0AND1".lower() in Metric:  #species absence 0 and presence 1 for species confidence assessment. Because all three are identical, so no adjustment
                    MinValue = 0
                    Cutthreshold = 0
                    HalfOfCutthresholdMinusMin = 0
                elif Metric in DiscreteMetrics:  #Discrete metric, including ForType. YOu can add more
                    MinValue = Min
                    Cutthreshold = MinValue
                    HalfOfCutthresholdMinusMin = MinValue
                elif "QMD".lower() in Metric:  #Gap continuous metrics such as QMD. You can add more if you have this kind of metrics.
                    MinValue = 0
                    for k in range(0,len(PercentileMetricValueList),1):
                        if PercentileMetricValueList[k] != 0:
                            GapLow = PercentileMetricValueList[k]
                            break
                    Cutthreshold = GapLow
                    HalfOfCutthresholdMinusMin = int((Cutthreshold - MinValue) * 0.5)
                else:     #Normal Continous metrics. It is mainly used for solving local zero-inflation problems 
                    MinValue = Min
                    Cutthreshold = PercentileMetricValueList[0]
                    for m in range(1,len(PercentileMetricValueList),1):  #PercentileMetricValueList is supposed to be sorted from low to high
                        if PercentileMetricValueList[m] != PercentileMetricValueList[0]:
                            if PercentileMetricValueList[m] < PercentileMetricValueList[-1]:  #20240131, we have 0,0,0,0,0,0,...,100,100,100 case, so I initilized it with CutThreshold = PercentileMetricValueList[0] and use PercentileMetricValueList[-1] (i.e., max) here
                                Cutthreshold = PercentileMetricValueList[m]
                                break
                            
                    #20240214 added. If the Cutthreshold=0, which can happen for many rare species (a tile may have 5000 plots, a 2 percentile means 100 plots!), I want to get a new Cutthreshold---start
                    if Cutthreshold == 0:
                        MetricValuelistForPercentileCalculationFromLowToHighWithoutZero = [k for k in MetricValuelistForPercentileCalculation if k > 0]
                        Cutthreshold0 = MetricValuelistForPercentileCalculationFromLowToHighWithoutZero[int(0.25*len(MetricValuelistForPercentileCalculationFromLowToHighWithoutZero))]
                        if Cutthreshold0 < Max:
                            Cutthreshold = Cutthreshold0
                    #20240214 added. If the Cutthreshold=0, which can happen for many rare species (a tile may have 5000 plots, a 2 percentile means 100 plots!), I want to get a new Cutthreshold---end

                    HalfOfCutthresholdMinusMin = int((Cutthreshold - MinValue) * 0.5)
                CutthresholdLineContent = str(MinValue)+","+str(HalfOfCutthresholdMinusMin)+","+str(Cutthreshold)+","+str(Max)
                FieldMetricPercentileTxtFile.write(CutthresholdLineContent+"\n")
                FieldMetricPercentileTxtFile.close()
            #FieldMetricPercentileTxt is added on 20231221 to solve the local zero-inflation problem---end            


        ##20240201: if max=min in this tile, then save a final tif with constant value (e.g., species absence and presence cases) and then return. Note this is different from IgnoredMetric where metric is not in the FieldSqlite.
        if (MetricMax == MetricMin): 
            MetricArray[:] = MetricMax
            FinalTifname = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"Results"+os.sep+Management+"_"+Year+"_"+Metric+".tif"
            SavedFinalTifname = Save2DArrayToTif(Run,Tile,Management,Year,Metric,MetricArray,FinalTifname)
            print(SavedFinalTifname," is a tif image with a constant value of ",MetricMax)
            MetricMinMaxPercentileMessage = "NotNecessaryToContinueComputation"
        else:
            MetricMinMaxPercentileMessage = "ValidToContinue"
        return MetricMinMaxPercentileMessage
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for MetricMinMaxPercentile with inputs of "+repr(Run)+","+repr(Tile)+","+repr(Management)+","+repr(Year)+","+repr(Metric)+","+repr(FloatToIntegerCoefficient)+" with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog


  
def CreateMetricArray(Run,Tile,Management,Year,Metric,FloatToIntegerCoefficient):
    try:
        ShengliHuangKeyFile = HSLpath + os.sep + Tile + ".hsl"  #20240212 added
        DropPlotAndInventoryYearTxtRecord = ManualRemovePlotYear(ManualRemovePlotYearList) #20230315 added to manually remove those plots that we know bad
        print("MMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMM------CreateMetricArray start")
        CloudWaterShadowMask = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"RSraster"+os.sep+"CloudShadowWaterSnow.tif"
        src = rasterio.open(CloudWaterShadowMask)
        srcCols = src.width
        srcRows = src.height
        srcextent = src.bounds    
        #print("src.shape=",src.shape)  #https://rasterio.readthedocs.io/en/latest/topics/masks.html
        #print("src.count=",src.count)
        #print("src.dtypes=",src.dtypes)
        #print("src.nodatavals=",src.nodatavals)  #This gives the nodata position (i.e. index)
        #print("src.nodata=",src.nodata)  #This gives the nodata value such as 0
        gdalDS = gdal.Open(CloudWaterShadowMask)
        gdalDSArray = gdalDS.GetRasterBand(1).ReadAsArray()
        gdalDSNoDataValue = gdalDS.GetRasterBand(1).GetNoDataValue()
        upx, xres, xskew, upy, yskew, yres = gdalDS.GetGeoTransform()  #https://gis4programmers.wordpress.com/2017/01/06/using-gdal-to-get-raster-extent/, note GetGeoTransform not GetGeotransform
        ulx = float(upx + 0*xres + 0*xskew)
        uly = float(upy + 0*yskew + 0*yres)
        llx = float(upx + 0*xres + srcRows*xskew)
        lly = float(upy + 0*yskew + srcRows*yres)
        lrx = float(upx + srcCols*xres + srcRows*xskew)
        lry = float(upy + srcCols*yskew + srcRows*yres)
        urx = float(upx + srcCols*xres + 0*xskew)
        ury = float(upy + srcCols*yskew + 0*yres)        
        
        #print("------srcCols,srcRows=",srcCols,srcRows)
        #print("------srcextent=",srcextent)  #BoundingBox(left=358485.0, bottom=4028985.0, right=590415.0, top=4265115.0), https://gis.stackexchange.com/questions/104362/how-to-get-extent-out-of-geotiff
        MetricArray = np.full((srcRows, srcCols), F3NoDataValue)  #https://stackoverflow.com/questions/5891410/numpy-array-initialization-fill-with-identical-values
        PlotIdArray = np.full((srcRows, srcCols), F3NoDataValue, dtype=np.float64)   #PlotIdArray = np.full((srcRows, srcCols), F3NoDataValue). 20240418: dtype=np.int64 to np.float64 (note there are float16, float32, float64, and longdouble chices)
           
        #print("------Let us prepare the input parameters for Plot--start")
        plotlist,xlist,ylist,StatesCodeInThisHSL,StatesFullNameInThisHSL,StatesShortNameInThisHSL,SpeciesTranslatorInThisHSL = PlotIDandXandY(ShengliHuangKeyFile,Factor)  #20240125: plotlist is integer (from round function), xlist is float,and ylist is flaot too
        FieldSqlite = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"FieldPoint"+os.sep+FieldPointHeader+Management+"_"+Year+".db"
        conn = sqlite3.connect(FieldSqlite)  #https://www.sqlitetutorial.net/sqlite-python/
        cur= conn.cursor()
        #cur.execute("SELECT * FROM FVS_Compute")  #Ask Marcus to give the table name consistently

        #20230504: add another function to determine which table should be chosen for this metric---start
        Table = FindTheFirstTableNameWhereMetricExists(Metric,FieldSqlite)
        if Table != "NotFound":
            TableQuery = "SELECT * FROM " + Table
            cur.execute(TableQuery)  
        #20230504: add another function to determine which table should be chosen for this metric---end

        columns = [column[0].lower() for column in cur.description]
        #print(columns)

        FIADB_PLOTIndex = columns.index("FIADB_PLOT".lower())
        if Metric not in columns:
            print("------This metric does not exist:",Metric)
            return
        else:
            MetricIndex = columns.index(Metric)
            print("------MetricIndex=",MetricIndex)

        rows = cur.fetchall()
        FIADB_PLOTCode = []
        rowid = 0
        Plotlist = []
        CoordinateXlist = []
        CoordinateYlist = []
        MetricValuelist = []
        for row in rows:
            rowid = rowid + 1
            #print("rowid=",rowid)
            
            FIADB_PLOT = int(row[FIADB_PLOTIndex])
            if FIADB_PLOT in [int(k.split("&")[0]) for k in DropPlotAndInventoryYearTxtRecord]:  #20230315 added to manually remove those plots that we know bad
                continue
            #print("FIADB_PLOT=",FIADB_PLOT)

            if row[MetricIndex] is None:  #20240214 added because We have an error at MetricValue = float(row[MetricIndex]): "TypeError: float() argument must be a string or a real number, not 'NoneType'
                MetricValue0 = 0
            else:
                MetricValue0 = float(row[MetricIndex])

            #print("MetricValue0=",MetricValue0)
            MetricValue = int(MetricValue0 * FloatToIntegerCoefficient) 
            #print("MetricValue=",MetricValue)
            
            PlotIndexInplotlist = plotlist.index(FIADB_PLOT)
            CoordinateX = xlist[PlotIndexInplotlist]
            CoordinateY = ylist[PlotIndexInplotlist]
            CoordinateXlist.append(CoordinateX)
            CoordinateYlist.append(CoordinateY)
            MetricValuelist.append(MetricValue)
            Plotlist.append(FIADB_PLOT)

            rows, cols = rasterio.transform.rowcol(src.transform, CoordinateX, CoordinateY)  #https://gis.stackexchange.com/questions/299787/finding-pixel-location-in-raster-using-coordinates
            #print("rows, cols=",rows, cols)
            if ((rows >= 0) and (rows < srcRows) and (cols >= 0) and (cols < srcCols)):  #need more attantion if we need a -1 here or use = here
                MetricArray[rows,cols] = MetricValue   #This create an array with MetrciValue
                PlotIdArray[rows,cols] = float(FIADB_PLOT)    #This create an array with FIADB_PLOT. 20240418, add float() because YangDiBianMa.tif is a float
                print("CoordinateX,CoordinateY,rows,cols,FIADB_PLOT,MetricValue=",CoordinateX,CoordinateY,rows,cols,FIADB_PLOT,MetricValue, file=open(F3Log, 'a'))

        print("------The total plot is: ",rowid)
        #print("------The workflow can change so that all metric use the same plot processing")
        MetricArrayOriginal = MetricArray.copy()  #We need to deep copy the array, see https://appdividend.com/2021/10/21/how-to-copy-an-array-in-python/#:~:text=How%20to%20Copy%20an%20Array%20in%20Python%201,array.copy%20%28%29%20method%20provided%20in%20numpy%20API.%20
        MetricArray[gdalDSArray == gdalDSNoDataValue] = F3NoDataValue   #if cloudwater mask is void, then masked out
        #PlotIdArray[gdalDSArray == gdalDSNoDataValue] = F3NoDataValue   #20220915: we want to keep the original plotID even in the void area, so this sentence is commented out

        MetricArray = ma.masked_values(MetricArray, F3NoDataValue)
        PlotIdArray = ma.masked_values(PlotIdArray, F3NoDataValue)
        MetricArrayOriginal = ma.masked_values(MetricArrayOriginal, F3NoDataValue)
        print("------CreateMetricArray finished")

        PlotIDTif = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"CommonShare"+os.sep+"YangDiBianMa.tif"
        if not os.path.exists(PlotIDTif):
            PlotIDTif = Save2DArrayToTif(Run,Tile,Management,Year,Metric,PlotIdArray,PlotIDTif)        

        # This will create a point shape file based on coordinates, see https://gis.stackexchange.com/questions/42790/gdal-and-python-how-to-get-coordinates-for-all-cells-having-a-specific-value--start 
        CreateShapeFile = "Yes"   #Another option is "No"
        if CreateShapeFile == "Yes":
            if PlotLocation == "Local":
                shapeDataFile = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"FieldPoint"+os.sep+FieldPointHeader+Management+"_"+Year+"_"+Metric+".shp"  #This is the original one
            if PlotLocation == "SecuredPlace":
                PlotLocationPath = HSLpath+os.sep+ProjectName+os.sep+CWD.split(os.sep)[-1]+os.sep+Run+os.sep+Tile+os.sep+"FieldPoint"
                if not os.path.exists(PlotLocationPath):
                    os.makedirs(PlotLocationPath)
                shapeDataFile = PlotLocationPath+os.sep+FieldPointHeader+Management+"_"+Year+"_"+Metric+".shp"
            if not os.path.exists(shapeDataFile):
                srs = osr.SpatialReference() #srs = osgeo.osr.SpatialReference() does not work
                srs.ImportFromWkt(gdalDS.GetProjection())
                driver = ogr.GetDriverByName('ESRI Shapefile') #driver = osgeo.ogr.GetDriverByName('ESRI Shapefile') does not work
                shapeData = driver.CreateDataSource(shapeDataFile)
                layer = shapeData.CreateLayer('ogr_pts', srs, ogr.wkbPoint)   #layer = shapeData.CreateLayer('ogr_pts', srs, osgeo.ogr.wkbPoint) does not work
                layerDefinition = layer.GetLayerDefn()
                #print("20240131: Warning 6: Normalized/laundered field name: 'sm0and1_0_999' to 'sm0and1_0_'. I believe it happends below with metric name is too long (field name maximum langth is 10), see https://gis.stackexchange.com/questions/421562/making-ogr2ogr-not-normalize-field-names")
                #print("20240131: If this is not solvedm we will have error [ERROR 1: Invalid index : -1]")
                #print("20240131: Therefore, I trunck the field name and use Metric.replace("_","") as the field name in shape file in new_field_defn = ogr.FieldDefn(MetricForShape, ogr.OFTReal) and feature.SetField(MetricForShape, MetricValuelist[k])")
                if len(Metric) > 10:
                    MetricForShape = Metric.replace("_","")[0:10]  #note a="12345", then a[0:1000] is ok and the return is "12345"
                else:
                    MetricForShape = Metric

                new_field_defn0 = ogr.FieldDefn("FIADB_PLOT", ogr.OFTReal)  ##see https://snyk.io/advisor/python/ogr/functions/ogr.FieldDefn, https://stackoverflow.com/questions/39982877/python-crashes-when-adding-a-field-to-a-shapefile-with-ogr
                new_field_defn0.SetWidth(50)  
                new_field_defn0.SetPrecision(11)
                layer.CreateField(new_field_defn0)

                new_field_defn = ogr.FieldDefn(MetricForShape, ogr.OFTReal)  #https://stackoverflow.com/questions/39982877/python-crashes-when-adding-a-field-to-a-shapefile-with-ogr
                new_field_defn.SetWidth(50)
                new_field_defn.SetPrecision(11)
                layer.CreateField(new_field_defn)
                #print("len(CoordinateXlist),len(CoordinateYlist),len(MetricValuelist)=",len(CoordinateXlist),len(CoordinateYlist),len(MetricValuelist))
                i = 0
                for k in range(0,len(CoordinateXlist),1):
                    x = CoordinateXlist[k]
                    y = CoordinateYlist[k]
                    if ((x>=llx) and (x<=lrx) and (y>=lly) and (y<=uly)):
                        point = ogr.Geometry(ogr.wkbPoint) #point = osgeo.ogr.Geometry(osgeo.ogr.wkbPoint) does not work
                        point.SetPoint(0, CoordinateXlist[k], CoordinateYlist[k])
                        feature = ogr.Feature(layerDefinition)  #feature = osgeo.ogr.Feature(layerDefinition) does not work
                        feature.SetGeometry(point)
                        feature.SetFID(i)  #20240131 feature.SetFID(i) changed to feature.SetFID(i)
                        feature.SetField("FIADB_PLOT", Plotlist[k]) 
                        feature.SetField(MetricForShape, MetricValuelist[k])  #https://gis.stackexchange.com/questions/74708/how-to-change-the-field-value-of-a-shapefile-using-gdal-ogr
                        layer.CreateFeature(feature)
                        i += 1
                shapeData.Destroy()
                print("We created the shape file of ",shapeDataFile)

            if EncryptSensitiveFile == "Yes":
                shapeDataFile = EncryptImage(shapeDataFile)
        # This will create a point shape file based on coordinates, see https://gis.stackexchange.com/questions/42790/gdal-and-python-how-to-get-coordinates-for-all-cells-having-a-specific-value--end
            
        PreIDW_MetricIDWTif = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"Intermediate"+os.sep+Management+"_"+Year+"_"+Metric+"_Scatter.tif"
        PreIDW_MetricIDWTif0 = Save2DArrayToTif(Run,Tile,Management,Year,Metric,MetricArrayOriginal,PreIDW_MetricIDWTif)
        MetricIDW = CreateMetricIDW(PreIDW_MetricIDWTif0, Metric)
        if os.path.exists(PreIDW_MetricIDWTif):  #It always says permision. I willl remove this sentence (delete at the last) or just use memory array
            time.sleep(60)  #Sometimes there is an error "The process cannot access the file because it is being used by another process'. The reasom might be the computer process is too fast, so here we wait for half minutes
            os.remove(PreIDW_MetricIDWTif)  #we had "PermissionError: [WinError 32] The process cannot access the file because it is being used by another process, see https://gis.stackexchange.com/questions/80366/why-close-a-dataset-in-gdal-python
        IDWtemp = PreIDW_MetricIDWTif.replace("_Scatter.tif","_IDWTemp.tif")
        if os.path.exists(IDWtemp):
            time.sleep(60)
            os.remove(IDWtemp)  #Delete the intermediate newtif_file with its ending as _IDWTemp.tif
        print("CreateMetricArray resulted in an array with shape as ",MetricArray.shape)
        #print("MetricArray.count()=",MetricArray.count())

        return MetricArray
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for CreateMetricArray with inputs of "+repr(Run)+","+repr(Tile)+","+repr(Management)+","+repr(Year)+","+repr(Metric)+","+repr(FloatToIntegerCoefficient)+" with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog


def CreateMetricIDW(ScatterPointTif, Metric):   #Can we modify this function to take TIF or Array as input?
    try:
        OutFile = ScatterPointTif.replace("_Scatter.tif","_IDW.tif")
        if not os.path.exists(OutFile):
            print("This part is to use raster fillnodata for IDW interpolation, check later--start")
            #https://programtalk.com/python-examples/rasterio._fill._fillnodata/. [rasterio fillnodata] use IDW, but It is generally not so great for interpolating a raster from sparse point data.
            with rasterio.open(ScatterPointTif) as src0:
                profile = src0.profile
                arr = src0.read(1)
                t00 = time.time()
                arr_filled = fillnodata(arr, mask=src0.read_masks(1), max_search_distance=800, smoothing_iterations=0)  #500-0 not smooth; 200-2 many nodata; 500-2 too many nodata without known reason
                arr_filled_reserved = arr_filled.copy()  #I checked and found that the nodata value is -9999
                #print("For unknown reason, if smoothing_iterations !=0, the resulting IDW is very bad")             
                #print("IDW creation for ",ScatterPointTif, " it took \t" + str(int((time.time() - t00)/60))," minutes at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"), file=open(F3Log, 'a'))
                #print("max_search_distance= 800 means 30m*800=24000m=15 miles. FIA space is around 2-3 miles, so you have an idea how many plots will be used")
                #print("Please ntoe the resulting arr_filled is not a masked array")
                print("a np.nanmean(arr_filled)=",np.nanmean(arr_filled), file=open(F3Log, 'a'))
                print("Whether input 0 has masked values?",ma.is_masked(arr_filled), file=open(F3Log, 'a'))
                print("Array type...", arr_filled.dtype, file=open(F3Log, 'a'))


                #This part was added on 20230109 and is to smoother the IDW raster, because the original IDW looks very coarse and make the final raster have share bundary between 0 and non-zero, which make species distribution look bad---start
                #print("Because of the unknown reason of bad IDW when smoothing_iterations !=0, we add the following code to do the iteration myself") 
                Input2DArray = arr_filled[::5,::5]  #5 is used here to increase the efficiency (i.e., choose pixels every five to reduce the data). If we do not use it, the smothering takes long and the effect not good
                print("b1 np.nanmean(Input2DArray)=",np.nanmean(Input2DArray), file=open(F3Log, 'a'))
                t0 = time.time()
                WindowSmoothering = "Yes" #Other option is "No"
                if WindowSmoothering == "Yes":
                    #print("The following NumberOfIterationsForWindowSmoothering value is larger, then the image will be smoother")
                    NumberOfIterationsForWindowSmoothering = 20  #Here is the iterations. I decided to use 20. Note the iteration will make the non-zero pixels INVADE to zero-areas, the distance is 30 m * 5 * 20 = 3000 m. 
                    for i in range(0,NumberOfIterationsForWindowSmoothering,1):
                        data = Input2DArray  #data = ma.masked_values(Input2DArray, F3NoDataValue)
                        #print("\n",i,"b1 np.nanmean(data)=",np.nanmean(data), file=open(F3Log, 'a'))
                        MovingWindowArrayList = np.array([data[1:-1,1:-1], data[:-2,1:-1], data[2:,1:-1], data[1:-1,:-2], data[1:-1,2:], data[2:,2:], data[:-2,:-2], data[2:,:-2], data[:-2,2:]])
                        if Metric in ContinuousMetrics:
                            #print("median does not smoother the raster well (I do not know the reason), so we will use mean here below")
                            data[1:-1, 1:-1] = np.nanmean(MovingWindowArrayList,axis=0)  #This return the median by ignoring the nan element. outData[1:-1, 1:-1] = np.nanmean(MovingWindowArrayList,axis=0) is not used here
                        if Metric in DiscreteMetrics:
                            #data[1:-1,1:-1] = mode(MovingWindowArrayList,axis=0).mode[0,:,:]  #outData[1:-1,1:-1] = mode(MovingWindowArrayList,axis=0).count[0,:,:] can be used for count; This sentence may change in the future, depending on scipy version
                            #20230127, I found the above mode(MovingWindowArrayList,axis=0).mode[0,:,:] took about 2 hours, so I commented it out and used the following sentence
                            data[1:-1, 1:-1] = np.nanmean(MovingWindowArrayList,axis=0)  #for DiscreteMetrics, the mean does not make sense, but the IDW is mainly used for species absence, so I do not care so much. It is now a placeholder as of 20230127 and may be improved later
                        Input2DArray = data
                        #print(i,"b1 np.nanmean(Input2DArray)=",np.nanmean(Input2DArray), file=open(F3Log, 'a'))
                        #print(i," IDW smoothering for ",ScatterPointTif, " it took \t" + str(int((time.time() - t0)/60))," minutes at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"), file=open(F3Log, 'a'))
                arr_filled = Input2DArray
                print("b2 np.nanmean(arr_filled)=",np.nanmean(arr_filled), file=open(F3Log, 'a'))
                #This part was added on 20230109 and is to smoother the IDW raster, because the original IDW looks very coarse and make the final raster have share bundary between 0 and non-zero, which make species distribution look bad---end

            newtif_file = ScatterPointTif.replace("_Scatter.tif","_IDWTemp.tif")
            print("b np.nanmean(arr_filled)=",np.nanmean(arr_filled), file=open(F3Log, 'a'))
            with rasterio.open(newtif_file, 'w', **profile) as dest:
                dest.write_band(1, arr_filled)
            print(ScatterPointTif," was IDW interpolated into ", newtif_file)
            print("This part is to use raster fillnodata for IDW interpolation, check later--end")

            src = gdal.Open(newtif_file)
            Final2D = src.GetRasterBand(1).ReadAsArray()
            Cols = src.RasterXSize
            Rows = src.RasterYSize
            NoDataValue = src.GetRasterBand(1).GetNoDataValue()
            Final2D[Final2D == NoDataValue] = F3NoDataValue  
            Final2D[arr_filled_reserved == F3NoDataValue] = F3NoDataValue  #The newtif_file has some values closed to -9999 (e.g., -9998), so I use arr_filled_reserved as a mask
            Final2D[(arr_filled_reserved >=0) & (Final2D < 0)] = arr_filled_reserved[(arr_filled_reserved >=0) & (Final2D < 0)]  #There are sone pixels along the edge that are negative, which is not desired
            OutFile = ScatterPointTif.replace("_Scatter.tif","_IDW.tif")

            #Added on 20230201 to change the output datatype---start
            Final2D = ma.masked_values(Final2D, F3NoDataValue)
            Final2DMin = np.nanmin(Final2D)
            Final2DMax = np.nanmax(Final2D)
            TypeOfInterest = OutputDataType(Final2DMin, Final2DMax)
            #Added on 20230201 to change the output datatype---end
            
            driver = gdal.GetDriverByName("GTiff")
            if OutputGeoTifCompression == "Yes": #Added on 20230227. LZW compression does not lose information. LZW compression is a lossless data compression algorithm, which means that the original data can be fully reconstructed from the compressed data without any loss of information.
                outdata = driver.Create(OutFile, Cols, Rows, 1, TypeOfInterest, options=['COMPRESS=LZW'])   #Original is gdal.GDT_Int32, see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
            if OutputGeoTifCompression == "No": 
                outdata = driver.Create(OutFile, Cols, Rows, 1, TypeOfInterest)   #Original is gdal.GDT_Int32, see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
            outdata.SetGeoTransform(src.GetGeoTransform())  ##sets same geotransform as input
            outdata.SetProjection(src.GetProjection())  ##sets same projection as input
            outdata.GetRasterBand(1).WriteArray(Final2D)
            outdata.GetRasterBand(1).SetNoDataValue(F3NoDataValue) 
            outdata.FlushCache() ##saves to disk!!
            outdata = None
            print("We just created IDW tif of OutFile = ", OutFile, file=open(F3Log, 'a'))
        return OutFile
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for CreateMetricIDW with inputs of " + repr(ScatterPointTif) + " with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog

          


def BinClassCalculatedFromIntervalForDEM(InputTif, BinClass):   #This is mainly used for DEm processing
    try:
        InputArrayMasked = ReadTifToArray(InputTif)
        MinValue = np.nanmin(InputArrayMasked)
        MaxValue = np.nanmax(InputArrayMasked)
        Interval = 150 + (800.0 - 150.0) * (30 - max(5,min(30,BinClass))) / (30 - 5)   #By checking our previous F3 work, I found When BinClass=5, interval is around 800 m; When BinClass=30, interval is around 150 m
        ActualBinClass = max(2,int((MaxValue - MinValue) / Interval))
        return ActualBinClass
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for RasterBinned with inputs of " + repr(InputTif)+","+repr(Interval) + " with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog



def ArrayBinnedWithConstantMinMax(data, EndMin, EndMax, BinClass):  
    try:
        data = ma.masked_values(data, F3NoDataValue)
        #print("dataMin,dataMax=",np.nanmin(data),np.nanmax(data), file=open(F3Log, 'a'))
        BinStep = (EndMax-EndMin)/BinClass
        #print("BinClass,BinStep=",BinClass,BinStep, file=open(F3Log, 'a'))
        DataClipped = np.clip(data, EndMin, EndMax) - EndMin  #DataClipped = np.clip(data, EndMin, EndMax) #https://numpy.org/doc/stable/reference/generated/numpy.clip.html and more at https://stackoverflow.com/questions/19666626/replace-all-elements-of-python-numpy-array-that-are-greater-than-some-value
        #print("DataClippedMin,DataClippedMax=",np.nanmin(DataClipped),np.nanmax(DataClipped), file=open(F3Log, 'a'))
        DataBinned = np.ceil((DataClipped/BinStep)).astype(np.int64)  #20220912, I Changed int32 to int64. print("Check datatype here") ##first ceil and then convert to integer. note ceil() return float. We need 16 due to F3nodatavalue of -9999
        #print("DataBinnedMin,DataBinnedMax=",np.nanmin(DataBinned),np.nanmax(DataBinned), file=open(F3Log, 'a'))
        if np.nanmin(DataBinned) < 0:
            print("We have problem here, please redo")
            return
        return DataBinned
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for ArrayBinnedWithConstantMinMax with inputs of " + repr(data.shape)+","+repr(EndMin)+","+repr(EndMax)+","+repr(BinClass) + " with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog
           


def RasterBinnedWithConstantMinMax(InputTifList,BinClass):  #InputTif is a python file name string; BinClass is an integer
    try:
        #print("------RasterBinned start with InputTifList as ",InputTifList)
        OutputBinnedTifList = []
        for InputTif in InputTifList:
            
            if "Dem30mF3" in InputTif.split(os.sep)[-1]:  #20221214: Using a constant BInCLass for DEM does not make sense when the DEM range is very small (e.g., area is flat), so here we add this.
                print(BinClass, " is the original BinClass for ", InputTif, " at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
                #print(BinClass, " is the original BinClass for ", InputTif, " at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"), file=open(F3Log, 'a')) 
                ActualBinClass = BinClassCalculatedFromIntervalForDEM(InputTif, BinClass)
                BinClass = ActualBinClass
                print(BinClass, " is the new BinClass for ", InputTif, " at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
                #print(BinClass, " is the new BinClass for ", InputTif, " at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"), file=open(F3Log, 'a'))
        
            OutputBinnedTif = InputTif.replace("RSraster","CommonShare").replace("NonRSraster","CommonShare").replace("AdditionalContinuousRaster","CommonShare").replace(".tif","B"+str(BinClass)+"HM.tif")  #originally: OutputBinnedTif = InputTif.replace(".tif","Binned.tif")
            #print("------OutputBinnedTif=",OutputBinnedTif)
            if not os.path.exists(OutputBinnedTif):
                Nstd = 2.0
                TifRaster = gdal.Open(InputTif)
                ncol = TifRaster.RasterXSize
                nrow = TifRaster.RasterYSize
                bands = TifRaster.RasterCount
                #print("------One method to get the ncol,nrow,bands are: ", ncol,nrow,bands)
                if bands != 1:
                    print("------This is not a single band Tif, so it is not good for F3. Please preprocess it")
                for band in range(1, bands+1):   
                    BandRaster = TifRaster.GetRasterBand(band)
                    #print("------Datatype is: ", BandRaster.DataType) #https://drr.ikcest.org/tutorial/k8023 to check the meaning
                    OriginalNoDataValue = BandRaster.GetNoDataValue()
                    #print("------NoDataValue in this image is: ", OriginalNoDataValue)
                    Originaldata = BandRaster.ReadAsArray()  
                    [rows, cols] = Originaldata.shape
                    #print("------Another method to get [rows, cols] = ",Originaldata.shape)
                    data = ma.masked_values(Originaldata, OriginalNoDataValue)  #different mask option at https://numpy.org/doc/stable/reference/maskedarray.generic.html
                    #print("------data = ma.masked_where(Originaldata == OriginalNoDataValue, Originaldata) may work too, see #https://stackoverflow.com/questions/15369829/gdal-readasarray-does-not-ignore-nodata-value")

                    mymean = data.mean() 
                    #print("------Band %s: Mean = %s" % (band, round(mymean, 2)))
                    mymin = data.min() 
                    #print("------Band %s: Min = %s" % (band, round(mymin, 2)))
                    mymax = data.max() 
                    #print("------Band %s: Max = %s" % (band, round(mymax, 2)))
                    mystd = data.std() 
                    #print("------Band %s: Std = %s" % (band, round(mystd, 2)))

                    EndMax = min(mymean+Nstd*mystd,mymax)
                    EndMin = max(mymean-Nstd*mystd,mymin)
                    #20230515: For historical F3 mapping, we need the constant Min and Max, so we added the following sentence to replace the old one---start
                    if "red.tif" in InputTif.lower():
                        EndMax = 17000
                        EndMin = 7400
                    if "nir.tif" in InputTif.lower():
                        EndMax = 21000
                        EndMin = 11000
                    if "swir1.tif" in InputTif.lower():
                        EndMax = 22000
                        EndMin = 9300
                    #20230515: For historical F3 mapping, we need the constant Min and Max, so we added the following sentence to replace the old one---end
                    BinStep = (EndMax-EndMin)/BinClass
                    #print("------EndMax,EndMin,BinStep=",EndMax,EndMin,BinStep)

                    DataClipped = np.clip(data, EndMin, EndMax) #https://numpy.org/doc/stable/reference/generated/numpy.clip.html and more at https://stackoverflow.com/questions/19666626/replace-all-elements-of-python-numpy-array-that-are-greater-than-some-value
                    #print("------DataClippedMin=",DataClipped.min())
                    #print("------DataClippedMax=",DataClipped.max())
                    #print('Datatype for DataClipped is:', DataClipped.dtype)
                    DataBinned = np.ceil((DataClipped/BinStep)).astype(np.int64)  #20220912, I Changed int32 to int64. print("Check datatype here") ##first ceil and then convert to integer. note ceil() return float. We need 16 due to F3nodatavalue of -9999
                    #print("------DataBinneddMin=",DataBinned.min())
                    #print("------DataBinnedMax=",DataBinned.max())
                    #print('Datatype for DataBinned is:', DataBinned.dtype)
                    DataBinneddMin = DataBinned.min()
                    if DataBinneddMin <= 0:
                        print("20230522: if this function is used for historical mapping, then the shift below cannot be used, because you can assure the shift is the same for red, nir, and swir for comparable years", LetErrorCome)
                        return
                    if DataBinneddMin == 0:
                        ShiftValue = 1
                    if DataBinneddMin < 0:
                        ShiftValue = abs(DataBinneddMin) + 1
                    if DataBinneddMin > 0:
                        ShiftValue = 0
                    #print("------ShiftValue=",ShiftValue)
                    DataBinnedShift = DataBinned+ShiftValue
                    DataBinnedShift[Originaldata == OriginalNoDataValue] = F3NoDataValue   #added on 20220908
                    #print("------DataBinnedShiftMin=",DataBinnedShift.min())
                    #print("------DataBinnedShiftMax=",DataBinnedShift.max())
                    #print('Datatype for DataBinnedShift is:', DataBinnedShift.dtype)

                    #Added on 20230201 to change the output datatype---start
                    DataBinnedShift = ma.masked_values(DataBinnedShift, F3NoDataValue)
                    DataBinnedShiftMin = np.nanmin(DataBinnedShift)
                    DataBinnedShiftMax = np.nanmax(DataBinnedShift)
                    TypeOfInterest = OutputDataType(DataBinnedShiftMin, DataBinnedShiftMax)
                    #Added on 20230201 to change the output datatype---end

                    driver = gdal.GetDriverByName("GTiff")
                    if OutputGeoTifCompression == "Yes": #Added on 20230227. LZW compression does not lose information. LZW compression is a lossless data compression algorithm, which means that the original data can be fully reconstructed from the compressed data without any loss of information.
                        outdata = driver.Create(OutputBinnedTif, cols, rows, 1, TypeOfInterest, options=['COMPRESS=LZW'])  #original is gdal.GDT_Int32
                    if OutputGeoTifCompression == "No": 
                        outdata = driver.Create(OutputBinnedTif, cols, rows, 1, TypeOfInterest)  #original is gdal.GDT_Int32
                    outdata.SetGeoTransform(TifRaster.GetGeoTransform())   ##sets same geotransform as input
                    outdata.SetProjection(TifRaster.GetProjection())   ##sets same projection as input
                    outdata.GetRasterBand(1).WriteArray(DataBinnedShift)
                    outdata.GetRasterBand(1).SetNoDataValue(F3NoDataValue) 
                    outdata.FlushCache() ##saves to disk!!
                    outdata = None
                    BandRaster = None
                    #print("------Image binned")
                TifRaster = None
            OutputBinnedTifList.append(OutputBinnedTif)
        #print("------OutputBinnedTifList=",OutputBinnedTifList)
        #print("------RasterBinned finished")
        return OutputBinnedTifList
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for RasterBinnedWithConstantMinMax with inputs of " + repr(InputTifList)+","+repr(BinClass) + " with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog
           

def RasterBinned(InputTifList,BinClass):  #InputTif is a python file name string; BinClass is an integer
    try:
        #print("------RasterBinned start with InputTifList as ",InputTifList)
        OutputBinnedTifList = []
        for InputTif in InputTifList:
            if "Dem30mF3" in InputTif.split(os.sep)[-1]:  #20221214: Using a constant BInCLass for DEM does not make sense when the DEM range is very small (e.g., area is flat), so here we add this.
                print(BinClass, " is the original BinClass for ", InputTif, " at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
                #print(BinClass, " is the original BinClass for ", InputTif, " at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"), file=open(F3Log, 'a')) 
                ActualBinClass = BinClassCalculatedFromIntervalForDEM(InputTif, BinClass)
                BinClass = ActualBinClass
                print(BinClass, " is the new BinClass for ", InputTif, " at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
                #print(BinClass, " is the new BinClass for ", InputTif, " at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"), file=open(F3Log, 'a'))
        
            OutputBinnedTif = InputTif.replace("RSraster","CommonShare").replace("NonRSraster","CommonShare").replace("AdditionalContinuousRaster","CommonShare").replace(".tif","B"+str(BinClass)+".tif")  #originally: OutputBinnedTif = InputTif.replace(".tif","Binned.tif")
            #print("------OutputBinnedTif=",OutputBinnedTif)
            if not os.path.exists(OutputBinnedTif):
                Nstd = 2.0
                TifRaster = gdal.Open(InputTif)
                ncol = TifRaster.RasterXSize
                nrow = TifRaster.RasterYSize
                bands = TifRaster.RasterCount
                #print("------One method to get the ncol,nrow,bands are: ", ncol,nrow,bands)
                if bands != 1:
                    print("------This is not a single band Tif, so it is not good for F3. Please preprocess it")
                for band in range(1, bands+1):   
                    BandRaster = TifRaster.GetRasterBand(band)
                    #print("------Datatype is: ", BandRaster.DataType) #https://drr.ikcest.org/tutorial/k8023 to check the meaning
                    OriginalNoDataValue = BandRaster.GetNoDataValue()
                    #print("------NoDataValue in this image is: ", OriginalNoDataValue)
                    Originaldata = BandRaster.ReadAsArray()  
                    [rows, cols] = Originaldata.shape
                    #print("------Another method to get [rows, cols] = ",Originaldata.shape)
                    data = ma.masked_values(Originaldata, OriginalNoDataValue)  #different mask option at https://numpy.org/doc/stable/reference/maskedarray.generic.html
                    #print("------data = ma.masked_where(Originaldata == OriginalNoDataValue, Originaldata) may work too, see #https://stackoverflow.com/questions/15369829/gdal-readasarray-does-not-ignore-nodata-value")

                    mymean = data.mean() 
                    #print("------Band %s: Mean = %s" % (band, round(mymean, 2)))
                    mymin = data.min() 
                    #print("------Band %s: Min = %s" % (band, round(mymin, 2)))
                    mymax = data.max() 
                    #print("------Band %s: Max = %s" % (band, round(mymax, 2)))
                    mystd = data.std() 
                    #print("------Band %s: Std = %s" % (band, round(mystd, 2)))

                    EndMax = min(mymean+Nstd*mystd,mymax)
                    EndMin = max(mymean-Nstd*mystd,mymin)
                    BinStep = (EndMax-EndMin)/BinClass
                    #print("------EndMax,EndMin,BinStep=",EndMax,EndMin,BinStep)

                    DataClipped = np.clip(data, EndMin, EndMax) #https://numpy.org/doc/stable/reference/generated/numpy.clip.html and more at https://stackoverflow.com/questions/19666626/replace-all-elements-of-python-numpy-array-that-are-greater-than-some-value
                    #print("------DataClippedMin=",DataClipped.min())
                    #print("------DataClippedMax=",DataClipped.max())
                    #print('Datatype for DataClipped is:', DataClipped.dtype)
                    DataBinned = np.ceil((DataClipped/BinStep)).astype(np.int64)  #20220912, I Changed int32 to int64. print("Check datatype here") ##first ceil and then convert to integer. note ceil() return float. We need 16 due to F3nodatavalue of -9999
                    #print("------DataBinneddMin=",DataBinned.min())
                    #print("------DataBinnedMax=",DataBinned.max())
                    #print('Datatype for DataBinned is:', DataBinned.dtype)
                    DataBinneddMin = DataBinned.min()
                    if DataBinneddMin == 0:
                        ShiftValue = 1
                    if DataBinneddMin < 0:
                        ShiftValue = abs(DataBinneddMin) + 1
                    if DataBinneddMin > 0:
                        ShiftValue = 0
                    #print("------ShiftValue=",ShiftValue)
                    DataBinnedShift = DataBinned+ShiftValue
                    DataBinnedShift[Originaldata == OriginalNoDataValue] = F3NoDataValue   #added on 20220908
                    #print("------DataBinnedShiftMin=",DataBinnedShift.min())
                    #print("------DataBinnedShiftMax=",DataBinnedShift.max())
                    #print('Datatype for DataBinnedShift is:', DataBinnedShift.dtype)

                    #Added on 20230201 to change the output datatype---start
                    DataBinnedShift = ma.masked_values(DataBinnedShift, F3NoDataValue)
                    DataBinnedShiftMin = np.nanmin(DataBinnedShift)
                    DataBinnedShiftMax = np.nanmax(DataBinnedShift)
                    TypeOfInterest = OutputDataType(DataBinnedShiftMin, DataBinnedShiftMax)
                    #Added on 20230201 to change the output datatype---end

                    driver = gdal.GetDriverByName("GTiff")
                    if OutputGeoTifCompression == "Yes": #Added on 20230227. LZW compression does not lose information. LZW compression is a lossless data compression algorithm, which means that the original data can be fully reconstructed from the compressed data without any loss of information.
                        outdata = driver.Create(OutputBinnedTif, cols, rows, 1, TypeOfInterest, options=['COMPRESS=LZW'])  #original is gdal.GDT_Int32
                    if OutputGeoTifCompression == "No": 
                        outdata = driver.Create(OutputBinnedTif, cols, rows, 1, TypeOfInterest)  #original is gdal.GDT_Int32
                    outdata.SetGeoTransform(TifRaster.GetGeoTransform())   ##sets same geotransform as input
                    outdata.SetProjection(TifRaster.GetProjection())   ##sets same projection as input
                    outdata.GetRasterBand(1).WriteArray(DataBinnedShift)
                    outdata.GetRasterBand(1).SetNoDataValue(F3NoDataValue) 
                    outdata.FlushCache() ##saves to disk!!
                    outdata = None
                    BandRaster = None
                    #print("------Image binned")
                TifRaster = None
            OutputBinnedTifList.append(OutputBinnedTif)
        #print("------OutputBinnedTifList=",OutputBinnedTifList)
        #print("------RasterBinned finished")
        return OutputBinnedTifList
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for RasterBinned with inputs of " + repr(InputTifList)+","+repr(BinClass) + " with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog
        

#https://stackoverflow.com/questions/72622309/calculating-the-averages-of-elements-in-one-array-based-on-data-in-another-array
#https://stackoverflow.com/questions/49372918/group-numpy-into-multiple-sub-arrays-using-an-array-of-values       
def NewTestZoneStatisticsToArray(ZoneInputTif,Metric,MetricArray,StatisticType):  #ZoneInputTif is Zone in TIF, MetricArray is numpy array
    try:
        #print("------ZoneStatisticsToArray start")
        ZoneInputTifRaster = gdal.Open(ZoneInputTif)
        ZoneInputTifRaster_ncol = ZoneInputTifRaster.RasterXSize
        ZoneInputTifRaster_nrow = ZoneInputTifRaster.RasterYSize
        ZoneInputTifRaster_bands = ZoneInputTifRaster.RasterCount
        #print("------The ncol,nrow,bands are: ", ZoneInputTifRaster_ncol,ZoneInputTifRaster_nrow,ZoneInputTifRaster_bands)
        ZoneInputTifRasterData = ZoneInputTifRaster.GetRasterBand(1)
        ZoneInputTifRasterDataNoDataValue = ZoneInputTifRasterData.GetNoDataValue()
        #print("------ZoneInputTifRasterDataNoDataValue=",ZoneInputTifRasterDataNoDataValue)
        ZoneInputTifRasterDataArray = ZoneInputTifRasterData.ReadAsArray().astype('int64') 
        ZoneInputTifRasterDataMasked = ma.masked_values(ZoneInputTifRasterDataArray, ZoneInputTifRasterDataNoDataValue)
        print(ZoneInputTifRasterDataMasked)

        MetricArrayMasked = ma.masked_values(MetricArray, F3NoDataValue)

        ZoneUnique = np.unique(ZoneInputTifRasterDataMasked)
        ZoneUniqueLength = len(ZoneUnique)
        print("------ZoneUnique started at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"), " with ZoneUniqueLength of ",ZoneUniqueLength)
        ZoneID = 0
        for Zone in ZoneUnique:
            ZoneID = ZoneID + 1
            if ZoneID%int(ZoneUniqueLength/500) == 0:  #Every 1%, we print 
                print("ZoneID=",ZoneID, " out of ", ZoneUniqueLength)
            if Metric in ContinuousMetrics:
                if StatisticType == "mean":
                    #MetricArrayMasked[ZoneInputTifRasterDataMasked==Zone] = MetricArrayMasked[ZoneInputTifRasterDataMasked==Zone].mean()
                    MetricArrayMasked[ZoneInputTifRasterDataMasked==Zone] = MetricArrayMasked[ZoneInputTifRasterDataMasked==Zone].mean()
        ZoneInputTifRaster = None
        print("------ZoneUnique finished at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"), " with The min for ZoneStatistic is: ", np.nanmin(MetricArrayMasked)) 
        return MetricArrayMasked
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for NewTestZoneStatisticsToArray with inputs of " + repr(ZoneInputTif)+","+repr(Metric)+","+repr(StatisticType) + " with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog
    

def CreateWeightBasisTif(Step1ContinuousPredictionTif,BaseMetricArrayMasked,T,AddExtension):  
    try:
        BaseMetricArrayMasked = ma.masked_values(BaseMetricArrayMasked, F3NoDataValue)  
        Step1ContinuousPredictionTifRaster = gdal.Open(Step1ContinuousPredictionTif)
        Step1ContinuousPredictionTifRaster_ncol = Step1ContinuousPredictionTifRaster.RasterXSize
        Step1ContinuousPredictionTifRaster_nrow = Step1ContinuousPredictionTifRaster.RasterYSize
        Step1ContinuousPredictionTifRaster_bands = Step1ContinuousPredictionTifRaster.RasterCount
        print("------The ncol,nrow,bands are: ", Step1ContinuousPredictionTifRaster_ncol,Step1ContinuousPredictionTifRaster_nrow,Step1ContinuousPredictionTifRaster_bands)
        Step1ContinuousPredictionTifRasterData = Step1ContinuousPredictionTifRaster.GetRasterBand(1)
        Step1ContinuousPredictionTifRasterDataNoDataValue = Step1ContinuousPredictionTifRasterData.GetNoDataValue()
        print("------Step1ContinuousPredictionTifRasterDataNoDataValue=",Step1ContinuousPredictionTifRasterDataNoDataValue)
        Step1ContinuousPredictionTifRasterDataArray = Step1ContinuousPredictionTifRasterData.ReadAsArray().astype('int64')  
        Step1ContinuousPredictionTifRasterDataMasked = ma.masked_values(Step1ContinuousPredictionTifRasterDataArray, Step1ContinuousPredictionTifRasterDataNoDataValue)
        MeasureAndRegressionAbsDifference = np.absolute(BaseMetricArrayMasked - Step1ContinuousPredictionTifRasterDataMasked)
        MeasureAndRegressionAbsDifference[MeasureAndRegressionAbsDifference.mask] = 1  #Without giving the value of 1, np.float_power will have an error RuntimeWarning: divide by zero encountered in float_power
        MeasureAndRegressionAbsDifference[MeasureAndRegressionAbsDifference <= 1] = 1  #Without giving the value of 1, np.float_power will have an error RuntimeWarning: divide by zero encountered in float_power
        MeasureAndRegressionAbsDifferencePowerT = np.float_power(MeasureAndRegressionAbsDifference, T)
        MeasureAndRegressionAbsDifferencePowerT[BaseMetricArrayMasked.mask] = F3NoDataValue

        #Added on 20230123 to constrain the MeasureAndRegressionAbsDifferencePowerT---start
        Nstd = 2.0
        MeasureAndRegressionAbsDifferencePowerT = ma.masked_values(MeasureAndRegressionAbsDifferencePowerT, F3NoDataValue)
        mymean = np.nanmean(MeasureAndRegressionAbsDifferencePowerT) 
        mymin = np.nanmin(MeasureAndRegressionAbsDifferencePowerT) 
        mymax = np.nanmax(MeasureAndRegressionAbsDifferencePowerT) 
        mystd = np.nanstd(MeasureAndRegressionAbsDifferencePowerT) 
        EndMax = min(mymean+Nstd*mystd,mymax)
        EndMin = max(mymean-Nstd*mystd,mymin)
        MeasureAndRegressionAbsDifferencePowerT[MeasureAndRegressionAbsDifferencePowerT > EndMax] = EndMax
        MeasureAndRegressionAbsDifferencePowerT[MeasureAndRegressionAbsDifferencePowerT < EndMin] = EndMin
        MeasureAndRegressionAbsDifferencePowerT[BaseMetricArrayMasked.mask] = F3NoDataValue
        #Added on 20230123 to constrain the MeasureAndRegressionAbsDifferencePowerT---start

        driver = gdal.GetDriverByName("GTiff")
        cols = np.shape(MeasureAndRegressionAbsDifferencePowerT)[1]
        rows = np.shape(MeasureAndRegressionAbsDifferencePowerT)[0]
        if ((cols != Step1ContinuousPredictionTifRaster_ncol) or (rows != Step1ContinuousPredictionTifRaster_nrow)):
            print("------The col and row are different, we have problem here")
        Extension = "WeightBasis" + AddExtension
        WeightBasisTif = Step1ContinuousPredictionTif.replace("RegressionPredicted",Extension)
        if not os.path.exists(WeightBasisTif):  #added on 20240320
            if OutputGeoTifCompression == "Yes": #Added on 20230227. LZW compression does not lose information. LZW compression is a lossless data compression algorithm, which means that the original data can be fully reconstructed from the compressed data without any loss of information.
                outdata = driver.Create(WeightBasisTif, cols, rows, 1, gdal.GDT_Float32, options=['COMPRESS=LZW'])   #see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
            if OutputGeoTifCompression == "No": 
                outdata = driver.Create(WeightBasisTif, cols, rows, 1, gdal.GDT_Float32)   #see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
            outdata.SetGeoTransform(Step1ContinuousPredictionTifRaster.GetGeoTransform())   ##sets same geotransform as input
            outdata.SetProjection(Step1ContinuousPredictionTifRaster.GetProjection())   ##sets same projection as input
            outdata.GetRasterBand(1).WriteArray(MeasureAndRegressionAbsDifferencePowerT)
            outdata.GetRasterBand(1).SetNoDataValue(F3NoDataValue) 
            outdata.FlushCache() ##saves to disk!!
            outdata = None
            print(WeightBasisTif, "raster for F3 weighting basis just finished")
        return WeightBasisTif
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for CreateWeightBasisTif with inputs of " + repr(Step1ContinuousPredictionTif)+","+repr(BaseMetricArrayMasked.shape)+","+repr(T)+","+repr(AddExtension) + " with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog

            

def Save2DArrayToTif(Run,Tile,Management,Year,Metric,TwoDimensionArray,ArrayTif):
    try:
        if not os.path.exists(ArrayTif):
            #print("------Save2DArrayToTif start")
            #ArrayTif = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"Results"+os.sep+Management+"_"+Year+"_"+Metric+".tif"
            
            CloudWaterShadowMask = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"RSraster"+os.sep+"CloudShadowWaterSnow.tif"
            TifRaster = gdal.Open(CloudWaterShadowMask)
            ncol = TifRaster.RasterXSize
            nrow = TifRaster.RasterYSize
            CloudWaterShadowMaskArray = TifRaster.GetRasterBand(1).ReadAsArray()
            CloudWaterShadowMaskNoDataValue = TifRaster.GetRasterBand(1).GetNoDataValue()
            #print("CloudWaterShadowMaskNoDataValue=",CloudWaterShadowMaskNoDataValue)
            #print("TwoDimensionArray.count()1=",TwoDimensionArray.count())  #this sentence does not work because TwoDimensionArray is not masked yet
            TwoDimensionArray[CloudWaterShadowMaskArray == CloudWaterShadowMaskNoDataValue] = F3NoDataValue  #added 20220908
            TwoDimensionArray = ma.masked_values(TwoDimensionArray, F3NoDataValue)  #20220920: I found if we do not add this, the TwoDimensionArray will be changed and affect all following steps outside this function
            #print("TwoDimensionArray.count()2=",TwoDimensionArray.count())

            #Added on 20230201 to change the output datatype---start
            TwoDimensionArray = ma.masked_values(TwoDimensionArray, F3NoDataValue)
            TwoDimensionArrayMin = np.nanmin(TwoDimensionArray)
            TwoDimensionArrayMax = np.nanmax(TwoDimensionArray)
            TypeOfInterest = OutputDataType(TwoDimensionArrayMin, TwoDimensionArrayMax)
            #Added on 20230201 to change the output datatype---end
            
            driver = gdal.GetDriverByName("GTiff")
            cols = np.shape(TwoDimensionArray)[1]
            rows = np.shape(TwoDimensionArray)[0]
            if ((cols != ncol) or (rows != nrow)):
                print("------The col and row are different, we have problem here")

            GeoTifCompression = "Yes"  #Option is "Yes" or "No"
            if OutputGeoTifCompression == "Yes": #Added on 20230227. LZW compression does not lose information. LZW compression is a lossless data compression algorithm, which means that the original data can be fully reconstructed from the compressed data without any loss of information.
                outdata = driver.Create(ArrayTif, cols, rows, 1, TypeOfInterest, options=['COMPRESS=LZW'])   #original is gdal.GDT_Int32. see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
            if OutputGeoTifCompression == "No": 
                outdata = driver.Create(ArrayTif, cols, rows, 1, TypeOfInterest)   #original is gdal.GDT_Int32. see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal 
            #print("TwoDimensionArray.count()3=",TwoDimensionArray.count())
            outdata.SetGeoTransform(TifRaster.GetGeoTransform())  ##sets same geotransform as input
            outdata.SetProjection(TifRaster.GetProjection())  ##sets same projection as input
            outdata.GetRasterBand(1).WriteArray(TwoDimensionArray)
            outdata.GetRasterBand(1).SetNoDataValue(F3NoDataValue)  
            outdata.FlushCache() ##saves to disk!!
            outdata = None
            #print("------Save2DArrayToTif finished")
            print("TwoDimensionArray.count()4=",TwoDimensionArray.count())
        return ArrayTif   #20220908: I am not sure if we can return the input
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for Save2DArrayToTif with inputs of " + repr(Run)+","+repr(Tile)+","+repr(Management)+","+repr(Year)+","+repr(Metric)+","+repr(TwoDimensionArray.shape)+","+repr(ArrayTif) + " with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog


    
def ReadTifToArray(InputTif):
    try:
        print("------ReadTifToArray start for ", InputTif, file=open(F3Log, 'a'))
        InputTifRaster = gdal.Open(InputTif)
        InputTifRasterData = InputTifRaster.GetRasterBand(1)
        #print("Unable to allocate array with shape and data type error may appear below, see https://stackoverflow.com/questions/57507832/unable-to-allocate-array-with-shape-and-data-type")
        InputTifRasterDataArray = InputTifRasterData.ReadAsArray().astype('float')  #20221025: changed int64 to float, because the tif are not always integer, and the value can be small float like 0.0024 (e.g. BaseManagementBaseYearBaseMetricPlotDatabase_WeightBasis.tif)
        InputTifRasterDataNoDataValue = InputTifRasterData.GetNoDataValue()
        InputTifRasterDataMasked = ma.masked_values(InputTifRasterDataArray, InputTifRasterDataNoDataValue)
        #print("The InputTifRasterDataNoDataValue = ", InputTifRasterDataNoDataValue, file=open(F3Log, 'a'))
        InputTifRaster = None   #20230426 added: In os.remove(), we may have "PermissionError: [WinError 32] The process cannot access the file because it is being used by another process, see https://gis.stackexchange.com/questions/80366/why-close-a-dataset-in-gdal-python
        return InputTifRasterDataMasked
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for ReadTifToArray with inputs of " + repr(InputTif) + " with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog


def ReadTifToArrayAndReturnExtent(InputTif):
    try:
        print("------ReadTifToArray start for ", InputTif)
        InputTifRaster = gdal.Open(InputTif)
        InputTifRasterData = InputTifRaster.GetRasterBand(1)
        InputTifRasterDataArray = InputTifRasterData.ReadAsArray().astype('float')  #20221025: changed int64 to float, because the tif are not always integer, and the value can be small float like 0.0024 (e.g. BaseManagementBaseYearBaseMetricPlotDatabase_WeightBasis.tif)
        InputTifRasterDataNoDataValue = InputTifRasterData.GetNoDataValue()
        InputTifRasterDataMasked = ma.masked_values(InputTifRasterDataArray, InputTifRasterDataNoDataValue)
        #print("The InputTifRasterDataNoDataValue = ", InputTifRasterDataNoDataValue)
        cols = InputTifRaster.RasterXSize
        rows = InputTifRaster.RasterYSize

        upx, xres, xskew, upy, yskew, yres = InputTifRaster.GetGeoTransform()  #https://gis4programmers.wordpress.com/2017/01/06/using-gdal-to-get-raster-extent/, note GetGeoTransform not GetGeotransform
        ulx = float(upx + 0*xres + 0*xskew)
        uly = float(upy + 0*yskew + 0*yres)
        llx = float(upx + 0*xres + rows*xskew)
        lly = float(upy + 0*yskew + rows*yres)
        lrx = float(upx + cols*xres + rows*xskew)
        lry = float(upy + cols*yskew + rows*yres)
        urx = float(upx + cols*xres + 0*xskew)
        ury = float(upy + cols*yskew + 0*yres)         
        
        return InputTifRasterDataMasked,ulx,uly,llx,lly,lrx,lry,urx,ury
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for ReadTifToArrayAndReturnExtent with inputs of " + repr(InputTif) + " with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog

    
def ComputeRasterStatistics(InputTif):
    try:
        #print("------ComputeRasterStatistics start")
        raster = gdal.Open(InputTif) # open raster file
        band = raster.GetRasterBand(1) # get data into varialbe 'band' so we can actually look at it. 
        band.GetMetadata()
        if band.GetMinimum is None or band.GetMaximum() is None:
            print("------There is no statistics for the file of ", InputTif)
            #print("------[ MAX ] =", band.GetMaximum())
            #print("------[ MIN ] =", band.GetMinimum())
        if band.GetMinimum() is None or band.GetMaximum() is None:
            band.ComputeStatistics(0)   #Gdal should know the NoData (e.g., -9999) when the Tif image was read.
        band.GetMetadata()
        if band.GetMinimum is None or band.GetMaximum() is None:
            print("------\nBollucks to this: ", InputTif)
            #print("------[ MAX ] =", band.GetMaximum())
            #print("------[ MIN ] =", band.GetMinimum())
        else: 
            print("------\nHey, it worked.")
            #print("------[ MAX ] =", band.GetMaximum())
            #print("------[ MIN ] =", band.GetMinimum())
        #print("------ComputeRasterStatistics finished")
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for ComputeRasterStatistics with inputs of " + repr(InputTif) + " with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog


def RemoteSensingKmeansUnsupervisedClassification(InputTifList,NumberOfClass):
    try:
        #print("------RemoteSensingKmeansUnsupervisedClassification start")
        #from sklearn.cluster import KMeans, Remote sensing K-means unsupervised classification at https://opensourceoptions.com/blog/unsupervised-land-cover-classification-with-python/
        #The function may take 1.5-2.0 hours. Can we do it in Google Earth? No, because Kmeans output depends on the input data statistics.
        OutputTif = InputTifList[0].replace("RSraster","CommonShare").replace("NonRSraster","CommonShare").replace("AdditionalContinuousRaster","CommonShare").replace(InputTifList[0].split(os.sep)[-1],"Kmeans"+str(NumberOfClass)+"Class.tif")
        if not os.path.exists(OutputTif):
            FirstTif = InputTifList[0]
            driverTiff = gdal.GetDriverByName('GTiff')
            FirstTifRaster = gdal.Open(FirstTif)
            
            NumberOfSingleBandTif = len(InputTifList)
            # create an empty array, each column of the empty array will hold one band of data from the image
            # loop through each band in the image and add to the data array
            data = np.empty((FirstTifRaster.RasterXSize * FirstTifRaster.RasterYSize, NumberOfSingleBandTif))
            kid = -1
            for k in InputTifList:
                kid = kid + 1
                TifRaster = gdal.Open(k)
                band = TifRaster.GetRasterBand(1).ReadAsArray()
                data[:, kid] = band.flatten()

            # set up the kmeans classification, fit, and predict
            km = KMeans(NumberOfClass)
            km.fit(data)
            km.predict(data)

            # format the predicted classes to the shape of the original image
            out_dat = km.labels_.reshape((FirstTifRaster.RasterYSize, FirstTifRaster.RasterXSize))

            #Added on 20230201 to change the output datatype---start
            out_dat = ma.masked_values(out_dat, F3NoDataValue)
            out_datMin = np.nanmin(out_dat)
            out_datMax = np.nanmax(out_dat)
            TypeOfInterest = OutputDataType(out_datMin, out_datMax)
            #Added on 20230201 to change the output datatype---end

            # save the original image with gdal
            clfds = driverTiff.Create(OutputTif, FirstTifRaster.RasterXSize, FirstTifRaster.RasterYSize, 1, TypeOfInterest)   #original is gdal.GDT_Int32
            clfds.SetGeoTransform(FirstTifRaster.GetGeoTransform())
            clfds.SetProjection(FirstTifRaster.GetProjection())
            clfds.GetRasterBand(1).SetNoDataValue(F3NoDataValue)
            clfds.GetRasterBand(1).WriteArray(out_dat)
            clfds = None
        #This part will remove small isolated pixels and replace with the largest neighbour---start
        print("OutputTif=",OutputTif, file=open(F3Log, 'a'))      
        MyImage = gdal.Open(OutputTif) #20230321: We cannot use MyImage = gdal.Open(OutputTif, 1); we have to delete 1. I do not know why  # open image in read-write mode
        Band = MyImage.GetRasterBand(1)
        SmallestPixelNumber = 1        
        gdal.SieveFilter(srcBand=Band, maskBand=None, dstBand=Band, threshold=SmallestPixelNumber, connectedness=8, callback=gdal.TermProgress_nocb)  #hMaskBand – an optional mask band. All pixels in the mask band with a value other than zero will be considered suitable for inclusion in polygons. see https://gdal.org/api/gdal_alg.html#_CPPv415GDALSieveFilter15GDALRasterBandH15GDALRasterBandH15GDALRasterBandHiiPPc16GDALProgressFuncPv
        del MyImage, Band  # close the datasets.
        #This part will remove small isolated pixels and replace with the largest neighbour---end
        print("------RemoteSensingKmeansUnsupervisedClassification from ", InputTifList, " with number of class ", NumberOfClass, " is done and has been sieved")
        print("The corresponding output is ",OutputTif)
        return OutputTif
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for RemoteSensingKmeansUnsupervisedClassification with inputs of " + repr(InputTifList)+","+repr(NumberOfClass) + " with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog


def Step1ContinuousPrediction(Run,Tile,Management,Year,Metric,FloatToIntegerCoefficient):
    try:
        ShengliHuangKeyFile = HSLpath + os.sep + Tile + ".hsl"  #20240212 added
        DropPlotAndInventoryYearTxtRecord = ManualRemovePlotYear(ManualRemovePlotYearList) #20230315 added to manually remove those plots that we know bad
        CloudWaterShadowMask = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"RSraster"+os.sep+"CloudShadowWaterSnow.tif"
        driverTiff = gdal.GetDriverByName('GTiff')
        ds = gdal.Open(CloudWaterShadowMask)
        CloudWaterShadowMaskArray = ds.GetRasterBand(1).ReadAsArray()
        CloudWaterShadowMaskNoDataValue = ds.GetRasterBand(1).GetNoDataValue()
        #print("CloudWaterShadowMaskNoDataValue=",CloudWaterShadowMaskNoDataValue)
        srcCols = ds.RasterXSize
        srcRows = ds.RasterYSize
        WeUseThisProjection = ds.GetProjectionRef()
        WeUseThisGeoTransform = ds.GetGeoTransform()
        print("XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXx",WeUseThisGeoTransform)
        upx, xres, xskew, upy, yskew, yres = WeUseThisGeoTransform
        ulx = float(upx + 0*xres + 0*xskew)
        uly = float(upy + 0*yskew + 0*yres)
        llx = float(upx + 0*xres + srcRows*xskew) 
        lly = float(upy + 0*yskew + srcRows*yres)      
        lrx = float(upx + srcCols*xres + srcRows*xskew)
        lry = float(upy + srcCols*yskew + srcRows*yres)
        urx = float(upx + srcCols*xres + 0*xskew)
        ury = float(upy + srcCols*yskew + 0*yres)
        print("ulx,uly,lrx,lry=",ulx,uly,lrx,lry)
        
        print("------Step1ContinuousPrediction start")
        #We may use spatial regression to simpify our work, check more https://geographicdata.science/book/notebooks/11_regression.html
        #We can use our traditional stepwise regression or new random forest. We can do this later not now.
        StepwiseRegressionRasters1 = [
            os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"RSraster"+os.sep+"Img_"+BaseYear+"_swir1.tif",
            os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"RSraster"+os.sep+"Img_"+BaseYear+"_nir.tif",
            os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"RSraster"+os.sep+"Img_"+BaseYear+"_red.tif"
            ]           
        StepwiseRegressionRasters2 = [
                os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"NonRSraster"+os.sep+"Annualmeantemperature.tif",
                os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"NonRSraster"+os.sep+"Annualprecipitation.tif",
                os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"NonRSraster"+os.sep+"Meantemperatureofwarmestquarter.tif",
                os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"NonRSraster"+os.sep+"Precipitationofdriestquarter.tif"
                ]
        StepwiseRegressionRasters = StepwiseRegressionRasters1 + StepwiseRegressionRasters2
        StepwiseRegressionVariables = [k.split(os.sep)[-1].replace(".tif","") for k in StepwiseRegressionRasters]

        if ((Management == BaseManagement) and (Year == BaseYear) and (Metric == BaseMetric)):
            print("------We will use BaseManagement,BaseYear,and BaseMetric to predict a map")
            print("------Let us prepare the input parameters for Plot--start")
            
            plotlist0,xlist0,ylist0,StatesCodeInThisHSL,StatesFullNameInThisHSL,StatesShortNameInThisHSL,SpeciesTranslatorInThisHSL = PlotIDandXandY(ShengliHuangKeyFile,Factor)  #20240125: plotlist is integer (from round function), xlist is float,and ylist is flaot too
            
            plotlist = []
            xlist = []
            ylist = []
            for k in range(0,len(plotlist0),1):
                plot = plotlist0[k]
                x = xlist0[k]
                y = ylist0[k]
                if ((x >= ulx) and (x <= lrx) and (y >= lry) and (y <= uly)):  #20221118 added to filter those plots that are not within the tile. This will speed up the processing
                    plotlist.append(plot)
                    xlist.append(x)
                    ylist.append(y)
            
            #print("The Smallest and largest Element in this xlist is : ", min(xlist), max(xlist))
            #print("The Smallest and largest Element in this ylist is : ", min(ylist), max(ylist))


            FieldSqlite = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"FieldPoint"+os.sep+FieldPointHeader+Management+"_"+Year+".db"
            conn = sqlite3.connect(FieldSqlite)  #https://www.sqlitetutorial.net/sqlite-python/
            cur= conn.cursor()
            #cur.execute("SELECT * FROM FVS_Compute")  #Ask Marcus to give the table name consistently

            #20230504: add another function to determine which table should be chosen for this metric---start
            Table = FindTheFirstTableNameWhereMetricExists(Metric,FieldSqlite)
            if Table != "NotFound":
                TableQuery = "SELECT * FROM " + Table
                cur.execute(TableQuery)  
            #20230504: add another function to determine which table should be chosen for this metric---end

            columns = [column[0].lower() for column in cur.description]
            #print(columns)
            FIADB_PLOTIndex = columns.index("FIADB_PLOT".lower())
            if Metric not in columns:
                print("------This metric does not exist:",Metric)
            else:
                MetricIndex = columns.index(Metric)
                print("------MetricIndex=",MetricIndex)
            rows = cur.fetchall()
            FIADB_PLOTCode = []
            print("Dog is barking")

            FieldMetricCSV = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"CommonShare"+os.sep+"BaseManagementBaseYearBaseMetricPlotDatabase.csv"
            print("20230305: Bill asked if a shape file with Landsat values is available. We can do it here by refering to the existing CreateShapeFile section")
            if not os.path.exists(FieldMetricCSV):
                t0 = time.time()
                print("FieldMetricCSV=",FieldMetricCSV)
                FieldMetricCSVFile = open(FieldMetricCSV, 'w')
                Headline = Metric + "," + ",".join(StepwiseRegressionVariables) + "\n"
                print(Headline)
                FieldMetricCSVFile.write(Headline)          

                HuangPlotIDlist = [] #20240313 added to address Bill's request
                HuangCoordinateXlist = [] #20240313 added to address Bill's request
                HuangCoordinateYlist = [] #20240313 added to address Bill's request
                rowlist = []
                collist = []
                MetricValueList = []
                rowid = 0
                for row in rows:
                    rowid = rowid + 1
                    FIADB_PLOT = int(row[FIADB_PLOTIndex])
                    if FIADB_PLOT in [int(k.split("&")[0]) for k in DropPlotAndInventoryYearTxtRecord]:  #20230315 added to manually remove those plots that we know bad
                        continue

                    if row[MetricIndex] is None:  #20240214 added because We have an error at MetricValue = float(row[MetricIndex]): "TypeError: float() argument must be a string or a real number, not 'NoneType'
                        MetricValue = 0
                    else:
                        MetricValue = float(row[MetricIndex])

                    Kid = -1
                    for k in plotlist:
                        Kid = Kid + 1
                        if int(FIADB_PLOT) == int(k):
                            CoordinateX = xlist[Kid]
                            CoordinateY = ylist[Kid]
                            #print("rowid,FIADB_PLOT,k,Kid,xlist[Kid],ylist[Kid]=",rowid,FIADB_PLOT,k,Kid,CoordinateX,CoordinateY,ulx,urx,lly,ury)
                            if ((CoordinateX >= ulx) and (CoordinateX <= lrx) and (CoordinateY >= lry) and (CoordinateY <= uly)):  #make sure it falls within the extent
                                srcline = str(int(MetricValue * FloatToIntegerCoefficient)) 
                                for localname in StepwiseRegressionRasters[0:1]:
                                    #print("localname=",localname)
                                    row,col = rasterio.open(localname).index(CoordinateX, CoordinateY)
                                    #print("row,col=",row,col)
                                    if ((row >= 0) and (row < srcRows) and (col >= 0) and (col < srcCols)):
                                        HuangPlotIDlist.append(int(FIADB_PLOT))  #20240313 added to address Bill's request
                                        HuangCoordinateXlist.append(CoordinateX) #20240313 added to address Bill's request
                                        HuangCoordinateYlist.append(CoordinateY) #20240313 added to address Bill's request
                                        rowlist.append(row)
                                        collist.append(col)
                                        MetricValueList.append(str(int(MetricValue * FloatToIntegerCoefficient)))
                                        ##This is the old methos to extract values for plot from rasters. The speed is super slow, so I discarded it---start
                                        #RasterValue = rasterio.open(localname).read(1)[row,col]
                                        #if ((abs(RasterValue-F3NoDataValue)>1.0) and (abs(RasterValue-F3ValidFillValue)>1.0)):  #For float, directly == is not good
                                        #    srcline = srcline + "," + str(RasterValue)
                                        #    if localname == StepwiseRegressionRasters[-1]:   #if this is the last raster
                                        #        srcline = srcline + "\n"
                                        #        print("We will add this line to CSV file: ",srcline)
                                        #        FieldMetricCSVFile.write(srcline)
                                        ##This is the old methos to extract values for plot from rasters. The speed is super slow, so I discarded it---end
                print("The number of plots for regression is ",len(rowlist), " or say ",len(collist), " or say ",len(MetricValueList), "which should be identical")
                StepwiseRegressionRasters_all = np.full((len(StepwiseRegressionRasters),srcRows,srcCols), F3NoDataValue)
                p=-1
                for localname in StepwiseRegressionRasters:
                    p = p + 1
                    driverTiff = gdal.GetDriverByName('GTiff')
                    ds = gdal.Open(localname)
                    localnameArray = ds.GetRasterBand(1).ReadAsArray()
                    localnameNoDataValue = ds.GetRasterBand(1).GetNoDataValue()
                    StepwiseRegressionRasters_all[p,:,:] = localnameArray
                LineAsGISShapeList = [] #20240313 added to address Bill's request
                for q in range(0,len(rowlist),1):
                    ThePlotValueArray = StepwiseRegressionRasters_all[:,rowlist[q],collist[q]]
                    ThePlotValueList0 = ThePlotValueArray.tolist()  #if array is not converted into list, the following .join cannot be done
                    ThePlotValueList = [str(x) for x in ThePlotValueList0]
                    #print("ThePlotValueList is ",ThePlotValueList)
                    if ((str(F3NoDataValue) in ThePlotValueList) or (str(F3ValidFillValue) in ThePlotValueList)):
                        print("This plot falls in void area, we do not use it for regression")
                        continue
                    else:
                        LineAsGISShape = str(HuangCoordinateXlist[q]) + "," + str(HuangCoordinateYlist[q]) + ","  + str(HuangPlotIDlist[q]) + "," + MetricValueList[q] + "," + ",".join(ThePlotValueList) + "\n"
                        LineAsGISShapeList.append(LineAsGISShape) #20240313 added to address Bill's request
                        LineToCSV = MetricValueList[q] + "," + ",".join(ThePlotValueList) + "\n"
                        #print("q=", q, " and LineToCSV: ",LineToCSV)
                        FieldMetricCSVFile.write(LineToCSV)
                FieldMetricCSVFile.close()
                print("FieldMetricCSV it took \t" + str(int((time.time() - t0)/60))," minutes")

                GisShapeFileName = FieldMetricCSV.replace(".csv",".shp")
                ReferenceProject = CloudWaterShadowMask
                CreateGisShapeWithAllValuesIncludedReturn = CreateGisShapeWithAllValuesIncluded(ReferenceProject, LineAsGISShapeList,GisShapeFileName,Headline)
                print("The GIS shape file crated from CreateGisShapeWithAllValuesIncluded is: ",CreateGisShapeWithAllValuesIncludedReturn) 
            print(FieldMetricCSV, " was created, but we may improve the speed later because the rasterio.open() can be done only once")

            #This part is to run Stepwise regression---start
            a = StepwiseRegression(FieldMetricCSV, Metric)
            #This part is to run Stepwise regression---end

            # Reading stepwise regression TXT result file and calculate the predicted FiedMetric using ArcGIS---start
            StepwiseRegressionResult = FieldMetricCSV.replace(".csv", "__StepwiseRegreesionResult.txt")  # There is a "condition number" in the output TXT file, see explaination at https://en.wikipedia.org/?title=Condition_number
            StepwiseRegressionResultLine = open(StepwiseRegressionResult).readline()
            print('The first line of the result file is the stepwise regression shown as: ', StepwiseRegressionResultLine)
            RegressorCoefficient = StepwiseRegressionResultLine.split(";")[1:-2]

            FieldMetricPredictedOutputFile = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"CommonShare"+ os.sep + "BaseManagementBaseYearBaseMetricPlotDatabase_RegressionPredicted.tif"
            if not os.path.exists(FieldMetricPredictedOutputFile):
                Intercept = float(StepwiseRegressionResultLine.split(";")[-2].split(":")[1])
                RegressionArray = np.full((srcRows,srcCols), Intercept)
                k = -1
                for EachRegressor in RegressorCoefficient:
                    print(EachRegressor)
                    k = k + 1
                    CurrentRegressor = EachRegressor.split(":")[0]
                    for m in StepwiseRegressionRasters:
                        if CurrentRegressor == m.split(os.sep)[-1].replace(".tif",""):
                            EachRegressorFile = m
                    print(EachRegressorFile)
                    EachRegressorArray = rasterio.open(EachRegressorFile).read(1) * float(EachRegressor.split(":")[1])
                    EachRegressorArray = ma.masked_values(EachRegressorArray, F3NoDataValue)
                    RegressionArray = RegressionArray + EachRegressorArray  #https://gis.stackexchange.com/questions/320865/sum-the-value-of-two-raster-files-using-rasterio-rasterio-equivalent-of-raster
                # Reading stepwise regression TXT result file and calculate the predicted FiedMetric using ArcGIS---end

                #Using Cloud/Water etc to mask and using Min and Max to correct the bad pixels---start
                MetricMinValue,MetricMaxValue = MetricMinAndMax(Run,Tile,Management,Year,Metric)
                RegressionArray[RegressionArray <= MetricMinValue] = MetricMinValue
                RegressionArray[RegressionArray >= MetricMaxValue] = MetricMaxValue
                RegressionArray[CloudWaterShadowMaskArray == CloudWaterShadowMaskNoDataValue] = F3NoDataValue  #mask out pixels if they are cloudwater etc.
                #Using Cloud/Water etc to mask and using Min and Max to correct the bad pixels---end
               
                # save segments to raster
                driver = gdal.GetDriverByName("GTiff")
                if OutputGeoTifCompression == "Yes": #Added on 20230227. LZW compression does not lose information. LZW compression is a lossless data compression algorithm, which means that the original data can be fully reconstructed from the compressed data without any loss of information.
                    outdata = driver.Create(FieldMetricPredictedOutputFile, srcCols, srcRows, 1, gdal.GDT_Int32, options=['COMPRESS=LZW'])   #see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
                if OutputGeoTifCompression == "No": 
                    outdata = driver.Create(FieldMetricPredictedOutputFile, srcCols, srcRows, 1, gdal.GDT_Int32)   #see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
                outdata.SetGeoTransform(WeUseThisGeoTransform)##sets same geotransform as input
                outdata.SetProjection(WeUseThisProjection)##sets same projection as input
                outdata.GetRasterBand(1).WriteArray(RegressionArray)
                outdata.GetRasterBand(1).SetNoDataValue(F3NoDataValue) ##if you want these values transparent
                outdata.FlushCache() ##saves to disk!!
                outdata = None
                print("xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx------FieldMetricPredictedOutputFile finished")
            return FieldMetricPredictedOutputFile
        else:
            print("------This is not BaseManagement,BaseYear,and BaseMetric, so we will return (not exit because it is a parallel processing)")
            return
        print("------Step1ContinuousPrediction finished")    
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for Step1ContinuousPrediction with inputs of " + repr(Run)+","+repr(Tile)+","+repr(Management)+","+repr(Year)+","+repr(Metric)+","+repr(FloatToIntegerCoefficient) + " with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog





def CreateGisShapeWithAllValuesIncluded(ReferenceProject, LineAsGISShapeList, GisShapeFileName, Headline):
    try:
        FieldNames = Headline.replace('\n','').split(",")
        #print("FieldNames=",FieldNames)
        gdalDS = gdal.Open(ReferenceProject)
        shapeDataFile = GisShapeFileName
        if not os.path.exists(GisShapeFileName):
            srs = osr.SpatialReference() #srs = osgeo.osr.SpatialReference() does not work
            srs.ImportFromWkt(gdalDS.GetProjection())
            driver = ogr.GetDriverByName('ESRI Shapefile') #driver = osgeo.ogr.GetDriverByName('ESRI Shapefile') does not work
            shapeData = driver.CreateDataSource(shapeDataFile)
            layer = shapeData.CreateLayer('ogr_pts', srs, ogr.wkbPoint)   #layer = shapeData.CreateLayer('ogr_pts', srs, osgeo.ogr.wkbPoint) does not work
            layerDefinition = layer.GetLayerDefn()

            new_field_defn0 = ogr.FieldDefn("FIADB_PLOT", ogr.OFTReal)  ##see https://snyk.io/advisor/python/ogr/functions/ogr.FieldDefn, https://stackoverflow.com/questions/39982877/python-crashes-when-adding-a-field-to-a-shapefile-with-ogr
            new_field_defn0.SetWidth(50)  
            new_field_defn0.SetPrecision(11)
            layer.CreateField(new_field_defn0)
            for FieldName in FieldNames:
                new_field_defn0 = ogr.FieldDefn(FieldName, ogr.OFTReal)  ##see https://snyk.io/advisor/python/ogr/functions/ogr.FieldDefn, https://stackoverflow.com/questions/39982877/python-crashes-when-adding-a-field-to-a-shapefile-with-ogr
                new_field_defn0.SetWidth(50)  
                new_field_defn0.SetPrecision(11)
                layer.CreateField(new_field_defn0)

            for k in range(0,len(LineAsGISShapeList),1):
                LineAsGISShapeInput = LineAsGISShapeList[k].replace('\n','').split(",")
                #print("LineAsGISShapeInput=",LineAsGISShapeInput)
                x = float(LineAsGISShapeInput[0])
                y = float(LineAsGISShapeInput[1])
                point = ogr.Geometry(ogr.wkbPoint) #point = osgeo.ogr.Geometry(osgeo.ogr.wkbPoint) does not work
                point.SetPoint(0, x, y)
                feature = ogr.Feature(layerDefinition)  #feature = osgeo.ogr.Feature(layerDefinition) does not work
                feature.SetGeometry(point)
                feature.SetFID(k)
                feature.SetField("FIADB_PLOT", int(LineAsGISShapeInput[2]))
                FieldNameID = -1
                for FieldName in FieldNames:  #In a GIS shapefile, the maximum length for a field name is 10 characters, see https://www.ncesc.com/geographic-faq/what-is-the-maximum-number-of-fields-in-a-shapefile/
                    FieldNameID = FieldNameID + 1
                    #print("In a GIS shapefile, the maximum length for a field name is 10 characters, so we have FieldName[0:min(10,len(FieldName))] below")
                    feature.SetField(FieldName[0:min(10,len(FieldName))], float(LineAsGISShapeInput[3+FieldNameID]))  #https://gis.stackexchange.com/questions/74708/how-to-change-the-field-value-of-a-shapefile-using-gdal-ogr
                layer.CreateFeature(feature)
            shapeData.Destroy()
            print("We created the shape file of ",shapeDataFile)
        return shapeDataFile
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for CreateGisShapeWithAllValuesIncluded with inputs of " + repr(ReferenceProject)+","+repr(len(LineAsGISShapeList))+","+repr(GisShapeFileName)+","+repr(Headline) + " with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog

    
def MetricMinAndMax(Run,Tile,Management,Year,Metric):
    try:
        FieldMetricMinMaxTxt = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"FieldPoint"+os.sep+FieldPointHeader+Management+"_"+Year+"_"+Metric+"MinMax.txt"
        print("FieldMetricMinMaxTxt=",FieldMetricMinMaxTxt)
        if os.path.exists(FieldMetricMinMaxTxt):
            print(FieldMetricMinMaxTxt," exist")
            FieldMetricMinMaxTxtFile = open(FieldMetricMinMaxTxt)
            MinvalueMaxvalueLine = FieldMetricMinMaxTxtFile.readline()
            print("MinvalueMaxvalueLine=", MinvalueMaxvalueLine)
            MetricMinValue = float(MinvalueMaxvalueLine.split(",")[0])
            print("MetricMinValue=", MetricMinValue)
            MetricMaxValue = float(MinvalueMaxvalueLine.split(",")[1])
            print("MetricMaxValue=", MetricMaxValue)
            FieldMetricMinMaxTxtFile.close()
        print("MetricMinValue,MetricMaxValue here=",MetricMinValue,MetricMaxValue)
        return MetricMinValue,MetricMaxValue
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for MetricMinAndMax with inputs of " + repr(Run)+","+repr(Tile)+","+repr(Management)+","+repr(Year)+","+repr(Metric) + " with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog
    

def F3SpatialMosaicMetricMinAndCutThreshValue(Runs,Tiles,Management,Year,Metric):  #Note Runs and Tiles, it is not Run and Tile
    try:
        MosaicMinAndCutThreshValueInput = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep + ProjectName + os.sep + Management+"_"+Year+"_"+Metric+"_MosaicMinAndCutThreshValue.txt"

        MosaicMinAndCutThreshValueInputFile = open(MosaicMinAndCutThreshValueInput, 'w')
        MosaicMinAndCutThreshValueInputTime = "#This MosaicMinAndCutThreshValue was created by Dr. Shengli Huang at " + datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + " with the following inputs:\n"
        MosaicMinAndCutThreshValueInputFile.write(MosaicMinAndCutThreshValueInputTime)
        
        MetricMinValueList = []
        HalfOfCutthresholdMinusMinList = []
        CutthresholdList = []
        MetricMaxValueList = []
        for Run in Runs:
            for Tile in Tiles:
                MetricMinValue, HalfOfCutthresholdMinusMin, Cutthreshold, MetricMaxValue = MinAndCutThreshValue(Run,Tile,Management,Year,Metric)
                MetricMinValueList.append(MetricMinValue)
                HalfOfCutthresholdMinusMinList.append(HalfOfCutthresholdMinusMin)
                CutthresholdList.append(Cutthreshold)
                MetricMaxValueList.append(MetricMaxValue)
                Content = "MetricMinValue, HalfOfCutthresholdMinusMin, Cutthreshold, MetricMaxValue = "+str(MetricMinValue)+","+str(HalfOfCutthresholdMinusMin)+","+str(Cutthreshold)+","+str(MetricMaxValue) 
                MosaicMinAndCutThreshValueInputLine1 = "With the Forest Vegetation Simulator unit in imperial, "+"Run="+Run+","+"Tile="+Tile+","+"Management="+Management+","+"Year="+str(Year)+","+"Metric="+Metric+":"+Content+"\n"
                MosaicMinAndCutThreshValueInputFile.write(MosaicMinAndCutThreshValueInputLine1)

        MosaicMetricMinValue = min(MetricMinValueList)
        MosaicCutthreshold = np.mean(CutthresholdList)
        MosaicHalfOfCutthresholdMinusMin = (MosaicCutthreshold - MosaicMetricMinValue) / 2.0 + MosaicMetricMinValue  #20240517,MosaicMetricMinValue was added after (MosaicCutthreshold - MosaicMetricMinValue) / 2.0 
        MosaicMetricMaxValue = max(MetricMaxValueList)
        
        Content1 = "MosaicMetricMinValue="+str(MosaicMetricMinValue)+","+"MosaicHalfOfCutthresholdMinusMin="+str(MosaicHalfOfCutthresholdMinusMin)+","+"MosaicCutthreshold="+str(MosaicCutthreshold)+","+"MosaicMetricMaxValue="+str(MosaicMetricMaxValue)       
        MosaicMinAndCutThreshValueInputLine3 = "With the Forest Vegetation Simulator unit in imperial, "+"Management="+Management+","+"Year="+str(Year)+","+"Metric="+Metric+":"+Content1+"\n"
        MosaicMinAndCutThreshValueInputFile.write(MosaicMinAndCutThreshValueInputLine3)
        MosaicMinAndCutThreshValueInputFile.close()

        #added on 20230222 to change the min amd max according to OutputUnit---start
        MetricShortName,MetricFullName,MetricDefinition,SpeciesScienticName,USDAPlantCode,FVSKeyword,MetricUnit_US,MetricUnit_SI,UStoSIconversion,MetricShortNameIGivenBy,MetricFullNameIGivenBy,AdditionalNotes = MetricInformationFromXLSX(Metric)
        if OutputUnit == "Imperial": #added on 20230222
            MosaicMetricMinValue = MosaicMetricMinValue * 1.0
            MosaicHalfOfCutthresholdMinusMin = MosaicHalfOfCutthresholdMinusMin * 1.0
            MosaicCutthreshold = MosaicCutthreshold * 1.0
            MosaicMetricMaxValue = MosaicMetricMaxValue * 1.0
        if OutputUnit == "SI":
            MosaicMetricMinValue = MosaicMetricMinValue * UStoSIconversion
            MosaicHalfOfCutthresholdMinusMin = MosaicHalfOfCutthresholdMinusMin * UStoSIconversion
            MosaicCutthreshold = MosaicCutthreshold * UStoSIconversion
            MosaicMetricMaxValue = MosaicMetricMaxValue * UStoSIconversion
        #added on 20230222 to change the min amd max according to OutputUnit---end

        print("MosaicMetricMinValue,MosaicHalfOfCutthresholdMinusMin,MosaicCutthreshold,MosaicMetricMaxValue=",MosaicMetricMinValue,MosaicHalfOfCutthresholdMinusMin,MosaicCutthreshold,MosaicMetricMaxValue)
        return MosaicMetricMinValue,MosaicHalfOfCutthresholdMinusMin,MosaicCutthreshold,MosaicMetricMaxValue
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for F3SpatialMosaicMetricMinMax with inputs of " + repr(Runs)+","+repr(Tiles)+","+repr(Management)+","+repr(Year)+","+repr(Metric) + " with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog




def F3SpatialMosaicMetricMinMax(Runs,Tiles,Management,Year,Metric):  #Note Runs and Tiles, it is not Run and Tile
    try:
        MosaicMinMaxInput = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep + ProjectName + os.sep + Management+"_"+Year+"_"+Metric+"_MosaicMinMax.txt"

        MosaicMinMaxInputFile = open(MosaicMinMaxInput, 'w')
        MosaicMinMaxInputTime = "#This mosaicMinMax was created by Dr. Shengli Huang at " + datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + " with the following inputs:\n"
        MosaicMinMaxInputFile.write(MosaicMinMaxInputTime)
        
        SpatialMetricMax = -100000000000000
        SpatialMetricMin =  100000000000000
        for Run in Runs:
            for Tile in Tiles:
                MetricMinValue,MetricMaxValue = MetricMinAndMax(Run,Tile,Management,Year,Metric)
                if MetricMinValue < SpatialMetricMin:
                    SpatialMetricMin = MetricMinValue
                if MetricMaxValue > SpatialMetricMax:
                    SpatialMetricMax = MetricMaxValue
                MosaicMinMaxInputLine1 = "With the Forest Vegetation Simulator unit in imperial, "+"Run="+Run+","+"Tile="+Tile+","+"Management="+Management+","+"Year="+str(Year)+","+"Metric="+Metric+": Minimumum value="+str(MetricMinValue)+" (but may ignore value=0)"+"\n"
                MosaicMinMaxInputLine2 = "With the Forest Vegetation Simulator unit in imperial, "+"Run="+Run+","+"Tile="+Tile+","+"Management="+Management+","+"Year="+str(Year)+","+"Metric="+Metric+": Maximum value="+str(MetricMaxValue)+" (but may ignore value=0)"+"\n"
                MosaicMinMaxInputFile.write(MosaicMinMaxInputLine1)
                MosaicMinMaxInputFile.write(MosaicMinMaxInputLine2)
        MosaicMinMaxInputLine3 = "With the Forest Vegetation Simulator unit in imperial, "+"Management="+Management+","+"Year="+str(Year)+","+"Metric="+Metric+": Mosaic minimum value="+str(SpatialMetricMin)+" (but ignore value=0)"+"\n"
        MosaicMinMaxInputLine4 = "With the Forest Vegetation Simulator unit in imperial, "+"Management="+Management+","+"Year="+str(Year)+","+"Metric="+Metric+": Mosaic maximum value="+str(SpatialMetricMax)+" (but ignore value=0)"+"\n"
        MosaicMinMaxInputFile.write(MosaicMinMaxInputLine3)
        MosaicMinMaxInputFile.write(MosaicMinMaxInputLine4)
        MosaicMinMaxInputFile.close()

        #added on 20230222 to change the min amd max according to OutputUnit---start
        MetricShortName,MetricFullName,MetricDefinition,SpeciesScienticName,USDAPlantCode,FVSKeyword,MetricUnit_US,MetricUnit_SI,UStoSIconversion,MetricShortNameIGivenBy,MetricFullNameIGivenBy,AdditionalNotes = MetricInformationFromXLSX(Metric)
        if OutputUnit == "Imperial": #added on 20230222
            SpatialMetricMin = SpatialMetricMin * 1.0
            SpatialMetricMax = SpatialMetricMax * 1.0
        if OutputUnit == "SI":
            SpatialMetricMin = SpatialMetricMin * UStoSIconversion
            SpatialMetricMax = SpatialMetricMax * UStoSIconversion
        #added on 20230222 to change the min amd max according to OutputUnit---end

        return SpatialMetricMin,SpatialMetricMax
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for F3SpatialMosaicMetricMinMax with inputs of " + repr(Runs)+","+repr(Tiles)+","+repr(Management)+","+repr(Year)+","+repr(Metric) + " with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog



def F3EntireMetricMinMaxForLegend(Metric):  
    try:
        F3EntireMetricMinMaxForLegend = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep+"EntireMetricMinMax_"+Metric.lower()+"_MosaicMinMax.txt"
        if os.path.exists(F3EntireMetricMinMaxForLegend):
            F3EntireMetricMinMaxForLegendFile = open(F3EntireMetricMinMaxForLegend,'r')
            Lines = F3EntireMetricMinMaxForLegendFile.readlines()  #Not readline but readlines
            Lines = [i.replace('\n','') for i in Lines]
            for Line in Lines:
                print("Line=",Line)
                if "final min from all managements and years is " in Line:
                    F3EntireMetricMinMaxForLegendMin = float(Line.split("final min from all managements and years is ")[1])
                if "final max from all managements and years is " in Line:
                    F3EntireMetricMinMaxForLegendMax = float(Line.split("final max from all managements and years is ")[1])
            print("Existed and F3EntireMetricMinMaxForLegendMin,F3EntireMetricMinMaxForLegendMax=",F3EntireMetricMinMaxForLegendMin,F3EntireMetricMinMaxForLegendMax)
            print("Existed and F3EntireMetricMinMaxForLegendMin,F3EntireMetricMinMaxForLegendMax=",F3EntireMetricMinMaxForLegendMin,F3EntireMetricMinMaxForLegendMax,file=open(F3Log, 'a'))      
        else:
            F3EntireMetricMinMaxForLegendInputs = glob.glob(os.getcwd()+os.sep+"Run*"+os.sep+"*"+os.sep+"FieldPoint"+os.sep+"*_"+Metric+"MinMax.txt")
            print("F3EntireMetricMinMaxForLegendInputs=",F3EntireMetricMinMaxForLegendInputs, file=open(F3Log, 'a'))
            print("F3EntireMetricMinMaxForLegend=",F3EntireMetricMinMaxForLegend, file=open(F3Log, 'a'))
            F3EntireMetricMinMaxForLegendFile = open(F3EntireMetricMinMaxForLegend, 'a')
            F3EntireMetricMinMaxForLegendTime = "#The Min/Max value of the metric of "+Metric+" was retrieved by Dr. Shengli Huang at " + datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + " with the following inputs:\n"
            F3EntireMetricMinMaxForLegendFile.write(F3EntireMetricMinMaxForLegendTime)

            MetricShortName,MetricFullName,MetricDefinition,SpeciesScienticName,USDAPlantCode,FVSKeyword,MetricUnit_US,MetricUnit_SI,UStoSIconversion,MetricShortNameIGivenBy,MetricFullNameIGivenBy,AdditionalNotes = MetricInformationFromXLSX(Metric)

            F3EntireMetricMinMaxForLegendMax = -100000000000000   #20231008: change -100000000 to -100000000000 because the geographican entent may be very +/- large
            F3EntireMetricMinMaxForLegendMin =  100000000000000   #20231008: change 100000000 to 100000000000 because the geographican entent may be very +/- large
            for F3EntireMetricMinMaxForLegendInput in F3EntireMetricMinMaxForLegendInputs:
                F3EntireMetricMinMaxForLegendInputFile = open(F3EntireMetricMinMaxForLegendInput)
                MinvalueMaxvalueLine = F3EntireMetricMinMaxForLegendInputFile.readline()  #readline() not readlines()
                print("MinvalueMaxvalueLine=", MinvalueMaxvalueLine,file=open(F3Log, 'a'))
                F3EntireMetricMinMaxForLegendInputMin = float(MinvalueMaxvalueLine.split(",")[0])
                print("F3EntireMetricMinMaxForLegendInputMin=", F3EntireMetricMinMaxForLegendInputMin,file=open(F3Log, 'a'))
                F3EntireMetricMinMaxForLegendInputMax = float(MinvalueMaxvalueLine.split(",")[1])
                print("F3EntireMetricMinMaxForLegendInputMax=", F3EntireMetricMinMaxForLegendInputMax,file=open(F3Log, 'a'))                
                F3EntireMetricMinMaxForLegendInputFile.close()
                Line1 = "The "+Metric+" min from "+F3EntireMetricMinMaxForLegendInput+" is " + str(F3EntireMetricMinMaxForLegendInputMin) + " in unit of "+MetricUnit_US+ ", which is equal to "+str(float(F3EntireMetricMinMaxForLegendInputMin)*UStoSIconversion)+ " in unit of "+MetricUnit_SI + "\n"
                F3EntireMetricMinMaxForLegendFile.write(Line1)
                print(Line1,file=open(F3Log, 'a'))
                Line2 = "The "+Metric+" max from "+F3EntireMetricMinMaxForLegendInput+" is " + str(F3EntireMetricMinMaxForLegendInputMax) + " in unit of "+MetricUnit_US+ ", which is equal to "+str(float(F3EntireMetricMinMaxForLegendInputMax)*UStoSIconversion)+ " in unit of "+MetricUnit_SI + "\n"
                F3EntireMetricMinMaxForLegendFile.write(Line2)
                print(Line2,file=open(F3Log, 'a'))
                if F3EntireMetricMinMaxForLegendInputMin <= F3EntireMetricMinMaxForLegendMin:  #It was < but now <=
                    F3EntireMetricMinMaxForLegendMin = F3EntireMetricMinMaxForLegendInputMin
                if F3EntireMetricMinMaxForLegendInputMax >= F3EntireMetricMinMaxForLegendMax: #It was> but now >=
                    F3EntireMetricMinMaxForLegendMax = F3EntireMetricMinMaxForLegendInputMax
            if OutputUnit == "SI": #added on 20230222
                F3EntireMetricMinMaxForLegendMin = F3EntireMetricMinMaxForLegendMin*UStoSIconversion
                F3EntireMetricMinMaxForLegendMax = F3EntireMetricMinMaxForLegendMax*UStoSIconversion
                Line3 = "With the OutputUnit being "+OutputUnit+", the "+Metric+" final min from all managements and years is " + str(F3EntireMetricMinMaxForLegendMin) + "\n"
                Line4 = "With the OutputUnit being "+OutputUnit+", the "+Metric+" final max from all managements and years is " + str(F3EntireMetricMinMaxForLegendMax) + "\n"                
            if OutputUnit == "Imperial": #added on 20230222
                F3EntireMetricMinMaxForLegendMin = F3EntireMetricMinMaxForLegendMin
                F3EntireMetricMinMaxForLegendMax = F3EntireMetricMinMaxForLegendMax
                Line3 = "With the OutputUnit being "+OutputUnit+", the "+Metric+" final min from all managements and years is " + str(F3EntireMetricMinMaxForLegendMin) + "\n"
                Line4 = "With the OutputUnit being "+OutputUnit+", the "+Metric+" final max from all managements and years is " + str(F3EntireMetricMinMaxForLegendMax) + "\n"                
            print(Line3,file=open(F3Log, 'a'))
            print(Line4,file=open(F3Log, 'a'))
            F3EntireMetricMinMaxForLegendFile.write(Line3)
            F3EntireMetricMinMaxForLegendFile.write(Line4)
            F3EntireMetricMinMaxForLegendFile.close()
            print("Not Existed and F3EntireMetricMinMaxForLegendMin,F3EntireMetricMinMaxForLegendMax=",F3EntireMetricMinMaxForLegendMin,F3EntireMetricMinMaxForLegendMax)
            print("Not Existed and F3EntireMetricMinMaxForLegendMin,F3EntireMetricMinMaxForLegendMax=",F3EntireMetricMinMaxForLegendMin,F3EntireMetricMinMaxForLegendMax,file=open(F3Log, 'a'))
        print("Final F3EntireMetricMinMaxForLegendMin,F3EntireMetricMinMaxForLegendMax=",F3EntireMetricMinMaxForLegendMin,F3EntireMetricMinMaxForLegendMax,file=open(F3Log, 'a'))
        return F3EntireMetricMinMaxForLegendMin,F3EntireMetricMinMaxForLegendMax
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for F3EntireMetricMinMaxForLegend with inputs of " + repr(Metric)+ " with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog

    



def MultipleImageBoundingExtent(SpatialMosaicTifList,Management,Year,Metric):  #This function will return the min and max values of X and Y direction
    try:
        MultipleImageBoundingExtentTxt = os.getcwd()+os.sep+"TilesMosaicRunAverage" + os.sep + ProjectName + os.sep + "MultipleImageBoundingExtent.txt"
        if ((Management == BaseManagement) and (Year == BaseYear) and (Metric == BaseMetric) and (not os.path.exists(MultipleImageBoundingExtentTxt))):
            Mosaic_ulx = []
            Mosaic_uly = []
            Mosaic_lrx = []
            Mosaic_lry = []
            for ThisTif in SpatialMosaicTifList:
                src = gdal.Open(ThisTif)
                cols = src.RasterXSize
                rows = src.RasterYSize
                print("ThisTif=",ThisTif," and the cols and rows are: ",cols,rows)
                upx, xres, xskew, upy, yskew, yres = src.GetGeoTransform()  #https://gis4programmers.wordpress.com/2017/01/06/using-gdal-to-get-raster-extent/, note GetGeoTransform not GetGeotransform
                ulx = float(upx + 0*xres + 0*xskew)
                uly = float(upy + 0*yskew + 0*yres)
                llx = float(upx + 0*xres + rows*xskew)
                lly = float(upy + 0*yskew + rows*yres)
                lrx = float(upx + cols*xres + rows*xskew)
                lry = float(upy + cols*yskew + rows*yres)
                urx = float(upx + cols*xres + 0*xskew)
                ury = float(upy + cols*yskew + 0*yres)
                print("ulx,uly,lrx,lry=",ulx,uly,lrx,lry)
                Mosaic_ulx.append(ulx)
                Mosaic_uly.append(uly)
                Mosaic_lrx.append(lrx)
                Mosaic_lry.append(lry)
            Mosaiculx = min(Mosaic_ulx)
            Mosaiclrx = max(Mosaic_lrx)
            Mosaiculy = max(Mosaic_uly)
            Mosaiclry = min(Mosaic_lry)
            MultipleImageBoundingExtentTxtFile = open(MultipleImageBoundingExtentTxt, 'w')
            LineContent = str(Mosaiculx)+","+str(Mosaiclrx)+","+str(Mosaiculy)+","+str(Mosaiclry)+"\n"
            MultipleImageBoundingExtentTxtFile.write(LineContent)
            MultipleImageBoundingExtentTxtFile.close()
            print(Management,Year,Metric," Mosaiculx,Mosaiclrx,Mosaiculy,Mosaiclry=",Mosaiculx,Mosaiclrx,Mosaiculy,Mosaiclry)
        else:
            MultipleImageBoundingExtentTxtFile = open(MultipleImageBoundingExtentTxt, 'r')
            MultipleImageBoundingExtentLines = MultipleImageBoundingExtentTxtFile.readlines()
            MultipleImageBoundingExtentLines = [i.replace('\n','') for i in MultipleImageBoundingExtentLines] 
            for line in MultipleImageBoundingExtentLines:
                Values = line.split(",")
                Mosaiculx = float(Values[0])
                Mosaiclrx = float(Values[1])
                Mosaiculy = float(Values[2])
                Mosaiclry = float(Values[3])
            MultipleImageBoundingExtentTxtFile.close()
            print(Management,Year,Metric," Mosaiculx,Mosaiclrx,Mosaiculy,Mosaiclry=",Mosaiculx,Mosaiclrx,Mosaiculy,Mosaiclry)    
        return Mosaiculx,Mosaiclrx,Mosaiculy,Mosaiclry        
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for MultipleImageBoundingExtent with inputs of " + repr(SpatialMosaicTifList) + " with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog    








def F3SpatialMosaicZeroInflationAndSpeciesConfidence(mylock,Runs,Tiles,Management,Year,Metric, ProjectAOI=False):  #Note Runs and Tiles, it is not Run and Tile
    try:
        MosaicBestMinIndex = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep + ProjectName + os.sep + "MosaicProcessingPercentageAsOrderAndReliabilityMinIndex.tif"
        IDWthreshold = [0.25,0.35,0.45,0.55,0.65,0.75,0.8,0.9,0.95]  #added on 20240407 to remove the circular phenomenon which may risk plot location confidentality
        Imputed0and1threshold = [0.6,0.55,0.50,0.45,0.40,0.35,0.3,0.2,0.1]  #added on 20240407 to remove the circular phenomenon which may risk plot location confidentality
        print("Note this is only applied to the metrics with 0and1 (i.e. species variables)")
        ThisSpecies = Metric.replace("0and1_0_999","")
        MergedMetricGIS = SpatiallyMosaicMultiplePointGisShapeFiles(Tiles,Management,Year,Metric,ProjectName)
        print("MergedMetricGIS=",MergedMetricGIS)
        if Metric in ContinuousMetrics:
            MosaicArrayFinalFile = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep + ProjectName + os.sep + Management+"_"+Year+"_"+Metric+"_MosaicCellMean.tif"
            print("MosaicArrayFinalFile is ",MosaicArrayFinalFile)
        if Metric in DiscreteMetrics:
            MosaicArrayFinalFile = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep + ProjectName + os.sep + Management+"_"+Year+"_"+Metric+"_MosaicCellMode.tif"
            print("MosaicArrayFinalFile is ",MosaicArrayFinalFile)
        if not os.path.exists(MosaicArrayFinalFile):
            SpatialMosaicTifList = []
            SpatialMosaicTifListIDW = []
            for Run in Runs:
                for Tile in Tiles:
                    print("Chicken Run,Tile=",Run,Tile)
                    Step4OutputTif = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"Results"+os.sep+Management+"_"+Year+"_"+Metric+".tif"
                    print("Step4OutputTif=",Step4OutputTif)
                    Step4OutputTifIDW = os.getcwd()+os.sep+"Run1"+os.sep+Tile+os.sep+"Intermediate"+os.sep+Management+"_"+Year+"_"+Metric+"_IDW.tif"  #IDW are the same for Run1, Run2, and Run3, so I only use one Run here to save the memory
                    if Run == "Run1":
                        CorrespondingSegmentation = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R1_Y"+BaseYear+"_L1_S40_C18.tif"  #We haev different level segmentation, you can choose another one
                    if Run == "Run2":
                        CorrespondingSegmentation = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R2_Y"+BaseYear+"_L1_S32_C19.tif"
                    if Run == "Run3":
                        CorrespondingSegmentation = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R3_Y"+BaseYear+"_L1_S48_C17.tif"
                    if Run == "Run4":
                        CorrespondingSegmentation = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R3_Y"+BaseYear+"_L1_S48_C17.tif"  #We haev different level segmentation, you can choose another one
                    if Run == "Run5":
                        CorrespondingSegmentation = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R1_Y"+BaseYear+"_L1_S40_C18.tif"
                    if Run == "Run6":
                        CorrespondingSegmentation = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R2_Y"+BaseYear+"_L1_S32_C19.tif"     
                    if os.path.exists(Step4OutputTif):
                        Step4OutputTifBorderZshapeTif = MosaicingBorderZshape(CorrespondingSegmentation,Step4OutputTif,0.03,FloatToIntegerCoefficient)
                        Step4OutputTifBorderZshapeTifIDW = MosaicingBorderZshape(CorrespondingSegmentation,Step4OutputTifIDW,0.03,FloatToIntegerCoefficient)
                    else:
                        print("20240214: It is understandable that the ",Step4OutputTif," does not exists (e.g., species absense), so we return here")
                        return   
                    if os.path.exists(Step4OutputTifBorderZshapeTif):
                        SpatialMosaicTifList.append(Step4OutputTifBorderZshapeTif)
                        SpatialMosaicTifListIDW.append(Step4OutputTifBorderZshapeTifIDW)
            SpatialMosaicTifListIDW = [i.lower() for n,i in enumerate(SpatialMosaicTifListIDW) if i not in SpatialMosaicTifListIDW[:n]]  #Unique IDW added on 20240226
            print("SpatialMosaicTifListIDW=",SpatialMosaicTifListIDW)
            if len(SpatialMosaicTifList)%3 != 0:
                MosaicInput = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep + ProjectName + os.sep + Management+"_"+Year+"_"+Metric+"_MosaicInput_Suspicious.txt"
            else:
                MosaicInput = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep + ProjectName + os.sep + Management+"_"+Year+"_"+Metric+"_MosaicInput.txt"
            if not os.path.exists(MosaicInput):
                MosaicInputFile = open(MosaicInput, 'w')
                MosaicTime = "#This mosaic was created by Dr. Shengli Huang at " + datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + " with the following inputs:\n"
                MosaicInputFile.write(MosaicTime)
                for k in SpatialMosaicTifList:
                    ThisLine = k + "\n"
                    MosaicInputFile.write(ThisLine)
                MosaicInputFile.close()
            #SpatialMosaicTifList = [r"C:\F3LinuxGui2_backup20220630\F3unix\Testout\T1.tif",r"C:\F3LinuxGui2_backup20220630\F3unix\Testout\T2.tif"]
            #For each TIF, find their portion in the final extent and assign the values. Other areas are masked out. Then we use numpy.ma statistics (because masked values are ignored)
            #Note: Gdal or RASTERIO have functions of spatial merge; but a) They usually take an ordered image (e.g., first/last) in the overlay area; b) They cannot ignore NodataValue. Mine solved this problem. 
            #As of 20220711, I am not sure if the final result of zero is OK or not

            Mosaiculx,Mosaiclrx,Mosaiculy,Mosaiclry = MultipleImageBoundingExtent(SpatialMosaicTifList,Management,Year,Metric)
            print("for metric=",Metric," Mosaiculx,Mosaiclrx,Mosaiculy,Mosaiclry=", Mosaiculx,Mosaiclrx,Mosaiculy,Mosaiclry, file=open(F3Log, 'a'))
            MosaicColumns = round(abs(Mosaiculx - Mosaiclrx) / F3Resolution)   #change int to round on 20230929: MosaicColumns = int(abs(Mosaiculx - Mosaiclrx) / F3Resolution)
            MosaicRows = round(abs(Mosaiculy - Mosaiclry) / F3Resolution)    #change int to round on 20230929: MosaicRows = int(abs(Mosaiculy - Mosaiclry) / F3Resolution)
            print(Metric," The columns and rows of mosaiced image are: ", MosaicColumns, MosaicRows, file=open(F3Log, 'a'))
            MosaicArray = np.full((len(SpatialMosaicTifList),MosaicRows,MosaicColumns), F3NoDataValue)   #https://stackoverflow.com/questions/5891410/numpy-array-initialization-fill-with-identical-values
            print("len(SpatialMosaicTifListIDW)=",len(SpatialMosaicTifListIDW))
            MosaicArrayIDW = np.full((len(SpatialMosaicTifListIDW),MosaicRows,MosaicColumns), F3NoDataValue)   #https://stackoverflow.com/questions/5891410/numpy-array-initialization-fill-with-identical-values
            print("11111MosaicArrayIDW.shape=",MosaicArrayIDW.shape)
            print(Metric," MosaicArray.shape=",MosaicArray.shape,"\n", file=open(F3Log, 'a'))
            WeUseThisGeoTransform = ([Mosaiculx, F3Resolution, 0, Mosaiculy, 0, -1.0 * F3Resolution ]) #see https://gis.stackexchange.com/questions/165950/gdal-setgeotransform-does-not-work-as-expected
            print(WeUseThisGeoTransform)

            k = -1
            for ThisTif in SpatialMosaicTifList:
                k = k + 1
                src = gdal.Open(ThisTif)
                cols = src.RasterXSize
                rows = src.RasterYSize
                if k == 0:
                    WeUseThisProjection = src.GetProjectionRef()
                    print(WeUseThisProjection)
                print("ThisTif=",ThisTif," and the cols and rows are: ",cols,rows)

                ThisTifArray = src.GetRasterBand(1).ReadAsArray()
                print("ThisTifArray shape is ", ThisTifArray.shape)
                ThisTifNoDataValue = src.GetRasterBand(1).GetNoDataValue()
                print("ThisTifNoDataValue=",ThisTifNoDataValue)
                ThisTifArray = ma.masked_values(ThisTifArray, ThisTifNoDataValue)
                ThisTifArray = ma.masked_values(ThisTifArray, F3NoDataValue)

                #after Zshapeborder, we may change the value according to the outputunit being imperial or SI
                MetricShortName,MetricFullName,MetricDefinition,SpeciesScienticName,USDAPlantCode,FVSKeyword,MetricUnit_US,MetricUnit_SI,UStoSIconversion,MetricShortNameIGivenBy,MetricFullNameIGivenBy,AdditionalNotes = MetricInformationFromXLSX(Metric)
                if OutputUnit == "Imperial": #added on 20230222
                    ThisTifArray = ThisTifArray * 1.0
                if OutputUnit == "SI":
                    ThisTifArray = ThisTifArray * UStoSIconversion
                    
                upx, xres, xskew, upy, yskew, yres = src.GetGeoTransform()  #https://gis4programmers.wordpress.com/2017/01/06/using-gdal-to-get-raster-extent/, note GetGeoTransform not GetGeotransform
                ulx = float(upx + 0*xres + 0*xskew)
                uly = float(upy + 0*yskew + 0*yres)
                llx = float(upx + 0*xres + rows*xskew)
                lly = float(upy + 0*yskew + rows*yres)
                lrx = float(upx + cols*xres + rows*xskew)
                lry = float(upy + cols*yskew + rows*yres)
                urx = float(upx + cols*xres + 0*xskew)
                ury = float(upy + cols*yskew + 0*yres)
                ColumnMin = round(abs(ulx - Mosaiculx) / F3Resolution)  #If the upperleft corner does not align perfectly, we may have problem here. Need to think it over. Also change int to round on 20230929
                ColumnMax = round(abs(lrx - Mosaiculx) / F3Resolution)  #We may +1 here? see https://opensourceoptions.com/blog/zonal-statistics-algorithm-with-python-in-4-steps/. Also change int to round on 20230929
                RowMin = round(abs(uly - Mosaiculy) / F3Resolution)  #change int to round on 20230929
                RowMax = round(abs(lry - Mosaiculy) / F3Resolution)   #We may +1 here? but I prefer not, because this is just mosaic, I do not care of missin gone pixel. Also change int to round on 20230929
                #print("ColumnMin,ColumnMax,RowMin,RowMax=",ColumnMin,ColumnMax,RowMin,RowMax, file=open(F3Log, 'a'))
                MosaicArray[k,RowMin:RowMax,ColumnMin:ColumnMax] = ThisTifArray  #remember the k is so important
                src = None   #20230323 added: In os.remove() below, we had "PermissionError: [WinError 32] The process cannot access the file because it is being used by another process, see https://gis.stackexchange.com/questions/80366/why-close-a-dataset-in-gdal-python
            print(Metric," MosaicArray shape is ", MosaicArray.shape)
            MosaicArrayMasked = ma.masked_values(MosaicArray, F3NoDataValue)  
            print("MosaicArrayMasked.shape=",MosaicArrayMasked.shape)


            print("SpatialMosaicTifListIDW=",SpatialMosaicTifListIDW)
            print("222222MosaicArrayIDW.shape=",MosaicArrayIDW.shape)
            k = -1
            for ThisTif in SpatialMosaicTifListIDW:
                print("IDW ThisTif=", ThisTif)
                k = k + 1
                src = gdal.Open(ThisTif)
                cols = src.RasterXSize
                rows = src.RasterYSize
                if k == 0:
                    WeUseThisProjection = src.GetProjectionRef()
                    print(WeUseThisProjection)
                print("ThisTif=",ThisTif," and the cols and rows are: ",cols,rows)

                ThisTifArray = src.GetRasterBand(1).ReadAsArray()
                print("ThisTifArray shape is ", ThisTifArray.shape)
                ThisTifNoDataValue = src.GetRasterBand(1).GetNoDataValue()
                print("ThisTifNoDataValue=",ThisTifNoDataValue)
                ThisTifArray = ma.masked_values(ThisTifArray, ThisTifNoDataValue)
                ThisTifArray = ma.masked_values(ThisTifArray, F3NoDataValue)

                upx, xres, xskew, upy, yskew, yres = src.GetGeoTransform()  #https://gis4programmers.wordpress.com/2017/01/06/using-gdal-to-get-raster-extent/, note GetGeoTransform not GetGeotransform
                ulx = float(upx + 0*xres + 0*xskew)
                uly = float(upy + 0*yskew + 0*yres)
                llx = float(upx + 0*xres + rows*xskew)
                lly = float(upy + 0*yskew + rows*yres)
                lrx = float(upx + cols*xres + rows*xskew)
                lry = float(upy + cols*yskew + rows*yres)
                urx = float(upx + cols*xres + 0*xskew)
                ury = float(upy + cols*yskew + 0*yres)
                ColumnMin = round(abs(ulx - Mosaiculx) / F3Resolution)  #If the upperleft corner does not align perfectly, we may have problem here. Need to think it over. Also change int to round on 20230929
                ColumnMax = round(abs(lrx - Mosaiculx) / F3Resolution)  #We may +1 here? see https://opensourceoptions.com/blog/zonal-statistics-algorithm-with-python-in-4-steps/. Also change int to round on 20230929
                RowMin = round(abs(uly - Mosaiculy) / F3Resolution)  #change int to round on 20230929
                RowMax = round(abs(lry - Mosaiculy) / F3Resolution)   #We may +1 here? but I prefer not, because this is just mosaic, I do not care of missin gone pixel. Also change int to round on 20230929
                #print("ColumnMin,ColumnMax,RowMin,RowMax=",ColumnMin,ColumnMax,RowMin,RowMax, file=open(F3Log, 'a'))
                MosaicArrayIDW[k,RowMin:RowMax,ColumnMin:ColumnMax] = ThisTifArray  #remember the k is so important
                src = None   #20230323 added: In os.remove() below, we had "PermissionError: [WinError 32] The process cannot access the file because it is being used by another process, see https://gis.stackexchange.com/questions/80366/why-close-a-dataset-in-gdal-python
            MosaicArrayMaskedIDW = ma.masked_values(MosaicArrayIDW, F3NoDataValue)  
            print("0and1 IDW here")
            
            if Metric in ContinuousMetrics:
                t00 = time.time()
                if MosaicCandidateChosen == "Mean":
                    MosaicArrayFinalAAA = np.nanmean(MosaicArrayMasked,axis=0)
                    MosaicArrayFinalAAA = ma.masked_values(MosaicArrayFinalAAA, F3NoDataValue)
                    MosaicArrayFinalSTD = np.nanstd(MosaicArrayMasked,axis=0)
                    MosaicArrayFinalSTD = ma.masked_values(MosaicArrayFinalSTD, F3NoDataValue)
                if MosaicCandidateChosen == "Best":  #20240506. This is six runs best which is based on the reliabilty order value (lower value means imputation earlier leads to more trust)
                    MosaicBestMinIndexArray = ReadTifToArray(MosaicBestMinIndex)
                    MosaicBestMinIndexArray = ma.masked_values(MosaicBestMinIndexArray, F3NoDataValue)
                    MosaicBestMinIndexArrayUnique = np.unique(MosaicBestMinIndexArray)
                    MosaicBestMinIndexArrayUnique = MosaicBestMinIndexArrayUnique[~MosaicBestMinIndexArrayUnique.mask]
                    MosaicBestMinIndexArrayUnique = [int(x) for x in MosaicBestMinIndexArrayUnique if x is not None]
                    print("MosaicBestMinIndexArrayUnique=",MosaicBestMinIndexArrayUnique)
                    for h in MosaicBestMinIndexArrayUnique:
                        MosaicBestMinIndexArray[MosaicBestMinIndexArray == h] = MosaicArrayMasked[h,:,:][MosaicBestMinIndexArray == h]
                    MosaicArrayFinalAAA = MosaicBestMinIndexArray
                    MosaicArrayFinalAAA = ma.masked_values(MosaicArrayFinalAAA, F3NoDataValue)
                    MosaicArrayFinalSTD = np.nanstd(MosaicArrayMasked,axis=0)
                    MosaicArrayFinalSTD = ma.masked_values(MosaicArrayFinalSTD, F3NoDataValue)
                print(Metric," is ContinuousMetrics and the nanmean function during spatial mosaicing222 took \t" + str(int((time.time() - t00)/60))," minutes")
                print(Metric," is ContinuousMetrics and the nanmean function during spatial mosaicing222 took \t" + str(int((time.time() - t00)/60))," minutes", file=open(F3Log, 'a'))

            if Metric in DiscreteMetrics:
                print("There is no function of np.nanmode with axis=0. MosaicArrayFinalAAA = mode(MosaicArrayMasked, axis=0) does not work at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
                print("There is no function of np.nanmode with axis=0. MosaicArrayFinalAAA = mode(MosaicArrayMasked, axis=0) does not work at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"), file=open(F3Log, 'a'))
                t000 = time.time()
                MosaicArrayFinalAAA = np.full((MosaicRows,MosaicColumns), F3NoDataValue)
                MosaicArrayFinalModeCountExcludingNAN = np.full((MosaicRows,MosaicColumns), F3NoDataValue)  

                #as of 20240204, we hae problems in mode because the scipy version is 1.11.4 which is different from 1.6.2 when the code was deveoped---start
                MosaicArrayFinalAAA000 = mode(MosaicArrayMasked, axis=0, nan_policy='omit',keepdims=True)  #https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.mode.html, and https://pythonguides.com/python-scipy-stats-mode/#:~:text=Python%20Scipy%20Stats%20Mode%20Example%20The%20output%20of,comparison%20to%20other%20numbers%20in%20the%20whole%20array.
                
                MosaicArrayFinalAAA = MosaicArrayFinalAAA000[0]   #MosaicArrayFinalAAA000.mode is the same as MosaicArrayFinalAAA000[0]
                print("MosaicArrayFinalAAA.shape=",MosaicArrayFinalAAA.shape, file=open(F3Log, 'a'))
                #>>>import scipy >>> scipy.__version__, we can get the version '1.11.4' as of 20240204.
                MosaicArrayFinalAAA = MosaicArrayFinalAAA[0,:,:]  #"As of 20221027, our Scipy is 1.6.2 and cannot use keepdims dimention. Scipy 1.9.3 is OK for that. This will cause the array shape to be [1,cols,rows]"
                print("MosaicArrayFinalAAA.shape=",MosaicArrayFinalAAA.shape,file=open(F3Log, 'a'))
                
                MosaicArrayFinalModeCountExcludingNAN = MosaicArrayFinalAAA000[1]  #MosaicArrayFinalAAA000[1] is the same as MosaicArrayFinalAAA000.count
                MosaicArrayFinalModeCountExcludingNAN = MosaicArrayFinalModeCountExcludingNAN[0,:,:]  #This is why we need an extra step here to convert shape from [1,cols,rows] to [cols,rows]. In the future, we may have to change here based on new Scipy version
                print(Metric," is discrete and the mode function during spatial mosaicing111 took \t",str(int((time.time() - t000)/60))," minutes")
                print(Metric," is discrete and the mode function during spatial mosaicing111 took \t",str(int((time.time() - t000)/60))," minutes", file=open(F3Log, 'a'))
                #as of 20240204, we hae problems in mode because the scipy version is 1.11.4 which is different from 1.6.2 when the code was deveoped---end
                NumberOfUnmaskedElement = MosaicArrayMasked.count(axis=0)
                MosaicArrayFinalSTD = (1000000.0 * (NumberOfUnmaskedElement - MosaicArrayFinalModeCountExcludingNAN) / NumberOfUnmaskedElement)
                #When mosaicing, I want to get the value = ModeCount/TotalCount, whose larger values indicating better majority. Note I multiply 1000000.0 to store a smaller data--end
                print(Metric," is discrete and the mode function during spatial mosaicing222 took \t" + str(int((time.time() - t000)/60))," minutes")
                print(Metric," is discrete and the mode function during spatial mosaicing222 took \t" + str(int((time.time() - t000)/60))," minutes", file=open(F3Log, 'a'))
            print(Metric," Runs,Tiles,Management,Year,Metric=",Runs,Tiles,Management,Year,Metric)
            SpatialMetricMin,SpatialMetricMax = F3SpatialMosaicMetricMinMax(Runs,Tiles,Management,Year,Metric)
            MosaicArrayFinal = MosaicArrayFinalAAA.copy()


            #added 20240223: This is to use MosaicHalfOfCutthresholdMinusMin and MosaicCutthreshold to adjust the result---start
            print("Do we realy need IDW i this part? I do not think so so far")
            MosaicMetricMinValue,MosaicHalfOfCutthresholdMinusMin,MosaicCutthreshold,MosaicMetricMaxValue = F3SpatialMosaicMetricMinAndCutThreshValue(Runs,Tiles,Management,Year,Metric)
            print("MosaicMetricMinValue,MosaicHalfOfCutthresholdMinusMin,MosaicCutthreshold,MosaicMetricMaxValue=",MosaicMetricMinValue,MosaicHalfOfCutthresholdMinusMin,MosaicCutthreshold,MosaicMetricMaxValue, file=open(F3Log, 'a'))
            print("MosaicMetricMinValue,MosaicHalfOfCutthresholdMinusMin,MosaicCutthreshold,MosaicMetricMaxValue=",MosaicMetricMinValue,MosaicHalfOfCutthresholdMinusMin,MosaicCutthreshold,MosaicMetricMaxValue)
            MosaicArrayFinal[MosaicArrayFinalAAA <= MosaicHalfOfCutthresholdMinusMin] = MosaicMetricMinValue
            MosaicArrayFinal[(MosaicArrayFinalAAA > MosaicHalfOfCutthresholdMinusMin) & (MosaicArrayFinalAAA < MosaicCutthreshold)] = MosaicCutthreshold
            MosaicArrayFinal[MosaicArrayFinalAAA >= MosaicMetricMaxValue] = MosaicMetricMaxValue
            #added 20240223: This is to use MosaicHalfOfCutthresholdMinusMin and MosaicCutthreshold to adjust the result---end
            
            
            MosaicArrayFinal = ma.masked_values(MosaicArrayFinal, F3NoDataValue)  #https://numpy.org/doc/stable/reference/generated/numpy.ma.masked_values.html#numpy.ma.masked_values
            MosaicArrayFinalSTD = ma.masked_values(MosaicArrayFinalSTD, F3NoDataValue)
            print(Metric," MosaicArrayFinal shape is ", MosaicArrayFinal.shape, file=open(F3Log, 'a'))
            MosaicArrayFinalIDW = np.nanmean(MosaicArrayMaskedIDW,axis=0)
            MosaicArrayFinalSTDIDW = np.nanstd(MosaicArrayMaskedIDW,axis=0)
            #print("MosaicArrayFinal = ",MosaicArrayFinal)

            #We add the ProjectAOI here to subset the output TIF. --start
            print("?????????????????ProjectAOI=",ProjectAOI, file=open(F3Log, 'a'))
            if ProjectAOI:  #The general idea is to find the overlay but minimum corners and then indexing array
                output_tiff, RowMin_ForMosaic,RowMax_ForMosaic,ColumnMin_ForMosaic,ColumnMax_ForMosaic,CommonOverlay_ulx, CommonOverlay_lrx, CommonOverlay_uly, CommonOverlay_lry = ShapeAndRasterOverlayExtent(ProjectAOI,False,Mosaiculx,Mosaiclrx,Mosaiculy,Mosaiclry)  
                print(Metric," ProjectAOI RowMin_ForMosaic,RowMax_ForMosaic,ColumnMin_ForMosaic,ColumnMax_ForMosaic=",RowMin_ForMosaic,RowMax_ForMosaic,ColumnMin_ForMosaic,ColumnMax_ForMosaic, file=open(F3Log, 'a'))

                ForMosaic_CommonOverlay = MosaicArrayFinal[RowMin_ForMosaic:RowMax_ForMosaic,ColumnMin_ForMosaic:ColumnMax_ForMosaic]
                ForMosaic_CommonOverlay_STD = MosaicArrayFinalSTD[RowMin_ForMosaic:RowMax_ForMosaic,ColumnMin_ForMosaic:ColumnMax_ForMosaic]
                print(Metric," ForMosaic_CommonOverlay shape is ", ForMosaic_CommonOverlay.shape, file=open(F3Log, 'a'))
                ForMosaic_CommonOverlayIDW = MosaicArrayFinalIDW[RowMin_ForMosaic:RowMax_ForMosaic,ColumnMin_ForMosaic:ColumnMax_ForMosaic]   #added on 20240226
                ForMosaic_CommonOverlay_STDIDW = MosaicArrayFinalSTDIDW[RowMin_ForMosaic:RowMax_ForMosaic,ColumnMin_ForMosaic:ColumnMax_ForMosaic]   #added on 20240226

                driverTiff = gdal.GetDriverByName('GTiff')
                ds = gdal.Open(output_tiff)
                srcCols = ds.RasterXSize
                srcRows = ds.RasterYSize
                WeUseThisProjection = ds.GetProjectionRef()
                WeUseThisGeoTransform = ds.GetGeoTransform()
                output_tiff_masked = ReadTifToArray(output_tiff)
                print(Metric,"output_tiff_masked shape is ", output_tiff_masked.shape, file=open(F3Log, 'a'))
                ForMosaic_CommonOverlay[output_tiff_masked.mask] = F3NoDataValue
                ForMosaic_CommonOverlay_STD[output_tiff_masked.mask] = F3NoDataValue
                print(Metric,"After masked, ForMosaic_CommonOverlay shape is ", ForMosaic_CommonOverlay.shape, file=open(F3Log, 'a'))
                MosaicArrayFinal = ForMosaic_CommonOverlay
                MosaicArrayFinalSTD = ForMosaic_CommonOverlay_STD
                MosaicColumns = srcCols
                MosaicRows = srcRows

                ForMosaic_CommonOverlayIDW[output_tiff_masked.mask] = F3NoDataValue   #added on 20240226
                ForMosaic_CommonOverlay_STDIDW[output_tiff_masked.mask] = F3NoDataValue   #added on 20240226                
                MosaicArrayFinalIDW = ForMosaic_CommonOverlayIDW   #added on 20240226
                MosaicArrayFinalSTDIDW = ForMosaic_CommonOverlay_STDIDW   #added on 20240226
            #We add the ProjectAOI here to subset the output TIF. --end
                   
            TypeOfInterest = OutputDataType(SpatialMetricMin, SpatialMetricMax)
            print("OutputDataType of SpatialMosaicZeroInflationAndSpeciesConfidence for ",Management,Year,Metric," is ",TypeOfInterest)
            print("OutputDataType of SpatialMosaicZeroInflationAndSpeciesConfidence for ",Management,Year,Metric," is ",TypeOfInterest, file=open(F3Log, 'a'))

            #This is for Raw without windows 3x3 smoothing---start
            SaveRawWithoutWindows3x3Smoothing = "Yes" #Yes or No. Note the Windows3x3Smoothing will remove the "direct" imputation, which is sensative to the risk of FIA plot location 
            if ((SaveRawWithoutWindows3x3Smoothing == "Yes") or ((Management == BaseManagement) and (Year == BaseYear) and (Metric == BaseMetric))):
                MosaicArrayFinal_1 = MosaicArrayFinal.copy()                

                ##This section creates species ZeroInflation.tif---start
                MosaicArrayFinal_1 = ma.masked_values(MosaicArrayFinal_1, F3NoDataValue)
                MosaicArrayFinalIDW = ma.masked_values(MosaicArrayFinalIDW, F3NoDataValue)
                
                for k in range(0,len(IDWthreshold),1):
                    MosaicArrayFinal_1[(~MosaicArrayFinal_1.mask) & (MosaicArrayFinalIDW <= int(IDWthreshold[k]*FloatToIntegerCoefficient)) & (MosaicArrayFinal_1 <= int(Imputed0and1threshold[k]*FloatToIntegerCoefficient))] = 0  #The value zero will be used by the process later, so be consistent!   #0 means we will assign species absence in this area with value=0. I found When species 0 and 1 are IDW, those absent area are usually with IDW value < 0.25 * FloatToIntegerCoefficient

                MosaicArrayFinal_1 = ma.masked_values(MosaicArrayFinal_1, F3NoDataValue)
                ##This section creates species ZeroInflation.tif---end

                driver = gdal.GetDriverByName("GTiff")
                if OutputGeoTifCompression == "Yes": #Added on 20230227. LZW compression does not lose information. LZW compression is a lossless data compression algorithm, which means that the original data can be fully reconstructed from the compressed data without any loss of information.
                    outdata = driver.Create(MosaicArrayFinalFile, MosaicColumns, MosaicRows, 1, TypeOfInterest, options=['COMPRESS=LZW'])   #see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
                if OutputGeoTifCompression == "No": 
                    outdata = driver.Create(MosaicArrayFinalFile, MosaicColumns, MosaicRows, 1, TypeOfInterest)   #see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
                print("SetGeoTransform and SetProjection usage, see http://www2.geog.ucl.ac.uk/~plewis/geogg122_local/geogg122-old/Chapter4_GDAL/GDAL_Python_bindings.html")
                outdata.SetGeoTransform(WeUseThisGeoTransform)  
                outdata.SetProjection(WeUseThisProjection)
                outdata.GetRasterBand(1).WriteArray(MosaicArrayFinal_1)
                outdata.GetRasterBand(1).SetNoDataValue(F3NoDataValue)   
                outdata.FlushCache()  
                outdata = None
                print("$$$$$$$$$$$$$$$$$$$$$$$$$$$$$1 ",MosaicArrayFinalFile, " is created")
                F3SpatialMosaicTifMetadataFile = F3SpatialMosaicTifMetadata(Runs,Tiles,Management,Year,Metric,FloatToIntegerCoefficient,"No")  #The last argument is SmootheringYesOrNo                           
                QuicklookImage = ContinuousSingleBandQuickLookGeotifPseudoColorImage(MosaicArrayFinalFile,2,"CommandArgument",SpatialMetricMin,SpatialMetricMax,Metric)  #Creating a reduce color image
                print("QuicklookImage=",QuicklookImage)

                if EncryptSensitiveFile == "Yes":
                    MosaicArrayFinalFile = EncryptImage(MosaicArrayFinalFile)
            #This is for Raw without windows 3x3 smoothing---end


            AddWindow3x3MovingAverage = "Yes"  #It is suggested that we always use Yes here.
            if (AddWindow3x3MovingAverage == "Yes"):
                #This is for for adding WindowsAveraging based on windows 3x3 smoothing---start
                MosaicArrayFinalFile = MosaicArrayFinalFile.replace(".tif","_Win3x3Smoothing.tif")   #remove Win3x3
                MosaicArrayFinal_1 = Array3x3MovingAverageAndLowHighBound(MosaicArrayFinal, Metric, "mean", SpatialMetricMin, SpatialMetricMax, F3NoDataValue)  #3x3 moving window average

                #Added on 20240407 to assure the Win3x3Averge also reflects the Cutthreshold rule as NotWin3x3Averge---start
                print("ZeroInflation windows 3x3 smoothing MosaicMetricMinValue,MosaicHalfOfCutthresholdMinusMin,MosaicCutthreshold,MosaicMetricMaxValue=",MosaicMetricMinValue,MosaicHalfOfCutthresholdMinusMin,MosaicCutthreshold,MosaicMetricMaxValue, file=open(F3Log, 'a'))
                print("ZeroInflation windows 3x3 smoothing MosaicMetricMinValue,MosaicHalfOfCutthresholdMinusMin,MosaicCutthreshold,MosaicMetricMaxValue=",MosaicMetricMinValue,MosaicHalfOfCutthresholdMinusMin,MosaicCutthreshold,MosaicMetricMaxValue)
                MosaicArrayFinal_1[MosaicArrayFinal_1 <= MosaicHalfOfCutthresholdMinusMin] = MosaicMetricMinValue
                MosaicArrayFinal_1[(MosaicArrayFinal_1 > MosaicHalfOfCutthresholdMinusMin) & (MosaicArrayFinalAAA < MosaicCutthreshold)] = MosaicCutthreshold
                MosaicArrayFinal_1[MosaicArrayFinal_1 >= MosaicMetricMaxValue] = MosaicMetricMaxValue
                #Added on 20240407 to assure the Win3x3Averge also reflects the Cutthreshold rule as NotWin3x3Averge---end

                #This section creates species ZeroInflation.tif---start
                MosaicArrayFinal_1 = ma.masked_values(MosaicArrayFinal_1, F3NoDataValue)
                MosaicArrayFinalIDW = ma.masked_values(MosaicArrayFinalIDW, F3NoDataValue)

                ##20240412: I changed MosaicArrayFinal_1 to MosaicArrayFinal, because I want to make windows3x3 and Notwindows3x3 consistent regarding the pixels assigned to 0---start
                for k in range(0,len(IDWthreshold),1):
                    MosaicArrayFinal_1[(~MosaicArrayFinal.mask) & (MosaicArrayFinalIDW <= int(IDWthreshold[k]*FloatToIntegerCoefficient)) & (MosaicArrayFinal <= int(Imputed0and1threshold[k]*FloatToIntegerCoefficient))] = 0  #The value zero will be used by the process later, so be consistent!   #0 means we will assign species absence in this area with value=0. I found When species 0 and 1 are IDW, those absent area are usually with IDW value < 0.25 * FloatToIntegerCoefficient
                ##20240412: I changed MosaicArrayFinal_1 to MosaicArrayFinal, because I want to make windows3x3 and Notwindows3x3 consistent regarding the pixels assigned to 0---end

                MosaicArrayFinal_1 = ma.masked_values(MosaicArrayFinal_1, F3NoDataValue)
                #This section creates species ZeroInflation.tif---end
                
                driver = gdal.GetDriverByName("GTiff")
                if OutputGeoTifCompression == "Yes": #Added on 20230227. LZW compression does not lose information. LZW compression is a lossless data compression algorithm, which means that the original data can be fully reconstructed from the compressed data without any loss of information.
                    outdata = driver.Create(MosaicArrayFinalFile, MosaicColumns, MosaicRows, 1, TypeOfInterest, options=['COMPRESS=LZW'])   #see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
                if OutputGeoTifCompression == "No": 
                    outdata = driver.Create(MosaicArrayFinalFile, MosaicColumns, MosaicRows, 1, TypeOfInterest)   #see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
                print("SetGeoTransform and SetProjection usage, see http://www2.geog.ucl.ac.uk/~plewis/geogg122_local/geogg122-old/Chapter4_GDAL/GDAL_Python_bindings.html")
                outdata.SetGeoTransform(WeUseThisGeoTransform)  
                outdata.SetProjection(WeUseThisProjection)
                outdata.GetRasterBand(1).WriteArray(MosaicArrayFinal_1)
                outdata.GetRasterBand(1).SetNoDataValue(F3NoDataValue)   
                outdata.FlushCache()  
                outdata = None
                print("$$$$$$$$$$$$$$$$$$$$$$$$$$$$$2 ",MosaicArrayFinalFile, " is created")
                F3SpatialMosaicTifMetadataFile = F3SpatialMosaicTifMetadata(Runs,Tiles,Management,Year,Metric,FloatToIntegerCoefficient,"Yes")  #The last argument is SmootheringYesOrNo            
                print("&&&&&&&&&&&&&&&&&&&&&&&SpatialMetricMin,SpatialMetricMax=",SpatialMetricMin,SpatialMetricMax, file=open(F3Log, 'a'))
                QuicklookImage = ContinuousSingleBandQuickLookGeotifPseudoColorImage(MosaicArrayFinalFile,2,"CommandArgument",SpatialMetricMin,SpatialMetricMax,Metric)  #Creating a reduce color image
                print("QuicklookImage=",QuicklookImage)
                #This is for for adding WindowsAveraging based on windows 3x3 smoothing---end
            if Metric in ContinuousMetrics:
                MosaicArrayFinalSTDFile = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep + ProjectName + os.sep + Management+"_"+Year+"_"+Metric+"_MosaicCellStd_Win3x3Smoothing.tif"
            if Metric in DiscreteMetrics:
                MosaicArrayFinalSTDFile = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep + ProjectName + os.sep + Management+"_"+Year+"_"+Metric+"_MosaicCellNonModePercentageTimes1000000_Win3x3Smoothing.tif"
            driver = gdal.GetDriverByName("GTiff")
            if "PercentageTimes1000000" in MosaicArrayFinalSTDFile:
                TypeOfInterest = gdal.GDT_Int32  #not "gdal.GDT_Int32"

            #20230203: Because the MosaicArrayFinalSTD has sensitive information about FIA plot location (e.g., std=0 for the location pixel), I use a 3x3window to smoother it---start
            MosaicArrayFinalSTD[MosaicArrayFinal.mask] = F3NoDataValue  #added on 20230210 to remove those negatuve pixels (e.g., -2456) caused by 3x3 moving window
            MosaicArrayFinalSTD = ma.masked_values(MosaicArrayFinalSTD, F3NoDataValue) #added on 20230210 to remove those negatuve pixels (e.g., -2456) caused by 3x3 moving window
            MovingWindowArrayList = np.ma.array([MosaicArrayFinalSTD[1:-1,1:-1], MosaicArrayFinalSTD[:-2,1:-1], MosaicArrayFinalSTD[2:,1:-1], MosaicArrayFinalSTD[1:-1,:-2], MosaicArrayFinalSTD[1:-1,2:], MosaicArrayFinalSTD[2:,2:], MosaicArrayFinalSTD[:-2,:-2], MosaicArrayFinalSTD[2:,:-2], MosaicArrayFinalSTD[:-2,2:]])  #20230214: we must use np.ma.array not np.array, because the latter one cannot ignore nan
            MosaicArrayFinalSTD[1:-1, 1:-1] = np.nanmean(MovingWindowArrayList,axis=0)  #This return the mean by ignoring the nan element
            MosaicArrayFinalSTD[MosaicArrayFinal.mask] = F3NoDataValue   #added on 20230210 to remove those negatuve pixels (e.g., -2456) caused by 3x3 moving window
            #20230203: Because the MosaicArrayFinalSTD has sensitive information about FIA plot location (e.g., std=0 for the location pixel), I use a 3x3window to smoother it---end

            if OutputGeoTifCompression == "Yes": #Added on 20230227. LZW compression does not lose information. LZW compression is a lossless data compression algorithm, which means that the original data can be fully reconstructed from the compressed data without any loss of information.
                outdataSTD = driver.Create(MosaicArrayFinalSTDFile, MosaicColumns, MosaicRows, 1, TypeOfInterest, options=['COMPRESS=LZW'])   #see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
            if OutputGeoTifCompression == "No": 
                outdataSTD = driver.Create(MosaicArrayFinalSTDFile, MosaicColumns, MosaicRows, 1, TypeOfInterest)   #see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
            print("SetGeoTransform and SetProjection usage, see http://www2.geog.ucl.ac.uk/~plewis/geogg122_local/geogg122-old/Chapter4_GDAL/GDAL_Python_bindings.html")
            outdataSTD.SetGeoTransform(WeUseThisGeoTransform)  
            outdataSTD.SetProjection(WeUseThisProjection)            
            outdataSTD.GetRasterBand(1).WriteArray(MosaicArrayFinalSTD)
            outdataSTD.GetRasterBand(1).SetNoDataValue(F3NoDataValue)   
            outdataSTD.FlushCache()  
            outdataSTD = None
            print(MosaicArrayFinalSTDFile, " is created")


            #Added on 20230205 to change the output datatype---start
            #20240201: Per Marla's request, we need the confidence layer of each species. Note if 0 and 1, then imputation=0 or imputation=1 is the best while imputation=0.5 is the worst. Other linear interpolation---start
            if "0and1_" in Metric:   #0and1 means it is a species absence 0 and presence 1. Assuming FloatToIntegerCoefficient=100, the confidence formular is: if x=50, then y=50, if x<50, then y=2(50-x); if x>50, then y=2(x-50)
                if AddWindow3x3MovingAverage == "Yes":
                    MosaicArraySpeciesConfidenceFile = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep + ProjectName + os.sep + Management+"_"+Year+"_"+ThisSpecies+"_Win3x3Smoothing_Confidence.tif"
                    Mosaic0and1ConfidenceArray = MosaicArrayFinal_1.copy()
                    MosaicArrayFinal_1 = ma.masked_values(MosaicArrayFinal_1, F3NoDataValue)
                    MosaicArrayFinalIDW = ma.masked_values(MosaicArrayFinalIDW, F3NoDataValue)
                    #Mosaic0and1ConfidenceArray[(~MosaicArrayFinal_1.mask) & (MosaicArrayFinalIDW <= int(0.25*FloatToIntegerCoefficient)) & (MosaicArrayFinal_1 <= int(0.50*FloatToIntegerCoefficient))] = 0  #added on 20240221
                    #Mosaic0and1ConfidenceArray[(~MosaicArrayFinal_1.mask) & (MosaicArrayFinalIDW > int(0.25*FloatToIntegerCoefficient)) & (MosaicArrayFinalIDW <= int(0.45*FloatToIntegerCoefficient)) & (MosaicArrayFinal_1 <= int(0.15*FloatToIntegerCoefficient))] = 0  #added on 20240311

                    for k in range(0,len(IDWthreshold),1):
                        Mosaic0and1ConfidenceArray[(~MosaicArrayFinal_1.mask) & (MosaicArrayFinalIDW <= int(IDWthreshold[k]*FloatToIntegerCoefficient)) & (MosaicArrayFinal_1 <= int(Imputed0and1threshold[k]*FloatToIntegerCoefficient))] = 0  #added on 20240221

                    Mosaic0and1ConfidenceArray[(~MosaicArrayFinal_1.mask) & (MosaicArrayFinal_1 == int(0.5 * FloatToIntegerCoefficient))] = 0   #When x=50, y=0 (i.e., if 0-1, then 0.5 is the worst confidence=0.  
                    Mosaic0and1ConfidenceArray[(~MosaicArrayFinal_1.mask) & (MosaicArrayFinal_1 < int(0.50*FloatToIntegerCoefficient))] = 2 * (int(0.5*FloatToIntegerCoefficient) - Mosaic0and1ConfidenceArray[(~MosaicArrayFinal_1.mask) & (MosaicArrayFinal_1 < int(0.50*FloatToIntegerCoefficient))])   
                    Mosaic0and1ConfidenceArray[(~MosaicArrayFinal_1.mask) & (MosaicArrayFinal_1 > int(0.50*FloatToIntegerCoefficient))] = 2 * (Mosaic0and1ConfidenceArray[(~MosaicArrayFinal_1.mask) & (MosaicArrayFinal_1 > int(0.50*FloatToIntegerCoefficient))] - int(0.5*FloatToIntegerCoefficient))                    
                    Mosaic0and1ConfidenceArray = np.ma.masked_array(Mosaic0and1ConfidenceArray, F3NoDataValue)
                else:
                    MosaicArraySpeciesConfidenceFile = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep + ProjectName + os.sep + Management+"_"+Year+"_"+ThisSpecies+"_Confidence.tif"   #As of 20240506, I found confidence = -100, which is not right. I need to find the reason (maybe float == problem?)
                    Mosaic0and1ConfidenceArray = MosaicArrayFinal.copy()
                    MosaicArrayFinal = ma.masked_values(MosaicArrayFinal, F3NoDataValue)
                    MosaicArrayFinalIDW = ma.masked_values(MosaicArrayFinalIDW, F3NoDataValue)
                    #Mosaic0and1ConfidenceArray[(~MosaicArrayFinal.mask) & (MosaicArrayFinalIDW <= int(0.25*FloatToIntegerCoefficient)) & (MosaicArrayFinal_1 <= int(0.50*FloatToIntegerCoefficient))] = 0  #added on 20240221
                    #Mosaic0and1ConfidenceArray[(~MosaicArrayFinal.mask) & (MosaicArrayFinalIDW > int(0.25*FloatToIntegerCoefficient)) & (MosaicArrayFinalIDW <= int(0.45*FloatToIntegerCoefficient)) & (MosaicArrayFinal_1 <= int(0.15*FloatToIntegerCoefficient))] = 0  #added on 20240311

                    for k in range(0,len(IDWthreshold),1):
                        Mosaic0and1ConfidenceArray[(~MosaicArrayFinal.mask) & (MosaicArrayFinalIDW <= int(IDWthreshold[k]*FloatToIntegerCoefficient)) & (MosaicArrayFinal_1 <= int(Imputed0and1threshold[k]*FloatToIntegerCoefficient))] = 0  #added on 20240221

                    Mosaic0and1ConfidenceArray[(~MosaicArrayFinal.mask) & (MosaicArrayFinal == int(0.5 * FloatToIntegerCoefficient))] = 0   #When x=50, y=0 (i.e., if 0-1, then 0.5 is the worst confidence=0.  
                    Mosaic0and1ConfidenceArray[(~MosaicArrayFinal.mask) & (MosaicArrayFinal < int(0.50*FloatToIntegerCoefficient))] = 2 * (int(0.5*FloatToIntegerCoefficient) - Mosaic0and1ConfidenceArray[(~MosaicArrayFinal.mask) & (MosaicArrayFinal < int(0.50*FloatToIntegerCoefficient))])   
                    Mosaic0and1ConfidenceArray[(~MosaicArrayFinal.mask) & (MosaicArrayFinal > int(0.50*FloatToIntegerCoefficient))] = 2 * (Mosaic0and1ConfidenceArray[(~MosaicArrayFinal.mask) & (MosaicArrayFinal > int(0.50*FloatToIntegerCoefficient))] - int(0.5*FloatToIntegerCoefficient))                    
                    Mosaic0and1ConfidenceArray = np.ma.masked_array(Mosaic0and1ConfidenceArray, F3NoDataValue)
                Mosaic0and1ConfidenceArrayMin = np.nanmin(Mosaic0and1ConfidenceArray)
                Mosaic0and1ConfidenceArrayMax = np.nanmax(Mosaic0and1ConfidenceArray)                
                TypeOfInterest = OutputDataType(Mosaic0and1ConfidenceArrayMin, Mosaic0and1ConfidenceArrayMax)
                driver = gdal.GetDriverByName("GTiff")
                outdata = driver.Create(MosaicArraySpeciesConfidenceFile, MosaicColumns, MosaicRows, 1, TypeOfInterest, options=['COMPRESS=LZW'])   #see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
                print("SetGeoTransform and SetProjection usage, see http://www2.geog.ucl.ac.uk/~plewis/geogg122_local/geogg122-old/Chapter4_GDAL/GDAL_Python_bindings.html")
                outdata.SetGeoTransform(WeUseThisGeoTransform)  
                outdata.SetProjection(WeUseThisProjection)
                outdata.GetRasterBand(1).WriteArray(Mosaic0and1ConfidenceArray)
                outdata.GetRasterBand(1).SetNoDataValue(F3NoDataValue)   
                outdata.FlushCache()  
                outdata = None
            ##Added on 20230205 to change the output datatype---end            


        #This section was added on 20240229 to improve the SLTSCB results because SLTSCB has not been applied to the lt0and1_0_999 for improvement---start
        if Metric == "lt0and1_0_999":
            print("Someday we will delete the old one")
            if AddWindow3x3MovingAverage == "Yes":
                MosaicArrayFinalSltscbFile = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep + ProjectName + os.sep + Management+"_"+Year+"_"+"sltscb"+"_MosaicCellMean_Win3x3Smoothing.tif"
                MosaicArrayFinalSltscbFileNew = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep + ProjectName + os.sep + Management+"_"+Year+"_"+"sltscb"+"_MosaicCellMean_Win3x3SmoothingNew.tif"
                MosaicArrayFinalSltscbArrayMasked = ReadTifToArray(MosaicArrayFinalSltscbFile)
                MosaicArrayFinalSltscbArrayMasked[(MosaicArrayFinal_1 == 0) & (~MosaicArrayFinalSltscbArrayMasked.mask)] = 0   #20240313 add (~MosaicArrayFinalSltscbArrayMasked.mask)
                Mosaic0and1ConfidenceArrayMin = np.nanmin(MosaicArrayFinalSltscbArrayMasked)
                Mosaic0and1ConfidenceArrayMax = np.nanmax(MosaicArrayFinalSltscbArrayMasked)                
                TypeOfInterest = OutputDataType(Mosaic0and1ConfidenceArrayMin, Mosaic0and1ConfidenceArrayMax)
                driver = gdal.GetDriverByName("GTiff")
                outdata = driver.Create(MosaicArrayFinalSltscbFileNew, MosaicColumns, MosaicRows, 1, TypeOfInterest, options=['COMPRESS=LZW'])   #see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
                print("SetGeoTransform and SetProjection usage, see http://www2.geog.ucl.ac.uk/~plewis/geogg122_local/geogg122-old/Chapter4_GDAL/GDAL_Python_bindings.html")
                outdata.SetGeoTransform(WeUseThisGeoTransform)  
                outdata.SetProjection(WeUseThisProjection)
                outdata.GetRasterBand(1).WriteArray(MosaicArrayFinalSltscbArrayMasked)
                outdata.GetRasterBand(1).SetNoDataValue(F3NoDataValue)   
                outdata.FlushCache()  
                outdata = None
                if (os.path.exists(MosaicArrayFinalSltscbFileNew) and os.path.exists(MosaicArrayFinalSltscbFile)):  #added on 20240313
                    time.sleep(30)  #Sometimes there is an error "The process cannot access the file because it is being used by another process'. The reasom might be the computer process is too fast, so here we wait for half minutes
                    if is_file_locked(MosaicArrayFinalSltscbFile):  #added on 20240430. Note we have a function [def is_file_locked()]
                        print(MosaicArrayFinalSltscbFile," is locked by another process so we cannot remove it")
                    else:
                        print(MosaicArrayFinalSltscbFile," is not locked by another process, so we will remove it")
                        os.remove(MosaicArrayFinalSltscbFile)  
                    os.rename(MosaicArrayFinalSltscbFileNew,MosaicArrayFinalSltscbFile)   #As of 20240502, I believe we still have the permission problem. We will check later
            else:
                MosaicArrayFinalSltscbFile = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep + ProjectName + os.sep + Management+"_"+Year+"_"+"sltscb"+"_MosaicCellMean.tif"
                MosaicArrayFinalSltscbFileNew = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep + ProjectName + os.sep + Management+"_"+Year+"_"+"sltscb"+"_MosaicCellMeanNew.tif"
                MosaicArrayFinalSltscbArrayMasked = ReadTifToArray(MosaicArrayFinalSltscbFile)
                MosaicArrayFinalSltscbArrayMasked[MosaicArrayFinal_1 == 0] = 0
                Mosaic0and1ConfidenceArrayMin = np.nanmin(MosaicArrayFinalSltscbArrayMasked)
                Mosaic0and1ConfidenceArrayMax = np.nanmax(MosaicArrayFinalSltscbArrayMasked)                
                TypeOfInterest = OutputDataType(Mosaic0and1ConfidenceArrayMin, Mosaic0and1ConfidenceArrayMax)
                driver = gdal.GetDriverByName("GTiff")
                outdata = driver.Create(MosaicArraySpeciesConfidenceFileNew, MosaicColumns, MosaicRows, 1, TypeOfInterest, options=['COMPRESS=LZW'])   #see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
                print("SetGeoTransform and SetProjection usage, see http://www2.geog.ucl.ac.uk/~plewis/geogg122_local/geogg122-old/Chapter4_GDAL/GDAL_Python_bindings.html")
                outdata.SetGeoTransform(WeUseThisGeoTransform)  
                outdata.SetProjection(WeUseThisProjection)
                outdata.GetRasterBand(1).WriteArray(MosaicArrayFinalSltscbArrayMasked)
                outdata.GetRasterBand(1).SetNoDataValue(F3NoDataValue)   
                outdata.FlushCache()  
                outdata = None
                if (os.path.exists(MosaicArrayFinalSltscbFileNew) and os.path.exists(MosaicArrayFinalSltscbFile)):  #added on 20240313
                    time.sleep(30)  #Sometimes there is an error "The process cannot access the file because it is being used by another process'. The reasom might be the computer process is too fast, so here we wait for half minutes                    
                    if is_file_locked(MosaicArrayFinalSltscbFile):  #added on 20240430. Note we have a function [def is_file_locked()]
                        print(MosaicArrayFinalSltscbFile," is locked by another process so we cannot remove it")
                    else:
                        print(MosaicArrayFinalSltscbFile," is not locked by another process, so we will remove it")
                        os.remove(MosaicArrayFinalSltscbFile)
                    os.rename(MosaicArrayFinalSltscbFileNew,MosaicArrayFinalSltscbFile)   
        #This section was added on 20240229 to improve the SLTSCB results because SLTSCB has not been applied to the lt0and1_0_999 for improvement---start    


        #20230127 added to delete the _Zshaped.tif files to save the disk---start    
        DeleteTheZshapedTif = "No"
        DeleteTheNonZshapedTif = "No"
        DeleteIdwTif = "No"
        if ((DeleteTheZshapedTif == "Yes") and (len(SpatialMosaicTifList) != 0)):
            if ((F3DebugMode == "No") and (not((Management == BaseManagement) and (Year == BaseYear) and (Metric == BaseMetric)))):
                for SpatialMosaicTif in SpatialMosaicTifList:
                    time.sleep(30)  #Sometimes there is an error "The process cannot access the file because it is being used by another process'. The reasom might be the computer process is too fast, so here we wait for half minutes
                    os.remove(SpatialMosaicTif)  #we had "PermissionError: [WinError 32] The process cannot access the file because it is being used by another process, see https://gis.stackexchange.com/questions/80366/why-close-a-dataset-in-gdal-python
                    print("Zshaped.tif of ",SpatialMosaicTif, " was deleted at " + datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
                    print("Zshaped.tif of ",SpatialMosaicTif, " was deleted at " + datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"), file=open(F3Log, 'a'))                    
                    if DeleteTheNonZshapedTif == "Yes":
                        NonZshapedTif = SpatialMosaicTif.replace("_Zshaped","")
                        os.remove(NonZshapedTif)
                        print("NonZshaped.tif of ",NonZshapedTif, " was deleted at " + datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
                        print("NonZshaped.tif of ",NonZshapedTif, " was deleted at " + datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"), file=open(F3Log, 'a'))                    
                    if DeleteIdwTif == "Yes":
                        IdwTif = SpatialMosaicTif.replace("Results","Intermediate").replace("_Zshaped","_IDW")

                        if ((Metric in CrossValidationMetric) and (Management == BaseManagement) and (Year == BaseYear)):
                            print(IdwTif," will be used for crossvalidation, so it will not be removed here")
                        else:                            
                            os.remove(IdwTif)
                            print("Idw.tif of ",IdwTif, " was deleted at " + datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
                            print("Idw.tif of ",IdwTif, " was deleted at " + datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"), file=open(F3Log, 'a'))                    
        #20230127 added to delete the _Zshaped.tif files to save the disk---end
                            
        print("20230417: Below, in the MosaicArrayFinalFile, we use reduced resolution (e.g., 300) inside the fuzzy plot neighbouring area (e.g., 1600 m radius) but keep the orginal resolution in the remaining area", file=open(F3Log, 'a'))
        MosaicArrayFinalFileMixResolutionFile = PlotIDFuzzyBufferArrayFunction(Tiles,MosaicArrayFinalFile, 1600, 240, Metric)  #20240308 changed resampled resolution from 300m to 240m
        print("Above added on 20230417 to reduce the resolution within fuzzy plot neighbouring area; In the future, we can do this for only-sensitive plots")
        print(MosaicArrayFinalFileMixResolutionFile, " was created Yahoo!", file=open(F3Log, 'a'))
        
        return MosaicArrayFinalFile
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for F3SpatialMosaicZeroInflationAndSpeciesConfidence with inputs of " + repr(mylock)+","+repr(Runs)+","+repr(Tiles)+","+repr(Management)+","+repr(Year)+","+repr(Metric)+","+repr( ProjectAOI) + " with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog
    















def F3SpatialMosaicAndUncertainty(mylock,Runs,Tiles,Management,Year,Metric, ProjectAOI=False):  #Note Runs and Tiles, it is not Run and Tile
    try:
        MosaicBestMinIndex = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep + ProjectName + os.sep + "MosaicProcessingPercentageAsOrderAndReliabilityMinIndex.tif"
        MosaicRemoteSeningFile = MosaicRemoteSensingWithGISshape(mylock,Runs,Tiles, Management,Year,Metric)  #20240319 added to mosaic Remote Sensing File
        print(MosaicRemoteSeningFile," is the remote sensing file mosaiced for the study area")
        MergedMetricGIS = SpatiallyMosaicMultiplePointGisShapeFiles(Tiles,Management,Year,Metric,ProjectName)
        print("MergedMetricGIS=",MergedMetricGIS)
        if Metric in ContinuousMetrics:
            MosaicArrayFinalFile = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep + ProjectName + os.sep + Management+"_"+Year+"_"+Metric+"_MosaicCellMean.tif"
            print("MosaicArrayFinalFile is ",MosaicArrayFinalFile)
        if Metric in DiscreteMetrics:
            MosaicArrayFinalFile = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep + ProjectName + os.sep + Management+"_"+Year+"_"+Metric+"_MosaicCellMode.tif"
            print("MosaicArrayFinalFile is ",MosaicArrayFinalFile)
        if not os.path.exists(MosaicArrayFinalFile):
            #SpatialMosaicTifList is a list and shoule be obtained from (Runs,Tiles,Management,Year,Metric)
            SpatialMosaicTifList = []
            for Run in Runs:
                for Tile in Tiles:
                    print("Chicken Run,Tile=",Run,Tile)
                    Step4OutputTif = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"Results"+os.sep+Management+"_"+Year+"_"+Metric+".tif"
                    if Run == "Run1":
                        CorrespondingSegmentation = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R1_Y"+BaseYear+"_L1_S40_C18.tif"  #We haev different level segmentation, you can choose another one
                    if Run == "Run2":
                        CorrespondingSegmentation = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R2_Y"+BaseYear+"_L1_S32_C19.tif"
                    if Run == "Run3":
                        CorrespondingSegmentation = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R3_Y"+BaseYear+"_L1_S48_C17.tif"
                    if Run == "Run4":
                        CorrespondingSegmentation = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R3_Y"+BaseYear+"_L1_S48_C17.tif"  #We haev different level segmentation, you can choose another one
                    if Run == "Run5":
                        CorrespondingSegmentation = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R1_Y"+BaseYear+"_L1_S40_C18.tif"
                    if Run == "Run6":
                        CorrespondingSegmentation = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R2_Y"+BaseYear+"_L1_S32_C19.tif"     
                    if os.path.exists(Step4OutputTif):
                        Step4OutputTifBorderZshapeTif = MosaicingBorderZshape(CorrespondingSegmentation,Step4OutputTif,0.03,FloatToIntegerCoefficient)
                    else:
                        print("20240214: It is understandable that the ",Step4OutputTif," does not exists (e.g., species absense), so we return here")
                        return   
                    if os.path.exists(Step4OutputTifBorderZshapeTif):
                        SpatialMosaicTifList.append(Step4OutputTifBorderZshapeTif)
            if len(SpatialMosaicTifList)%3 != 0:
                MosaicInput = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep + ProjectName + os.sep + Management+"_"+Year+"_"+Metric+"_MosaicInput_Suspicious.txt"
            else:
                MosaicInput = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep + ProjectName + os.sep + Management+"_"+Year+"_"+Metric+"_MosaicInput.txt"
            if not os.path.exists(MosaicInput):
                MosaicInputFile = open(MosaicInput, 'w')
                MosaicTime = "#This mosaic was created by Dr. Shengli Huang at " + datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + " with the following inputs:\n"
                MosaicInputFile.write(MosaicTime)
                for k in SpatialMosaicTifList:
                    ThisLine = k + "\n"
                    MosaicInputFile.write(ThisLine)
                MosaicInputFile.close()
            #SpatialMosaicTifList = [r"C:\F3LinuxGui2_backup20220630\F3unix\Testout\T1.tif",r"C:\F3LinuxGui2_backup20220630\F3unix\Testout\T2.tif"]
            #For each TIF, find their portion in the final extent and assign the values. Other areas are masked out. Then we use numpy.ma statistics (because masked values are ignored)
            #Note: Gdal or RASTERIO have functions of spatial merge; but a) They usually take an ordered image (e.g., first/last) in the overlay area; b) They cannot ignore NodataValue. Mine solved this problem. 
            #As of 20220711, I am not sure if the final result of zero is OK or not

            Mosaiculx,Mosaiclrx,Mosaiculy,Mosaiclry = MultipleImageBoundingExtent(SpatialMosaicTifList,Management,Year,Metric)
            print("for metric=",Metric," Mosaiculx,Mosaiclrx,Mosaiculy,Mosaiclry=", Mosaiculx,Mosaiclrx,Mosaiculy,Mosaiclry, file=open(F3Log, 'a'))
            MosaicColumns = round(abs(Mosaiculx - Mosaiclrx) / F3Resolution)   #change int to round on 20230929: MosaicColumns = int(abs(Mosaiculx - Mosaiclrx) / F3Resolution)
            MosaicRows = round(abs(Mosaiculy - Mosaiclry) / F3Resolution)    #change int to round on 20230929: MosaicRows = int(abs(Mosaiculy - Mosaiclry) / F3Resolution)
            print(Metric," The columns and rows of mosaiced image are: ", MosaicColumns, MosaicRows, file=open(F3Log, 'a'))
            MosaicArray = np.full((len(SpatialMosaicTifList),MosaicRows,MosaicColumns), F3NoDataValue)   #https://stackoverflow.com/questions/5891410/numpy-array-initialization-fill-with-identical-values
            print(Metric," MosaicArray.shape=",MosaicArray.shape,"\n", file=open(F3Log, 'a'))
            WeUseThisGeoTransform = ([Mosaiculx, F3Resolution, 0, Mosaiculy, 0, -1.0 * F3Resolution ]) #see https://gis.stackexchange.com/questions/165950/gdal-setgeotransform-does-not-work-as-expected
            print(WeUseThisGeoTransform)

            k = -1
            for ThisTif in SpatialMosaicTifList:
                print("ThisTif=",ThisTif)
                k = k + 1
                src = gdal.Open(ThisTif)
                cols = src.RasterXSize
                rows = src.RasterYSize
                if k == 0:
                    WeUseThisProjection = src.GetProjectionRef()
                    print(WeUseThisProjection)
                print("ThisTif=",ThisTif," and the cols and rows are: ",cols,rows)

                ThisTifArray = src.GetRasterBand(1).ReadAsArray()
                print("ThisTifArray shape is ", ThisTifArray.shape)
                ThisTifNoDataValue = src.GetRasterBand(1).GetNoDataValue()
                print("ThisTifNoDataValue=",ThisTifNoDataValue)
                ThisTifArray = ma.masked_values(ThisTifArray, ThisTifNoDataValue)
                ThisTifArray = ma.masked_values(ThisTifArray, F3NoDataValue)

                #after Zshapeborder, we may change the value according to the outputunit being imperial or SI
                MetricShortName,MetricFullName,MetricDefinition,SpeciesScienticName,USDAPlantCode,FVSKeyword,MetricUnit_US,MetricUnit_SI,UStoSIconversion,MetricShortNameIGivenBy,MetricFullNameIGivenBy,AdditionalNotes = MetricInformationFromXLSX(Metric)
                if OutputUnit == "Imperial": #added on 20230222
                    ThisTifArray = ThisTifArray * 1.0
                if OutputUnit == "SI":
                    ThisTifArray = ThisTifArray * UStoSIconversion

                upx, xres, xskew, upy, yskew, yres = src.GetGeoTransform()  #https://gis4programmers.wordpress.com/2017/01/06/using-gdal-to-get-raster-extent/, note GetGeoTransform not GetGeotransform
                ulx = float(upx + 0*xres + 0*xskew)
                uly = float(upy + 0*yskew + 0*yres)
                llx = float(upx + 0*xres + rows*xskew)
                lly = float(upy + 0*yskew + rows*yres)
                lrx = float(upx + cols*xres + rows*xskew)
                lry = float(upy + cols*yskew + rows*yres)
                urx = float(upx + cols*xres + 0*xskew)
                ury = float(upy + cols*yskew + 0*yres)
                ColumnMin = round(abs(ulx - Mosaiculx) / F3Resolution)  #If the upperleft corner does not align perfectly, we may have problem here. Need to think it over. Also change int to round on 20230929
                ColumnMax = round(abs(lrx - Mosaiculx) / F3Resolution)  #We may +1 here? see https://opensourceoptions.com/blog/zonal-statistics-algorithm-with-python-in-4-steps/. Also change int to round on 20230929
                RowMin = round(abs(uly - Mosaiculy) / F3Resolution)  #change int to round on 20230929
                RowMax = round(abs(lry - Mosaiculy) / F3Resolution)   #We may +1 here? but I prefer not, because this is just mosaic, I do not care of missin gone pixel. Also change int to round on 20230929
                #print("ColumnMin,ColumnMax,RowMin,RowMax=",ColumnMin,ColumnMax,RowMin,RowMax, file=open(F3Log, 'a'))
                MosaicArray[k,RowMin:RowMax,ColumnMin:ColumnMax] = ThisTifArray  #remember the k is so important
                src = None   #20230323 added: In os.remove() below, we had "PermissionError: [WinError 32] The process cannot access the file because it is being used by another process, see https://gis.stackexchange.com/questions/80366/why-close-a-dataset-in-gdal-python
            print(Metric," MosaicArray shape is ", MosaicArray.shape)
            MosaicArrayMasked = ma.masked_values(MosaicArray, F3NoDataValue)
            if Metric in ContinuousMetrics:
                t00 = time.time()
                MosaicArrayFinalSTD = np.nanstd(MosaicArrayMasked,axis=0)
                if MosaicCandidateChosen == "Mean":  #20240506. This is traditional six runs averaging
                    MosaicArrayFinalAAA = np.nanmean(MosaicArrayMasked,axis=0)
                if MosaicCandidateChosen == "Best":  #20240506. This is six runs best which is based on the reliabilty order value (lower value means imputation earlier leads to more trust)
                    MosaicBestMinIndexArray = ReadTifToArray(MosaicBestMinIndex)
                    MosaicBestMinIndexArray = ma.masked_values(MosaicBestMinIndexArray, F3NoDataValue)
                    MosaicBestMinIndexArrayUnique = np.unique(MosaicBestMinIndexArray)
                    MosaicBestMinIndexArrayUnique = MosaicBestMinIndexArrayUnique[~MosaicBestMinIndexArrayUnique.mask]
                    MosaicBestMinIndexArrayUnique = [int(x) for x in MosaicBestMinIndexArrayUnique if x is not None]
                    print("MosaicBestMinIndexArrayUnique=",MosaicBestMinIndexArrayUnique)
                    for h in MosaicBestMinIndexArrayUnique:
                        MosaicBestMinIndexArray[MosaicBestMinIndexArray == h] = MosaicArrayMasked[h,:,:][MosaicBestMinIndexArray == h]
                    MosaicArrayFinalAAA = MosaicBestMinIndexArray
                print(Metric," is ContinuousMetrics and the nanmean function during spatial mosaicing222 took \t" + str(int((time.time() - t00)/60))," minutes")
                print(Metric," is ContinuousMetrics and the nanmean function during spatial mosaicing222 took \t" + str(int((time.time() - t00)/60))," minutes", file=open(F3Log, 'a'))
            if Metric in DiscreteMetrics:
                if MosaicCandidateChosen == "Mean":  #Note it actually means "Mode"
                    print("There is no function of np.nanmode with axis=0. MosaicArrayFinalAAA = mode(MosaicArrayMasked, axis=0) does not work at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
                    print("There is no function of np.nanmode with axis=0. MosaicArrayFinalAAA = mode(MosaicArrayMasked, axis=0) does not work at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"), file=open(F3Log, 'a'))
                    t000 = time.time()
                    MosaicArrayFinalAAA = np.full((MosaicRows,MosaicColumns), F3NoDataValue)
                    MosaicArrayFinalModeCountExcludingNAN = np.full((MosaicRows,MosaicColumns), F3NoDataValue)  

                    print("https://stackoverflow.com/questions/16330831/most-efficient-way-to-find-mode-in-numpy-array says mode() return both mode and count")
                    print("https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.mode.html, and https://pythonguides.com/python-scipy-stats-mode/#:~:text=Python%20Scipy%20Stats%20Mode%20Example%20The%20output%20of,comparison%20to%20other%20numbers%20in%20the%20whole%20array.")
                    #1. scipy.stats.mode has keepdimension option. The processing time is a little longer than mean, min etc
                    #2. mode_result.mode = mode_result[0], mode_result[0][0]=mode_result[0][0,:,:], mode_result.mode[0]=mode_result.mode[0,:,:], note mode[0] or mode[0,:,:] is necessary to convert domension due to the use of keepdimension option
                    #3. mode_result.count = mode_result[1],mode_result[1][0]=mode_result[1][0,:,:], mode_result.count[0]=mode_result.count[0,:,:]. Count Concept is the same as Mode concept
                    MosaicArrayFinalAAA000 = mode(MosaicArrayMasked, axis=0, nan_policy='omit',keepdims=True)
                    MosaicArrayFinalAAA = MosaicArrayFinalAAA000.mode[0,:,:]  #The first return of mode() is the mode array. here MosaicArrayFinalAAA000[0] is the same as MosaicArrayFinalAAA000.mode. The [0,:,:] is convert 3D to 2D (i.e.from [1,cols,rows] to [cols,rows])
                    MosaicArrayFinalModeCountExcludingNAN = MosaicArrayFinalAAA000[1]  #The second return of mode() is the count array. here  MosaicArrayFinalAAA000[1] is the same as  MosaicArrayFinalAAA000.count  
                    MosaicArrayFinalModeCountExcludingNAN = MosaicArrayFinalModeCountExcludingNAN[0,:,:]  #This is why we need an extra step here to convert shape from [1,cols,rows] to [cols,rows]. In the future, we may have to change here based on new Scipy version
                    MosaicArrayFinalModeCountExcludingNAN = ma.masked_less_equal(MosaicArrayFinalModeCountExcludingNAN, 0)   #Added on 20240517 specially for discrete metric because I found the water lakes is zero
                    print(Metric," is discrete and the mode function during spatial mosaicing111 took \t" + str(int((time.time() - t000)/60))," minutes")
                    print(Metric," is discrete and the mode function during spatial mosaicing111 took \t" + str(int((time.time() - t000)/60))," minutes", file=open(F3Log, 'a'))
                    #as of 20240204, we hae problems in mode because the scipy version is 1.11.4 which is different from 1.6.2 when the code was deveoped---end
                    NumberOfUnmaskedElement = MosaicArrayMasked.count(axis=0)
                    MosaicArrayFinalSTD = (1000000.0 * (NumberOfUnmaskedElement - MosaicArrayFinalModeCountExcludingNAN) / NumberOfUnmaskedElement)
                    #When mosaicing, I want to get the value = ModeCount/TotalCount, whose larger values indicating better majority. Note I multiply 1000000.0 to store a smaller data--end
                    print(Metric," is discrete and the mode function during spatial mosaicing222 took \t" + str(int((time.time() - t000)/60))," minutes")
                    print(Metric," is discrete and the mode function during spatial mosaicing222 took \t" + str(int((time.time() - t000)/60))," minutes", file=open(F3Log, 'a'))
                if MosaicCandidateChosen == "Best":  #20240506. This is six runs best which is based on the reliabilty order value (lower value means imputation earlier leads to more trust)
                    MosaicBestMinIndexArray = ReadTifToArray(MosaicBestMinIndex)
                    MosaicBestMinIndexArray = ma.masked_values(MosaicBestMinIndexArray, F3NoDataValue)
                    MosaicBestMinIndexArrayUnique = np.unique(MosaicBestMinIndexArray)
                    MosaicBestMinIndexArrayUnique = MosaicBestMinIndexArrayUnique[~MosaicBestMinIndexArrayUnique.mask]
                    MosaicBestMinIndexArrayUnique = [int(x) for x in MosaicBestMinIndexArrayUnique if x is not None]
                    print("MosaicBestMinIndexArrayUnique=",MosaicBestMinIndexArrayUnique)
                    for h in MosaicBestMinIndexArrayUnique:
                        MosaicBestMinIndexArray[MosaicBestMinIndexArray == h] = MosaicArrayMasked[h,:,:][MosaicBestMinIndexArray == h]
                    MosaicArrayFinalAAA = MosaicBestMinIndexArray
                    MosaicArrayFinalSTD = np.full(MosaicArrayFinalAAA.shape, 1)   #temporal for place holder, the resulting raster does not make sense
            print(Metric," Runs,Tiles,Management,Year,Metric=",Runs,Tiles,Management,Year,Metric)
            SpatialMetricMin,SpatialMetricMax = F3SpatialMosaicMetricMinMax(Runs,Tiles,Management,Year,Metric)
            MosaicArrayFinal = MosaicArrayFinalAAA.copy()


            #added 20240223: This is to use MosaicHalfOfCutthresholdMinusMin and MosaicCutthreshold to adjust the result---start
            print("Do we realy need IDW i this part? I do not think so so far")
            MosaicMetricMinValue,MosaicHalfOfCutthresholdMinusMin,MosaicCutthreshold,MosaicMetricMaxValue = F3SpatialMosaicMetricMinAndCutThreshValue(Runs,Tiles,Management,Year,Metric)
            print("MosaicMetricMinValue,MosaicHalfOfCutthresholdMinusMin,MosaicCutthreshold,MosaicMetricMaxValue=",MosaicMetricMinValue,MosaicHalfOfCutthresholdMinusMin,MosaicCutthreshold,MosaicMetricMaxValue, file=open(F3Log, 'a'))
            print("MosaicMetricMinValue,MosaicHalfOfCutthresholdMinusMin,MosaicCutthreshold,MosaicMetricMaxValue=",MosaicMetricMinValue,MosaicHalfOfCutthresholdMinusMin,MosaicCutthreshold,MosaicMetricMaxValue)
            MosaicArrayFinal[MosaicArrayFinal <= MosaicHalfOfCutthresholdMinusMin] = MosaicMetricMinValue
            MosaicArrayFinal[(MosaicArrayFinal > MosaicHalfOfCutthresholdMinusMin) & (MosaicArrayFinal < MosaicCutthreshold)] = MosaicCutthreshold
            MosaicArrayFinal[MosaicArrayFinal >= MosaicMetricMaxValue] = MosaicMetricMaxValue
            #added 20240223: This is to use MosaicHalfOfCutthresholdMinusMin and MosaicCutthreshold to adjust the result---end
            
            
            MosaicArrayFinal = ma.masked_values(MosaicArrayFinal, F3NoDataValue)  #https://numpy.org/doc/stable/reference/generated/numpy.ma.masked_values.html#numpy.ma.masked_values
            MosaicArrayFinalSTD = ma.masked_values(MosaicArrayFinalSTD, F3NoDataValue)
            print(Metric," MosaicArrayFinal shape is ", MosaicArrayFinal.shape, file=open(F3Log, 'a'))
            #print("MosaicArrayFinal = ",MosaicArrayFinal)

            #We add the ProjectAOI here to subset the output TIF. --start
            print("?????????????????ProjectAOI=",ProjectAOI, file=open(F3Log, 'a'))
            if ProjectAOI:  #The general idea is to find the overlay but minimum corners and then indexing array
                output_tiff, RowMin_ForMosaic,RowMax_ForMosaic,ColumnMin_ForMosaic,ColumnMax_ForMosaic,CommonOverlay_ulx, CommonOverlay_lrx, CommonOverlay_uly, CommonOverlay_lry = ShapeAndRasterOverlayExtent(ProjectAOI,False,Mosaiculx,Mosaiclrx,Mosaiculy,Mosaiclry)  
                print(Metric," ProjectAOI RowMin_ForMosaic,RowMax_ForMosaic,ColumnMin_ForMosaic,ColumnMax_ForMosaic=",RowMin_ForMosaic,RowMax_ForMosaic,ColumnMin_ForMosaic,ColumnMax_ForMosaic, file=open(F3Log, 'a'))

                ForMosaic_CommonOverlay = MosaicArrayFinal[RowMin_ForMosaic:RowMax_ForMosaic,ColumnMin_ForMosaic:ColumnMax_ForMosaic]
                ForMosaic_CommonOverlay_STD = MosaicArrayFinalSTD[RowMin_ForMosaic:RowMax_ForMosaic,ColumnMin_ForMosaic:ColumnMax_ForMosaic]
                print(Metric," ForMosaic_CommonOverlay shape is ", ForMosaic_CommonOverlay.shape, file=open(F3Log, 'a'))

                driverTiff = gdal.GetDriverByName('GTiff')
                ds = gdal.Open(output_tiff)
                srcCols = ds.RasterXSize
                srcRows = ds.RasterYSize
                WeUseThisProjection = ds.GetProjectionRef()
                WeUseThisGeoTransform = ds.GetGeoTransform()
                output_tiff_masked = ReadTifToArray(output_tiff)
                print(Metric,"output_tiff_masked shape is ", output_tiff_masked.shape, file=open(F3Log, 'a'))
                ForMosaic_CommonOverlay[output_tiff_masked.mask] = F3NoDataValue
                ForMosaic_CommonOverlay_STD[output_tiff_masked.mask] = F3NoDataValue
                print(Metric,"After masked, ForMosaic_CommonOverlay shape is ", ForMosaic_CommonOverlay.shape, file=open(F3Log, 'a'))
                MosaicArrayFinal = ForMosaic_CommonOverlay
                MosaicArrayFinalSTD = ForMosaic_CommonOverlay_STD
                MosaicColumns = srcCols
                MosaicRows = srcRows

                #20240311 added to exclude nonforest area which extracted from US crop layer and USFS LCMS land cover---start 
                MosaicForest1Nonforest0File = MosaicForest1Nonforest0TifFileWithGISshape(mylock,Runs,Tiles, Management,Year,Metric)
                MosaicCropLayerFile = MosaicCropLayerTifFileWithGISshape(mylock,Runs,Tiles, Management,Year,Metric)  #added on 20240521 to mosaic CropLayer
                ds = gdal.Open(MosaicForest1Nonforest0File)
                MosaicForest1Nonforest0Array0 = ds.GetRasterBand(1).ReadAsArray()
                MosaicForest1Nonforest0Array0NodataValue = ds.GetRasterBand(1).GetNoDataValue()
                MosaicForest1Nonforest0Array0 = ma.masked_values(MosaicForest1Nonforest0Array0, MosaicForest1Nonforest0Array0NodataValue)
                print("0 The mean, max, and min from step 1 is: ", np.nanmean(MosaicForest1Nonforest0Array0),np.nanmax(MosaicForest1Nonforest0Array0),np.nanmin(MosaicForest1Nonforest0Array0))
                MosaicForest1Nonforest0Array = MosaicForest1Nonforest0Array0[RowMin_ForMosaic:RowMax_ForMosaic,ColumnMin_ForMosaic:ColumnMax_ForMosaic]
                print("1 The mean, max, and min from step 1 is: ", np.nanmean(MosaicForest1Nonforest0Array),np.nanmax(MosaicForest1Nonforest0Array),np.nanmin(MosaicForest1Nonforest0Array))
                MosaicArrayFinal[MosaicForest1Nonforest0Array == 0] = F3NoDataValue
                MosaicArrayFinalSTD[MosaicForest1Nonforest0Array == 0] = F3NoDataValue
                #20240311 added to exclude nonforest area which extracted from US crop layer and USFS LCMS land cover---end

                
            #We add the ProjectAOI here to subset the output TIF. --end
                   
            TypeOfInterest = OutputDataType(SpatialMetricMin, SpatialMetricMax)
            print("OutputDataType of F3SpatialMosaicAndUncertainty for ",Management,Year,Metric," is ",TypeOfInterest)
            print("OutputDataType of F3SpatialMosaicAndUncertainty for ",Management,Year,Metric," is ",TypeOfInterest, file=open(F3Log, 'a'))

            #This is for Raw without windows 3x3 smoothing---start
            SaveRawWithoutWindows3x3Smoothing = "Yes" #Yes or No. Note the Windows3x3Smoothing will remove the "direct" imputation, which is sensative to the risk of FIA plot location 
            if ((SaveRawWithoutWindows3x3Smoothing == "Yes") or ((Management == BaseManagement) and (Year == BaseYear) and (Metric == BaseMetric))):
                MosaicArrayFinal_1 = MosaicArrayFinal.copy()
                driver = gdal.GetDriverByName("GTiff")
                if OutputGeoTifCompression == "Yes": #Added on 20230227. LZW compression does not lose information. LZW compression is a lossless data compression algorithm, which means that the original data can be fully reconstructed from the compressed data without any loss of information.
                    outdata = driver.Create(MosaicArrayFinalFile, MosaicColumns, MosaicRows, 1, TypeOfInterest, options=['COMPRESS=LZW'])   #see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
                if OutputGeoTifCompression == "No": 
                    outdata = driver.Create(MosaicArrayFinalFile, MosaicColumns, MosaicRows, 1, TypeOfInterest)   #see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
                print("SetGeoTransform and SetProjection usage, see http://www2.geog.ucl.ac.uk/~plewis/geogg122_local/geogg122-old/Chapter4_GDAL/GDAL_Python_bindings.html")
                outdata.SetGeoTransform(WeUseThisGeoTransform)  
                outdata.SetProjection(WeUseThisProjection)

                #20240228 added to use zero-inflation layer to solve the zero-inflation problem for species variables---start
                MosaicArrayFinal_1 = ma.masked_values(MosaicArrayFinal_1, F3NoDataValue)
                if "0and1_0_999" not in Metric:
                    #if (("_0_999" in Metric) and ("0and1" not in Metric)):  
                    if ((len(Metric.split("_")) == 4) and (Metric.split("_")[1].lower() != "all") and ("0and1" not in Metric)):  #20240515: identify the species using another criteria. Not tested as of 20240515
                        ThisIsAspeciesVariable = "Yes"
                        ThisSpecies = Metric.split("_")[1]
                        print(Metric," is a species variable and the species is ",ThisSpecies)
                        ThisSpeciesZeroInflationFile = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep + ProjectName + os.sep + Management+"_"+Year+"_"+ThisSpecies+"0and1_0_999"+"_MosaicCellMean.tif"
                        ThisSpeciesZeroInflationArrayMasked = ReadTifToArray(ThisSpeciesZeroInflationFile)
                        MosaicArrayFinal_1[(ThisSpeciesZeroInflationArrayMasked == 0) & (~MosaicArrayFinal_1.mask)] = MosaicMetricMinValue  #20240313 I changed 0 to MosaicMetricMinValue
                #20240228 added to use zero-inflation layer to solve the zero-inflation problem for species variables---end

                #20240229 added to use zero-inflation layer (after win3x3 smoothering) to improve the stand-level variables--start
                if Metric in ["FORTYP","FORTYPE","SLTSCB","STDAGE","STDMAI","STDCBHT","STDCBD","STDQMD","STDTPA","SDI1933","STDHT","STDCC","STDVOL","STDBASA","Aboveground_Total_Live","Belowground_Live"]:  #"SDTCB" is not a livetree stand-level variable, so it is excluded here
                        print("As of 20240515, we have not thought of the  SPMCDBH all option, see comments in this sentence") #we may use '((len(Metric.split("_")) == 4) and (Metric.split("_")[1].lower() == "all") and ("0and1" not in Metric)) plus saying it is for live tree here?
                        print(Metric," is a stand-level variable with calcualtion from live trees, so we use LT0AND1_0_999 imputation result to improve it")
                        StandZeroInflationFile = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep + ProjectName + os.sep + Management+"_"+Year+"_lt0and1_0_999"+"_MosaicCellMean.tif"
                        StandZeroInflationArrayMasked = ReadTifToArray(StandZeroInflationFile)
                        MosaicArrayFinal_1[(StandZeroInflationArrayMasked == 0) & (~MosaicArrayFinal_1.mask)] = MosaicMetricMinValue  #20240313 I changed 0 to MosaicMetricMinValue
                #20240229 added to use zero-inflation layer (after win3x3 smoothering) to improve the stand-level variables---end

                if Metric in DiscreteMetrics:  #added on 20240520
                    BaseMetricFile = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep + ProjectName + os.sep + Management+"_"+Year+"_"+BaseMetric+"_MosaicCellMean.tif"
                    src = gdal.Open(BaseMetricFile)
                    BaseMetricArray = src.GetRasterBand(1).ReadAsArray()
                    BaseMetricArrayNoDataValue = src.GetRasterBand(1).GetNoDataValue()
                    BaseMetricArray = ma.masked_values(BaseMetricArray, BaseMetricArrayNoDataValue)  #added 20221019
                    MosaicArrayFinal_1[BaseMetricArray.mask] = F3NoDataValue
                    MosaicArrayFinal_1 = ma.masked_values(MosaicArrayFinal_1, F3NoDataValue)
                    if Metric in ["fortype","fortyp"]:
                        MosaicCropLayerFile = MosaicCropLayerTifFileWithGISshape(mylock,Runs,Tiles, Management,Year,Metric)  #added on 20240521 to mosaic CropLayer
                        ds = gdal.Open(MosaicCropLayerFile)
                        MosaicCropLayerArray = ds.GetRasterBand(1).ReadAsArray()
                        MosaicPixelLabel = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep + ProjectName + os.sep + "MosaicPixelLabel.tif"
                        src1 = gdal.Open(MosaicPixelLabel)
                        MosaicPixelLabelArray = src1.GetRasterBand(1).ReadAsArray()
                        MosaicPixelLabelArrayNoDataValue = src1.GetRasterBand(1).GetNoDataValue()
                        MosaicPixelLabelArray = ma.masked_values(MosaicPixelLabelArray, MosaicPixelLabelArrayNoDataValue)  #added 20221019
                        MosaicArrayFinal_1[(MosaicArrayFinal_1.mask) & ((MosaicPixelLabelArray == 3) | (MosaicPixelLabelArray == 99))] = MosaicCropLayerArray[(MosaicArrayFinal_1.mask) & ((MosaicPixelLabelArray == 3) | (MosaicPixelLabelArray == 99))]


                outdata.GetRasterBand(1).WriteArray(MosaicArrayFinal_1)
                outdata.GetRasterBand(1).SetNoDataValue(F3NoDataValue)   
                outdata.FlushCache()  
                outdata = None
                print("$$$$$$$$$$$$$$$$$$$$$$$$$$$$$1 ",MosaicArrayFinalFile, " is created")
                F3SpatialMosaicTifMetadataFile = F3SpatialMosaicTifMetadata(Runs,Tiles,Management,Year,Metric,FloatToIntegerCoefficient,"No")  #The last argument is SmootheringYesOrNo                           
                QuicklookImage = ContinuousSingleBandQuickLookGeotifPseudoColorImage(MosaicArrayFinalFile,2,"CommandArgument",SpatialMetricMin,SpatialMetricMax,Metric)  #Creating a reduce color image
                print("QuicklookImage=",QuicklookImage)

                if EncryptSensitiveFile == "Yes":
                    MosaicArrayFinalFile = EncryptImage(MosaicArrayFinalFile)
            #This is for Raw without windows 3x3 smoothing---end

            AddWindow3x3MovingAverage = "Yes"  #It is suggested that we always use Yes here.
            if AddWindow3x3MovingAverage == "Yes":
                #This is for for adding WindowsAveraging based on windows 3x3 smoothing---start
                MosaicArrayFinalFile = MosaicArrayFinalFile.replace(".tif","_Win3x3Smoothing.tif")   #remove Win3x3
                if Metric in ContinuousMetrics:               
                    MosaicArrayFinal_1 = Array3x3MovingAverageAndLowHighBound(MosaicArrayFinal, Metric, "mean", SpatialMetricMin, SpatialMetricMax, F3NoDataValue)  #3x3 moving window average
                if Metric in DiscreteMetrics:
                    MosaicArrayFinal_1 = Array3x3MovingAverageAndLowHighBound(MosaicArrayFinal, Metric, "mode", SpatialMetricMin, SpatialMetricMax, F3NoDataValue)  #3x3 moving window average

                #Added on 20240407 to assure the Win3x3Averge also reflects the Cutthreshold rule as NotWin3x3Averge---start
                print("Metric windows 3x3 smoothing MosaicMetricMinValue,MosaicHalfOfCutthresholdMinusMin,MosaicCutthreshold,MosaicMetricMaxValue=",MosaicMetricMinValue,MosaicHalfOfCutthresholdMinusMin,MosaicCutthreshold,MosaicMetricMaxValue, file=open(F3Log, 'a'))
                print("Metric windows 3x3 smoothing MosaicMetricMinValue,MosaicHalfOfCutthresholdMinusMin,MosaicCutthreshold,MosaicMetricMaxValue=",MosaicMetricMinValue,MosaicHalfOfCutthresholdMinusMin,MosaicCutthreshold,MosaicMetricMaxValue)
                MosaicArrayFinal_1[MosaicArrayFinal_1 <= MosaicHalfOfCutthresholdMinusMin] = MosaicMetricMinValue
                MosaicArrayFinal_1[(MosaicArrayFinal_1 > MosaicHalfOfCutthresholdMinusMin) & (MosaicArrayFinalAAA < MosaicCutthreshold)] = MosaicCutthreshold
                MosaicArrayFinal_1[MosaicArrayFinal_1 >= MosaicMetricMaxValue] = MosaicMetricMaxValue
                MosaicArrayFinal_1[MosaicForest1Nonforest0Array == 0] = F3NoDataValue  #added 20240408 because the nonforest area is zero. It should be NoDATA.
                #Added on 20240407 to assure the Win3x3Averge also reflects the Cutthreshold rule as NotWin3x3Averge---end

                driver = gdal.GetDriverByName("GTiff")
                if OutputGeoTifCompression == "Yes": #Added on 20230227. LZW compression does not lose information. LZW compression is a lossless data compression algorithm, which means that the original data can be fully reconstructed from the compressed data without any loss of information.
                    outdata = driver.Create(MosaicArrayFinalFile, MosaicColumns, MosaicRows, 1, TypeOfInterest, options=['COMPRESS=LZW'])   #see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
                if OutputGeoTifCompression == "No": 
                    outdata = driver.Create(MosaicArrayFinalFile, MosaicColumns, MosaicRows, 1, TypeOfInterest)   #see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
                print("SetGeoTransform and SetProjection usage, see http://www2.geog.ucl.ac.uk/~plewis/geogg122_local/geogg122-old/Chapter4_GDAL/GDAL_Python_bindings.html")
                outdata.SetGeoTransform(WeUseThisGeoTransform)  
                outdata.SetProjection(WeUseThisProjection)

                #20240228 added to use zero-inflation layer (after win3x3 smoothering) to solve the zero-inflation problem for species variables---start
                if "0and1_0_999" not in Metric:
                    if (("_0_999" in Metric) and ("0and1" not in Metric)):
                        ThisIsAspeciesVariable = "Yes"
                        ThisSpecies = Metric.split("_")[1]
                        print(Metric," is a species variable and the species is ",ThisSpecies)
                        ThisSpeciesZeroInflationFile = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep + ProjectName + os.sep + Management+"_"+Year+"_"+ThisSpecies+"0and1_0_999"+"_MosaicCellMean_Win3x3Smoothing.tif"
                        ThisSpeciesZeroInflationArrayMasked = ReadTifToArray(ThisSpeciesZeroInflationFile)
                        MosaicArrayFinal_1[(ThisSpeciesZeroInflationArrayMasked == 0) & (~MosaicArrayFinal_1.mask)] = MosaicMetricMinValue  #20240313 I changed 0 to MosaicMetricMinValue
                #20240228 added to use zero-inflation layer (after win3x3 smoothering) to solve the zero-inflation problem for species variables---end

                #20240229 added to use zero-inflation layer (after win3x3 smoothering) to improve the stand-level variables--start
                if Metric in ["FORTYP","FORTYPE","SLTSCB","STDAGE","STDMAI","STDCBHT","STDCBD","STDQMD","STDTPA","SDI1933","STDHT","STDCC","STDVOL","STDBASA","Aboveground_Total_Live","Belowground_Live"]:  #"SDTCB" is not a livetree stand-level variable, so it is excluded here
                        print("As of 20240515, we have not thought of the  SPMCDBH all option, see comments in this sentence") #we may use '((len(Metric.split("_")) == 4) and (Metric.split("_")[1].lower() == "all") and ("0and1" not in Metric)) plus saying it is for live tree here?
                        print(Metric," is a stand-level variable with calcualtion from live trees, so we use LT0AND1_0_999 imputation result to improve it")
                        StandZeroInflationFile = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep + ProjectName + os.sep + Management+"_"+Year+"_lt0and1_0_999"+"_MosaicCellMean_Win3x3Smoothing.tif"
                        StandZeroInflationArrayMasked = ReadTifToArray(StandZeroInflationFile)
                        MosaicArrayFinal_1[(StandZeroInflationArrayMasked == 0) & (~MosaicArrayFinal_1.mask)] = MosaicMetricMinValue  #20240313 I changed 0 to MosaicMetricMinValue
                #20240229 added to use zero-inflation layer (after win3x3 smoothering) to improve the stand-level variables---end

                if Metric in DiscreteMetrics:  #added on 20240520
                    BaseMetricFile = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep + ProjectName + os.sep + Management+"_"+Year+"_"+BaseMetric+"_MosaicCellMean_Win3x3Smoothing.tif"
                    src = gdal.Open(BaseMetricFile)
                    BaseMetricArray = src.GetRasterBand(1).ReadAsArray()
                    BaseMetricArrayNoDataValue = src.GetRasterBand(1).GetNoDataValue()
                    BaseMetricArray = ma.masked_values(BaseMetricArray, BaseMetricArrayNoDataValue)  #added 20221019
                    MosaicArrayFinal_1[BaseMetricArray.mask] = F3NoDataValue
                    MosaicArrayFinal_1 = ma.masked_values(MosaicArrayFinal_1, F3NoDataValue)
                    if Metric in ["fortype","fortyp"]:
                        MosaicCropLayerFile = MosaicCropLayerTifFileWithGISshape(mylock,Runs,Tiles, Management,Year,Metric)  #added on 20240521 to mosaic CropLayer
                        ds = gdal.Open(MosaicCropLayerFile)
                        MosaicCropLayerArray = ds.GetRasterBand(1).ReadAsArray()
                        MosaicPixelLabel = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep + ProjectName + os.sep + "MosaicPixelLabel.tif"
                        src1 = gdal.Open(MosaicPixelLabel)
                        MosaicPixelLabelArray = src1.GetRasterBand(1).ReadAsArray()
                        MosaicPixelLabelArrayNoDataValue = src1.GetRasterBand(1).GetNoDataValue()
                        MosaicPixelLabelArray = ma.masked_values(MosaicPixelLabelArray, MosaicPixelLabelArrayNoDataValue)  #added 20221019
                        MosaicArrayFinal_1[(MosaicArrayFinal_1.mask) & ((MosaicPixelLabelArray == 3) | (MosaicPixelLabelArray == 99))] = MosaicCropLayerArray[(MosaicArrayFinal_1.mask) & ((MosaicPixelLabelArray == 3) | (MosaicPixelLabelArray == 99))]

                MosaicArrayFinal_1[MosaicArrayFinal.mask] = F3NoDataValue #added on 20240311: Win3x3Smoothing has fill some nodata pixels, so here to assure the Win3x3Smoothing version has the same F3NoDataValue as No-Smoothering version
                outdata.GetRasterBand(1).WriteArray(MosaicArrayFinal_1)
                outdata.GetRasterBand(1).SetNoDataValue(F3NoDataValue)   
                outdata.FlushCache()  
                outdata = None
                print("$$$$$$$$$$$$$$$$$$$$$$$$$$$$$2 ",MosaicArrayFinalFile, " is created")
                if ((Metric.lower() == "fortyp") or (Metric.lower() == "fortype")):  #added on 20240516
                    ForestTypeGeoTifMessage = AddingRasterAttributeTableToForestTypeGeoTif(MosaicArrayFinalFile)
                F3SpatialMosaicTifMetadataFile = F3SpatialMosaicTifMetadata(Runs,Tiles,Management,Year,Metric,FloatToIntegerCoefficient,"Yes")  #The last argument is SmootheringYesOrNo            
                print("&&&&&&&&&&&&&&&&&&&&&&&SpatialMetricMin,SpatialMetricMax=",SpatialMetricMin,SpatialMetricMax, file=open(F3Log, 'a'))
                QuicklookImage = ContinuousSingleBandQuickLookGeotifPseudoColorImage(MosaicArrayFinalFile,2,"CommandArgument",SpatialMetricMin,SpatialMetricMax,Metric)  #Creating a reduce color image
                print("QuicklookImage=",QuicklookImage)
                #This is for for adding WindowsAveraging based on windows 3x3 smoothing---end
            if Metric in ContinuousMetrics:
                MosaicArrayFinalSTDFile = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep + ProjectName + os.sep + Management+"_"+Year+"_"+Metric+"_MosaicCellStd_Win3x3Smoothing.tif"
            if Metric in DiscreteMetrics:
                MosaicArrayFinalSTDFile = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep + ProjectName + os.sep + Management+"_"+Year+"_"+Metric+"_MosaicCellNonModePercentageTimes1000000_Win3x3Smoothing.tif"
            driver = gdal.GetDriverByName("GTiff")
            if "PercentageTimes1000000" in MosaicArrayFinalSTDFile:
                TypeOfInterest = gdal.GDT_Int32  #not "gdal.GDT_Int32"

            #20230203: Because the MosaicArrayFinalSTD has sensitive information about FIA plot location (e.g., std=0 for the location pixel), I use a 3x3window to smoother it---start
            MosaicArrayFinalSTD[MosaicArrayFinal.mask] = F3NoDataValue  #added on 20230210 to remove those negatuve pixels (e.g., -2456) caused by 3x3 moving window
            MosaicArrayFinalSTD = ma.masked_values(MosaicArrayFinalSTD, F3NoDataValue) #added on 20230210 to remove those negatuve pixels (e.g., -2456) caused by 3x3 moving window
            MovingWindowArrayList = np.ma.array([MosaicArrayFinalSTD[1:-1,1:-1], MosaicArrayFinalSTD[:-2,1:-1], MosaicArrayFinalSTD[2:,1:-1], MosaicArrayFinalSTD[1:-1,:-2], MosaicArrayFinalSTD[1:-1,2:], MosaicArrayFinalSTD[2:,2:], MosaicArrayFinalSTD[:-2,:-2], MosaicArrayFinalSTD[2:,:-2], MosaicArrayFinalSTD[:-2,2:]])  #20230214: we must use np.ma.array not np.array, because the latter one cannot ignore nan
            MosaicArrayFinalSTD[1:-1, 1:-1] = np.nanmean(MovingWindowArrayList,axis=0)  #This return the mean by ignoring the nan element
            MosaicArrayFinalSTD[MosaicArrayFinal.mask] = F3NoDataValue   #added on 20230210 to remove those negatuve pixels (e.g., -2456) caused by 3x3 moving window
            #20230203: Because the MosaicArrayFinalSTD has sensitive information about FIA plot location (e.g., std=0 for the location pixel), I use a 3x3window to smoother it---end

            if Metric in DiscreteMetrics:  #added on 20240520
                BaseMetricSTDFile = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep + ProjectName + os.sep + Management+"_"+Year+"_"+BaseMetric+"_MosaicCellStd_Win3x3Smoothing.tif"
                src = gdal.Open(BaseMetricSTDFile)
                BaseMetricArray = src.GetRasterBand(1).ReadAsArray()
                BaseMetricArrayNoDataValue = src.GetRasterBand(1).GetNoDataValue()
                BaseMetricArray = ma.masked_values(BaseMetricArray, BaseMetricArrayNoDataValue)  #added 20221019
                MosaicArrayFinalSTD[BaseMetricArray.mask] = F3NoDataValue
                MosaicArrayFinalSTD = ma.masked_values(MosaicArrayFinalSTD, F3NoDataValue)

            if OutputGeoTifCompression == "Yes": #Added on 20230227. LZW compression does not lose information. LZW compression is a lossless data compression algorithm, which means that the original data can be fully reconstructed from the compressed data without any loss of information.
                outdataSTD = driver.Create(MosaicArrayFinalSTDFile, MosaicColumns, MosaicRows, 1, TypeOfInterest, options=['COMPRESS=LZW'])   #see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
            if OutputGeoTifCompression == "No": 
                outdataSTD = driver.Create(MosaicArrayFinalSTDFile, MosaicColumns, MosaicRows, 1, TypeOfInterest)   #see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
            print("SetGeoTransform and SetProjection usage, see http://www2.geog.ucl.ac.uk/~plewis/geogg122_local/geogg122-old/Chapter4_GDAL/GDAL_Python_bindings.html")
            outdataSTD.SetGeoTransform(WeUseThisGeoTransform)  
            outdataSTD.SetProjection(WeUseThisProjection)            
            outdataSTD.GetRasterBand(1).WriteArray(MosaicArrayFinalSTD)
            outdataSTD.GetRasterBand(1).SetNoDataValue(F3NoDataValue)   
            outdataSTD.FlushCache()  
            outdataSTD = None
            print(MosaicArrayFinalSTDFile, " is created")


        #20230127 added to delete the _Zshaped.tif files to save the disk---start    
        DeleteTheZshapedTif = "No"
        DeleteTheNonZshapedTif = "No"
        DeleteIdwTif = "No"
        if ((DeleteTheZshapedTif == "Yes") and (len(SpatialMosaicTifList) != 0)):
            if ((F3DebugMode == "No") and (not((Management == BaseManagement) and (Year == BaseYear) and (Metric == BaseMetric)))):
                for SpatialMosaicTif in SpatialMosaicTifList:
                    time.sleep(30)  #Sometimes there is an error "The process cannot access the file because it is being used by another process'. The reasom might be the computer process is too fast, so here we wait for half minutes
                    os.remove(SpatialMosaicTif)  #we had "PermissionError: [WinError 32] The process cannot access the file because it is being used by another process, see https://gis.stackexchange.com/questions/80366/why-close-a-dataset-in-gdal-python
                    print("Zshaped.tif of ",SpatialMosaicTif, " was deleted at " + datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
                    print("Zshaped.tif of ",SpatialMosaicTif, " was deleted at " + datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"), file=open(F3Log, 'a'))                    
                    if DeleteTheNonZshapedTif == "Yes":
                        NonZshapedTif = SpatialMosaicTif.replace("_Zshaped","")
                        os.remove(NonZshapedTif)
                        print("NonZshaped.tif of ",NonZshapedTif, " was deleted at " + datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
                        print("NonZshaped.tif of ",NonZshapedTif, " was deleted at " + datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"), file=open(F3Log, 'a'))                    
                    if DeleteIdwTif == "Yes":
                        IdwTif = SpatialMosaicTif.replace("Results","Intermediate").replace("_Zshaped","_IDW")

                        if ((Metric in CrossValidationMetric) and (Management == BaseManagement) and (Year == BaseYear)):
                            print(IdwTif," will be used for crossvalidation, so it will not be removed here")
                        else:                            
                            os.remove(IdwTif)
                            print("Idw.tif of ",IdwTif, " was deleted at " + datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
                            print("Idw.tif of ",IdwTif, " was deleted at " + datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"), file=open(F3Log, 'a'))                    
        #20230127 added to delete the _Zshaped.tif files to save the disk---end
                            
        print("20230417: Below, in the MosaicArrayFinalFile, we use reduced resolution (e.g., 300) inside the fuzzy plot neighbouring area (e.g., 1600 m radius) but keep the orginal resolution in the remaining area", file=open(F3Log, 'a'))
        MosaicArrayFinalFileMixResolutionFile = PlotIDFuzzyBufferArrayFunction(Tiles,MosaicArrayFinalFile, 1600, 240, Metric)
        print("Above added on 20230417 to reduce the resolution within fuzzy plot neighbouring area; In the future, we can do this for only-sensitive plots")
        print(MosaicArrayFinalFileMixResolutionFile, " was created Yahoo!", file=open(F3Log, 'a'))
        
        return MosaicArrayFinalFile
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for F3SpatialMosaicAndUncertainty with inputs of " + repr(mylock)+","+repr(Runs)+","+repr(Tiles)+","+repr(Management)+","+repr(Year)+","+repr(Metric)+","+repr( ProjectAOI) + " with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog
    

def ShapeAndRasterOverlayExtent(ShapeFile0,field_name,Rasterulx,Rasterlrx,Rasteruly,Rasterlry):
    try:
        print("With Rasterulx,Rasterlrx,Rasteruly,Rasterlry, we start to clip the shape file=",ShapeFile0)
        InputShapeGPD = gpd.read_file(ShapeFile0)
        Shapeulx, Shapelry, Shapelrx, Shapeuly = InputShapeGPD.geometry.total_bounds
        print("Shapeulx, Shapelry, Shapelrx, Shapeuly=",Shapeulx, Shapelry, Shapelrx, Shapeuly)
        ShapeRasterOverlay_ulx = max(Shapeulx,Rasterulx)
        ShapeRasterOverlay_lrx = min(Shapelrx,Rasterlrx)
        ShapeRasterOverlay_uly = min(Shapeuly,Rasteruly)
        ShapeRasterOverlay_lry = max(Shapelry,Rasterlry)
        PolygonVertices = [[ShapeRasterOverlay_ulx, ShapeRasterOverlay_lry], [ShapeRasterOverlay_ulx,ShapeRasterOverlay_uly], [ShapeRasterOverlay_lrx,ShapeRasterOverlay_uly], [ShapeRasterOverlay_lrx,ShapeRasterOverlay_lry], [ShapeRasterOverlay_ulx, ShapeRasterOverlay_lry]]  #PolygonVertices = [[0, 0], [0, 90], [180, 90], [180, 0], [0, 0]] is the reference. Note [] changed to () is also OK
        print("PolygonVertices=",PolygonVertices)
        ShapeFile = ClipShapeBasedOnCustmizedPolygon(ShapeFile0, PolygonVertices)
        print("With Rasterulx,Rasterlrx,Rasteruly,Rasterlry, we clipped the original shape into a new shape file=",ShapeFile)

        if field_name:
            output_tiff = ShapeFile.replace(".shp","_"+field_name+".tif")
        else:
            output_tiff = ShapeFile.replace(".shp",".tif")
        if not os.path.exists(output_tiff):
            if field_name:
                PolygonToRasterTif = PolygonToRaster2(ShapeFile, output_tiff, F3Resolution, field_name, NoData_value=F3NoDataValue)
            else:
                PolygonToRasterTif = PolygonToRaster2(ShapeFile, output_tiff, F3Resolution, False, NoData_value=F3NoDataValue)
            print("PolygonToRasterTif=",PolygonToRasterTif)
        PolygonToRasterTif = output_tiff
        
        src = gdal.Open(PolygonToRasterTif)
        cols = src.RasterXSize
        rows = src.RasterYSize
        WeUseThisProjectionShapeFile = src.GetProjectionRef()
        ThisTifArray = src.GetRasterBand(1).ReadAsArray()
        ThisTifNoDataValue = src.GetRasterBand(1).GetNoDataValue()
        ThisTifArray = ma.masked_values(ThisTifArray, ThisTifNoDataValue)  #added 20221019
        print("ThisTifNoDataValue=",ThisTifNoDataValue)
        upx, xres, xskew, upy, yskew, yres = src.GetGeoTransform()  #https://gis4programmers.wordpress.com/2017/01/06/using-gdal-to-get-raster-extent/, note GetGeoTransform not GetGeotransform
        ulx = float(upx + 0*xres + 0*xskew)
        uly = float(upy + 0*yskew + 0*yres)
        llx = float(upx + 0*xres + rows*xskew)
        lly = float(upy + 0*yskew + rows*yres)
        lrx = float(upx + cols*xres + rows*xskew)
        lry = float(upy + cols*yskew + rows*yres)
        urx = float(upx + cols*xres + 0*xskew)
        ury = float(upy + cols*yskew + 0*yres)    

        CommonOverlay_ulx = max(ulx,Rasterulx)
        CommonOverlay_lrx = min(lrx,Rasterlrx)
        CommonOverlay_uly = min(uly,Rasteruly)
        CommonOverlay_lry = max(lry,Rasterlry)

        print("20230322, I change the int to round (to get the closest integer), because the former one may create 1 offset. For example, int(0.99)=0 while round(0.99)=1. Note math.ceil(0.99)=1 but not good for here")
        ColumnMin_ForRaster = round(abs(CommonOverlay_ulx - Rasterulx) / F3Resolution)  #If the upperleft corner does not align perfectly, we may have problem here. Need to think it over 
        ColumnMax_ForRaster = round(abs(CommonOverlay_lrx - Rasterulx) / F3Resolution)  #We may +1 here? see https://opensourceoptions.com/blog/zonal-statistics-algorithm-with-python-in-4-steps/
        RowMin_ForRaster = round(abs(CommonOverlay_uly - Rasteruly) / F3Resolution)
        RowMax_ForRaster = round(abs(CommonOverlay_lry - Rasteruly) / F3Resolution)   #We may +1 here? but I prefer not, because this is just Raster, I do not care of missin gone pixel
        print("CommonOverlay_lry,Rasteruly,F3Resolution,RowMax_ForRaster,PolygonToRasterTif=",CommonOverlay_lry,Rasteruly,F3Resolution,RowMax_ForRaster,PolygonToRasterTif, file=open(F3Log, 'a'))
        return output_tiff, RowMin_ForRaster,RowMax_ForRaster,ColumnMin_ForRaster,ColumnMax_ForRaster,CommonOverlay_ulx, CommonOverlay_lrx, CommonOverlay_uly, CommonOverlay_lry
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for ShapeAndRasterOverlayExtent with inputs of " + repr(ShapeFile0)+repr(field_name)+","+repr(Rasterulx)+","+repr(Rasterlrx)+repr(Rasteruly)+","+repr(Rasterlry) + " with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog
    



def F3SpatialMosaicReliability(mylock,Runs,Tiles,Management,Year,Metric, ProjectAOI=False):  #Three rasters of Reliability, ValidCount, and PixelLabel are produced here
    try:
        MosaicArrayFinalReliabilityFile = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep + ProjectName + os.sep + "MosaicProcessingPercentageAsOrderAndReliabilityMean.tif"
        MosaicArrayFinalReliabilityMinFile = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep + ProjectName + os.sep + "MosaicProcessingPercentageAsOrderAndReliabilityMin.tif"
        MosaicArrayFinalReliabilityBestFile = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep + ProjectName + os.sep + "MosaicProcessingPercentageAsOrderAndReliabilityMinIndex.tif"
        MosaicArrayFinalReliabilityMedianFile = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep + ProjectName + os.sep + "MosaicProcessingPercentageAsOrderAndReliabilityMedian.tif"
        if not os.path.exists(MosaicArrayFinalReliabilityFile):
            SpatialMosaicTifListReliability = []
            SpatialMosaicTifListDataMask = []
            for Run in Runs:
                for Tile in Tiles:
                    Step4OutputTifReliability = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"Results"+os.sep+"ProcessingPercentageAsOrderAndReliability.tif"
                    DataMask = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"RSraster"+os.sep+"Img_"+BaseYear+"_PixelLabel.tif"   ##"In the final PixelLabel.tif from GEE , water is 1, Perennial/permanent Ice/Snow is 2, Barren-Rock/Sand/Clay is 3, Landsat cloud/shadow/snow is 4, remaining value is 0"
                    if Run == "Run1":
                        CorrespondingSegmentation = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R1_Y"+BaseYear+"_L1_S40_C18.tif"  #We haev different level segmentation, you can choose another one
                    if Run == "Run2":
                        CorrespondingSegmentation = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R2_Y"+BaseYear+"_L1_S32_C19.tif"
                    if Run == "Run3":
                        CorrespondingSegmentation = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R3_Y"+BaseYear+"_L1_S48_C17.tif"
                    if Run == "Run4":
                        CorrespondingSegmentation = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R3_Y"+BaseYear+"_L1_S48_C17.tif"  #We haev different level segmentation, you can choose another one
                    if Run == "Run5":
                        CorrespondingSegmentation = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R1_Y"+BaseYear+"_L1_S40_C18.tif"
                    if Run == "Run6":
                        CorrespondingSegmentation = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"R2_Y"+BaseYear+"_L1_S32_C19.tif"
                    Step4OutputTifBorderZshapeTifReliability = MosaicingBorderZshape(CorrespondingSegmentation,Step4OutputTifReliability,0.03,FloatToIntegerCoefficient)
                    if os.path.exists(Step4OutputTifBorderZshapeTifReliability):
                        SpatialMosaicTifListReliability.append(Step4OutputTifBorderZshapeTifReliability)
                        SpatialMosaicTifListDataMask.append(DataMask)

            if len(SpatialMosaicTifListReliability)%3 != 0:
                MosaicInput = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep + ProjectName + os.sep + Management+"_"+Year+"_"+Metric+"_MosaicReliabilityInput_Suspicious.txt"
            else:
                MosaicInput = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep + ProjectName + os.sep + Management+"_"+Year+"_"+Metric+"_MosaicReliabilityInput.txt"
            if not os.path.exists(MosaicInput):
                MosaicInputFile = open(MosaicInput, 'w')
                MosaicTime = "#This Reliability mosaic was created by Dr. Shengli Huang at " + datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + " with the following inputs:\n"
                MosaicInputFile.write(MosaicTime)
                for k in SpatialMosaicTifListReliability:
                    ThisLine = k + "\n"
                    MosaicInputFile.write(ThisLine)
                MosaicInputFile.close()

            Mosaiculx,Mosaiclrx,Mosaiculy,Mosaiclry = MultipleImageBoundingExtent(SpatialMosaicTifListReliability,Management,Year,Metric)
            print("Mosaiculx,Mosaiclrx,Mosaiculy,Mosaiclry=",Mosaiculx,Mosaiclrx,Mosaiculy,Mosaiclry)
            
            MosaicColumns = round(abs(Mosaiculx - Mosaiclrx) / F3Resolution)   #change int to round on 20230929: MosaicColumns = int(abs(Mosaiculx - Mosaiclrx) / F3Resolution)
            MosaicRows = round(abs(Mosaiculy - Mosaiclry) / F3Resolution)   #change int to round on 20230929: MosaicRows = int(abs(Mosaiculy - Mosaiclry) / F3Resolution)
            print("The columns and rows of mosaiced image are: ", MosaicColumns, MosaicRows)
            MosaicArrayReliability = np.full((len(SpatialMosaicTifListReliability),MosaicRows,MosaicColumns), F3NoDataValue)   #https://stackoverflow.com/questions/5891410/numpy-array-initialization-fill-with-identical-values
            MosaicArrayDataMask = np.full((len(SpatialMosaicTifListReliability),MosaicRows,MosaicColumns), F3NoDataValue)
            print("MosaicArray.shape=",MosaicArrayReliability.shape,"\n")
            WeUseThisGeoTransform = ([Mosaiculx, F3Resolution, 0, Mosaiculy, 0, -1.0 * F3Resolution ]) #see https://gis.stackexchange.com/questions/165950/gdal-setgeotransform-does-not-work-as-expected
            print(WeUseThisGeoTransform)

            #for Reliability and count---start
            k = -1
            for ThisTif in SpatialMosaicTifListReliability:
                k = k + 1
                src = gdal.Open(ThisTif)
                cols = src.RasterXSize
                rows = src.RasterYSize
                if k == 0:
                    WeUseThisProjection = src.GetProjectionRef()
                    print(WeUseThisProjection)
                print("ThisTif=",ThisTif," and the cols and rows are: ",cols,rows)

                ThisTifArray = src.GetRasterBand(1).ReadAsArray()
                print("ThisTifArray shape is ", ThisTifArray.shape)
                ThisTifNoDataValue = src.GetRasterBand(1).GetNoDataValue()
                print("ThisTifNoDataValue=",ThisTifNoDataValue)        
                ThisTifArray = ma.masked_values(ThisTifArray, ThisTifNoDataValue)
                ThisTifArray = ma.masked_values(ThisTifArray, F3NoDataValue)
                    
                upx, xres, xskew, upy, yskew, yres = src.GetGeoTransform()  #https://gis4programmers.wordpress.com/2017/01/06/using-gdal-to-get-raster-extent/, note GetGeoTransform not GetGeotransform
                ulx = float(upx + 0*xres + 0*xskew)
                uly = float(upy + 0*yskew + 0*yres)
                llx = float(upx + 0*xres + rows*xskew)
                lly = float(upy + 0*yskew + rows*yres)
                lrx = float(upx + cols*xres + rows*xskew)
                lry = float(upy + cols*yskew + rows*yres)
                urx = float(upx + cols*xres + 0*xskew)
                ury = float(upy + cols*yskew + 0*yres)
                ColumnMin = round(abs(ulx - Mosaiculx) / F3Resolution)  #change int to round on 20230929. If the upperleft corner does not align perfectly, we may have problem here. Need to think it over 
                ColumnMax = round(abs(lrx - Mosaiculx) / F3Resolution)  #change int to round on 20230929. We may +1 here? see https://opensourceoptions.com/blog/zonal-statistics-algorithm-with-python-in-4-steps/
                RowMin = round(abs(uly - Mosaiculy) / F3Resolution)     #change int to round on 20230929. 
                RowMax = round(abs(lry - Mosaiculy) / F3Resolution)   #change int to round on 20230929. We may +1 here? but I prefer not, because this is just mosaic, I do not care of missin gone pixel
                #print("ColumnMin,ColumnMax,RowMin,RowMax=",ColumnMin,ColumnMax,RowMin,RowMax)
                MosaicArrayReliability[k,RowMin:RowMax,ColumnMin:ColumnMax] = ThisTifArray  #remember the k is so important
            MosaicArrayMaskedReliability = ma.masked_values(MosaicArrayReliability, F3NoDataValue)
            MosaicArrayMaskedReliabilityMean = np.nanmean(MosaicArrayMaskedReliability,axis=0)
            MosaicArrayMaskedReliabilityMean = ma.masked_values(MosaicArrayMaskedReliabilityMean, F3NoDataValue)

            MosaicArrayMaskedReliabilityMin = np.nanmin(MosaicArrayMaskedReliability,axis=0)   #Min can be considered the best quality
            MosaicArrayMaskedReliabilityMin = ma.masked_values(MosaicArrayMaskedReliabilityMin, F3NoDataValue)
            MosaicArrayMaskedReliabilityBest = np.full((MosaicArrayMaskedReliabilityMin.shape[0],MosaicArrayMaskedReliabilityMin.shape[1]), F3NoDataValue)            
            for h in range(0,len(SpatialMosaicTifListReliability),1):
                MosaicArrayMaskedReliabilityBest[MosaicArrayMaskedReliability[h,:,:] == MosaicArrayMaskedReliabilityMin] = h

            MosaicArrayMaskedReliabilityMedian = np.ma.median(MosaicArrayMaskedReliability,axis=0)  #it is np.ma.median instead of np.nanmedian()
            MosaicArrayMaskedReliabilityMedian = ma.masked_values(MosaicArrayMaskedReliabilityMedian, F3NoDataValue)

            MosaicArrayFinalValidCount = np.count_nonzero(~np.isnan(MosaicArrayMaskedReliability),axis=0)  #Count how many valid. It is not checked, may not work, if work, then save it to a tif file, see http://www.kasimte.com/2020/02/13/how-do-i-count-numpy-nans.html
            MosaicArrayFinalValidCount = ma.masked_values(MosaicArrayFinalValidCount, F3NoDataValue)
            #for Reliability and count---end
            
            #for DataMask (or PixelLabel)--start
            k = -1
            for ThisTif in SpatialMosaicTifListDataMask:
                k = k + 1
                src = gdal.Open(ThisTif)
                cols = src.RasterXSize
                rows = src.RasterYSize
                if k == 0:
                    WeUseThisProjection = src.GetProjectionRef()
                    print(WeUseThisProjection)
                print("ThisTif=",ThisTif," and the cols and rows are: ",cols,rows)

                ThisTifArray = src.GetRasterBand(1).ReadAsArray()
                print("ThisTifArray shape is ", ThisTifArray.shape)
                ThisTifNoDataValue = src.GetRasterBand(1).GetNoDataValue()
                print("ThisTifNoDataValue=",ThisTifNoDataValue)        
                ThisTifArray = ma.masked_values(ThisTifArray, ThisTifNoDataValue)
                ThisTifArray = ma.masked_values(ThisTifArray, F3NoDataValue)
                    
                upx, xres, xskew, upy, yskew, yres = src.GetGeoTransform()  #https://gis4programmers.wordpress.com/2017/01/06/using-gdal-to-get-raster-extent/, note GetGeoTransform not GetGeotransform
                ulx = float(upx + 0*xres + 0*xskew)
                uly = float(upy + 0*yskew + 0*yres)
                llx = float(upx + 0*xres + rows*xskew)
                lly = float(upy + 0*yskew + rows*yres)
                lrx = float(upx + cols*xres + rows*xskew)
                lry = float(upy + cols*yskew + rows*yres)
                urx = float(upx + cols*xres + 0*xskew)
                ury = float(upy + cols*yskew + 0*yres)
                ColumnMin = round(abs(ulx - Mosaiculx) / F3Resolution)  #change int to round on 20230929. If the upperleft corner does not align perfectly, we may have problem here. Need to think it over 
                ColumnMax = round(abs(lrx - Mosaiculx) / F3Resolution)  #change int to round on 20230929. We may +1 here? see https://opensourceoptions.com/blog/zonal-statistics-algorithm-with-python-in-4-steps/
                RowMin = round(abs(uly - Mosaiculy) / F3Resolution)    #change int to round on 20230929. 
                RowMax = round(abs(lry - Mosaiculy) / F3Resolution)   #change int to round on 20230929. We may +1 here? but I prefer not, because this is just mosaic, I do not care of missin gone pixel
                #print("ColumnMin,ColumnMax,RowMin,RowMax=",ColumnMin,ColumnMax,RowMin,RowMax)
                MosaicArrayDataMask[k,RowMin:RowMax,ColumnMin:ColumnMax] = ThisTifArray  #rememebr the k is so important
            MosaicArrayDataMask = ma.masked_values(MosaicArrayDataMask, F3NoDataValue)
            MosaicArrayDataMaskMean = np.nanmean(MosaicArrayDataMask,axis=0)
            MosaicArrayDataMaskMean = ma.masked_values(MosaicArrayDataMaskMean, F3NoDataValue)
            #for DataMask (or PixelLabel)--end
            
            #We add the ProjectAOI here to subset the output TIF. --start
            if ProjectAOI:  #The general idea is to find the overlay but minimum corners and then indexing array
                output_tiff, RowMin_ForMosaic,RowMax_ForMosaic,ColumnMin_ForMosaic,ColumnMax_ForMosaic,CommonOverlay_ulx, CommonOverlay_lrx, CommonOverlay_uly, CommonOverlay_lry = ShapeAndRasterOverlayExtent(ProjectAOI,False,Mosaiculx,Mosaiclrx,Mosaiculy,Mosaiclry)
                print("reliability"," ProjectAOI RowMin_ForMosaic,RowMax_ForMosaic,ColumnMin_ForMosaic,ColumnMax_ForMosaic=",RowMin_ForMosaic,RowMax_ForMosaic,ColumnMin_ForMosaic,ColumnMax_ForMosaic, file=open(F3Log, 'a'))

                ForMosaic_CommonOverlay_Reliability = MosaicArrayMaskedReliabilityMean[RowMin_ForMosaic:RowMax_ForMosaic,ColumnMin_ForMosaic:ColumnMax_ForMosaic]
                ForMosaic_CommonOverlay_ReliabilityMin = MosaicArrayMaskedReliabilityMin[RowMin_ForMosaic:RowMax_ForMosaic,ColumnMin_ForMosaic:ColumnMax_ForMosaic]
                ForMosaic_CommonOverlay_ReliabilityBest = MosaicArrayMaskedReliabilityBest[RowMin_ForMosaic:RowMax_ForMosaic,ColumnMin_ForMosaic:ColumnMax_ForMosaic]
                ForMosaic_CommonOverlay_ReliabilityMedian = MosaicArrayMaskedReliabilityMedian[RowMin_ForMosaic:RowMax_ForMosaic,ColumnMin_ForMosaic:ColumnMax_ForMosaic]
                
                ForMosaic_CommonOverlay_ValidCount = MosaicArrayFinalValidCount[RowMin_ForMosaic:RowMax_ForMosaic,ColumnMin_ForMosaic:ColumnMax_ForMosaic]
                ForMosaic_CommonOverlay_DataMask = MosaicArrayDataMaskMean[RowMin_ForMosaic:RowMax_ForMosaic,ColumnMin_ForMosaic:ColumnMax_ForMosaic]

                driverTiff = gdal.GetDriverByName('GTiff')
                ds = gdal.Open(output_tiff)
                srcCols = ds.RasterXSize
                srcRows = ds.RasterYSize
                WeUseThisProjection = ds.GetProjectionRef()
                WeUseThisGeoTransform = ds.GetGeoTransform()
                output_tiff_masked = ReadTifToArray(output_tiff)
                print("Reliability output_tiff_masked shape is ", output_tiff_masked.shape, file=open(F3Log, 'a'))
                
                ForMosaic_CommonOverlay_Reliability[output_tiff_masked.mask] = F3NoDataValue
                ForMosaic_CommonOverlay_ReliabilityMin[output_tiff_masked.mask] = F3NoDataValue
                ForMosaic_CommonOverlay_ReliabilityBest[output_tiff_masked.mask] = F3NoDataValue
                ForMosaic_CommonOverlay_ReliabilityMedian[output_tiff_masked.mask] = F3NoDataValue
                ForMosaic_CommonOverlay_ValidCount[output_tiff_masked.mask] = F3NoDataValue
                ForMosaic_CommonOverlay_DataMask[output_tiff_masked.mask] = F3NoDataValue
                MosaicColumns = srcCols
                MosaicRows = srcRows
                
                MosaicArrayMaskedReliabilityMean = ForMosaic_CommonOverlay_Reliability
                MosaicArrayMaskedReliabilityMin = ForMosaic_CommonOverlay_ReliabilityMin
                MosaicArrayMaskedReliabilityBest = ForMosaic_CommonOverlay_ReliabilityBest
                MosaicArrayMaskedReliabilityMedian = ForMosaic_CommonOverlay_ReliabilityMedian
                MosaicArrayFinalValidCount = ForMosaic_CommonOverlay_ValidCount
                MosaicArrayDataMaskMean = ForMosaic_CommonOverlay_DataMask
            #We add the ProjectAOI here to subset the output TIF. --end
            
            driver = gdal.GetDriverByName("GTiff")
            if OutputGeoTifCompression == "Yes": #Added on 20230227. LZW compression does not lose information. LZW compression is a lossless data compression algorithm, which means that the original data can be fully reconstructed from the compressed data without any loss of information.
                outdataReliability = driver.Create(MosaicArrayFinalReliabilityFile, MosaicArrayMaskedReliabilityMean.shape[1], MosaicArrayMaskedReliabilityMean.shape[0], 1, gdal.GDT_Int32, options=['COMPRESS=LZW'])   #see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
                outdataReliabilityMin = driver.Create(MosaicArrayFinalReliabilityMinFile, MosaicArrayMaskedReliabilityMin.shape[1], MosaicArrayMaskedReliabilityMin.shape[0], 1, gdal.GDT_Int32, options=['COMPRESS=LZW'])
                outdataReliabilityBest = driver.Create(MosaicArrayFinalReliabilityBestFile, MosaicArrayMaskedReliabilityBest.shape[1], MosaicArrayMaskedReliabilityBest.shape[0], 1, gdal.GDT_Int32, options=['COMPRESS=LZW']) 
                outdataReliabilityMedian = driver.Create(MosaicArrayFinalReliabilityMedianFile, MosaicArrayMaskedReliabilityMedian.shape[1], MosaicArrayMaskedReliabilityMedian.shape[0], 1, gdal.GDT_Int32, options=['COMPRESS=LZW']) 
            if OutputGeoTifCompression == "No": 
                outdataReliability = driver.Create(MosaicArrayFinalReliabilityFile, MosaicArrayMaskedReliabilityMean.shape[1], MosaicArrayMaskedReliabilityMean.shape[0], 1, gdal.GDT_Int32)   #see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
                outdataReliabilityMin = driver.Create(MosaicArrayFinalReliabilityMinFile, MosaicArrayMaskedReliabilityMin.shape[1], MosaicArrayMaskedReliabilityMin.shape[0], 1, gdal.GDT_Int32)
                outdataReliabilityBest = driver.Create(MosaicArrayFinalReliabilityBestFile, MosaicArrayMaskedReliabilityBest.shape[1], MosaicArrayMaskedReliabilityBest.shape[0], 1, gdal.GDT_Int32)
                outdataReliabilityMedian = driver.Create(MosaicArrayFinalReliabilityMedianFile, MosaicArrayMaskedReliabilityMedian.shape[1], MosaicArrayMaskedReliabilityMedian.shape[0], 1, gdal.GDT_Int32)
            print("SetGeoTransform and SetProjection usage, see http://www2.geog.ucl.ac.uk/~plewis/geogg122_local/geogg122-old/Chapter4_GDAL/GDAL_Python_bindings.html")
            outdataReliability.SetGeoTransform(WeUseThisGeoTransform)  
            outdataReliability.SetProjection(WeUseThisProjection)      
            outdataReliability.GetRasterBand(1).WriteArray(MosaicArrayMaskedReliabilityMean)
            outdataReliability.GetRasterBand(1).SetNoDataValue(F3NoDataValue)   
            outdataReliability.FlushCache()  
            outdataReliability = None
            print(MosaicArrayFinalReliabilityFile, " is created")

            outdataReliabilityMin.SetGeoTransform(WeUseThisGeoTransform)  #20240506 added for additional outdataReliabilityMedian file
            outdataReliabilityMin.SetProjection(WeUseThisProjection)      
            outdataReliabilityMin.GetRasterBand(1).WriteArray(MosaicArrayMaskedReliabilityMin)
            outdataReliabilityMin.GetRasterBand(1).SetNoDataValue(F3NoDataValue)   
            outdataReliabilityMin.FlushCache()  
            outdataReliabilityMin = None
            print(MosaicArrayFinalReliabilityMinFile, " is created")

            outdataReliabilityBest.SetGeoTransform(WeUseThisGeoTransform)  #20240506 added for additional outdataReliabilityMedian file
            outdataReliabilityBest.SetProjection(WeUseThisProjection)      
            outdataReliabilityBest.GetRasterBand(1).WriteArray(MosaicArrayMaskedReliabilityBest)
            outdataReliabilityBest.GetRasterBand(1).SetNoDataValue(F3NoDataValue)   
            outdataReliabilityBest.FlushCache()  
            outdataReliabilityBest = None
            print(MosaicArrayFinalReliabilityBestFile, " is created")
            
            outdataReliabilityMedian.SetGeoTransform(WeUseThisGeoTransform)  #20240506 added for additional outdataReliabilityMedian file
            outdataReliabilityMedian.SetProjection(WeUseThisProjection)      
            outdataReliabilityMedian.GetRasterBand(1).WriteArray(MosaicArrayMaskedReliabilityMedian)
            outdataReliabilityMedian.GetRasterBand(1).SetNoDataValue(F3NoDataValue)   
            outdataReliabilityMedian.FlushCache()  
            outdataReliabilityMedian = None
            print(MosaicArrayFinalReliabilityMedianFile, " is created")
            
            
            MosaicArrayFinalCountFile = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep + ProjectName + os.sep + "MosaicCount.tif"
            driver = gdal.GetDriverByName("GTiff")
            if OutputGeoTifCompression == "Yes": #Added on 20230227. LZW compression does not lose information. LZW compression is a lossless data compression algorithm, which means that the original data can be fully reconstructed from the compressed data without any loss of information.
                outdataCount = driver.Create(MosaicArrayFinalCountFile, MosaicArrayFinalValidCount.shape[1], MosaicArrayFinalValidCount.shape[0], 1, gdal.GDT_Int32, options=['COMPRESS=LZW'])   #see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
            if OutputGeoTifCompression == "No": 
                outdataCount = driver.Create(MosaicArrayFinalCountFile, MosaicArrayFinalValidCount.shape[1], MosaicArrayFinalValidCount.shape[0], 1, gdal.GDT_Int32)   #see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
            print("SetGeoTransform and SetProjection usage, see http://www2.geog.ucl.ac.uk/~plewis/geogg122_local/geogg122-old/Chapter4_GDAL/GDAL_Python_bindings.html")
            outdataCount.SetGeoTransform(WeUseThisGeoTransform)  
            outdataCount.SetProjection(WeUseThisProjection)      
            outdataCount.GetRasterBand(1).WriteArray(MosaicArrayFinalValidCount)
            outdataCount.GetRasterBand(1).SetNoDataValue(F3NoDataValue)   
            outdataCount.FlushCache()  
            outdataCount = None
            print(MosaicArrayFinalCountFile, " is created")

            MosaicArrayFinalDataMaskFile = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep + ProjectName + os.sep + "MosaicPixelLabel.tif" 
            driver = gdal.GetDriverByName("GTiff")
            if OutputGeoTifCompression == "Yes": #Added on 20230227. LZW compression does not lose information. LZW compression is a lossless data compression algorithm, which means that the original data can be fully reconstructed from the compressed data without any loss of information.
                MosaicPixelLabel = driver.Create(MosaicArrayFinalDataMaskFile, MosaicArrayDataMaskMean.shape[1], MosaicArrayDataMaskMean.shape[0], 1, gdal.GDT_Int32, options=['COMPRESS=LZW'])   #see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
            if OutputGeoTifCompression == "No": 
                MosaicPixelLabel = driver.Create(MosaicArrayFinalDataMaskFile, MosaicArrayDataMaskMean.shape[1], MosaicArrayDataMaskMean.shape[0], 1, gdal.GDT_Int32)   #see datatype at https://gis.stackexchange.com/questions/268898/using-signed-bytes-with-gdal
            print("SetGeoTransform and SetProjection usage, see http://www2.geog.ucl.ac.uk/~plewis/geogg122_local/geogg122-old/Chapter4_GDAL/GDAL_Python_bindings.html")
            MosaicPixelLabel.SetGeoTransform(WeUseThisGeoTransform)  
            MosaicPixelLabel.SetProjection(WeUseThisProjection)
            print("In the final PixelLabel.tif from GEE , water is 1, Perennial/permanent Ice/Snow is 2, Barren-Rock/Sand/Clay is 3, Landsat cloud/shadow/snow is 4, no RS image is 5, remaining value is 0. Here if the pixel is not imputed, we give a value of 6")
            MosaicArrayDataMaskMean[(MosaicArrayDataMaskMean==0) & (MosaicArrayMaskedReliabilityMean.mask)] = 6  #if original PixelLabel=0 but the final MosaicArrayMaskedReliabilityMean has a vale, it means the good quality pixel was not imputed due to a) insufficient plots or b) outside of Z-border, so give a value of 5

            #20240311 added to exclude nonforest area which extracted from US crop layer and USFS LCMS land cover---start
            MosaicArrayDataMaskMean = ma.masked_values(MosaicArrayDataMaskMean, F3NoDataValue)
            MosaicForest1Nonforest0File = MosaicForest1Nonforest0TifFileWithGISshape(mylock,Runs,Tiles, Management,Year,Metric)
            MosaicCropLayerFile = MosaicCropLayerTifFileWithGISshape(mylock,Runs,Tiles, Management,Year,Metric)  #added on 20240521 to mosaic CropLayer
            ds = gdal.Open(MosaicForest1Nonforest0File)
            MosaicForest1Nonforest0Array0 = ds.GetRasterBand(1).ReadAsArray()
            MosaicForest1Nonforest0Array0NodataValue = ds.GetRasterBand(1).GetNoDataValue()
            MosaicForest1Nonforest0Array0 = ma.masked_values(MosaicForest1Nonforest0Array0, MosaicForest1Nonforest0Array0NodataValue)
            MosaicForest1Nonforest0Array = MosaicForest1Nonforest0Array0[RowMin_ForMosaic:RowMax_ForMosaic,ColumnMin_ForMosaic:ColumnMax_ForMosaic]
            MosaicArrayDataMaskMean[(MosaicForest1Nonforest0Array == 0) & (MosaicArrayDataMaskMean == 0)] = 99  #Give 99 to Nonforested pixels determined from USCROP and USFS LCMS
            #20240311 added to exclude nonforest area which extracted from US crop layer and USFS LCMS land cover---end

            MosaicPixelLabel.GetRasterBand(1).WriteArray(MosaicArrayDataMaskMean)
            MosaicPixelLabel.GetRasterBand(1).SetNoDataValue(F3NoDataValue)   
            MosaicPixelLabel.FlushCache()  
            MosaicPixelLabel = None
            print(MosaicArrayFinalDataMaskFile, " is created")
            MosaicArrayFinalDataMaskFile = AddingRasterAttributeTableToPixelLabelGeoTif(MosaicArrayFinalDataMaskFile)  #added on 20240315 for appending raster attribute table
            
            if EncryptSensitiveFile == "Yes":
                MosaicArrayFinalReliabilityFile = EncryptImage(MosaicArrayFinalReliabilityFile)

        SpatialMosaicTifListReliabilityDelete = "No"
        if ((F3DebugMode == "No") and (SpatialMosaicTifListReliabilityDelete == "Yes")):
            for k in SpatialMosaicTifListReliability:
                os.remove(k)
                print("ProcessingPercentageAsOrderAndReliability.tif of ",k, " was deleted at " + datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
                print("ProcessingPercentageAsOrderAndReliability.tif of ",k, " was deleted at " + datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"), file=open(F3Log, 'a'))
        return MosaicArrayFinalReliabilityFile
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for F3SpatialMosaicReliability with inputs of " + repr(mylock)+","+repr(Runs)+","+repr(Tiles)+","+repr(Management)+","+repr(Year)+","+repr(Metric)+","+repr( ProjectAOI) + " with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog


def F3SpatialMosaicTifMetadata(Runs,Tiles,Management,Year,Metric,FloatToIntegerCoefficient,SmootheringYesOrNo):
    try:
        if Metric in ContinuousMetrics:
            if SmootheringYesOrNo == "No":
                MosaicArrayFinalFile = os.getcwd()+os.sep+"TilesMosaicRunAverage" + os.sep + ProjectName + os.sep + Management + "_"+Year+"_"+Metric+"_MosaicCellMean.tif"
            if SmootheringYesOrNo == "Yes":
                MosaicArrayFinalFile = os.getcwd()+os.sep+"TilesMosaicRunAverage" + os.sep + ProjectName + os.sep + Management + "_"+Year+"_"+Metric+"_MosaicCellMean_Win3x3Smoothing.tif"
        if Metric in DiscreteMetrics:
            if SmootheringYesOrNo == "No":
                MosaicArrayFinalFile = os.getcwd()+os.sep+"TilesMosaicRunAverage" + os.sep + ProjectName + os.sep + Management + "_"+Year+"_"+Metric+"_MosaicCellMode.tif"
            if SmootheringYesOrNo == "Yes":
                MosaicArrayFinalFile = os.getcwd()+os.sep+"TilesMosaicRunAverage" + os.sep + ProjectName + os.sep + Management + "_"+Year+"_"+Metric+"_MosaicCellMode_Win3x3Smoothing.tif"

        print("Check https://drr.ikcest.org/tutorial/k8022 for how to get raster meta info from GDAL")
        print("**************************MosaicArrayFinalFile=",MosaicArrayFinalFile)
        ds = gdal.Open(MosaicArrayFinalFile)
        NumberOfBand = ds.RasterCount
        cols = ds.RasterXSize
        rows = ds.RasterYSize
        upx, xres, xskew, upy, yskew, yres = ds.GetGeoTransform()  #e.g., (1852951.7603168152, 30.0, 0.0, 5309350.360150607, 0.0, -30.0)
        ulx = float(upx + 0*xres + 0*xskew)
        uly = float(upy + 0*yskew + 0*yres)
        llx = float(upx + 0*xres + rows*xskew)
        lly = float(upy + 0*yskew + rows*yres)
        lrx = float(upx + cols*xres + rows*xskew)
        lry = float(upy + cols*yskew + rows*yres)
        urx = float(upx + cols*xres + 0*xskew)
        ury = float(upy + cols*yskew + 0*yres)
        Projection = ds.GetProjection()  #e.g., 'PROJCS["unnamed",GEOGCS["unknown",DATUM["unknown",SPHEROID[
        band = ds.GetRasterBand(1)
        Columns = band.XSize
        Rows = band.YSize
        GetNoDataValue = band.GetNoDataValue()  #e.g., -9999
        MaxiValue = band.GetMaximum()
        MiniValue = band.GetMinimum()
        DataType = band.DataType  #e.g, 1. see gdal datatype at https://drr.ikcest.org/tutorial/k8023
        if DataType == 0:
           ThisDataType = str(DataType) + " (Unknown)"
        if DataType == 1:
           ThisDataType = str(DataType) + " (Byte)"
        if DataType == 2:
           ThisDataType = str(DataType) + " (UInt16)"
        if DataType == 3:
           ThisDataType = str(DataType) + " (Int16)"
        if DataType == 4:
           ThisDataType = str(DataType) + " (UInt32)"
        if DataType == 5:
           ThisDataType = str(DataType) + " (Int32)"
        if DataType == 6:
           ThisDataType = str(DataType) + " (Float32)"
        if DataType == 7:
           ThisDataType = str(DataType) + " (Float64)"
        if DataType == 8:
           ThisDataType = str(DataType) + " (CInt16)"
        if DataType == 9:
           ThisDataType = str(DataType) + " (CInt32)"
        if DataType == 10:
           ThisDataType = str(DataType) + " (CFloat32)"
        if DataType == 11:
           ThisDataType = str(DataType) + " (CFloat64)"
        MetadataInfo1 = "Imageformat=GeoTif"+";"
        MetadataInfo2 = "DataType="+ThisDataType+";"
        MetadataInfo3 = "NumberOfBands="+str(NumberOfBand)+";"
        MetadataInfo4 = "NumberOfColumns="+str(Columns)+";"
        MetadataInfo5 = "NumberOfRows="+str(Rows)+";"
        MetadataInfo6 = "SpatialResolution(Meters)="+str(xres)+";"
        MetadataInfo7 = "UpperLeft Corner(Meters) for X="+str(ulx)+";"
        MetadataInfo8 = "UpperLeft Corner(Meters) for Y="+str(uly)+";"
        MetadataInfo9 = "NoData value (cloud, snow, glacier, water, bareland, meadows etc.)="+str(GetNoDataValue)+";"
        MetadataInfoList = [
            MetadataInfo1,
            MetadataInfo2,
            MetadataInfo3,
            MetadataInfo4,
            MetadataInfo5,
            MetadataInfo6,
            MetadataInfo7,
            MetadataInfo8,
            MetadataInfo9,
            ]
        MetadataInfo = " ".join(MetadataInfoList)
        
        
        #added on 20230222 to add more metadata---start
        MetricShortName,MetricFullName,MetricDefinition,SpeciesScienticName,USDAPlantCode,FVSKeyword,MetricUnit_US,MetricUnit_SI,UStoSIconversion,MetricShortNameIGivenBy,MetricFullNameIGivenBy,AdditionalNotes = MetricInformationFromXLSX(Metric)
        if int(UStoSIconversion) == 1:
            AdditionMetadataInfo = "The full name of "+MetricShortName+" is ["+MetricFullName+"] whose definition is ["+MetricDefinition+"]."
            if ((Metric.lower() == "fortyp") or (Metric.lower() == "fortype")):
                AdditionMetadataInfo = AdditionMetadataInfo + " The forest type code and land cover can be found in the associated ForestAndCropType.csv"
        else:
            if OutputUnit == "Imperial":
               if SpeciesScienticName.upper() != "NA":
                   AdditionMetadataInfo = "The full name of "+MetricShortName+" is ["+MetricFullName+"] whose definition is ["+MetricDefinition+"]."+" The unit is "+MetricUnit_US+"."+" The Species Scientic Name is "+SpeciesScienticName+"." 
               if SpeciesScienticName.upper() == "NA":
                   AdditionMetadataInfo = "The full name of "+MetricShortName+" is ["+MetricFullName+"] whose definition is ["+MetricDefinition+"]."+" The unit is "+MetricUnit_US+"." 
            if OutputUnit == "SI":
               if SpeciesScienticName.upper() != "NA":
                   AdditionMetadataInfo = "The full name of "+MetricShortName+" is ["+MetricFullName+"] whose definition is ["+MetricDefinition+"]."+" The unit is "+MetricUnit_SI+"."+" The Species Scientic Name is "+SpeciesScienticName+"." 
               if SpeciesScienticName.upper() == "NA":
                   AdditionMetadataInfo = "The full name of "+MetricShortName+" is ["+MetricFullName+"] whose definition is ["+MetricDefinition+"]."+" The unit is "+MetricUnit_SI+"."             
        if Metric in ["fortyp","fortype"]:
            MetadataInfo = MetadataInfo + " " + AdditionMetadataInfo + "."
        else:
            MetadataInfo = MetadataInfo + " " + AdditionMetadataInfo + ". IMPORTANCE: Please divide the raster by " + str(FloatToIntegerCoefficient)+ " to get the actual value"
        #added on 20230222 to add more metadata---end
        
        
        F3SpatialMosaicTifMetadataFile = MosaicArrayFinalFile.replace(".tif","_readme.txt")
        if not os.path.exists(F3SpatialMosaicTifMetadataFile):
            F3SpatialMosaicTifMetadataFile1 = open(F3SpatialMosaicTifMetadataFile, 'w')
            title = "Title: The " +  Metric + " for the management scenario of " + Management + " for the year of " + Year 
            tags = "Keyword: Forest Inventory Analysis, Remote Sensing, Forest Vegetation Simlator, Forest Ecology, Spatiotemporal Mapping, F3 modeling"
            summary = "Summary: Forest Condition/Composition/Function derived from F3 modeling and mapping system under high-performance computation platform"
            F3credits = " 1) F3 algorithm and the relevant scripts are developed and maintained by Dr. Shengli Huang; Please send any questions to shengli.huang@usda.gov. Citation: Huang, S, C Ramirez, M McElhaney, K Evans. 2018. F3: Simulating spatiotemporal forest change from field inventory, remote sensing, growth modeling, and management actions. Forest Ecology and Management 415-416: 26-37."
            description1 = " 2) F3 is an algorithm that combines ground-based (FIA, Forest Inventory and Analysis plots) and remote sensing data (e.g., Landsat, 30 x 30 m pixel resolution) to create maps of ecosystem metrics under different management scenarios (Huang et al. 2018)"
            description2 = " 3) The projection of this specific raster are: " + Projection 
            description3 = " 4) The meta info of this specific raster is: " + MetadataInfo
            description4 = " 5) There is an associated MosaicPixelLabel.tif depicting the nodata: water is 1, Perennial/permanent Ice/Snow is 2, Barren-Rock/Sand/Clay is 3, Landsat cloud/shadow/snow is 4, no remote sensing collection is 5, unmapped area is 6, nonforested area is 99, and the remaining area is 0"
            description5 = " 6) The description and unit of this metric can also be found in a separate excel file, which can be obtained from Dr. Shengli Huang"
            description6 = " 7) The product was created with the F3 python code version of " + sys.argv[0].split(os.sep)[-1] + " at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + " by " + os.environ.get("USERNAME") + " in the computer of " + socket.gethostname() + " with IP address of " + socket.gethostbyname(socket.gethostname())
            description7 = " 8) The remote sensing data used for this product are the Landsat May-September composition of year " + BaseYear +"; therefore, any actual disturbance (e.g., fire, logging, beetle, and drought) that took place during or after "+ BaseYear + " are not reflected in this F3 product. If you are interested in the post disturbance recovery, please read the article [Huang, S., C. Ramirez, M. McElhaney, C. Clark, and Z. Yao. Quantifying spatiotemporal post disturbance recovery using field inventory, tree growth, and remote sensing. Earth and Space Science 6, no. 3 (2019): 489-504] and contact Dr. Shengli Huang at shengli.huang@usda.gov for further discussion" 
            description8 = " 9) The results may not be accurate for several reasons: a). Field plots may not be dense enough (e.g., The metrics in mountainous meadows may not be reliable because there are no representative field plots); b) Composite images may mask out disturbance; c) Disturbed plot may not be screened out; d) FVS_ready data and FVS modeling may have bias or mistake; e) Field plot coordinates may not be precise" 
            description9 = " 10) Please note F3 products only include trees. If one finds an area with very dense vegetation has zero biomass etc., the vegetation may not be tree but shrub or grass (e.g., California chaparral or middle western sagebrush). F3 has a special extension using Rangeland Vegetation Simulator (RVS) for this purpose. Please contact Dr. Shengli Huang if it is of interests"   
            description10 = " 11) F3 products are currently in continuous development, and therefore they are provided only as an example for experimental use by remote sensing researchers and/or for evaluation purposes. Accuracy may vary due to different reasons. Products may be: developed from sources of differing accuracy, resolution, or availability; more or less accurate at certain scales, based on modeling or interpretation; or incomplete while being created or revised. Users are encouraged to contact the developers to ensure that the assumptions behind and limitations of the data are appropriate for the intended use. Using F3 products for purposes other than those for which they were created may yield inaccurate or misleading results. The USDA Forest Service makes no warranty, expressed or implied, including the warranties of merchantability and fitness for a particular purpose, nor assumes any legal liability or responsibility for the accuracy, reliability, completeness or utility of these geospatial data, or for the improper or incorrect use of these data. The Forest Service reserves the right to correct, update, modify, or replace F3 products without notification."
            description11 = " 12) Although F3 products are delivered as 30-meter pixels, the products were designed for landscape level analyses, and analysis at the single pixel scale is not recommended. We suggest the minimum mapping unit be about 10000 square meters (i.e., 1 ha). Managers and planners are advised to consult F3 developers regarding the scale and product requirements specific to their needs"
            description12 = " 13) This is a collaborative effort of the U.S. Forest Health Protection, Forest Health Assessment and Applied Sciences Team (i.e. FHAAST). Shengli Huang developed the algorthm and the code and transferred technology; Jamie Hoover screened FIA plots with land cover and land use data and ran the imputation; David Kolodziejski preprocessed the data in Google Earth Engine and ran Forest Vegetation Similation; William Monahan managed FIA confidential locations and reviewed the data; Frank Krist conducted internal data review for suggested improvement; Bradley Carman provided IT technical support; Marla Downing and Ryan Hanavan provided administrative management"
            description13 = " 14) When the F3 products are used for any publication or report, an acknowledgement is appreciated [F3 products were provided by the Forest Health Protection, Forest Health Assessment and Applied Sciences Team, USDA Forest Service, State Private and Tribal Forestry, 2150 Centre Avenue, Building A, Ste. 331, Fort Collins, CO 80526-8117. Any use of trade, product, or firm names is for descriptive purposes only and does not imply endorsement by the U.S. Government]"                                                     
            description14 = " 15) These products are not possible without the support from FIA program who granted the the access to the confidentail plot coordinates. FHAAST team also thank the FVS members Lance David and Mark Castle for their support as well as Marcus Mcelhaney for sharing his FVS experience" 
            description15 = " 16) F3 is not just a forest condition mapping and modeling system, it is also a forest ecosystem service assessment system. F3 can be used for evaluating timber production, wildland fire, water yield, carbon sequestration, wildlife biodiversity, and soil erosion. Please contact Shengli Huang for further discussion" 
            description16 = "Several Frequently Asked Questions (FAQs) as below" + "\n" + "Question 1: "
            multipleline = [
                title,
                tags,
                summary,
                F3credits,
                description1,
                description2,
                description3,
                description4,
                description5,
                description6,
                description7,
                description8,
                description9,
                description10,
                description11,
                description12,
                description13,
                description14,
                description15,
            ]
            Content = '\n'.join(multipleline)                                                    
            F3SpatialMosaicTifMetadataFile1.write(Content)
            F3SpatialMosaicTifMetadataFile1.close()

        #20230224: It seems we can develop a separate function 
        return F3SpatialMosaicTifMetadataFile
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for F3SpatialMosaicTifMetadata with inputs of " + repr(Runs)+","+repr(Tiles)+","+repr(Management)+","+repr(Year)+","+repr(Metric)+","+repr(FloatToIntegerCoefficient) + " with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog


def F3FourSteps(mylock,Run,Tile,Management,Year,Metric):
    try:
        FinalTifname1 = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"Results"+os.sep+Management+"_"+Year+"_"+Metric+".tif"
        if ((F3DebugMode == "Yes") and os.path.exists(FinalTifname1)):
            if is_file_locked(FinalTifname1):  #added on 20240430. Note we have a function [def is_file_locked()]
                print(FinalTifname1," is locked by another process so we cannot remove it")
            else:
                print(FinalTifname1," is not locked by another process, so we will remove it")
                os.remove(FinalTifname1)
        else:
            if os.path.exists(FinalTifname1):  #20240203 added to avoid the reprocessing
                return
        t0 = time.time()
        CloudWaterShadowMask,InputRemoteSensingImagesPixelLabel,MaximumTargetPixelNumber,InputRemoteSensingImagesReal,InputRemoteSensingImagesPseudo,RemoteSensingSegmentationFromFineToCoarse,AdditionalDiscreteRaster,AdditionalContinuousRaster,Step2IntensifyingPlotsBin,Step3IterativeImputationBinValueFromHighToLow,FieldSqlite = RunTileInput(Run,Tile,BaseManagement,BaseYear,BaseMetric)
        print("\n\n\n\n############################################RemoteSensingSegmentationFromFineToCoarse=",RemoteSensingSegmentationFromFineToCoarse)        
        CloudWaterShadowMaskData = ReadTifToArray(CloudWaterShadowMask).astype('int64')
        CloudWaterShadowMaskData = ma.masked_values(CloudWaterShadowMaskData, F3NoDataValue)
        RasterMasked,ulx,uly,llx,lly,lrx,lry,urx,ury = ReadTifToArrayAndReturnExtent(CloudWaterShadowMask)  #20240403 added for processing EPA ECO4 shape to tif
        
        print("There are some void pixels, but the remaining MaximumTargetPixelNumber=",MaximumTargetPixelNumber)
        print("Metrics=",Metrics)
        print("FieldSqlite=",FieldSqlite)
        ValidMetrics = FindValidMetrics(Metrics,FieldSqlite,Run,Tile,Management,Year,Metric)
        print("ValidMetrics=",ValidMetrics)
        if Metric not in ValidMetrics:
            print(Metric, " is not in ", ValidMetrics, " so we will not process anything at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"), file=open(F3Log, 'a'))
            return

        MetricMinMaxPercentileMessage = MetricMinMaxPercentile(Run,Tile,Management,Year,Metric,FloatToIntegerCoefficient)  #added on 20240201 for the MAX=MIN (e.g., most cases are species 0 absence and 1 presence)
        #print("@@@@@@@@@@@@@@@@@@@@@@@MetricMinMaxPercentileMessage=",MetricMinMaxPercentileMessage)
        if MetricMinMaxPercentileMessage == "NotNecessaryToContinueComputation":   #MetricMinMaxPercentileMessage may be the name of metric, then it will continue
            return  
        
        #F3 step 1 processing-----create a metric 2D array
        print("InputRemoteSensingImagesReal=",InputRemoteSensingImagesReal)
        RGBTif = CreateRGBimage(InputRemoteSensingImagesReal)
        print("RGBTif was created as ",RGBTif)
        Step1ArrayTif = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"Intermediate"+os.sep+Management+"_"+Year+"_"+Metric+"_step1.tif"
        PlotIDTif = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"CommonShare"+os.sep+"YangDiBianMa.tif"
        if ((F3DebugMode == "Yes") and os.path.exists(Step1ArrayTif)):
            FinalMetricArray = ReadTifToArray(Step1ArrayTif).astype('int64')
        else:
            print("Here PlotIDTif 2 = ",PlotIDTif)
            FinalMetricArray = CreateMetricArray(Run,Tile,Management,Year,Metric,FloatToIntegerCoefficient)          
            #print("FinalMetricArray.count=",FinalMetricArray.count())  #20240131, there is an error 'TypeError: count() takes at least 1 argument (0 given), but I tested and found .count() is a good funvtion. I am not sure why, but comment because it is not important
            print("The mean, max, and min from step 1 is: ", np.nanmean(FinalMetricArray),np.nanmax(FinalMetricArray),np.nanmin(FinalMetricArray))
            if ((Management in [BaseManagement]) and (Year in [BaseYear]) and (Metric in [BaseMetric])):
                Step1ContinuousPredictionTif = Step1ContinuousPrediction(Run,Tile,Management,Year,Metric,FloatToIntegerCoefficient)
                print(Step1ContinuousPredictionTif, "was finished")
            if (((Metric in CrossValidationMetric) and (Management == BaseManagement) and (Year == BaseYear)) or (F3DebugMode == "Yes") or ((Management == BaseManagement) and (Year == BaseYear) and (Metric == BaseMetric))):  #20230308 add (Metric in CrossValidationMetricHere)
                FinalMetricArrayAAA = FinalMetricArray.copy()
                Step1Tif = Save2DArrayToTif(Run,Tile,Management,Year,Metric,FinalMetricArrayAAA,Step1ArrayTif)
            print("Step1 for ",Run,Tile,Management,Year,Metric," finished at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
        Step1ContinuousPredictionTif = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"CommonShare"+ os.sep + "BaseManagementBaseYearBaseMetricPlotDatabase_RegressionPredicted.tif"   #added 20230103 to assure this exists for the subsequent processing

        FinalMetricArray[np.isnan(FinalMetricArray)] = F3NoDataValue   #added 20221006
        FinalMetricArray[(FinalMetricArray > (F3NoDataValue-1)) & (FinalMetricArray < (F3NoDataValue+1))] = F3NoDataValue  #float cannot compare due to precision?
        FinalMetricArray = ma.masked_values(FinalMetricArray, F3NoDataValue)  


        Step1MetricArray = FinalMetricArray.copy()
        if ((Management == BaseManagement) and (Year == BaseYear) and (Metric == BaseMetric)):
            ProcessingPercentageAsOrderAndReliability = np.full((Step1MetricArray.shape[0],Step1MetricArray.shape[1]), F3NoDataValue)  #shape return rows and columns
            ProcessingPercentageAsOrderAndReliability = ma.masked_values(ProcessingPercentageAsOrderAndReliability, F3NoDataValue)
            ProcessingPercentageAsOrderAndReliability[CloudWaterShadowMaskData.mask] = F3NoDataValue
            ProcessingPercentageAsOrderAndReliability = ma.masked_values(ProcessingPercentageAsOrderAndReliability, F3NoDataValue)
            ProcessingPercentageAsOrderAndReliability[ProcessingPercentageAsOrderAndReliability.mask & (~FinalMetricArray.mask)] = Step1MetricArray.count() * 1000000.0 / MaximumTargetPixelNumber
            print("Step1MetricArray.count() * 1000000.0 / MaximumTargetPixelNumber=",Step1MetricArray.count() * 1000000.0 / MaximumTargetPixelNumber)
        
        #F3 step 2 processing-----intensifying plots
        ZoneTifList = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"CommonShare"+os.sep+Management+"_"+Year+"_"+Metric+"_ZoneTifList.txt"
        ZoneTifListFileStatus = "Closed"
        if not os.path.exists(ZoneTifList):
            if ((Management == BaseManagement) and (Year == BaseYear) and (Metric == BaseMetric)):
                ZoneTifListFile = open(ZoneTifList, 'w')
                print(ZoneTifList, " is open at", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"), file=open(F3Log, 'a'))
                ZoneTifListFileStatus = "Opened"
        Step2ArrayTif = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"Intermediate"+os.sep+Management+"_"+Year+"_"+Metric+"_step2.tif"
        if ((F3DebugMode == "Yes") and os.path.exists(Step2ArrayTif)):
            FinalMetricArray = ReadTifToArray(Step2ArrayTif).astype('int64')
        else:
            Step2IntensifyingPlotsRaster = InputRemoteSensingImagesReal
            SDPI8class = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"CommonShare"+os.sep+"SDPI8.tif"   #added on 20240423 following Frank's suggestion
            Phenology = AdditionalDiscreteRaster[2] 
            Step2IntensifyingPlotsInputLandsat = RasterBinned(Step2IntensifyingPlotsRaster,Step2IntensifyingPlotsBin[0]) 
            Step2IntensifyingPlotsInput = [RemoteSensingSegmentationFromFineToCoarse[0]] + Step2IntensifyingPlotsInputLandsat + [SDPI8class]   #20240423 added [SDPI8class]. add segmentation layer. This sentence sometimes is very slow and may stop. The reason is the computer
            Step2CombineOutput = RasterCombine(CloudWaterShadowMask,Step2IntensifyingPlotsInput)
            print("Step2CombineOutput=",Step2CombineOutput, file=open(F3Log, 'a'))

            #This section make the code more flexibile for adding more info to step2 ZoneTifList, revised on 20230307---start
            Step2ZoneInputTif = Step2CombineOutput
            Step2Metric = Metric
            Step2InputMetricArray = Step1MetricArray
            if Metric in ContinuousMetrics:
                Step2StatisticType = "mean"
            if Metric in DiscreteMetrics:
                Step2StatisticType = "mode"
            Step2PixelNumberTif = PlotIDTif
            Step2RequiredMinimumPixelNumberYesOrNo = "Yes"
            Step2MinimumNumberOfInputPixel = 1
            Step2MetricArray = ZoneStatisticsToArrayWangNing(Step2ZoneInputTif,Step2Metric,Step2InputMetricArray,Step2StatisticType,Step2PixelNumberTif,Step2RequiredMinimumPixelNumberYesOrNo,Step2MinimumNumberOfInputPixel)
            if ((Management == BaseManagement) and (Year == BaseYear) and (Metric == BaseMetric) and (ZoneTifListFileStatus == "Opened")):
                ZoneTifListStep2Line = "2-0||"+Step2ZoneInputTif+"||"+Step2StatisticType+"||"+Step2PixelNumberTif+"||"+Step2RequiredMinimumPixelNumberYesOrNo+"||"+str(Step2MinimumNumberOfInputPixel)
                ZoneTifListFile.write(ZoneTifListStep2Line +"\n")
                print(ZoneTifList, " is written with ",ZoneTifListStep2Line," at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"), file=open(F3Log, 'a'))
            #This section make the code more flexibile for adding more info to step2 ZoneTifList, revised on 20230307---start
                
            FinalMetricArray[np.isnan(FinalMetricArray)] = F3NoDataValue   #added 20221006
            FinalMetricArray[(FinalMetricArray > (F3NoDataValue-1)) & (FinalMetricArray < (F3NoDataValue+1))] = F3NoDataValue #float cannot compare due to precision?
            FinalMetricArray = ma.masked_values(FinalMetricArray, F3NoDataValue)  #Is this redundant?

            Step2MetricArray[np.isnan(Step2MetricArray)] = F3NoDataValue   #added 20221006
            Step2MetricArray[(Step2MetricArray > (F3NoDataValue-1)) & (Step2MetricArray < (F3NoDataValue+1))] = F3NoDataValue #float cannot compare due to precision?
            Step2MetricArray = ma.masked_values(Step2MetricArray, F3NoDataValue)  

            FinalMetricArray[FinalMetricArray.mask] = Step2MetricArray[FinalMetricArray.mask]  

            print("We may add the base regression - step2intensifiedplot and the PowerT as the basis of weighting--start")
            if ((Management in [BaseManagement]) and (Year in [BaseYear]) and (Metric in [BaseMetric])):
                FinalMetricArrayMMM = FinalMetricArray.copy()
                WeightBaseTif = CreateWeightBasisTif(Step1ContinuousPredictionTif,FinalMetricArrayMMM,-1,"BasedOnStep2Pixel")  # The last -1 is T (i.e. T = -1). According to FastEmap paper, t=0 (equal weight), -1 or -2. The most common one is -1. The T comes from the function's argument
                print("WeightBaseTif=",WeightBaseTif)
            print("We may add the base regression - step2intensifiedplot and the PowerT as the basis of weighting--end")


            if (((Metric in CrossValidationMetric) and (Management == BaseManagement) and (Year == BaseYear)) or (F3DebugMode == "Yes") or ((Management == BaseManagement) and (Year == BaseYear) and (Metric == BaseMetric))):
                FinalMetricArrayBBB = FinalMetricArray.copy()
                Step2Tif = Save2DArrayToTif(Run,Tile,Management,Year,Metric,FinalMetricArrayBBB,Step2ArrayTif)
            print("Step2 for ",Run,Tile,Management,Year,Metric," finished at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
        Step2MetricArray = FinalMetricArray.copy()
        if ((Management == BaseManagement) and (Year == BaseYear) and (Metric == BaseMetric)):
            ProcessingPercentageAsOrderAndReliability[CloudWaterShadowMaskData.mask] = F3NoDataValue
            ProcessingPercentageAsOrderAndReliability = ma.masked_values(ProcessingPercentageAsOrderAndReliability, F3NoDataValue)
            ProcessingPercentageAsOrderAndReliability[ProcessingPercentageAsOrderAndReliability.mask & (~FinalMetricArray.mask)] = Step2MetricArray.count() * 1000000.0 / MaximumTargetPixelNumber
            print("Step2MetricArray.count() * 1000000.0 / MaximumTargetPixelNumber=",Step2MetricArray.count() * 1000000.0 / MaximumTargetPixelNumber)
        

    
        #F3 step 3 processing-----iterative imputation
        print("\n\n\n---------------------------------")
        Step3ArrayTif = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"Intermediate"+os.sep+Management+"_"+Year+"_"+Metric+"_step3.tif"
        if ((F3DebugMode == "Yes") and os.path.exists(Step3ArrayTif)):
            FinalMetricArray = ReadTifToArray(Step3ArrayTif).astype('int64')
        else:        
            Step3IterativeImputationRaster = InputRemoteSensingImagesReal.copy() #a=[1,2,3]; b=a; b.append(4); now a=[1,2,3,4]. Please be careful, use https://stackoverflow.com/questions/2612802/how-do-i-clone-a-list-so-that-it-doesnt-change-unexpectedly-after-assignment
            Step3IterativeImputationRaster.append(AdditionalContinuousRaster[0]) #We add DEM here. You can customize step3 rasters here
            k=-1
            #print("%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%RemoteSensingSegmentationFromFineToCoarse[:-2]=",RemoteSensingSegmentationFromFineToCoarse[:-2])
            for SNIC in RemoteSensingSegmentationFromFineToCoarse[:-2]:  #The last two is omitted here 
                for BinNumber in Step3IterativeImputationBinValueFromHighToLow:

                    Step3MetricArray = np.full(FinalMetricArray.shape, F3NoDataValue)  #added on 20221115, this is necessary for initializing empty array; otherwise, we have problem
                    Step3MetricArray = ma.masked_values(Step3MetricArray, F3NoDataValue) 

                    FinalMetricArrayCount = FinalMetricArray.copy()
                    FinalMetricArrayCount[~FinalMetricArray.mask] = 1
                    FinalMetricArrayCount[FinalMetricArray.mask] = 0
                    CurrentValidPixelNumber = FinalMetricArray.count()
                    if  CurrentValidPixelNumber < MaximumTargetPixelNumber * 100:   #20221115, change MaximumTargetPixelNumber to MaximumTargetPixelNumber * 100 to skip this condition
                        k=k+1

                        #This is the new settings starting 20230112---start
                        Step3IterativeImputationInputLandsat = RasterBinned(Step3IterativeImputationRaster[:-1],BinNumber)
                        DemBinNumber = min(20,max(5,int(BinNumber/3.0)))
                        DEMbin = RasterBinned([Step3IterativeImputationRaster[-1]],DemBinNumber)  #note it is [Step3IterativeImputationRaster[-1]] not Step3IterativeImputationRaster[-1]
                        SDPI8class = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"CommonShare"+os.sep+"SDPI8.tif"   #added on 20240423 following Frank's suggestion
                        Phenology = AdditionalDiscreteRaster[2]
                        Step3IterativeImputationInput = [SNIC] + Step3IterativeImputationInputLandsat + DEMbin + [SDPI8class] 
                        #This is the new settings starting 20230112---end

                        Step3CombineOutput = RasterCombine(CloudWaterShadowMask,Step3IterativeImputationInput)
                        print("Step3CombineOutput=",Step3CombineOutput, file=open(F3Log, 'a'))

                        #This section make the code more flexibile for adding more info to step3 ZoneTifList, revised on 20230307---start
                        Step3ZoneInputTif = Step3CombineOutput
                        Step3Metric = Metric
                        Step3InputMetricArray = Step2MetricArray
                        if Metric in ContinuousMetrics:
                            Step3StatisticType = "weightedmeantimesregressionratio"
                        if Metric in DiscreteMetrics:
                            Step3StatisticType = "mode"
                        Step3PixelNumberTif = PlotIDTif
                        Step3RequiredMinimumPixelNumberYesOrNo = "Yes"
                        Step3MinimumNumberOfInputPixel = 2  #20240522, I change Step3MinimumNumberOfInputPixel = 1 to Step3MinimumNumberOfInputPixel = 2 back
                        #Step3MinimumNumberOfInputPixel = 2 is reasonable, because step2 used expanding, so Step3MinimumNumberOfInputPixel = 2 may have outliers. Using Step3MinimumNumberOfInputPixel = 2 can make sure that step 4 will have a good base for imputation
                        Step3MetricArray = ZoneStatisticsToArrayWangNing(Step3ZoneInputTif,Step3Metric,Step3InputMetricArray,Step3StatisticType,Step3PixelNumberTif,Step3RequiredMinimumPixelNumberYesOrNo,Step3MinimumNumberOfInputPixel)
                        if ((Management == BaseManagement) and (Year == BaseYear) and (Metric == BaseMetric) and (ZoneTifListFileStatus == "Opened")):
                            ZoneTifListStep3Line = "3-"+str(k)+"||"+Step3ZoneInputTif+"||"+Step3StatisticType+"||"+Step3PixelNumberTif+"||"+Step3RequiredMinimumPixelNumberYesOrNo+"||"+str(Step3MinimumNumberOfInputPixel)
                            ZoneTifListFile.write(ZoneTifListStep3Line +"\n")
                            print(ZoneTifList, " is written with ",ZoneTifListStep3Line," at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"), file=open(F3Log, 'a'))
                        #This section make the code more flexibile for adding more info to step3 ZoneTifList, revised on 20230307---start

                        FinalMetricArray[np.isnan(FinalMetricArray)] = F3NoDataValue   #added 20221006
                        FinalMetricArray[(FinalMetricArray > (F3NoDataValue-1)) & (FinalMetricArray < (F3NoDataValue+1))] =  F3NoDataValue #float cannot compare due to precision?
                        FinalMetricArray = ma.masked_values(FinalMetricArray, F3NoDataValue)  

                        Step3MetricArray[np.isnan(Step3MetricArray)] = F3NoDataValue   #added 20221006
                        Step3MetricArray[(Step3MetricArray > (F3NoDataValue-1)) & (Step3MetricArray < (F3NoDataValue+1))] =  F3NoDataValue #float cannot compare due to precision?
                        Step3MetricArray = ma.masked_values(Step3MetricArray, F3NoDataValue)  

                        print("31The mean,min, and max from step 3 AAA is: ", FinalMetricArray.mean(),FinalMetricArray.min(),FinalMetricArray.max()," the min=0 but mean is negative, very weird, but do not affect results, so ignored now")
                        FinalMetricArray[FinalMetricArray.mask] = Step3MetricArray[FinalMetricArray.mask]  #original sentence no good result
                        print("31The mean,min, and max from step 3 BBB is: ", FinalMetricArray.mean(),FinalMetricArray.min(),FinalMetricArray.max()," the min=0 but mean is negative, very weird, but do not affect results, so ignored now")
                        

                        if F3DebugMode == "Yes":
                            print("We have to use the FinalMetricArrayMMM = FinalMetricArray.copy() below; othersie, the FinalMetricArray will become unmasked again, which is a serious problem")
                            FinalMetricArrayMMM = FinalMetricArray.copy()
                            print(k,"Step 3 FinalMetricArrayMMM.count()=",FinalMetricArrayMMM.count())
                            Step3MiddleTif = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"Intermediate"+os.sep+Management+"_"+Year+"_"+Metric+"_step3_"+str(k)+".tif"
                            Step3MiddleTif = Save2DArrayToTif(Run,Tile,Management,Year,Metric,FinalMetricArrayMMM,Step3MiddleTif)

                        if ((Management == BaseManagement) and (Year == BaseYear) and (Metric == BaseMetric)):
                            FinalMetricArrayForProcessingPercentage = FinalMetricArray.copy()
                            ProcessingPercentageAsOrderAndReliability[CloudWaterShadowMaskData.mask] = F3NoDataValue
                            ProcessingPercentageAsOrderAndReliability = ma.masked_values(ProcessingPercentageAsOrderAndReliability, F3NoDataValue)
                            ProcessingPercentageAsOrderAndReliability[ProcessingPercentageAsOrderAndReliability.mask & (~FinalMetricArrayForProcessingPercentage.mask)] = FinalMetricArrayForProcessingPercentage.count() * 1000000.0 / MaximumTargetPixelNumber
                            print(k,"Step 3 FinalMetricArrayForProcessingPercentage.count()=",FinalMetricArrayForProcessingPercentage.count() * 1000000.0 / MaximumTargetPixelNumber)
                            print("MaximumTargetPixelNumber=",MaximumTargetPixelNumber)
                            print("With SNIC and BinNumber of ", SNIC, BinNumber," Step 3 FinalMetricArray.count() * 1000000.0 / MaximumTargetPixelNumber=",FinalMetricArrayForProcessingPercentage.count() * 1000000.0 / MaximumTargetPixelNumber)
                    else:
                        break
           
            if (((Metric in CrossValidationMetric) and (Management == BaseManagement) and (Year == BaseYear)) or (F3DebugMode == "Yes") or ((Management == BaseManagement) and (Year == BaseYear) and (Metric == BaseMetric))):
                FinalMetricArrayCCC = FinalMetricArray.copy()
                Step3Tif = Save2DArrayToTif(Run,Tile,Management,Year,Metric,FinalMetricArrayCCC,Step3ArrayTif)
            print("Step3 for ",Run,Tile,Management,Year,Metric," finished at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))

            #This section was added on 20230119 so that step4 can use step3 output to calculate the pixel number for imputation---start
            Step3ArrayMaskTif = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"CommonShare"+os.sep+BaseManagement+"_"+BaseYear+"_"+BaseMetric+"_step3mask.tif"
            if ((Management == BaseManagement) and (Year == BaseYear) and (Metric == BaseMetric)):
                if not os.path.exists(Step3ArrayMaskTif):
                    FinalMetricArrayCCC[(~FinalMetricArrayCCC.mask) & (FinalMetricArrayCCC != F3NoDataValue)] = 1   #as of 20230124, we have problem here, because there is no 1
                    Step3ArrayMaskTif = Save2DArrayToTif(Run,Tile,Management,Year,Metric,FinalMetricArrayCCC,Step3ArrayMaskTif)
            #This section was added on 20230119 so that step4 can use step3 output to calculate the pixel number for imputation---end
                
        Step3MetricArray = FinalMetricArray.copy()

           

        print("DOGGGGGGGGGGGGRemoteSensingSegmentationFromFineToCoarse=",RemoteSensingSegmentationFromFineToCoarse)                         
        #F3 step 4 processing-----remaing pixel filling
        Step4ArrayTif = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"Intermediate"+os.sep+Management+"_"+Year+"_"+Metric+"_step4.tif"
        if ((F3DebugMode == "Yes") and os.path.exists(Step4ArrayTif)):
            FinalMetricArray = ReadTifToArray(Step4ArrayTif).astype('int64')
        else:
            print("The old F3 has the order of [RemoteSensingClassFile, EcognitionZoneFile, outUnsupervisedFile, LandFireBpsZoneFile, ClimateZoneFile]. FYI")
            Step4RemainingPixelFillingRaster = []
            RemoteSensingClassFile = RasterCombine(CloudWaterShadowMask,RasterBinned(InputRemoteSensingImagesReal,3))  #20230117: if not good, I can use unsupervised classification here
            print("20230403: I decided not to use this RemoteSensingClassFile in Step4 because it has similar information to unsupervised classification")
            #Step4RemainingPixelFillingRaster.append(RemoteSensingClassFile)  #Landsat Bin class. note you cannot use Step4RemainingPixelFillingRaster=Step4RemainingPixelFillingRaster.append(RemoteSensingClassFile)

            #20240403: Trying to include EPA ECO4 into step 4 processing---start
            EpaEco4Tif = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"CommonShare"+os.sep+"EpaEco4.tif"
            if not os.path.exists(EpaEco4Tif):
                EpaEco4Original = gpd.read_file(EpaEco4)  #This is to use GPD to copy a shaoe file
                EpaEco4Copy = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"CommonShare"+os.sep+"EpaEco4.shp"
                EpaEco4Original.to_file(EpaEco4Copy, driver='ESRI Shapefile')
                EpaEco4_field_name = "Eco4Value"   #This is a field Shengli added on 20240304. Each polygon has a unique value. It is based on https://support.esri.com/en-us/knowledge-base/how-to-sort-and-create-a-sequentially-ordered-id-field--000018847
                output_tiff, RowMin_ForRaster,RowMax_ForRaster,ColumnMin_ForRaster,ColumnMax_ForRaster,CommonOverlay_ulx, CommonOverlay_lrx, CommonOverlay_uly, CommonOverlay_lry = ShapeAndRasterOverlayExtent(EpaEco4Copy,EpaEco4_field_name,ulx,lrx,uly,lry)
                os.rename(output_tiff,EpaEco4Tif)
                print(output_tiff," was rename as a new file of ",EpaEco4Tif)
                print(output_tiff," was rename as a new file of ",EpaEco4Tif, file=open(F3Log, 'a'))
                driver = ogr.GetDriverByName("ESRI Shapefile")
                if os.path.exists(EpaEco4Copy):
                    driver.DeleteDataSource(EpaEco4Copy)
                print(EpaEco4Copy," was deleted")
                print(EpaEco4Copy," was deleted", file=open(F3Log, 'a'))
            #20240403: Trying to include EPA ECO4 into step 4 processing---end


            #20240404: Trying to include HUC8 into step 4 processing---start
            HUC8Tif = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"CommonShare"+os.sep+"HUC8.tif"
            if not os.path.exists(HUC8Tif):
                HUC8Original = gpd.read_file(HUC8)  #This is to use GPD to copy a shaoe file
                HUC8Copy = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"CommonShare"+os.sep+"HUC8.shp"
                HUC8Original.to_file(HUC8Copy, driver='ESRI Shapefile')
                HUC8_field_name = "HUC8"   #This is a field Shengli added on 20240304. Each polygon has a unique value. It is based on https://support.esri.com/en-us/knowledge-base/how-to-sort-and-create-a-sequentially-ordered-id-field--000018847
                output_tiff, RowMin_ForRaster,RowMax_ForRaster,ColumnMin_ForRaster,ColumnMax_ForRaster,CommonOverlay_ulx, CommonOverlay_lrx, CommonOverlay_uly, CommonOverlay_lry = ShapeAndRasterOverlayExtent(HUC8Copy,HUC8_field_name,ulx,lrx,uly,lry)
                os.rename(output_tiff,HUC8Tif)
                print(output_tiff," was rename as a new file of ",HUC8Tif)
                print(output_tiff," was rename as a new file of ",HUC8Tif, file=open(F3Log, 'a'))
                driver = ogr.GetDriverByName("ESRI Shapefile")
                if os.path.exists(HUC8Copy):
                    driver.DeleteDataSource(HUC8Copy)
                print(HUC8Copy," was deleted")
                print(HUC8Copy," was deleted", file=open(F3Log, 'a'))
            #20240404: Trying to include HUC8 into step 4 processing---end

            #20240405: Trying to include HUC10 into step 4 processing---start
            HUC10Tif = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"CommonShare"+os.sep+"HUC10.tif"
            if not os.path.exists(HUC10Tif):
                HUC10Original = gpd.read_file(HUC10)  #This is to use GPD to copy a shaoe file
                HUC10Copy = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"CommonShare"+os.sep+"HUC10.shp"
                HUC10Original.to_file(HUC10Copy, driver='ESRI Shapefile')
                HUC10_field_name = "HUC10"   #This is a field Shengli added on 20240304. Each polygon has a unique value. It is based on https://support.esri.com/en-us/knowledge-base/how-to-sort-and-create-a-sequentially-ordered-id-field--000018847
                output_tiff, RowMin_ForRaster,RowMax_ForRaster,ColumnMin_ForRaster,ColumnMax_ForRaster,CommonOverlay_ulx, CommonOverlay_lrx, CommonOverlay_uly, CommonOverlay_lry = ShapeAndRasterOverlayExtent(HUC10Copy,HUC10_field_name,ulx,lrx,uly,lry)
                os.rename(output_tiff,HUC10Tif)
                print(output_tiff," was rename as a new file of ",HUC10Tif)
                print(output_tiff," was rename as a new file of ",HUC10Tif, file=open(F3Log, 'a'))
                driver = ogr.GetDriverByName("ESRI Shapefile")
                if os.path.exists(HUC10Copy):
                    driver.DeleteDataSource(HUC10Copy)
                print(HUC10Copy," was deleted")
                print(HUC10Copy," was deleted", file=open(F3Log, 'a'))
            #20240405: Trying to include HUC10 into step 4 processing---end

            #20240307: This section is to prepare SoilDrainageProductivityIndex24 according to the suggestion from Frank and Bill---start
            ShapeFile = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"Area_Extent.shp"
            SourceRaster = SoilDrainageProductivityIndex24
            ClipedRasterOutput = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"CommonShare"+os.sep+"SDPI24.tif"  #note in the void area, they use a value of 0
            SoilDrainageProductivityIndex24File = UsingShapeFileToClipRaster(ShapeFile, SourceRaster, ClipedRasterOutput)
            #Step4RemainingPixelFillingRaster.append(SoilDrainageProductivityIndex24File)
            #20240307: This section is to prepare SoilDrainageProductivityIndex24 according to the suggestion from Frank and Bill---end

            #20240411: This section is to prepare SoilDrainageProductivityIndex8 according to the suggestion from Frank and Bill---start
            ShapeFile = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"Area_Extent.shp"
            SourceRaster = SoilDrainageProductivityIndex8
            ClipedRasterOutput = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"CommonShare"+os.sep+"SDPI8.tif"  #note in the void area, they use a value of 0
            SoilDrainageProductivityIndex8File = UsingShapeFileToClipRaster(ShapeFile, SourceRaster, ClipedRasterOutput)
            #Step4RemainingPixelFillingRaster.append(SoilDrainageProductivityIndex8File)
            #20240411: This section is to prepare SoilDrainageProductivityIndex8 according to the suggestion from Frank and Bill---end

            level6Segmentation = RemoteSensingSegmentationFromFineToCoarse[-1]  #20230117: level6 is used before level5

            #20240314: This section is to prepare ecological land unit at 250m for step 4 enhancement---start
            print("20230314: ecological land unit is put between Level6 coarser segmentation and Level5 finer segmentation, because I found the reliability % jumped too much from 22% to 64%")
            ShapeFile = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"InputZone"+os.sep+"Area_Extent.shp"
            SourceRaster = EcologicalLandUnit
            ClipedRasterOutput = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"CommonShare"+os.sep+"ELU.tif"  #note in the void area, they use a value of 0
            EcologicalLandUnitFile = UsingShapeFileToClipRaster(ShapeFile, SourceRaster, ClipedRasterOutput)
            #Step4RemainingPixelFillingRaster.append(EcologicalLandUnitFile)  #I found the Wangning zonestatics has error of "index out of range", so comment out this or increase wangning's number? Will check
            #20240314: This section is to prepare ecological land unit at 250m for step 4 enhancement---end

            level5Segmentation = RemoteSensingSegmentationFromFineToCoarse[-2]   #20230117: level5 is used after level6
            
            if Run == "Run1":
                KmeansClassNumber = 30 
                DemBinNumber = 20   
            if Run == "Run2":
                KmeansClassNumber = 35
                DemBinNumber = 18
            if Run == "Run3":
                KmeansClassNumber = 37
                DemBinNumber = 15
            if Run == "Run4":
                KmeansClassNumber = 40
                DemBinNumber = 21
            if Run == "Run5":
                KmeansClassNumber = 32
                DemBinNumber = 19
            if Run == "Run6":
                KmeansClassNumber = 38
                DemBinNumber = 16
            outUnsupervisedFile = RemoteSensingKmeansUnsupervisedClassification(InputRemoteSensingImagesReal,KmeansClassNumber)

            LandfireBPS = AdditionalDiscreteRaster[0]

            BioClimateZone = AdditionalDiscreteRaster[1]  #added on 20221130. Without this, step 4 a) increase too much from step 3 to step 4; b) sharp boundary

            Phenology = AdditionalDiscreteRaster[2]  #added on 20221130. Without this, step 4 a) increase too much from step 3 to step 4; b) sharp boundary

            Dem = AdditionalContinuousRaster[0]
            DemBin = RasterBinned([Dem],DemBinNumber)  #note here it is [Dem] instead of Dem

            #Phenolgy may be useful but it may not be so important as expected, because 1) Our Remote sensing is based on MEDOID instead of MVC, so phenology can be captured in the composite, and 2) Phenology dataset may have issues too because five years are used where disturbance can happen. Frank also found there are issues (i.e., disimilar lumped into one class) 
            Step4RemainingPixelFillingRaster = [outUnsupervisedFile,SoilDrainageProductivityIndex8File,SoilDrainageProductivityIndex24File,EpaEco4Tif,Phenology,HUC8Tif,HUC10Tif,level6Segmentation,EcologicalLandUnitFile,level5Segmentation,LandfireBPS,BioClimateZone] + DemBin
            print("20240530, Frank said EpaEco4 should be before Phenology (i.e.,EpaEco4 has higher priority than Phenology")
            print("Step4RemainingPixelFillingRaster includes the files of ",Step4RemainingPixelFillingRaster, file=open(F3Log, 'a'))
            print("Step4RemainingPixelFillingRaster includes the files of ",Step4RemainingPixelFillingRaster)

            mm = -1
            for m in range(0,len(Step4RemainingPixelFillingRaster),1):

                Step4MetricArray = np.full(FinalMetricArray.shape, F3NoDataValue)  #added on 20221115, this is necessary for initializing empty array; otherwise, we have problem
                Step4MetricArray = ma.masked_values(Step4MetricArray, F3NoDataValue) 
                
                CurrentValidPixelNumber = FinalMetricArray.count()
                if CurrentValidPixelNumber < MaximumTargetPixelNumber * 100:   #20221115, change MaximumTargetPixelNumber to MaximumTargetPixelNumber * 100 to skip this condition  
                    mm = mm + 1
                    Step4CombineInput = Step4RemainingPixelFillingRaster[0:len(Step4RemainingPixelFillingRaster)-m]
                    print("m and Step4CombineInput=",m,Step4CombineInput)
                    Step4CombineOutput = RasterCombine(CloudWaterShadowMask,Step4CombineInput)
                    print("Step4CombineOutput=",Step4CombineOutput, file=open(F3Log, 'a'))




                    #This section make the code more flexibile for adding more info to step4 ZoneTifList, revised on 20230307---start
                    Step4ZoneInputTif = Step4CombineOutput
                    Step4Metric = Metric
                    Step4InputMetricArray = Step3MetricArray
                    if Metric in ContinuousMetrics:
                        Step4StatisticType = "meantimesregressionratio"
                    if Metric in DiscreteMetrics:
                        Step4StatisticType = "mode"
                    if m < len(Step4RemainingPixelFillingRaster)-1:  #before the last Step
                        Step4RequiredMinimumPixelNumberYesOrNo = "Yes"
                        NumberOfInputPixelTifSource = "OriginalPlot"  #Other option is "Step3Output"
                        if NumberOfInputPixelTifSource == "OriginalPlot":
                            Step4PixelNumberTif = PlotIDTif
                            Step4MinimumNumberOfInputPixel = 1   #We use Yes and 1 to make the pixels to be imputed has enough pixels; otherwise the imputation may be influenced by outliers
                        if NumberOfInputPixelTifSource == "Step3Output":
                            Step4PixelNumberTif = Step3ArrayMaskTif
                            Step4MinimumNumberOfInputPixel = 10   #We use Yes and 1 to make the pixels to be imputed has enough pixels; otherwise the imputation may be influenced by outliers
                    if m == len(Step4RemainingPixelFillingRaster)-1:  #The last Step. As of 20221109, I have not seen the effect (i.e., less unimputed holes) of this sentence
                        Step4RequiredMinimumPixelNumberYesOrNo = "No"   #When this is "No", the MinimumNumberOfInputPixel is ignored (i.e. not used)
                        Step4MinimumNumberOfInputPixel = 0   #We use No and 0 to make all pixels to be imputed as much as possible; otherwise we may have holes
                    Step4MetricArray = ZoneStatisticsToArrayWangNing(Step4ZoneInputTif,Step4Metric,Step4InputMetricArray,Step4StatisticType,Step4PixelNumberTif,Step4RequiredMinimumPixelNumberYesOrNo,Step4MinimumNumberOfInputPixel)
                    if ((Management == BaseManagement) and (Year == BaseYear) and (Metric == BaseMetric) and (ZoneTifListFileStatus == "Opened")):
                        ZoneTifListStep4Line = "4-"+str(mm)+"||"+Step4ZoneInputTif+"||"+Step4StatisticType+"||"+Step4PixelNumberTif+"||"+Step4RequiredMinimumPixelNumberYesOrNo+"||"+str(Step4MinimumNumberOfInputPixel)
                        ZoneTifListFile.write(ZoneTifListStep4Line +"\n")
                        print(ZoneTifList, " is written with ",ZoneTifListStep4Line," at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"), file=open(F3Log, 'a'))
                    #This section make the code more flexibile for adding more info to step4 ZoneTifList, revised on 20230307---start


                    '''
                    #Before, 20230307: This section uses ZoneStatisticsToArrayWangNing for zonestatistics calculation---start
                    #if ((Management == BaseManagement) and (Year == BaseYear) and (Metric == BaseMetric) and (ZoneTifListFileStatus == "Opened")):
                    #    ZoneTifListFile.write("4-"+str(mm)+"||"+Step4CombineOutput+"\n")
                    #    print(ZoneTifList, " is written ","4-",mm,"||",Step4CombineOutput," at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"), file=open(F3Log, 'a'))
                    if m < len(Step4RemainingPixelFillingRaster)-1:  #before the last step
                        RequiredMinimumPixelNumberYesOrNo = "Yes"
                        NumberOfInputPixelTifSource = "OriginalPlot"  #Other option is "Step3Output"
                        if NumberOfInputPixelTifSource == "OriginalPlot":
                            NumberOfInputPixelTif = PlotIDTif
                            MinimumNumberOfInputPixel = 1   #We use Yes and 1 to make the pixels to be imputed has enough pixels; otherwise the imputation may be influenced by outliers
                        if NumberOfInputPixelTifSource == "Step3Output":
                            NumberOfInputPixelTif = Step3ArrayMaskTif
                            MinimumNumberOfInputPixel = 10   #We use Yes and 1 to make the pixels to be imputed has enough pixels; otherwise the imputation may be influenced by outliers
                    if m == len(Step4RemainingPixelFillingRaster)-1:  #The last step. As of 20221109, I have not seen the effect (i.e., less unimputed holes) of this sentence
                        RequiredMinimumPixelNumberYesOrNo = "No"   #When this is "No", the MinimumNumberOfInputPixel is ignored (i.e. not used)
                        MinimumNumberOfInputPixel = 0   #We use No and 0 to make all pixels to be imputed as much as possible; otherwise we may have holes
                    if Metric in ContinuousMetrics:
                        #Step4MetricArray = ZoneStatisticsToArray(Step4CombineOutput,Metric,Step3MetricArray,"mean",PlotIDTif,RequiredMinimumPixelNumberYesOrNo,MinimumNumberOfInputPixel)
                        print("20230125: I decided to use [meantimesregressionratio] for the new F3 work, althugh we have two options below")
                        Step4ContinuousMetricsImputationMethod = "meantimesregressionratio"  #Two options here: "mean" or "meantimesregressionratio"
                        Step4MetricArray = ZoneStatisticsToArrayWangNing(Step4CombineOutput,Metric,Step3MetricArray,Step4ContinuousMetricsImputationMethod,NumberOfInputPixelTif,RequiredMinimumPixelNumberYesOrNo,MinimumNumberOfInputPixel)
                    if Metric in DiscreteMetrics:  
                        #Step4MetricArray = ZoneStatisticsToArray(Step4CombineOutput,Metric,Step3MetricArray,"mode",False,RequiredMinimumPixelNumberYesOrNo,MinimumNumberOfInputPixel)
                        Step4MetricArray = ZoneStatisticsToArrayWangNing(Step4CombineOutput,Metric,Step3MetricArray,"mode",NumberOfInputPixelTif,RequiredMinimumPixelNumberYesOrNo,MinimumNumberOfInputPixel)
                    #Before, 20230307: This section uses ZoneStatisticsToArrayWangNing for zonestatistics calculation---end
                    '''



                    FinalMetricArray[np.isnan(FinalMetricArray)] = F3NoDataValue   #added 20221006
                    FinalMetricArray[(FinalMetricArray > (F3NoDataValue-1)) & (FinalMetricArray < (F3NoDataValue+1))] =  F3NoDataValue #float cannot compare due to precision?
                    FinalMetricArray = ma.masked_values(FinalMetricArray, F3NoDataValue)  

                    Step4MetricArray[np.isnan(Step4MetricArray)] = F3NoDataValue   #added 20221006
                    Step4MetricArray[(Step4MetricArray > (F3NoDataValue-1)) & (Step4MetricArray < (F3NoDataValue+1))] =  F3NoDataValue #float cannot compare due to precision?
                    Step4MetricArray = ma.masked_values(Step4MetricArray, F3NoDataValue)  


                    #####20240403: This section intended to solve the local zero-inflation, but yesterday we found it can miss the species absence area if a) The area is last imputed here, and b) The area is within IDW=0 areas. Since now we have species 0and1 for solving local zero-inflation, this section canbe commented out---start
                    ###20230123: 1) Moved from above to here to reduce the redundant processing; 2) Add the if m == (len(Step4RemainingPixelFillingRaster)-1); For species distribution mapping--start
                    ###if m == (len(Step4RemainingPixelFillingRaster)-1):   #Added 20230123 (i.e., only applied to the last step as the old F3)
                    ##if ((m == (len(Step4RemainingPixelFillingRaster)-1)) or (m == (len(Step4RemainingPixelFillingRaster)-2))):  #20240313 add another condition because SDPI is added
                    ##    IDWfile = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"Intermediate"+os.sep+Management+"_"+Year+"_"+Metric+"_IDW.tif"
                    ##    print("IDWfile=",IDWfile)
                    ##    IDWraster = ReadTifToArray(IDWfile).astype('int64')
                    ##    MetricMinValue,MetricMaxValue = MetricMinAndMax(Run,Tile,Management,Year,Metric)
                    ##    print("MetricMinValue,MetricMaxValue=",MetricMinValue,MetricMaxValue)
                    ##    print("Step4MetricArray.shape=",Step4MetricArray.shape)
                    ##    print("IDWraster.shape=",IDWraster.shape) 
                    ##    if MetricMinValue >= 0:
                    ##        print("MetricMinValue,MetricMaxValue=",MetricMinValue,MetricMaxValue)
                    ##        print("Step4MetricArray.shape=",Step4MetricArray.shape)
                    ##        print("IDWraster.shape=",IDWraster.shape)                         
                    ##        Step4MetricArray[(IDWraster == 0) & (~Step4MetricArray.mask)] = 0   #& (~Step4MetricArray.mask) as added 20220123. This is used for caring for "species absence problem". The problem of "GAP continuous metric" is not handled here but in spatial mosaic
                    ##        print("20231228: I think the sentence above is better revised as Step4MetricArray[(IDWraster == MetricMinValue) & (~Step4MetricArray.mask)] = MetricMinValue. Please think it over")
                    ###20230123: 1) Moved from above to here to reduce the redundant processing; 2) Add the if m == (len(Step4RemainingPixelFillingRaster)-1); For species distribution mapping--end
                    #####20240403: This section intended to solve the local zero-inflation, but yesterday we found it can miss the species absence area if a) The area is last imputed here, and b) The area is within IDW=0 areas. Since now we have species 0and1 for solving local zero-inflation, this section canbe commented out---end


                    print("41The mean,min, and max from step 4 AAA is: ", FinalMetricArray.mean(),FinalMetricArray.min(),FinalMetricArray.max())
                    FinalMetricArray[FinalMetricArray.mask] = Step4MetricArray[FinalMetricArray.mask]  
                    print("41The mean,min, and max from step 4 BBB is: ", FinalMetricArray.mean(),FinalMetricArray.min(),FinalMetricArray.max())

                    if F3DebugMode == "Yes":
                        print("We have to use the FinalMetricArrayMMM = FinalMetricArray.copy() below; othersie, the FinalMetricArray will become unmasked again, which is a serious problem")
                        FinalMetricArrayNNN = FinalMetricArray.copy()
                        print(m,"Step 4 FinalMetricArrayNNN.count()=",FinalMetricArrayNNN.count())
                        Step4MiddleTif = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"Intermediate"+os.sep+Management+"_"+Year+"_"+Metric+"_step4_"+str(m)+".tif"
                        Step4MiddleTif = Save2DArrayToTif(Run,Tile,Management,Year,Metric,FinalMetricArrayNNN,Step4MiddleTif)
                        
                    if ((Management == BaseManagement) and (Year == BaseYear) and (Metric == BaseMetric)):
                        FinalMetricArrayForProcessingPercentage = FinalMetricArray.copy()
                        ProcessingPercentageAsOrderAndReliability[CloudWaterShadowMaskData.mask] = F3NoDataValue                       
                        ProcessingPercentageAsOrderAndReliability = ma.masked_values(ProcessingPercentageAsOrderAndReliability, F3NoDataValue)
                        ProcessingPercentageAsOrderAndReliability[ProcessingPercentageAsOrderAndReliability.mask & (~FinalMetricArrayForProcessingPercentage.mask)] = FinalMetricArrayForProcessingPercentage.count() * 1000000.0 / MaximumTargetPixelNumber
                        print(m,"Step 4 FinalMetricArrayForProcessingPercentage.count()=",FinalMetricArrayForProcessingPercentage.count() * 1000000.0 / MaximumTargetPixelNumber)
                        print("MaximumTargetPixelNumber=",MaximumTargetPixelNumber)
                        print("With m=",m," Step 4 FinalMetricArray.count() * 1000000.0 / MaximumTargetPixelNumber=",FinalMetricArrayForProcessingPercentage.count() * 1000000.0 / MaximumTargetPixelNumber)
                else:
                    break       

            if (((Metric in CrossValidationMetric) and (Management == BaseManagement) and (Year == BaseYear)) or (F3DebugMode == "Yes") or ((Management == BaseManagement) and (Year == BaseYear) and (Metric == BaseMetric))):
                FinalMetricArrayDDD = FinalMetricArray.copy()
                Step4Tif = Save2DArrayToTif(Run,Tile,Management,Year,Metric,FinalMetricArrayDDD,Step4ArrayTif)
            print("Step4 for ",Run,Tile,Management,Year,Metric," finished at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
            
        FinalTifname = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"Results"+os.sep+Management+"_"+Year+"_"+Metric+".tif"
        #20231220 added: F3 solves the zero-inflation problem, but F3 still has Local-ZeroInflation problem. We need to add something here to solve this problem-----start
        
        MetricMinValue, HalfOfCutthresholdMinusMin, Cutthreshold, MetricMaxValue = MinAndCutThreshValue(Run,Tile,Management,Year,Metric)
        print("20240214: shoud I use BaseYear instead of Year in this MinAndCutThreshValue function? Will this make the consistent of temporal products?")
        ###This is to use IDW and Cutthreshold to solve the zero-inflation problem---start
        IDWfile = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"Intermediate"+os.sep+Management+"_"+Year+"_"+Metric+"_IDW.tif"
        IDWraster = ReadTifToArray(IDWfile).astype('int64')
        FinalMetricArray[(FinalMetricArray < Cutthreshold) & (IDWraster == MetricMinValue)] = MetricMinValue    #it is [FinalMetricArray < Cutthreshold] not [FinalMetricArray <= Cutthreshold]    
        #This is to use IDW and Cutthreshold to solve the zero-inflation problem---end
        #This is to use HalfOfCutthresholdMinusMin and Cutthreshold to adjust the result---start
        FinalMetricArray[FinalMetricArray <= HalfOfCutthresholdMinusMin] = MetricMinValue
        FinalMetricArray[(FinalMetricArray > HalfOfCutthresholdMinusMin) & (FinalMetricArray < Cutthreshold)] = Cutthreshold
        FinalMetricArray[FinalMetricArray >= MetricMaxValue] = MetricMaxValue
        #This is to use HalfOfCutthresholdMinusMin and Cutthreshold to adjust the result---end
        
        #20231220 added: F3 solves the zero-inflation problem, but F3 still has Local-ZeroInflation problem. We need to add something here to solve this problem-----end
        FinalTif = Save2DArrayToTif(Run,Tile,Management,Year,Metric,FinalMetricArray,FinalTifname)

        if ((Management == BaseManagement) and (Year == BaseYear) and (Metric == BaseMetric)):
            if ZoneTifListFileStatus == "Opened":
                ZoneTifListFile.close()
            ProcessingPercentageAsOrderAndReliabilityname = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"Results"+os.sep+"ProcessingPercentageAsOrderAndReliability.tif"
            if not os.path.exists(ProcessingPercentageAsOrderAndReliabilityname):
                ProcessingPercentageAsOrderAndReliabilityAAA = ProcessingPercentageAsOrderAndReliability.copy()
                ProcessingPercentageAsOrderAndReliability = Save2DArrayToTif(Run,Tile,Management,Year,Metric,ProcessingPercentageAsOrderAndReliabilityAAA,ProcessingPercentageAsOrderAndReliabilityname)
                print("20231004: if we have 6 runs, there should be 21 values in this ProcessingPercentageAsOrderAndReliability tif; however, it may be less than 21, because some numbers may be identical (e.g., 2-0 step and 3-0 step)")
        print("The final F3 Tif for ",Run,Tile,Management,Year,Metric," is ",FinalTif, " and took \t" + str(int((time.time() - t0)/60))," minutes")         
        return FinalTif
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for F3FourSteps with inputs of " + repr(mylock)+","+repr(Run)+","+repr(Tile)+","+repr(Management)+","+repr(Year)+","+repr(Metric) + " with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog


    
def CrossValidationContinuousGraphic(CrossCSV):
    try:
        print("CrossCSV=",CrossCSV, file=open(F3Log, 'a'))
        print("os.path.exists(CrossCSV)=",os.path.exists(CrossCSV), file=open(F3Log, 'a'))
        CSVdata = pd.read_csv(CrossCSV, delimiter=',', parse_dates=True, usecols = ['PlotID', 'ObservedValue', 'ImputedValue','MeanValue','WeightedMeanValue','MeanTimesRatioValue','WeightedMeanTimesRatioValue','AllFourValue','IntegratedValue'], index_col='PlotID')  #https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html and https://www.geeksforgeeks.org/python-read-csv-using-pandas-read_csv/
        print("The first rows of the data is: ",CSVdata.head(), file=open(F3Log, 'a'))  #Above usecols is to select which columns are processed
        print(CSVdata.dtypes, file=open(F3Log, 'a'))
        print("waaaaaaaa", file=open(F3Log, 'a'))
        EachPlotMeanObservedValue = CSVdata.groupby("PlotID").mean()["ObservedValue"].to_numpy(dtype=np.int64,copy=True,na_value=F3NoDataValue)
        for F3CrossValidationValue in ["ImputedValue"]: #["ImputedValue","MeanValue","WeightedMeanValue","MeanTimesRatioValue","WeightedMeanTimesRatioValue","AllFourValue","IntegratedValue"]:
            EachPlotMeanModelledValue = CSVdata.groupby("PlotID").mean()[F3CrossValidationValue].to_numpy(dtype=np.int64,copy=True,na_value=F3NoDataValue)  
            #print("see plt.scatter at https://pythongeeks.org/python-scatter-plot/#:~:text=Scatter%20plot%20in%20Python%20is%20one%20type%20of,set%20of%20arrays%20represents%20the%20y%20axis%20data")
            #print("https://www.statology.org/scatterplot-with-regression-line-python/#:~:text=You%20can%20also%20use%20the%20regplot%20%28%29%20function,hide%20the%20confidence%20interval%20bands%20on%20the%20plot")
            #print("if necessary, check https://www.statology.org/residual-plot-python/#:~:text=We%20can%20create%20a%20residual%20vs.%20fitted%20plot,right%20corner%20is%20the%20residual%20vs.%20fitted%20plot")
            #print("add text in plot, see https://www.geeksforgeeks.org/add-text-inside-the-plot-in-matplotlib/#:~:text=The%20matplotlib.pyplot.text%20%28%29%20function%20is%20used%20to%20add,expressions.%20Syntax%3A%20matplotlib.pyplot.text%20%28x%2C%20y%2C%20s%2C%20fontdict%3DNone%2C%20%2A%2Akwargs%29")
            plt.scatter(EachPlotMeanObservedValue, EachPlotMeanModelledValue,color='red', linewidths = 1, marker ="*", edgecolor ="black", s = 25) #["black","blue","violet","pink","yellow","red","green","maroon","orange","brown"]
            plt.title("Comparision between FIA/FVS and prediction")
            plt.xlabel("Value from FIA/FVS"+" (pls /" + str(FloatToIntegerCoefficient) + ")")
            plt.ylabel("Value of F3 prediction of "+F3CrossValidationValue+" (pls /" + str(FloatToIntegerCoefficient) + ")" )

            CrossValidationPlotOption = "RobustRegression" # Options are "OrdinaryLinearRegression" or "RobustRegression"
            if CrossValidationPlotOption == "OrdinaryLinearRegression":
                slope, intercept, r_value, p_value, std_err = stats.linregress(EachPlotMeanObservedValue,EachPlotMeanModelledValue)
                print("slope, intercept, r_value, p_value, std_err=",slope, intercept, r_value, p_value, std_err)
            if CrossValidationPlotOption == "RobustRegression":
                #https://stackoverflow.com/questions/64881898/robust-linear-regression-with-scipy
                #https://www.statsmodels.org/dev/generated/statsmodels.robust.robust_linear_model.RLM.html
                rlm = huangsm.RLM(EachPlotMeanModelledValue,huangsm.add_constant(EachPlotMeanObservedValue),M=huangsm.robust.norms.HuberT())
                rlm_results = rlm.fit()
                print("rlm_results is: ",rlm_results)
                print("rlm_results.summary() is: ",rlm_results.summary())
                print("rlm_results.params is: ",rlm_results.params)
                intercept = rlm_results.params[0]
                slope = rlm_results.params[1]
                wls_results = huangsm.WLS(rlm.endog, rlm.exog, weights=rlm.weights).fit() #RLM has no r-squared, but it can be gotton using WLS, see ttps://stackoverflow.com/questions/31655196/how-to-get-r-squared-for-robust-regression-rlm-in-statsmodels
                print("wls_results.rsquared_adj=",wls_results.rsquared_adj)
                print("wls_results.rsquared_adj=",wls_results.rsquared)
                r_value = math.sqrt(max(wls_results.rsquared,wls_results.rsquared_adj))
                print("wls_results is: ",wls_results)
                print("wls_results.summary() is: ",wls_results.summary())
                print("wls_results.params is: ",wls_results.params)
                print("Someday we may remove the outliers, because the FIA is not perfect for validation. In this case, see https://machinelearningmastery.com/model-based-outlier-detection-and-removal-in-python/ discussed how to detect the outliers")
                
            plt.plot(EachPlotMeanObservedValue, 1*EachPlotMeanObservedValue+0, color='black')  #This is line 1:1
            line = slope*EachPlotMeanObservedValue+intercept
            plt.plot(EachPlotMeanObservedValue, line, 'r', label='y={:.2f}x+{:.2f}'.format(slope,intercept))
            #plt.legend(loc='upper left', fontsize=9, edgecolor="white") #https://www.geeksforgeeks.org/matplotlib-pyplot-legend-in-python/ loc = ‘upper left’, ‘upper right’, ‘lower left’, ‘lower right’

            Equation = "Y="+str(round(slope,2))+"X + " + str(round(intercept,2)) 
            R2 = "R2 = " + str(round(r_value*r_value,2))
            RMSE = "RMSE = "+str(round(np.sqrt(pow((EachPlotMeanObservedValue-EachPlotMeanModelledValue),2).mean()),2))
            MAE = "MAE = " + str(round(abs(EachPlotMeanObservedValue-EachPlotMeanModelledValue).mean(),2)) 
            Bias = "Bias = " + str(round((EachPlotMeanObservedValue-EachPlotMeanModelledValue).mean(),2))
            n = "n = " + str(round(EachPlotMeanObservedValue.shape[0],2)) 
            EachPlotMeanObservedValuePosition = EachPlotMeanObservedValue.min() * 1.10
            EachPlotMeanModelledValuePosition = max(EachPlotMeanObservedValue.max(),EachPlotMeanModelledValue.max()) * 0.98
            TextSpace = EachPlotMeanModelledValuePosition * 0.05
            LegentFontsize = 10
            plt.text(EachPlotMeanObservedValuePosition, EachPlotMeanModelledValuePosition-1*TextSpace, Equation, fontsize = LegentFontsize, color="blue")  #we can add [, bbox = dict(facecolor = 'blue', alpha = 0.5)]
            plt.text(EachPlotMeanObservedValuePosition, EachPlotMeanModelledValuePosition-2*TextSpace, R2, fontsize = LegentFontsize, color="blue")
            plt.text(EachPlotMeanObservedValuePosition, EachPlotMeanModelledValuePosition-3*TextSpace, RMSE, fontsize = LegentFontsize, color="blue")
            plt.text(EachPlotMeanObservedValuePosition, EachPlotMeanModelledValuePosition-4*TextSpace, MAE, fontsize = LegentFontsize, color="blue")
            plt.text(EachPlotMeanObservedValuePosition, EachPlotMeanModelledValuePosition-5*TextSpace, Bias, fontsize = LegentFontsize, color="blue")
            plt.text(EachPlotMeanObservedValuePosition, EachPlotMeanModelledValuePosition-6*TextSpace, n, fontsize = LegentFontsize, color="blue")

            ScatterPlotFile = CrossCSV.replace(".csv","_"+F3CrossValidationValue+".pdf")  #supported formats [eps, jpeg, jpg, pdf, pgf, png, ps, raw, rgba, svg, svgz, tif, tiff]
            plt.savefig(ScatterPlotFile)
            plt.clf()  #This is to clear the matlab figure. Without this, the display will be stacked together.
            #plt.show()
        return ScatterPlotFile
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for CrossValidationContinuousGraphic with inputs of " + repr(CrossCSV)+ " with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog



def CrossValidationDiscreteExcel(CrossCSV):
    try:
        CSVdata = pd.read_csv(CrossCSV, delimiter=',', parse_dates=True, usecols = ['PlotID', 'ObservedValue', 'ImputedValue'], index_col='PlotID')  #https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html and https://www.geeksforgeeks.org/python-read-csv-using-pandas-read_csv/ 
        PandasSeries = CSVdata.groupby("PlotID")
        EachPlotModeObservedValue = np.full(len(PandasSeries), F3NoDataValue, dtype="int64")
        EachPlotModeModelledValue = np.full(len(PandasSeries), F3NoDataValue, dtype="int64")
        print("len(PandasSeries)=",len(PandasSeries))
        groupid = -1
        for group in PandasSeries:
            groupid = groupid + 1
            EachPlotModeObservedValue[groupid] = group[1]["ObservedValue"].mode()[0]
            EachPlotModeModelledValue[groupid] = group[1]["ImputedValue"].mode()[0]
        #print("EachPlotModeObservedValue=",EachPlotModeObservedValue)
        #print("EachPlotModeModelledValue=",EachPlotModeModelledValue)
        TwoArrayCombine = np.concatenate((EachPlotModeObservedValue, EachPlotModeModelledValue))
        TwoArrayCombineUnique = np.unique(TwoArrayCombine)
        TwoArrayCombineUniqueList = TwoArrayCombineUnique.tolist()
        TwoArrayCombineUniqueListString = [str(k) for k in TwoArrayCombineUniqueList]
        #print("TwoArrayCombineUniqueList=",TwoArrayCombineUniqueList)
        DiscreteAccuracy = CrossCSV.replace(".csv","_DiscreteAccuracy.csv")
        DiscreteAccuracyFile = open(DiscreteAccuracy, 'w')
        DiscreteAccuracyNote1 = "#Columns are observed reference while rows are modelled predictions. The Kappa coefficient is not calculated here (if necessary, check https://support.microsoft.com/en-us/office/mmult-function-40593ed7-a3cd-4b6b-b9a3-e4ad3c7245eb)"+ "\n"
        DiscreteAccuracyNote2 = "#Created by Dr. Shengli Huang at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + " for F3 discrete metric accuracy assessment" + "\n"
        DiscreteAccuracyFile.write(DiscreteAccuracyNote1)
        DiscreteAccuracyFile.write(DiscreteAccuracyNote2)
        DiscreteAccuracyHead = "ClassCode," + ",".join(TwoArrayCombineUniqueListString) + ",ReferenceTotals,ClassifiedTotals,NumberCorrect,ProducerAccuracy(%),UsersAccuracy(%)" + "\n"
        DiscreteAccuracyFile.write(DiscreteAccuracyHead)

        ReferenceTotalsList = []
        ClassifiedTotalsList = []
        NumberCorrectSum = 0
        for m in TwoArrayCombineUniqueListString:
            mPair = []
            for n in TwoArrayCombineUniqueListString:
                mnPairCount = 0
                mnPairCountCorrect = 0
                for k in range(0,len(EachPlotModeObservedValue),1):
                    if ((EachPlotModeModelledValue[k] == int(m)) & (EachPlotModeObservedValue[k] == int(n))):
                        mnPairCount = mnPairCount + 1
                    if ((EachPlotModeModelledValue[k] == int(m)) & (EachPlotModeObservedValue[k] == int(m))):
                        mnPairCountCorrect = mnPairCountCorrect + 1
                #print("m,n,mnPairCount=",m,n,mnPairCount)
                mPair.append(mnPairCount)
            #print("mPair=",mPair)
            mPairString = [str(k) for k in mPair]
            ReferenceTotals = len(EachPlotModeObservedValue[EachPlotModeObservedValue == int(m)])
            ReferenceTotalsList.append(ReferenceTotals)
            ClassifiedTotals = len(EachPlotModeModelledValue[EachPlotModeModelledValue == int(m)])  #sum(mPair) may be OK too
            ClassifiedTotalsList.append(ClassifiedTotals)
            NumberCorrect = mnPairCountCorrect
            NumberCorrectSum = NumberCorrectSum + NumberCorrect
            print("ReferenceTotals,ClassifiedTotals,NumberCorrect=",ReferenceTotals,ClassifiedTotals,NumberCorrect)
            if ReferenceTotals != 0:
                ProducerAccuracy = NumberCorrect / ReferenceTotals * 100
            else:
                ProducerAccuracy = 100  #Here I use 0/0 = 1.0
            if ClassifiedTotals != 0:
                UsersAccuracy = NumberCorrect / ClassifiedTotals * 100
            else:
                UsersAccuracy = 100 #Here I use 0/0 = 1.0
            Line = str(m)+","+",".join(mPairString)+","+str(ReferenceTotals)+","+str(ClassifiedTotals)+","+str(NumberCorrect)+","+str(ProducerAccuracy)+","+str(UsersAccuracy)+"\n"
            print("Line=",Line)
            DiscreteAccuracyFile.write(Line)
        ReferenceTotalValue = sum(ReferenceTotalsList)
        ReferenceTotalsListString = [str(k) for k in ReferenceTotalsList]
        TotalLine = "Total,"+ ",".join(ReferenceTotalsListString) + "," + str(ReferenceTotalValue) + "," + str(ReferenceTotalValue) + "," + str(NumberCorrectSum) + ",-,-" + "\n"
        DiscreteAccuracyFile.write(TotalLine)
        OverallClassificationAccuracy = NumberCorrectSum / ReferenceTotalValue * 100
        Line1 = "Overall classification accuracy = " + str(OverallClassificationAccuracy) + "%" + "\n"
        print(Line1)
        DiscreteAccuracyFile.write(Line1)
        DiscreteAccuracyFile.close()

        plt.scatter(EachPlotModeObservedValue, EachPlotModeModelledValue,color='red', linewidths = 1, marker ="*", edgecolor ="black", s = 100) #["black","blue","violet","pink","yellow","red","green","maroon","orange","brown"]
        plt.title("Classification comparision between FIA/FVS and prediction")
        plt.xlabel("Discrete Value from FIA/FVS")
        plt.ylabel("Discrete Value of F3 prediction")
        slope, intercept, r_value, p_value, std_err = stats.linregress(EachPlotModeObservedValue,EachPlotModeModelledValue)
        print("slope, intercept, r_value, p_value, std_err=",slope, intercept, r_value, p_value, std_err)
        plt.plot(EachPlotModeObservedValue, 1*EachPlotModeObservedValue+0, color='black')  #This is line 1:1
        line = slope*EachPlotModeObservedValue+intercept
        plt.plot(EachPlotModeObservedValue, line, 'r', label='y={:.2f}x+{:.2f}'.format(slope,intercept))
        #plt.legend(loc='upper left', fontsize=9, edgecolor="white") #This add a legend box but I do not need it here, so comment out. see more info at https://www.geeksforgeeks.org/matplotlib-pyplot-legend-in-python/ loc = ‘upper left’, ‘upper right’, ‘lower left’, ‘lower right’
        OverallClassificationAccuracy = "Overall classification accuracy = " + str(OverallClassificationAccuracy) + "%"
        n = "n = " + str(round(EachPlotModeObservedValue.shape[0],2)) 
        EachPlotModeObservedValuePosition = EachPlotModeObservedValue.min() * 1.10
        EachPlotModeModelledValuePosition = max(EachPlotModeObservedValue.max(),EachPlotModeModelledValue.max()) * 0.98
        TextSpace = EachPlotModeModelledValuePosition * 0.05
        LegentFontsize = 10
        plt.text(EachPlotModeObservedValuePosition, EachPlotModeModelledValuePosition-1*TextSpace, OverallClassificationAccuracy, fontsize = LegentFontsize, color="blue")  #we can add [, bbox = dict(facecolor = 'blue', alpha = 0.5)]
        plt.text(EachPlotModeObservedValuePosition, EachPlotModeModelledValuePosition-2*TextSpace, n, fontsize = LegentFontsize, color="blue")

        ScatterPlotFile = CrossCSV.replace(".csv",".pdf")  #supported formats [eps, jpeg, jpg, pdf, pgf, png, ps, raw, rgba, svg, svgz, tif, tiff]
        plt.savefig(ScatterPlotFile)
        #plt.show()
        return ScatterPlotFile
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for CrossValidationDiscreteExcel with inputs of " + repr(CrossCSV)+ " with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog


def CrossValidationNewIdeasBasedOnArray(PlotID1D, StepNZoneArray1DList, StepNResultTifArray1D, StepNplus1ZoneArray1DList, StatisticType, RequiredMinimumPixelNumberYesOrNoList, RequiredMinimumPixelNumberList,StepNplus1ZoneArray_PlotNumber1DList, StepNplus1ZoneArray_RatioInZone1DList,WeightBasisTifArray1D,FieldMetricPredictedOutputArray1D, IdwArray1D):
    try:
        t0 = time.time()
        NumberOfStepNZoneArray1DList = StepNZoneArray1DList.shape[0]
        PlotIDList = []
        PlotIDImputedValue = []
        PlotIDImputedMeanValue = []
        PlotIDImputedWeightedMeanValue = []
        PlotIDImputedMeanTimesRatioValue = []
        PlotIDImputedWeightedMeanTimesRatioValue = []
        PlotIDImputedAllFourValue = []
        PlotIDImputedZoneAndOrder = [] 
        PlotIDUnique = np.unique(PlotID1D)
        PlotIDUnique = PlotIDUnique[~PlotIDUnique.mask]
        for PlotID in PlotIDUnique:
            print("\n********************************************************")
            StepNResultTifArray1DCopy1 = StepNResultTifArray1D.copy()  #THis is the copy of the shrunked StepNResultTifArray1D, not the copy of the original StepNResultTifArray1D

            index_a = int(np.where(PlotID1D == PlotID)[0])  #I believe np.where(PlotID1D == PlotID) has only one element. To assure it, I add [0] to get the first value
            IndexInterest = []
            CrossValidationOption = "RemoveThisPlotPlusIntensified"  #options are "OnlyRemoveThisPlot", "RemoveThisPlotPlusIntensified", or "RemoveThisPlotPlusPlotNumberEqualOne". 
            if CrossValidationOption == "RemoveThisPlotPlusIntensified":  
                for n in range(0,NumberOfStepNZoneArray1DList,1):
                    StepNZoneArray1DListIndexaValue = StepNZoneArray1DList[n,:][index_a]
                    ThisIndex = np.where(StepNZoneArray1DList[n,:] == StepNZoneArray1DListIndexaValue)[0]  ##Without [0], we have error: Sorry, there is an error :  all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)
                    IndexInterest = np.hstack((IndexInterest, ThisIndex))  
                IndexInterest = np.unique(IndexInterest).astype('int64')  #Without astype('int64'), in StepNResultTifArray1DCopy1[IndexInterest] = F3NoDataValue, we have error: Sorry, there is an error :  arrays used as indices must be of integer (or boolean) type
            if CrossValidationOption == "OnlyRemoveThisPlot":
                IndexInterest = index_a
            if CrossValidationOption == "RemoveThisPlotPlusPlotNumberEqualOne":
                for n in range(0,NumberOfStepNZoneArray1DList,1):
                    StepNZoneArray1DListIndexaValue = StepNZoneArray1DList[n,:][index_a]
                    ThisIndex1 = np.where(StepNZoneArray1DList[n,:] == StepNZoneArray1DListIndexaValue)[0]  
                    ThisIndex2 = np.where(StepNResultTifArray1DCopy1 == StepNResultTifArray1DCopy1[index_a])[0]   
                    ThisIndex = [k for k in ThisIndex1 if k in ThisIndex2] #This add another condition that only the "specific plot and its directly intensitfied plots" are used (i.e., mixed plots are kept) 
                    IndexInterest = np.hstack((IndexInterest, ThisIndex))  
                IndexInterest = np.unique(IndexInterest).astype('int64')  #Without astype('int64'), in StepNResultTifArray1DCopy1[IndexInterest] = F3NoDataValue, we have error: Sorry, there is an error :  arrays used as indices must be of integer (or boolean) type                

            StepNResultTifArray1DCopy1[IndexInterest] = F3NoDataValue
            StepNResultTifArray1DCopy1 = ma.masked_values(StepNResultTifArray1DCopy1, F3NoDataValue)

            ImputationValue = F3NoDataValue
            ImputedMeanValue = F3NoDataValue
            ImputedWeightedMeanValue = F3NoDataValue
            ImputedMeanTimesRatioValue = F3NoDataValue
            ImputedWeightedMeanTimesRatioValue = F3NoDataValue
            ImputedAllFourValue = F3NoDataValue
            ImputedZoneAndOrder = "NA"

            RemoveThePlotItselfWithPlotNumberCondition = "Yes"  #Yes or No
            NumberOfStepNplus1ZoneArray1DList = len(StepNplus1ZoneArray1DList)
            for m in range(0,NumberOfStepNplus1ZoneArray1DList,1):

                #This section is remove the data of the zone where the PlotID is located as well as PlotNumber condition---start
                if RemoveThePlotItselfWithPlotNumberCondition == "Yes":  #Yes or No
                    Index1 = np.where(PlotID1D == PlotID)[0]
                    Index2 = np.where(StepNplus1ZoneArray1DList[m,:] == StepNplus1ZoneArray1DList[m,:][Index1])[0]
                    if RequiredMinimumPixelNumberYesOrNoList[m] == "Yes":
                        RequiredMinimumPixelNumber = RequiredMinimumPixelNumberList[m]  #RequiredMinimumPixelNumber = 1 can be tried for fun
                        if np.nanmax(StepNplus1ZoneArray_PlotNumber1DList[m,:][Index2]) < RequiredMinimumPixelNumber:   ##originally I used but discarded: Index3 = np.where(StepNplus1ZoneArray_PlotNumber1DList[m,:] >= RequiredMinimumPixelNumberList[m])[0]
                           continue  #if PlotNumber >= RequiredMinimumPixelNumber, then proceed to calculation; otherwise, stop here and go to next-level searching (i.e. continue here) 
                    Index2 = np.unique(Index2).astype('int64')  #20230314: Thsi is the new one by adding PlotNumber criteria               
                    SelectedElements = StepNResultTifArray1DCopy1[Index2]
                    WeightBasisTifArray1DforSelectedElements = WeightBasisTifArray1D[Index2]
                    FieldMetricPredictedOutputArray1DforSelectedElements = FieldMetricPredictedOutputArray1D[Index2]
                    PlotID1DforSelectedElements = PlotID1D[Index2]
                    if ((type(IdwArray1D) == np.ma.core.MaskedArray) or (type(IdwArray1D) == np.ndarray)):
                        IdwArray1DforSelectedElements = IdwArray1D[Index2]
                #This section is remove the data of the zone where the PlotID is located as well as PlotNumber condition---end

                if RemoveThePlotItselfWithPlotNumberCondition == "No":  #Yes or No
                    SelectedElements = StepNResultTifArray1DCopy1
                    WeightBasisTifArray1DforSelectedElements = WeightBasisTifArray1D
                    FieldMetricPredictedOutputArray1DforSelectedElements = FieldMetricPredictedOutputArray1D
                    PlotID1DforSelectedElements = PlotID1D
                    IdwArray1DforSelectedElements = IdwArray1D

                print("len(SelectedElements)=",len(SelectedElements))
                print("SelectedElements=",SelectedElements)
                if ma.MaskedArray.count(SelectedElements) > 0:  #https://www.tutorialspoint.com/count-the-non-masked-elements-of-the-masked-array-in-numpy, note SelectedElements must be a masked array, otherwise error: AttributeError: 'numpy.ndarray' object has no attribute '_mask'
                    ImputationUsedInCrossvalidation = StatisticType[m]
                    print("ImputationUsedInCrossvalidation=",ImputationUsedInCrossvalidation)

                    print("1WeightBasisTifArray1DforSelectedElements=",WeightBasisTifArray1DforSelectedElements)
                    if "weighted" in ImputationUsedInCrossvalidation:
                        WeightBasisSumInZone = np.nansum(WeightBasisTifArray1DforSelectedElements[~SelectedElements.mask])
                        MyWeight = WeightBasisTifArray1DforSelectedElements[~SelectedElements.mask] / WeightBasisSumInZone  #We calclulate Weight here instead of using the "WeightInZone.tif", because I am not sure if they are consistent
                    else:
                        WeightBasisTifArray1DforSelectedElements[:] = 1  #note weight is only applied to F3 step3 not to step4; therefore, we assign a value to 1 so that every element in F3 step4 has the same weight
                        WeightBasisSumInZone = np.nansum(WeightBasisTifArray1DforSelectedElements[~SelectedElements.mask])
                        MyWeight = WeightBasisTifArray1DforSelectedElements[~SelectedElements.mask] / WeightBasisSumInZone  #We calclulate Weight here instead of using the "WeightInZone.tif", because I am not sure if they are consistent
                    print("2WeightBasisTifArray1DforSelectedElements=",WeightBasisTifArray1DforSelectedElements)
                        
                    FieldMetricPredictedOutputArray1DMeanInZone = np.nanmean(FieldMetricPredictedOutputArray1DforSelectedElements)
                    MyRatio = FieldMetricPredictedOutputArray1DforSelectedElements / FieldMetricPredictedOutputArray1DMeanInZone
                    ThisPlotRatio = MyRatio[PlotID1DforSelectedElements == PlotID][0]  #Find the MyRatio for this plot

                    ImputedMeanValue = np.nanmean(SelectedElements[~SelectedElements.mask])
                    print("ImputedMeanValue=",ImputedMeanValue)
                    ImputedWeightedMeanValue = np.nansum(SelectedElements[~SelectedElements.mask] * MyWeight)
                    print("ImputedWeightedMeanValue=",ImputedWeightedMeanValue)
                    ImputedMeanTimesRatioValue = ImputedMeanValue * ThisPlotRatio
                    print("ImputedMeanTimesRatioValue=",ImputedMeanTimesRatioValue)
                    ImputedWeightedMeanTimesRatioValue = ImputedWeightedMeanValue * ThisPlotRatio
                    print("ImputedWeightedMeanTimesRatioValue=",ImputedWeightedMeanTimesRatioValue)
                    ImputedAllFourValue = (ImputedMeanValue + ImputedWeightedMeanValue + ImputedMeanTimesRatioValue + ImputedWeightedMeanTimesRatioValue) / 4
                    print("ImputedAllFourValue=",ImputedAllFourValue)
                    if ((type(IdwArray1D) == np.ma.core.MaskedArray) or (type(IdwArray1D) == np.ndarray)):  #it is not np.ndarray but np.ma.core.MaskedArray
                        ImputedZoneAndOrder = "CrossValidationBasedonStep3_" + str(m)
                    else:
                        ImputedZoneAndOrder = "CrossValidationBasedonStep2_" + str(m) 
                    print("ImputedZoneAndOrder=",ImputedZoneAndOrder) 
                    
                    #if (("mean" in ImputationUsedInCrossvalidation.lower()) or ("allfour" in ImputationUsedInCrossvalidation.lower())):
                    #    MyMean = np.nanmean(SelectedElements[~SelectedElements.mask])
                    #    print("MyMean=",MyMean)
                    #if (("weighted" in ImputationUsedInCrossvalidation.lower()) or ("allfour" in ImputationUsedInCrossvalidation.lower())):
                    #    print("WeightBasisTifArray1DforSelectedElements=",WeightBasisTifArray1DforSelectedElements)
                    #    print("len(WeightBasisTifArray1DforSelectedElements)=",len(WeightBasisTifArray1DforSelectedElements))
                    #    WeightBasisSumInZone = np.nansum(WeightBasisTifArray1DforSelectedElements[~SelectedElements.mask])  
                    #    MyWeight = WeightBasisTifArray1DforSelectedElements[~SelectedElements.mask] / WeightBasisSumInZone  #We calclulate Weight here instead of using the "WeightInZone.tif", because I am not sure if they are consistent
                    #    print("MyWeight=",MyWeight)
                    #    print("len(MyWeight)=",len(MyWeight))
                    #    print("np.nansum(MyWeight)=",np.nansum(MyWeight))
                    #if (("ratio" in ImputationUsedInCrossvalidation.lower()) or ("allfour" in ImputationUsedInCrossvalidation.lower())):
                    #    FieldMetricPredictedOutputArray1DMeanInZone = np.nanmean(FieldMetricPredictedOutputArray1DforSelectedElements)
                    #    MyRatio = FieldMetricPredictedOutputArray1DforSelectedElements / FieldMetricPredictedOutputArray1DMeanInZone
                    #    print("MyRatio=",MyRatio)
                    #    print("len(MyRatio)=",len(MyRatio))
                    #    print("PlotID and PlotID1DforSelectedElements=",PlotID,PlotID1DforSelectedElements)
                    #    ThisPlotRatio = MyRatio[PlotID1DforSelectedElements == PlotID][0]  #Find the MyRatio for this plot
                    #    print("ThisPlotRatio=",ThisPlotRatio)
                    if ImputationUsedInCrossvalidation.lower() == "mean":
                        ImputationValue = ImputedMeanValue
                    if ImputationUsedInCrossvalidation.lower() == "weightedmean":
                        ImputationValue = ImputedWeightedMeanValue
                    if ImputationUsedInCrossvalidation.lower() == "meantimesregressionratio":
                        ImputationValue = ImputedMeanTimesRatioValue
                    if ImputationUsedInCrossvalidation.lower() == "weightedmeantimesregressionratio":
                        ImputationValue = ImputedWeightedMeanTimesRatioValue                     
                    if ImputationUsedInCrossvalidation.lower() == "allfour":
                        ImputationValue = ImputedAllFourValue
                    if ImputationUsedInCrossvalidation.lower() == "mode":
                        ImputationValue = SelectedElements[~SelectedElements.mask].mode()[0]  #This is the mode of an array but first to remove the masked elements
                    if m == (NumberOfStepNplus1ZoneArray1DList-1):  #If this is the last step
                        if ((type(IdwArray1D) == np.ma.core.MaskedArray) or (type(IdwArray1D) == np.ndarray)):  #not np.ndarray, only appied to step4; this is why we have IdwArray1D=False in step3; https://stackoverflow.com/questions/43748991/how-to-check-if-a-variable-is-either-a-python-list-numpy-array-or-pandas-series
                            IDWvalue = IdwArray1DforSelectedElements[PlotID1DforSelectedElements == PlotID][0]
                            if IDWvalue == 0:
                                ImputedValue = 0
                                ImputedMeanValue = 0
                                ImputedWeightedMeanValue = 0
                                ImputedMeanTimesRatioValue = 0
                                ImputedWeightedMeanTimesRatioValue = 0
                                ImputedAllFourValue = 0
                    break
            print("PlotID=",PlotID," has a value of ",ImputationValue, ", process is over!")
            if ImputationValue != F3NoDataValue:
                PlotIDList.append(int(PlotID))
                PlotIDImputedValue.append(int(ImputationValue))
                PlotIDImputedMeanValue.append(int(ImputedMeanValue))
                PlotIDImputedWeightedMeanValue.append(int(ImputedWeightedMeanValue))
                PlotIDImputedMeanTimesRatioValue.append(int(ImputedMeanTimesRatioValue))
                PlotIDImputedWeightedMeanTimesRatioValue.append(int(ImputedWeightedMeanTimesRatioValue))
                PlotIDImputedAllFourValue.append(int(ImputedAllFourValue))
                PlotIDImputedZoneAndOrder.append(ImputedZoneAndOrder)
                
                
        print(len(PlotIDList), " out of ", len(PlotIDUnique), " plots has been crossvalidation imputed as follows:", file=open(F3Log, 'a'))
        print("type(IdwArray1D) is: ", type(IdwArray1D), file=open(F3Log, 'a'))
        print("PlotIDList=",PlotIDList, file=open(F3Log, 'a'))
        print("PlotIDImputedValue=",PlotIDImputedValue, file=open(F3Log, 'a'))
        print("PlotIDImputedMeanValue=",PlotIDImputedMeanValue, file=open(F3Log, 'a'))
        print("PlotIDImputedWeightedMeanValue=",PlotIDImputedWeightedMeanValue, file=open(F3Log, 'a'))
        print("PlotIDImputedMeanTimesRatioValue=",PlotIDImputedMeanTimesRatioValue, file=open(F3Log, 'a'))
        print("PlotIDImputedWeightedMeanTimesRatioValue=",PlotIDImputedWeightedMeanTimesRatioValue, file=open(F3Log, 'a'))
        print("PlotIDImputedAllFourValue=",PlotIDImputedAllFourValue, file=open(F3Log, 'a'))
        print("PlotIDImputedZoneAndOrder=",PlotIDImputedZoneAndOrder, file=open(F3Log, 'a'))
        print("It took \t" + str(int((time.time() - t0)/60))," minutes")
        return PlotIDList, PlotIDImputedValue, PlotIDImputedMeanValue, PlotIDImputedWeightedMeanValue, PlotIDImputedMeanTimesRatioValue, PlotIDImputedWeightedMeanTimesRatioValue, PlotIDImputedAllFourValue, PlotIDImputedZoneAndOrder
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)                                                                                                                                                                                                                                  
        Content2 = "The error was for CrossValidationNewIdeasBasedOnArraySimilarToF3StepNplus1 with inputs of " + repr(len(PlotID1D)) + repr(len(StepNZoneArray1DList)) + repr(len(StepNResultTifArray1D)) + repr(len(StepNplus1ZoneArray1DList))+ repr(len(StatisticType)) + repr(len(RequiredMinimumPixelNumberYesOrNoList)) + repr(len(RequiredMinimumPixelNumberList)) + " with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog
                


def CrossValidation(mylock,Run,Tile,Management,Year,Metric):
    try:
        print("As of 20230309, I am thinking of another option of PlotAndArray, which is based on intensityied plot (step2) and loop for each plot within array")
        print("Basic idea. 1: for all original plots, extract values from all tif's")
        print("Basic idea. 2: loop for removing each plot from step2.tif (can use the same step1 zone criteria)")
        print("Basic idea. 3: Remove all nodata pixels and only keep the valid pixels and transferred to 1D array")
        print("Basic idea. 4: Search the array element who has the same step3 zoneID")
        print("Basic idea. 5: if not found, continue to next level simuated as step4 based on step 3 tif")
        print("Basic idea. 6: if not found, continue to next level simuated as step4 based on step 4 tif")
              
        CrossValidationIntermediateTifSave = "Yes"
        MetricStep1ArrayTif = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"Intermediate"+os.sep+Management+"_"+Year+"_"+Metric+"_step1.tif"  #note if in crossmetric, then save step1.tif
        if os.path.exists(MetricStep1ArrayTif):
            FinalArray = ReadTifToArray(MetricStep1ArrayTif)
        else:
            FinalArray = CreateMetricArray(Run,Tile,Management,Year,Metric,FloatToIntegerCoefficient)
        #print("1FinalArray.shape[0], FinalArray.shape[1]=",FinalArray.shape[0], FinalArray.shape[1])
        FinalArray1DOriginal = FinalArray.flatten()  #Sometimes error Unable to allocate 606. MiB for an array with shape (79414875,) and data type int64, it means your machine does not have enough RAM to hold the data, see https://github.com/ageron/handson-ml2/issues/309
        #print("2FinalArray.shape[0], FinalArray.shape[1]=",FinalArray.shape[0], FinalArray.shape[1])
        
        PlotIDTif = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"CommonShare"+os.sep+"YangDiBianMa.tif"
        PlotIDArray1D = ReadTifToArray(PlotIDTif).flatten()
        PlotIDArray1DOriginal = PlotIDArray1D.copy()
                                                                              
        IdwTif = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"Intermediate"+os.sep+Management+"_"+Year+"_"+Metric+"_IDW.tif"
        IdwArray1D = ReadTifToArray(IdwTif).flatten()
        IdwArray1DOriginal = PlotIDArray1D.copy()
        
        FieldMetricPredictedOutputFile = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"CommonShare"+os.sep+"BaseManagementBaseYearBaseMetricPlotDatabase_RegressionPredicted.tif"
        FieldMetricPredictedOutputArray1D = ReadTifToArray(FieldMetricPredictedOutputFile).flatten()
        FieldMetricPredictedOutputArray1DOriginal = FieldMetricPredictedOutputArray1D.copy()
        WeightBasisTif = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"CommonShare"+os.sep+"BaseManagementBaseYearBaseMetricPlotDatabase_WeightBasisBasedOnStep2Pixel.tif"
        WeightBasisTifArray1D = ReadTifToArray(WeightBasisTif).flatten()
        WeightBasisTifArray1DOriginal = WeightBasisTifArray1D.copy()
        
        ZoneTifList = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"CommonShare"+os.sep+Management+"_"+Year+"_"+BaseMetric+"_ZoneTifList.txt"
        ZoneTifListFile = open(ZoneTifList, 'r')
        Lines = ZoneTifListFile.readlines()
        ZoneTif = [i.replace('\n','') for i in Lines]
        #print("ZoneTif=",ZoneTif)
        
        Step2ZoneInputTif = []
        Step2ZoneInputTif_PlotNumber = []
        Step2StatisticType = []
        Step2PixelNumberTif = []
        Step2RequiredMinimumPixelNumberYesOrNo = []
        Step2MinimumNumberOfInputPixel = []
        
        Step3ZoneInputTif = []
        Step3ZoneInputTif_PlotNumber = []
        Step3ZoneInputTif_RatioInZone = []
        Step3StatisticType = []
        Step3PixelNumberTif = []
        Step3RequiredMinimumPixelNumberYesOrNo = []
        Step3MinimumNumberOfInputPixel = []

        Step4ZoneInputTif = []
        Step4ZoneInputTif_PlotNumber = []
        Step4ZoneInputTif_RatioInZone = []
        Step4StatisticType = []
        Step4PixelNumberTif = []
        Step4RequiredMinimumPixelNumberYesOrNo = []
        Step4MinimumNumberOfInputPixel = []
        
        for EachZoneTif in ZoneTif:
            if "2-" in EachZoneTif.split("||")[0]:
                Step2ZoneInputTif.append(EachZoneTif.split("||")[1])
                Step2ZoneInputTif_PlotNumber.append(EachZoneTif.split("||")[1].replace(".tif","_PlotNumber.tif"))    #20230313: Not sure if and how to use these
                Step2StatisticType.append(EachZoneTif.split("||")[2])
                Step2PixelNumberTif.append(EachZoneTif.split("||")[3])
                Step2RequiredMinimumPixelNumberYesOrNo.append(EachZoneTif.split("||")[4])
                Step2MinimumNumberOfInputPixel.append(int(EachZoneTif.split("||")[5]))
            if "3-" in EachZoneTif.split("||")[0]:
                Step3ZoneInputTif.append(EachZoneTif.split("||")[1])
                Step3ZoneInputTif_PlotNumber.append(EachZoneTif.split("||")[1].replace(".tif","_PlotNumber.tif"))
                Step3ZoneInputTif_RatioInZone.append(EachZoneTif.split("||")[1].replace(".tif","_RatioInZone.tif"))
                Step3StatisticType.append(EachZoneTif.split("||")[2])
                Step3PixelNumberTif.append(EachZoneTif.split("||")[3])
                Step3RequiredMinimumPixelNumberYesOrNo.append(EachZoneTif.split("||")[4])
                Step3MinimumNumberOfInputPixel.append(int(EachZoneTif.split("||")[5]))
            if "4-" in EachZoneTif.split("||")[0]:
                Step4ZoneInputTif.append(EachZoneTif.split("||")[1])
                Step4ZoneInputTif_PlotNumber.append(EachZoneTif.split("||")[1].replace(".tif","_PlotNumber.tif"))
                Step4ZoneInputTif_RatioInZone.append(EachZoneTif.split("||")[1].replace(".tif","_RatioInZone.tif"))
                Step4StatisticType.append(EachZoneTif.split("||")[2])
                Step4PixelNumberTif.append(EachZoneTif.split("||")[3])
                Step4RequiredMinimumPixelNumberYesOrNo.append(EachZoneTif.split("||")[4])
                Step4MinimumNumberOfInputPixel.append(int(EachZoneTif.split("||")[5]))
        if Metric in DiscreteMetrics:
            Step2StatisticType = ["mode" for k in Step2StatisticType]
            Step3StatisticType = ["mode" for k in Step3StatisticType]
            Step4StatisticType = ["mode" for k in Step4StatisticType]


        #This is to the CrossValidation Based on Step2 result---start
        print("CrossValidation new dieas just started", file=open(F3Log, 'a'))
        Step2ResultTif = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"Intermediate"+os.sep+Management+"_"+Year+"_"+Metric+"_step2.tif"
        Step2ResultTifArrayOriginal =  ReadTifToArray(Step2ResultTif).flatten()
        Step2ResultTifArray = Step2ResultTifArrayOriginal[~Step2ResultTifArrayOriginal.mask].astype('int64')
        WeightBasisTifArray1D = WeightBasisTifArray1DOriginal[~Step2ResultTifArrayOriginal.mask].astype('float')  #THis is not int64 but float
        FieldMetricPredictedOutputArray1D = FieldMetricPredictedOutputArray1DOriginal[~Step2ResultTifArrayOriginal.mask].astype('int64')
        PlotIDArray1D = PlotIDArray1DOriginal[~Step2ResultTifArrayOriginal.mask].astype('int64')
        IdwArray1D = IdwArray1DOriginal[~Step2ResultTifArrayOriginal.mask].astype('int64')
        PixelNumber = len(Step2ResultTifArray)
        Step2ZoneArray = np.full((len(Step2ZoneInputTif),PixelNumber), F3NoDataValue)
        for p in range(0,len(Step2ZoneInputTif),1):
            Step2ZoneArray[p,:] = ReadTifToArray(Step2ZoneInputTif[p]).flatten()[~Step2ResultTifArrayOriginal.mask].astype('int64')
        Step3ZoneArray = np.full((len(Step3ZoneInputTif),PixelNumber), F3NoDataValue)
        for p in range(0,len(Step3ZoneInputTif),1):
            Step3ZoneArray[p,:] = ReadTifToArray(Step3ZoneInputTif[p]).flatten()[~Step2ResultTifArrayOriginal.mask].astype('int64')                
        Step2ZoneArray_PlotNumber = np.full((len(Step2ZoneInputTif_PlotNumber),PixelNumber), F3NoDataValue)
        for p in range(0,len(Step2ZoneInputTif_PlotNumber),1):
            Step2ZoneArray_PlotNumber[p,:] = ReadTifToArray(Step2ZoneInputTif_PlotNumber[p]).flatten()[~Step2ResultTifArrayOriginal.mask].astype('int64')  
        Step3ZoneArray_PlotNumber = np.full((len(Step3ZoneInputTif_PlotNumber),PixelNumber), F3NoDataValue)
        for p in range(0,len(Step3ZoneInputTif_PlotNumber),1):
            Step3ZoneArray_PlotNumber[p,:] = ReadTifToArray(Step3ZoneInputTif_PlotNumber[p]).flatten()[~Step2ResultTifArrayOriginal.mask].astype('int64')
        Step3ZoneArray_RatioInZone = np.full((len(Step3ZoneInputTif_RatioInZone),PixelNumber), F3NoDataValue)
        for p in range(0,len(Step3ZoneInputTif_RatioInZone),1):
            Step3ZoneArray_RatioInZone[p,:] = ReadTifToArray(Step3ZoneInputTif_RatioInZone[p]).flatten()[~Step2ResultTifArrayOriginal.mask].astype('int64')
        CrossValidationBasedonStep2 = CrossValidationNewIdeasBasedOnArray(PlotIDArray1D, Step2ZoneArray, Step2ResultTifArray, Step3ZoneArray, Step3StatisticType, Step3RequiredMinimumPixelNumberYesOrNo, Step3MinimumNumberOfInputPixel, Step3ZoneArray_PlotNumber, Step3ZoneArray_RatioInZone,WeightBasisTifArray1D,FieldMetricPredictedOutputArray1D, IdwArray1D=False)  #IdwArray1D=False must be at the end, see https://www.geeksforgeeks.org/how-to-fix-syntaxerror-positional-argument-follows-keyword-argument-in-python/
        CrossValidationBasedonStep2PlotID = CrossValidationBasedonStep2[0]
        CrossValidationBasedonStep2PlotIDImputedValue = CrossValidationBasedonStep2[1]
        CrossValidationBasedonStep2PlotIDImputedMeanValue = CrossValidationBasedonStep2[2]
        CrossValidationBasedonStep2PlotIDImputedWeightedMeanValue = CrossValidationBasedonStep2[3]
        CrossValidationBasedonStep2PlotIDImputedMeanTimesRatioValue = CrossValidationBasedonStep2[4]
        CrossValidationBasedonStep2PlotIDImputedWeightedMeanTimesRatioValue = CrossValidationBasedonStep2[5]
        CrossValidationBasedonStep2PlotIDImputedAllFourValue = CrossValidationBasedonStep2[6]
        CrossValidationBasedonStep2PlotIDImputedZoneAndOrder = CrossValidationBasedonStep2[7]
        print("!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!Step3CrossValidation is done!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n\n\n\n", file=open(F3Log, 'a'))
        #This is to the CrossValidation Based on Step2 result---end  


        #This is to the CrossValidation Based on Step3 result---start
        Step3ResultTif = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"Intermediate"+os.sep+Management+"_"+Year+"_"+Metric+"_step3.tif"
        Step3ResultTifArrayOriginal = ReadTifToArray(Step3ResultTif).flatten()
        Step3ResultTifArray = Step3ResultTifArrayOriginal[~Step3ResultTifArrayOriginal.mask].astype('int64')
        WeightBasisTifArray1D = WeightBasisTifArray1DOriginal[~Step3ResultTifArrayOriginal.mask]
        FieldMetricPredictedOutputArray1D = FieldMetricPredictedOutputArray1DOriginal[~Step3ResultTifArrayOriginal.mask].astype('int64')
        PlotIDArray1D = PlotIDArray1DOriginal[~Step3ResultTifArrayOriginal.mask].astype('int64')
        IdwArray1D = IdwArray1DOriginal[~Step3ResultTifArrayOriginal.mask].astype('int64')
        PixelNumber = len(Step3ResultTifArray)
        Step3ZoneArray = np.full((len(Step3ZoneInputTif),PixelNumber), F3NoDataValue)
        for p in range(0,len(Step3ZoneInputTif),1):
            Step3ZoneArray[p,:] = ReadTifToArray(Step3ZoneInputTif[p]).flatten()[~Step3ResultTifArrayOriginal.mask].astype('int64')
        Step4ZoneArray = np.full((len(Step4ZoneInputTif),PixelNumber), F3NoDataValue)
        for p in range(0,len(Step4ZoneInputTif),1):
            Step4ZoneArray[p,:] = ReadTifToArray(Step4ZoneInputTif[p]).flatten()[~Step3ResultTifArrayOriginal.mask].astype('int64')
        Step3ZoneArray_PlotNumber = np.full((len(Step3ZoneInputTif_PlotNumber),PixelNumber), F3NoDataValue)
        for p in range(0,len(Step3ZoneInputTif_PlotNumber),1):
            Step3ZoneArray_PlotNumber[p,:] = ReadTifToArray(Step3ZoneInputTif_PlotNumber[p]).flatten()[~Step3ResultTifArrayOriginal.mask].astype('int64')
        Step4ZoneArray_PlotNumber = np.full((len(Step4ZoneInputTif_PlotNumber),PixelNumber), F3NoDataValue)
        for p in range(0,len(Step4ZoneInputTif_PlotNumber),1):
            Step4ZoneArray_PlotNumber[p,:] = ReadTifToArray(Step4ZoneInputTif_PlotNumber[p]).flatten()[~Step3ResultTifArrayOriginal.mask].astype('int64')
        Step3ZoneArray_RatioInZone = np.full((len(Step3ZoneInputTif_RatioInZone),PixelNumber), F3NoDataValue)
        for p in range(0,len(Step3ZoneInputTif_RatioInZone),1):
            Step3ZoneArray_RatioInZone[p,:] = ReadTifToArray(Step3ZoneInputTif_RatioInZone[p]).flatten()[~Step3ResultTifArrayOriginal.mask].astype('int64')
        Step4ZoneArray_RatioInZone = np.full((len(Step4ZoneInputTif_RatioInZone),PixelNumber), F3NoDataValue)
        for p in range(0,len(Step4ZoneInputTif_RatioInZone),1):
            Step4ZoneArray_RatioInZone[p,:] = ReadTifToArray(Step4ZoneInputTif_RatioInZone[p]).flatten()[~Step3ResultTifArrayOriginal.mask].astype('int64')           
        CrossValidationBasedonStep3 = CrossValidationNewIdeasBasedOnArray(PlotIDArray1D, Step3ZoneArray, Step3ResultTifArray, Step4ZoneArray, Step4StatisticType, Step4RequiredMinimumPixelNumberYesOrNo, Step4MinimumNumberOfInputPixel, Step4ZoneArray_PlotNumber, Step4ZoneArray_RatioInZone,WeightBasisTifArray1D,FieldMetricPredictedOutputArray1D,IdwArray1D)
        CrossValidationBasedonStep3PlotID = CrossValidationBasedonStep3[0]
        CrossValidationBasedonStep3PlotIDImputedValue = CrossValidationBasedonStep3[1]
        CrossValidationBasedonStep3PlotIDImputedMeanValue = CrossValidationBasedonStep3[2]
        CrossValidationBasedonStep3PlotIDImputedWeightedMeanValue = CrossValidationBasedonStep3[3]
        CrossValidationBasedonStep3PlotIDImputedMeanTimesRatioValue = CrossValidationBasedonStep3[4]
        CrossValidationBasedonStep3PlotIDImputedWeightedMeanTimesRatioValue = CrossValidationBasedonStep3[5]
        CrossValidationBasedonStep3PlotIDImputedAllFourValue = CrossValidationBasedonStep3[6]
        CrossValidationBasedonStep3PlotIDImputedZoneAndOrder = CrossValidationBasedonStep3[7]
        print("!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!Step4CrossValidation is done!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n\n\n\n", file=open(F3Log, 'a'))        
        #This is to the CrossValidation Based on Step3 result---end



        #print("len(CrossValidationBasedonStep2PlotID)=",len(CrossValidationBasedonStep2PlotID))
        #print("len(CrossValidationBasedonStep2PlotIDImputedValue)=",len(CrossValidationBasedonStep2PlotIDImputedValue))
        #print("len(CrossValidationBasedonStep3PlotID)=",len(CrossValidationBasedonStep3PlotID))
        #print("len(CrossValidationBasedonStep3PlotIDImputedValue)=",len(CrossValidationBasedonStep3PlotIDImputedValue))
        CrossValidationPlotID = CrossValidationBasedonStep2PlotID
        CrossValidationPlotIDImputedValue = CrossValidationBasedonStep2PlotIDImputedValue
        CrossValidationPlotIDImputedMeanValue = CrossValidationBasedonStep2PlotIDImputedMeanValue
        CrossValidationPlotIDImputedWeightedMeanValue = CrossValidationBasedonStep2PlotIDImputedWeightedMeanValue
        CrossValidationPlotIDImputedMeanTimesRatioValue = CrossValidationBasedonStep2PlotIDImputedMeanTimesRatioValue
        CrossValidationPlotIDImputedWeightedMeanTimesRatioValue = CrossValidationBasedonStep2PlotIDImputedWeightedMeanTimesRatioValue
        CrossValidationPlotIDImputedAllFourValue = CrossValidationBasedonStep2PlotIDImputedAllFourValue
        CrossValidationPlotIDImputedZoneAndOrder = CrossValidationBasedonStep2PlotIDImputedZoneAndOrder
        for kk in range(0,len(CrossValidationBasedonStep3PlotID),1):
            if CrossValidationBasedonStep3PlotID[kk] not in CrossValidationBasedonStep2PlotID:
                CrossValidationPlotID.append(CrossValidationBasedonStep3PlotID[kk])
                CrossValidationPlotIDImputedValue.append(CrossValidationBasedonStep3PlotIDImputedValue[kk])
                CrossValidationPlotIDImputedMeanValue.append(CrossValidationBasedonStep3PlotIDImputedMeanValue[kk])
                CrossValidationPlotIDImputedWeightedMeanValue.append(CrossValidationBasedonStep3PlotIDImputedWeightedMeanValue[kk])
                CrossValidationPlotIDImputedMeanTimesRatioValue.append(CrossValidationBasedonStep3PlotIDImputedMeanTimesRatioValue[kk])
                CrossValidationPlotIDImputedWeightedMeanTimesRatioValue.append(CrossValidationBasedonStep3PlotIDImputedWeightedMeanTimesRatioValue[kk])
                CrossValidationPlotIDImputedAllFourValue.append(CrossValidationBasedonStep3PlotIDImputedAllFourValue[kk])
                CrossValidationPlotIDImputedZoneAndOrder.append(CrossValidationBasedonStep3PlotIDImputedZoneAndOrder[kk])  
        #print("CrossValidationPlotID=",CrossValidationPlotID)
        #print("CrossValidationPlotIDImputedValue=",CrossValidationPlotIDImputedValue)
        #print("CrossValidation new dieas just tested", file=open(F3Log, 'a'))
        #This will test the new ideas but I am nto sure if it work. Will see---end


        FieldPlotInThisTileList = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"FieldPoint"+os.sep+Management+"_"+Year+"_"+Metric+"_FieldPlotInThisTileList.txt"
        FieldPlotInThisTileListFile = open(FieldPlotInThisTileList, 'r')
        Lines = FieldPlotInThisTileListFile.readlines()
        FieldPlotInThisTileList = []
        FieldPlotInThisTileListRow = []
        FieldPlotInThisTileListColumn = []
        FieldPlotInThisTileList1DIndex = []
        FieldPlotInThisTileListMetricValue = []
        for i in Lines:
            LineSplit = i.replace('\n','').split(",")
            FieldPlotInThisTileList.append(int(LineSplit[0]))
            FieldPlotInThisTileListRow.append(int(LineSplit[1]))
            FieldPlotInThisTileListColumn.append(int(LineSplit[2]))
            FieldPlotInThisTileList1DIndex.append(int(LineSplit[1]) * FinalArray.shape[1] + int(LineSplit[2]))  #1Dindex = row * collength + col (note here row and col startes from zero
            FieldPlotInThisTileListMetricValue.append(int(LineSplit[3]))
        #print("FieldPlotInThisTileList=",FieldPlotInThisTileList)
        #print("FieldPlotInThisTileList1DIndex=",FieldPlotInThisTileList1DIndex)
        #print("FieldPlotInThisTileListMetricValue=",FieldPlotInThisTileListMetricValue)

        FinalCrossValidationCSV = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep+Management+"_"+Year+"_"+Metric+"_CrossValidation.csv"
        FinalCrossValidationCSVFile = open(FinalCrossValidationCSV, 'a')  #Note: Here is a not w
        #FinalCrossValidationCSVHeader = "PlotID,Row,Column,Run,Tile,Management,Year,Metric,MetricType,ObservedValue,ImputedValue,MeanValue,WeightedMeanValue,MeanTimesRatioValue,WeightedMeanTimesRatioValue,AllFourValue,IntegratedValue,ImputedValuePercentage,MeanValuePercentage,WeightedMeanValuePercentage,MeanTimesRatioValuePercentage,WeightedMeanTimesRatioValuePercentage,AllFourValuePercentage,IntegratedValuePercentage,ZoneAndOrder,Modeller,Time" + "\n"
        #FinalCrossValidationCSVFile.write(FinalCrossValidationCSVHeader)
        if Metric in ContinuousMetrics:
            MetricType = "Continuous"
        if Metric in DiscreteMetrics:
            MetricType = "Discrete"
        for m in range(0,len(FieldPlotInThisTileList),1):
            for n in range(0,len(CrossValidationPlotID),1):
                #print("int(FieldPlotInThisTileList[m],int(CrossValidationPlotID[n])=",int(FieldPlotInThisTileList[m]),int(CrossValidationPlotID[n]), file=open(F3Log, 'a'))
                if int(CrossValidationPlotID[n]) == int(FieldPlotInThisTileList[m]):                          
                    ImputedValue = CrossValidationPlotIDImputedValue[n]
                    MeanValue = CrossValidationPlotIDImputedMeanValue[n] 
                    WeightedMeanValue = CrossValidationPlotIDImputedWeightedMeanValue[n]
                    MeanTimesRatioValue = CrossValidationPlotIDImputedMeanTimesRatioValue[n]
                    WeightedMeanTimesRatioValue = CrossValidationPlotIDImputedWeightedMeanTimesRatioValue[n]
                    AllFourValue = CrossValidationPlotIDImputedAllFourValue[n]
                    ZoneAndOrder = CrossValidationPlotIDImputedZoneAndOrder[n]

                    ObservedValue = FieldPlotInThisTileListMetricValue[m]
                    ValueArray = np.array([ImputedValue,MeanValue,WeightedMeanValue,MeanTimesRatioValue,WeightedMeanTimesRatioValue,AllFourValue])
                    ValueArrayAbsDif = np.array([abs(ImputedValue-ObservedValue),abs(MeanValue-ObservedValue),abs(WeightedMeanValue-ObservedValue),abs(MeanTimesRatioValue-ObservedValue),abs(WeightedMeanTimesRatioValue-ObservedValue),abs(AllFourValue-ObservedValue)])
                    ValueArrayAbsDifMin = np.nanmin(ValueArrayAbsDif)
                    IntegratedValue = np.nanmean(ValueArray[ValueArrayAbsDif == ValueArrayAbsDifMin])

                    if ObservedValue != 0:  
                        #print("ValueArray=",ValueArray, file=open(F3Log, 'a'))
                        #print("ObservedValue=",ObservedValue, file=open(F3Log, 'a'))
                        RelativeDifference = ((np.append(ValueArray,IntegratedValue) - ObservedValue) / ObservedValue) * 100  #offset Percentage, https://www.digitalocean.com/community/tutorials/python-add-to-array
                        #print("RelativeDifference=",RelativeDifference, file=open(F3Log, 'a'))
                        ImputedValuePercentage = RelativeDifference[0]
                        MeanValuePercentage = RelativeDifference[1]
                        WeightedMeanValuePercentage = RelativeDifference[2]
                        MeanTimesRatioValuePercentage = RelativeDifference[3]
                        WeightedMeanTimesRatioValuePercentage = RelativeDifference[4]
                        AllFourValuePercentage = RelativeDifference[5]
                        IntegratedValuePercentage = RelativeDifference[6]
                    else:
                        ImputedValuePercentage = 9999
                        MeanValuePercentage = 9999
                        WeightedMeanValuePercentage = 9999
                        MeanTimesRatioValuePercentage = 9999
                        WeightedMeanTimesRatioValuePercentage = 9999
                        AllFourValuePercentage = 9999
                        IntegratedValuePercentage = 9999                        
                    #print("ImputedValuePercentage,MeanValuePercentage,WeightedMeanValuePercentage,MeanTimesRatioValuePercentage,WeightedMeanTimesRatioValuePercentage,AllFourValuePercentage,IntegratedValuePercentage=",ImputedValuePercentage,MeanValuePercentage,WeightedMeanValuePercentage,MeanTimesRatioValuePercentage,WeightedMeanTimesRatioValuePercentage,AllFourValuePercentage,IntegratedValuePercentage, file=open(F3Log, 'a'))     
                    Content0 = [str(FieldPlotInThisTileList[m]), str(FieldPlotInThisTileListRow[m]), str(FieldPlotInThisTileListColumn[m]), Run, Tile, Management, str(Year), Metric, MetricType, str(FieldPlotInThisTileListMetricValue[m]), str(ImputedValue), str(MeanValue), str(WeightedMeanValue), str(MeanTimesRatioValue), str(WeightedMeanTimesRatioValue), str(AllFourValue), str(IntegratedValue), str(ImputedValuePercentage),str(MeanValuePercentage),str(WeightedMeanValuePercentage),str(MeanTimesRatioValuePercentage),str(WeightedMeanTimesRatioValuePercentage),str(AllFourValuePercentage),str(IntegratedValuePercentage),str(ZoneAndOrder), "Dr. Shengli Huang (shengli.huang@usda.gov)", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")]            
                    Content = ",".join(Content0) + "\n"
                    print("Content=",Content, file=open(F3Log, 'a'))
                    FinalCrossValidationCSVFile.write(Content)
                    break
                           
        '''
        print("This section is to use Zonestatistics for cross-validation, but we discarded it on 20230322 because of the following problems:")
        print("Problem 1: The speed is very slow; Problem 2: Leave-one-out crossvalidation is also impossible")
        print("Therefore, Dr. Shengli Huang decided to use a new approach, which is based on CrossValidationNewIdeasBasedOnArray")
        CrossValidationTimes = max(int(1/CrossFolderPercentage),1)
        CrossValidationSteps = max(int(1/CrossFolderPercentage),1)
        for k in range(0,CrossValidationTimes,1):
            FinalArray1D = FinalArray1DOriginal.copy()  #This will initial the FinalArray1D as the original FinalArray1DOriginal
            PlotIDArray1D = PlotIDArray1DOriginal.copy()
            
            RemovedPlotInThisTileList = FieldPlotInThisTileList[k:len(FieldPlotInThisTileList):CrossValidationSteps]
            RemovedPlotInThisTileListRow = FieldPlotInThisTileListRow[k:len(FieldPlotInThisTileList):CrossValidationSteps]
            RemovedPlotInThisTileListColumn = FieldPlotInThisTileListColumn[k:len(FieldPlotInThisTileList):CrossValidationSteps]
            RemovedPlotInThisTileListIndex = FieldPlotInThisTileList1DIndex[k:len(FieldPlotInThisTileList):CrossValidationSteps]
            RemovedPlotInThisTileListMetricValue = FieldPlotInThisTileListMetricValue[k:len(FieldPlotInThisTileList):CrossValidationSteps]
            
            for plot in RemovedPlotInThisTileList:
                PlotIDArray1D[PlotIDArray1D == plot] = F3NoDataValue
            PlotIDArray1D = ma.masked_values(PlotIDArray1D, F3NoDataValue)
            FinalArray1D[PlotIDArray1D.mask] = F3NoDataValue
            
            FinalArray1D[np.isnan(FinalArray1D)] = F3NoDataValue   #added 20221006
            FinalArray1D[(FinalArray1D > (F3NoDataValue-1)) & (FinalArray1D < (F3NoDataValue+1))] =  F3NoDataValue #float cannot compare due to precision?
            FinalArray1D = ma.masked_values(FinalArray1D, F3NoDataValue)  
            Step1Final1D = FinalArray1D.copy()

            #20230308: Save CrossValidationPlotIDTif here, where the PlotID to be removed in crossvalidation is discarded---start
            if ((Management == BaseManagement) and (Year == BaseYear) and (Metric == BaseMetric)):
                PlotIDArray2D = PlotIDArray1D.reshape(FinalArray.shape[0],FinalArray.shape[1])
                CrossValidationPlotIDTif = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"CommonShare"+os.sep+"CrossFolderPercentage"+str(int(CrossFolderPercentage*100))+"CrossValidation"+str(k)+"_YangDiBianMa.tif"
                if not os.path.exists(CrossValidationPlotIDTif):
                    CrossValidationPlotIDTif = Save2DArrayToTif(Run,Tile,Management,Year,Metric,PlotIDArray2D,CrossValidationPlotIDTif)
                    print("CrossValidationPlotIDTif=",CrossValidationPlotIDTif)
                    print("CrossValidationPlotIDTif=",CrossValidationPlotIDTif, file=open(F3Log, 'a'))
            #20230308: Save CrossValidationPlotIDTif here, where the PlotID to be removed in crossvalidation is discarded---start
            
            if CrossValidationIntermediateTifSave == "Yes":
                Step1Final2DArray = Step1Final1D.reshape(FinalArray.shape[0],FinalArray.shape[1])  #shape[0] is row and shape[1] is col
                ArrayTif = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"Intermediate"+os.sep+"CrossFolderPercentage"+str(int(CrossFolderPercentage*100))+"CrossValidation"+str(k)+"_"+Metric+"_Step1.tif"
                if not os.path.exists(ArrayTif):
                    Step1FinalTifFile = Save2DArrayToTif(Run,Tile,Management,Year,Metric,Step1Final2DArray,ArrayTif)
                    print("Step1FinalTifFile=",Step1FinalTifFile)
            
            for p in range(0,len(Step2ZoneInputTif),1):
                if CrossValidationImputationFunction == "CrossValidationSelf":
                    ZoneTifArray1D = Step2ZoneArray[p,:]
                    if Metric in ContinuousMetrics:
                        MetricStep2Array1D = pd.Series(Step1Final1D).groupby(ZoneTifArray1D).transform(lambda x: x.mean(skipna=True)).to_numpy(dtype=np.int64,copy=True,na_value=F3NoDataValue)
                    if Metric in DiscreteMetrics:
                        MetricStep2Array1D = np.full((FinalArray.shape[0]*FinalArray.shape[1]), F3NoDataValue)
                        PandasSeries = pd.Series(Step1Final1D).groupby(ZoneTifArray1D)  #This is a pandas series object, which is actually a list of tuples
                        for group in PandasSeries:  
                            if group[1].mode().empty:  #If the majority is empty, we give a F3NoDataValue for the corresponding indexes
                                MetricStep2Array1D[group[1].index] = F3NoDataValue
                            else:
                                MetricStep2Array1D[group[1].index] = group[1].mode()[0]  ##If the majority is not empty, we give the mode value for the corresponding indexes
                if CrossValidationImputationFunction == "ZoneStatisticsToArrayWangNing":
                    MetricStep2Array = ZoneStatisticsToArrayWangNing(Step2ZoneInputTif[p],Metric,Step1Final1D,Step2StatisticType[p],CrossValidationPlotIDTif,Step2RequiredMinimumPixelNumberYesOrNo[p],Step2MinimumNumberOfInputPixel[p])
                    MetricStep2Array1D = MetricStep2Array.flatten()
                    print("MetricStep2Array1D.shape=",MetricStep2Array1D.shape, file=open(F3Log, 'a'))

                FinalArray1D[np.isnan(FinalArray1D)] = F3NoDataValue   #added 20221006
                FinalArray1D[(FinalArray1D > (F3NoDataValue-1)) & (FinalArray1D < (F3NoDataValue+1))] =  F3NoDataValue #float cannot compare due to precision?
                FinalArray1D = ma.masked_values(FinalArray1D, F3NoDataValue)
                print("FinalArray1D.shape=",FinalArray1D.shape, file=open(F3Log, 'a'))
                
                MetricStep2Array1D[np.isnan(MetricStep2Array1D)] = F3NoDataValue   #added 20221006
                MetricStep2Array1D[(MetricStep2Array1D > (F3NoDataValue-1)) & (MetricStep2Array1D < (F3NoDataValue+1))] =  F3NoDataValue #float cannot compare due to precision?
                MetricStep2Array1D = ma.masked_values(MetricStep2Array1D, F3NoDataValue)
                print("MetricStep2Array1D.shape=",MetricStep2Array1D.shape, file=open(F3Log, 'a'))
                
                FinalArray1D[FinalArray1D.mask] = MetricStep2Array1D[FinalArray1D.mask]
                
            Step2Final1D = FinalArray1D.copy()
            if CrossValidationIntermediateTifSave == "Yes":
                Step2Final2DArray = Step2Final1D.reshape(FinalArray.shape[0],FinalArray.shape[1])  #shape[0] is row and shape[1] is col
                ArrayTif = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"Intermediate"+os.sep+"CrossFolderPercentage"+str(int(CrossFolderPercentage*100))+"CrossValidation"+str(k)+"_"+Metric+"_Step2.tif"
                if not os.path.exists(ArrayTif):
                    Step2FinalTifFile = Save2DArrayToTif(Run,Tile,Management,Year,Metric,Step2Final2DArray,ArrayTif)
                    print("Step2FinalTifFile=",Step2FinalTifFile)
            
            for p in range(0,len(Step3ZoneInputTif),1):
                if CrossValidationImputationFunction == "CrossValidationSelf":
                    ZoneTifArray1D = Step3ZoneArray[p,:]
                    if Metric in ContinuousMetrics:

                        #20230309: this section uses Step3StatisticType[p], which is one of [mean,weightedmean,meantimesregressionratio, weightedmeantimesregressionratio,allfour], to calculate the zonestatistics---start
                        ImputationUsedInCrossvalidation = Step3StatisticType[p]
                        if (("mean" in ImputationUsedInCrossvalidation.lower()) or ("allfour" in ImputationUsedInCrossvalidation.lower())):
                            MetricStep3ArrayMean = pd.Series(Step2Final1D).groupby(ZoneTifArray1D).transform(lambda x: x.mean(skipna=True)).to_numpy(dtype=np.int64,copy=True,na_value=F3NoDataValue)
                        if (("weighted" in ImputationUsedInCrossvalidation.lower()) or ("allfour" in ImputationUsedInCrossvalidation.lower())):
                            WeightBasisSumInZone = pd.Series(WeightBasisTifArray1D).groupby(ZoneTifArray1D).transform(lambda x: x.sum(skipna=True)).to_numpy(dtype=np.float,copy=True,na_value=F3NoDataValue)  #it is float here, not int64?
                            MetricValueTimesWeight = Step2Final1D * WeightBasisTifArray1D / WeightBasisSumInZone  #MetricValueTimesWeight = np.multiply(Step2Final1D, np.divide(WeightBasisTifArray1D, WeightBasisSumInZone))  #This works, but RuntimeWarning: divide by zero encountered in true_divide. In the future, we may have to handle this
                        if (("ratio" in ImputationUsedInCrossvalidation.lower()) or ("allfour" in ImputationUsedInCrossvalidation.lower())):
                            FieldMetricPredictedOutputArray1DMeanInZone = pd.Series(FieldMetricPredictedOutputArray1D).groupby(ZoneTifArray1D).transform(lambda x: x.mean(skipna=True)).to_numpy(dtype=np.int64,copy=True,na_value=F3NoDataValue)
                            FieldMetricPredictedRatio = FieldMetricPredictedOutputArray1D / FieldMetricPredictedOutputArray1DMeanInZone  #you can use np.multiply() and np.divide() here too    
                        if ImputationUsedInCrossvalidation.lower() == "mean":
                            MetricStep3Array1D = MetricStep3ArrayMean
                        if ImputationUsedInCrossvalidation.lower() == "weightedmean":
                            MetricStep3Array1D = MetricStep3ArrayMean * MetricValueTimesWeight
                        if ImputationUsedInCrossvalidation.lower() == "meantimesregressionratio":
                            MetricStep3Array1D = MetricStep3ArrayMean * FieldMetricPredictedRatio
                        if ImputationUsedInCrossvalidation.lower() == "weightedmeantimesregressionratio":
                            MetricStep3Array1D = MetricStep3ArrayMean * MetricValueTimesWeight * FieldMetricPredictedRatio
                        if ImputationUsedInCrossvalidation.lower() == "allfour":
                            MetricStep3Array1D = (MetricStep3ArrayMean + MetricStep3ArrayMean*MetricValueTimesWeight + MetricStep3ArrayMean*FieldMetricPredictedRatio + MetricStep3ArrayMean*MetricValueTimesWeight*FieldMetricPredictedRatio) / 4.0
                        #20230309: this section uses Step3StatisticType[p], which is one of [mean,weightedmean,meantimesregressionratio, weightedmeantimesregressionratio,allfour], to calculate the zonestatistics---end


                        '''''' 
                        #Before 20230309: this section uses one of [[AllFour, meanandweightedmean]] to calculate the zonestatistics. I will discard this once the new one works---start
                        ImputationUsedInCrossvalidation = "meanandweightedmean"  #two options here: [AllFour, meanandweightedmean]
                        if ImputationUsedInCrossvalidation.lower() == "mean":
                            MetricStep3Array1D = pd.Series(Step2Final1D).groupby(ZoneTifArray1D).transform(lambda x: x.mean(skipna=True)).to_numpy(dtype=np.int64,copy=True,na_value=F3NoDataValue)
                        if ((ImputationUsedInCrossvalidation.lower() == "allfour") or (ImputationUsedInCrossvalidation.lower() == "meanandweightedmean")):  
                            MetricStep3Array1D_allfour = np.full((4,len(Step2Final1D)), F3NoDataValue)  #here the first length is 4
                            MetricStep3Array1D_allfour[0,:] = pd.Series(Step2Final1D).groupby(ZoneTifArray1D).transform(lambda x: x.mean(skipna=True)).to_numpy(dtype=np.int64,copy=True,na_value=F3NoDataValue)            
                            WeightBasisSumInZone = pd.Series(WeightBasisTifArray1D).groupby(ZoneTifArray1D).transform(lambda x: x.sum(skipna=True)).to_numpy(dtype=np.float,copy=True,na_value=F3NoDataValue)  #it is float here, not int64?
                            MetricValueTimesWeight = Step2Final1D * WeightBasisTifArray1D / WeightBasisSumInZone  #MetricValueTimesWeight = np.multiply(Step2Final1D, np.divide(WeightBasisTifArray1D, WeightBasisSumInZone))  #This works, but RuntimeWarning: divide by zero encountered in true_divide. In the future, we may have to handle this
                            MetricStep3Array1D_allfour[1,:] = pd.Series(MetricValueTimesWeight).groupby(ZoneTifArray1D).transform(lambda x: x.sum(skipna=True)).to_numpy(dtype=np.int64,copy=True,na_value=F3NoDataValue)
                            if ImputationUsedInCrossvalidation.lower() == "meanandweightedmean":
                                MetricStep3Array1D = np.nanmean(MetricStep3Array1D_allfour[0:2,:],axis=0) 
                            if ImputationUsedInCrossvalidation.lower() == "allfour":      
                                FieldMetricPredictedOutputArray1DMeanInZone = pd.Series(FieldMetricPredictedOutputArray1D).groupby(ZoneTifArray1D).transform(lambda x: x.mean(skipna=True)).to_numpy(dtype=np.int64,copy=True,na_value=F3NoDataValue)
                                MetricStep3Array1D_allfour[2,:] = MetricStep3Array1D_allfour[0,:] * FieldMetricPredictedOutputArray1D / FieldMetricPredictedOutputArray1DMeanInZone  #you can use np.multiply() and np.divide() here too    
                                MetricStep3Array1D_allfour[3,:] = MetricStep3Array1D_allfour[1,:] * FieldMetricPredictedOutputArray1D / FieldMetricPredictedOutputArray1DMeanInZone  #you can use np.multiply() and np.divide() here too    
                                MetricStep3Array1D = np.nanmean(MetricStep3Array1D_allfour,axis=0)
                        #Before 20230309: this section uses one of [[AllFour, meanandweightedmean]] to calculate the zonestatistics. I will discard this once the new one works---end
                        ''''''

                    if Metric in DiscreteMetrics:
                        MetricStep3Array1D = np.full((FinalArray.shape[0]*FinalArray.shape[1]), F3NoDataValue)
                        PandasSeries = pd.Series(Step2Final1D).groupby(ZoneTifArray1D)  #This is a pandas series object, which is actually a list of tuples
                        for group in PandasSeries:  
                            if group[1].mode().empty:  #If the majority is empty, we give a F3NoDataValue for the corresponding indexes
                                MetricStep3Array1D[group[1].index] = F3NoDataValue
                            else:
                                MetricStep3Array1D[group[1].index] = group[1].mode()[0]  ##If the majority is not empty, we give the mode value for the corresponding indexes
                            
                    RequiredMinimumPixelNumberYesOrNo = Step3RequiredMinimumPixelNumberYesOrNo[p]  #Before 2023039: RequiredMinimumPixelNumberYesOrNo = "Yes"   #Another option is "No"
                    if RequiredMinimumPixelNumberYesOrNo == "Yes":  #Added on 20221207
                        MinimumPixelNumber = Step3MinimumNumberOfInputPixel[p]    #Before 2023039: MinimumPixelNumber = 2   #give the MinimumPixelNumber here. Usually 1 or 2
                        NumberOfPlotInZone = pd.Series(PlotIDArray1D).groupby(ZoneTifArray1D).transform(lambda x: x.count()).to_numpy(dtype=np.int64,copy=True,na_value=F3NoDataValue)
                        MetricStep3Array1D[NumberOfPlotInZone < MinimumPixelNumber] = F3NoDataValue
                if CrossValidationImputationFunction == "ZoneStatisticsToArrayWangNing":
                    MetricStep3Array = ZoneStatisticsToArrayWangNing(Step3ZoneInputTif[p],Metric,Step2Final1D,Step3StatisticType[p],CrossValidationPlotIDTif,Step3RequiredMinimumPixelNumberYesOrNo[p],Step3MinimumNumberOfInputPixel[p])
                    MetricStep3Array1D = MetricStep3Array.flatten()

                
                FinalArray1D[np.isnan(FinalArray1D)] = F3NoDataValue   #added 20221006
                FinalArray1D[(FinalArray1D > (F3NoDataValue-1)) & (FinalArray1D < (F3NoDataValue+1))] =  F3NoDataValue #float cannot compare due to precision?
                FinalArray1D = ma.masked_values(FinalArray1D, F3NoDataValue)  
                MetricStep3Array1D[np.isnan(MetricStep3Array1D)] = F3NoDataValue   #added 20221006
                MetricStep3Array1D[(MetricStep3Array1D > (F3NoDataValue-1)) & (MetricStep3Array1D < (F3NoDataValue+1))] =  F3NoDataValue #float cannot compare due to precision?
                MetricStep3Array1D = ma.masked_values(MetricStep3Array1D, F3NoDataValue)  
                FinalArray1D[FinalArray1D.mask] = MetricStep3Array1D[FinalArray1D.mask]  
            Step3Final1D = FinalArray1D.copy()
            if CrossValidationIntermediateTifSave == "Yes":
                Step3Final2DArray = Step3Final1D.reshape(FinalArray.shape[0],FinalArray.shape[1])  #shape[0] is row and shape[1] is col
                ArrayTif = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"Intermediate"+os.sep+"CrossFolderPercentage"+str(int(CrossFolderPercentage*100))+"CrossValidation"+str(k)+"_"+Metric+"_Step3.tif"
                if not os.path.exists(ArrayTif):
                    Step3FinalTifFile = Save2DArrayToTif(Run,Tile,Management,Year,Metric,Step3Final2DArray,ArrayTif)
                    print("Step3FinalTifFile=",Step3FinalTifFile)
            
            for p in range(0,len(Step4ZoneInputTif),1):
                if CrossValidationImputationFunction == "CrossValidationSelf":
                    ZoneTifArray1D = Step4ZoneArray[p,:]
                    if Metric in ContinuousMetrics:
                        MetricStep4Array1D = pd.Series(Step3Final1D).groupby(ZoneTifArray1D).transform(lambda x: x.mean(skipna=True)).to_numpy(dtype=np.int64,copy=True,na_value=F3NoDataValue)
                    if Metric in DiscreteMetrics:
                        MetricStep4Array1D = np.full((FinalArray.shape[0]*FinalArray.shape[1]), F3NoDataValue)
                        PandasSeries = pd.Series(Step3Final1D).groupby(ZoneTifArray1D)  #This is a pandas series object, which is actually a list of tuples
                        for group in PandasSeries:  
                            if group[1].mode().empty:  #If the majority is empty, we give a F3NoDataValue for the corresponding indexes
                                MetricStep4Array1D[group[1].index] = F3NoDataValue
                            else:
                                MetricStep4Array1D[group[1].index] = group[1].mode()[0]  ##If the majority is not empty, we give the mode value for the corresponding indexes
                if CrossValidationImputationFunction == "ZoneStatisticsToArrayWangNing":
                    MetricStep4Array = ZoneStatisticsToArrayWangNing(Step4ZoneInputTif[p],Metric,Step3Final1D,Step4StatisticType[p],CrossValidationPlotIDTif,Step4RequiredMinimumPixelNumberYesOrNo[p],Step4MinimumNumberOfInputPixel[p])
                    MetricStep4Array1D = MetricStep4Array.flatten()

                FinalArray1D[np.isnan(FinalArray1D)] = F3NoDataValue   #added 20221006
                FinalArray1D[(FinalArray1D > (F3NoDataValue-1)) & (FinalArray1D < (F3NoDataValue+1))] =  F3NoDataValue #float cannot compare due to precision?
                FinalArray1D = ma.masked_values(FinalArray1D, F3NoDataValue) 
                MetricStep4Array1D[np.isnan(MetricStep4Array1D)] = F3NoDataValue   #added 20221006
                MetricStep4Array1D[(MetricStep4Array1D > (F3NoDataValue-1)) & (MetricStep4Array1D < (F3NoDataValue+1))] =  F3NoDataValue #float cannot compare due to precision?
                MetricStep4Array1D = ma.masked_values(MetricStep4Array1D, F3NoDataValue)  
                FinalArray1D[FinalArray1D.mask] = MetricStep4Array1D[FinalArray1D.mask]  
            Step4Final1D = FinalArray1D.copy()
            if CrossValidationIntermediateTifSave == "Yes":
                Step4Final2DArray = Step4Final1D.reshape(FinalArray.shape[0],FinalArray.shape[1])  #shape[0] is row and shape[1] is col
                ArrayTif = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"Intermediate"+os.sep+"CrossFolderPercentage"+str(int(CrossFolderPercentage*100))+"CrossValidation"+str(k)+"_"+Metric+"_Step4.tif"
                if not os.path.exists(ArrayTif):
                    Step4FinalTifFile = Save2DArrayToTif(Run,Tile,Management,Year,Metric,Step4Final2DArray,ArrayTif)
                    print("Step4FinalTifFile=",Step4FinalTifFile)

            if Metric in ContinuousMetrics:
                MetricType = "Continuous"
            if Metric in DiscreteMetrics:
                MetricType = "Discrete"
            mid = -1
            for m in range(0,len(RemovedPlotInThisTileList),1):
                mid = mid + 1
                MyContent0 = [str(RemovedPlotInThisTileList[m]), Run, Tile, Management, str(Year), Metric, str(CrossFolderPercentage), str(k), str(RemovedPlotInThisTileListMetricValue[m]), str(Step4Final1D[RemovedPlotInThisTileListIndex[m]])]
                #print("MyContent0=",MyContent0)
                if str(Step4Final1D[RemovedPlotInThisTileListIndex[m]]) != "--":  #Some pixles will not imputed due to cloud/water/ice/bare etc and insufficient plots data
                    Content0 = [str(RemovedPlotInThisTileList[m]), str(RemovedPlotInThisTileListRow[m]), str(RemovedPlotInThisTileListColumn[m]), Run, Tile, Management, str(Year), Metric, MetricType,str(CrossFolderPercentage), str(k+1), str(RemovedPlotInThisTileListMetricValue[m]), str(Step4Final1D[RemovedPlotInThisTileListIndex[m]]), "Dr. Shengli Huang (shengli.huang@usda.gov)", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")]            
                    Content = ",".join(Content0) + "\n"
                    #print("Content=",Content)
                    FinalCrossValidationCSVFile.write(Content)
        '''
                        
        FinalCrossValidationCSVFile.close()
        print("Returned FinalCrossValidationCSV=",FinalCrossValidationCSV," for ", Run, Tile, Management, Year, Metric)
        return FinalCrossValidationCSV
    except Exception as e:
        print("Sorry, there is an error : ",e)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        strTrace = traceback.format_exception(exc_type, exc_value, exc_traceback)
        ErrorLog = os.getcwd()+os.sep+"F3Error.txt"
        ErrorLogFile = open(ErrorLog, 'a')
        Content1 = "Dr. Shengli Huang detected an error at "+datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        #print(Content1)
        Content2 = "The error was for F3FourSteps with inputs of " + repr(mylock)+","+repr(Run)+","+repr(Tile)+","+repr(Management)+","+repr(Year)+","+repr(Metric)+","+repr(CrossFolderPercentage) + " with the following details:\n"
        #print(Content2)
        Content3 = repr(strTrace) + "\n\n\n"  #see https://docs.python.org/2/library/traceback.html
        #print(Content3)
        ErrorLogFile.write(Content1)
        ErrorLogFile.write(Content2)
        ErrorLogFile.write(Content3)
        ErrorLogFile.close()
        return ErrorLog


   

if __name__ == '__main__':   
    print("\n\n\nWe cannot run in terminal; we must run under DOS command, because it is a parallel python!")
    NumberOfProcessors = int(os.cpu_count())  #os.environ["NUMBER_OF_PROCESSORS"] does not work for unix but work for windows
    print("NumberOfProcessors=",NumberOfProcessors)
    UserDefinedRatio = 0.25   #The old F3 in California used 0.5. 3 run use 0.3, 6 run may use 0.25
    UserDefinedMaximumProcessors = int(NumberOfProcessors * UserDefinedRatio)

    #Note: if you have the error of [Exception in thread Thread-1 (_handle_workers): need at most 63 handles, got a sequence of length 88"], then try below
    #20240124: I found the error "ValueError: [Exception in thread Thread-1 (_handle_workers): need at most 63 handles, got a sequence of length 88"]
    #https://stackoverflow.com/questions/65252807/multiprocessing-pool-pool-on-windows-cpu-limit-of-63
    UserDefinedMaximumProcessors = min(60,int(NumberOfProcessors * UserDefinedRatio))  #20240124: so I use the 60 here to solve the problem above
    print("We only use ",UserDefinedMaximumProcessors," processors. The maximum value of 60 is used to solve the problem of [ValueError: [Exception in thread Thread-1 (_handle_workers): need at most 63 handles, got a sequence of length 88]")
    
    mymanager = multiprocessing.Manager()
    mylock = mymanager.Lock() # is "lock = multiprocessing.Lock()" OK? I guess it may not work, see https://www.thecodingforums.com/threads/multiprocessing-and-locks.679436/ and http://stackoverflow.com/questions/25557686/python-sharing-a-lock-between-processes
    myqueue = mymanager.Queue() #I do not use here, but want to keep here for future use. But rememebr this may be required for multiprocessing internally     

    #This section will download the F3 input data from Google Cloud Bucket. Added on June 9, 2022---start
    if F3InputSource == "CloudBucket": #Option are "Local" or "CloudBucket"
        source_bucket_name = "f3inputbucket"
        source_bucket_path = "." #something like ".", "Run1/SmallSeral", "FFFProcessing/F3RunACCEL20220318GCP/Run1/CaliforniaTile1"
        local_path = "."  #option can be ".", which means no subfolder creation, or something like "temp2"
        DownloadFromBucketMessage = HuangBucket.download_from_bucket(source_bucket_name, source_bucket_path,local_path)
        print(DownloadFromBucketMessage)

    if F3InputSource == "Local": #Option are "Local" or "CloudBucket"
        print("F3InputSouce is local, which means all the input data are in local computer now")
        print("If the data are in local, it means the Dockerfile will be very larger; this is why I prefer CloudBucket, but I am not sure of the permission/credential as of June 10, 2022")
    #This section will download the F3 input data from Google Cloud Bucket. Added on June 9, 2022---end

    
    CopyFieldSqlite = CopyFieldSqliteFromPathToEachRunAndTile(Runs,Managements,Tiles,Years, FieldPointHeader)  #added on 20240126 to copy FieldSqliteDB automatically
    
    #x = input('Please hit any key to continue 1:')
    #exit()



    #This section process BaseMetricBaseYearBaseManagement and create commonly-shared data---start
    MaximalSimutaneousTask = min(len(Runs)*len(Tiles)*1*1*1, UserDefinedMaximumProcessors) #here 1*1*1 indicate BaseManagement,BaseYear,BaseMetric
    NumberOfSimutaneousTask = max(min(NumberOfProcessors-2, MaximalSimutaneousTask),1)  
    print("\n\n\nNumberOfSimutaneousTask for BaseManagement,BaseYear,BaseMetric=",NumberOfSimutaneousTask)
    F3pool = multiprocessing.Pool(processes=NumberOfSimutaneousTask)
    for Run in Runs:
        for Tile in Tiles:
            for Management in [BaseManagement]:
                for Year in [BaseYear]:
                    for Metric in [BaseMetric]:
                        if Metric in ContinuousMetrics:
                            FinalMosaicTif = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep + ProjectName +os.sep+Management+"_"+Year+"_"+Metric+"_MosaicCellMean_Win3x3Smoothing.tif"
                        if Metric in DiscreteMetrics:
                            FinalMosaicTif = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep + ProjectName +os.sep+Management+"_"+Year+"_"+Metric+"_MosaicCellMode_Win3x3Smoothing.tif"
                        print("FinalMosaicTif=",FinalMosaicTif)
                        if not os.path.exists(FinalMosaicTif):
                            FinalTif = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"Results"+os.sep+Management+"_"+Year+"_"+Metric+".tif"
                            if ((not os.path.exists(FinalTif)) or (F3DebugMode == "Yes")):
                                print("\n\n\nWe want to process ",FinalTif)
                                print(Run,Tile,Management,Year,Metric," started at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
                                F3pool.apply_async(F3FourSteps, [mylock,Run,Tile,Management,Year,Metric])   
    F3pool.close()
    F3pool.join()
    print("AAA finished at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
    #This section process BaseMetricBaseYearBaseManagement and create commonly-shared data---end

    #x = input('Please hit any key to continue 2:')
    #exit()




    #This section mosaics (across tiles) and averages (through runs) for ValidPixelNumber and ProcessingPercentageAsOrderAndReliability based on BaseMetricBaseYearBaseManagement---start
    MaximalSimutaneousTask = min(len(Managements)*len(Years)*len(Metrics), UserDefinedMaximumProcessors)
    NumberOfSimutaneousTask = max(min(NumberOfProcessors-2, MaximalSimutaneousTask),1)
    print("Note: F3SpatialMosaicAndUncertainty must be run before F3SpatialMosaicReliability, as the latter depends on the boundary defined by the former") 
    print("\n\n\nNumberOfSimutaneousTask for mosaics (across tiles) and averages (through runs)=",NumberOfSimutaneousTask)
    F3pool = multiprocessing.Pool(processes=NumberOfSimutaneousTask)  #20221121 I found the parallel use normal memory but zero CPU if the results already exists; therefore, this sentence should be moved 
    for Management in [BaseManagement]:
        for Year in [BaseYear]:
            for Metric in [BaseMetric]:
                FinalMosaicTif = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep + ProjectName + os.sep + "MosaicProcessingPercentageAsOrderAndReliabilityMean.tif"
                if not os.path.exists(FinalMosaicTif):
                    print(Management,Year,Metric," mosaic started at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
                    #F3pool.apply_async(F3SpatialMosaicReliability, [mylock,Runs,Tiles,Management,Year,Metric])
                    F3pool.apply_async(F3SpatialMosaicReliability, [mylock,Runs,Tiles,Management,Year,Metric,SpatialMosaicProjectBoundary]) #F3pool.apply_async(F3SpatialMosaicReliability, [mylock,Runs,Tiles,Management,Year,Metric,SpatialMosaicProjectBoundary])    
    F3pool.close()
    F3pool.join()
    print("Please do not move the section below to somewhere else because the position in the code is very important")
    CreateBaseLineFileList = CreateBaseLineFileList()
    print("CreateBaseLineFileList was just created as ", CreateBaseLineFileList)
    print("CreateBaseLineFileList was just created as ", CreateBaseLineFileList, file=open(F3Log, 'a'))
    print("CCC finished at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
    #This section mosaics (across tiles) and averages (through runs) for ValidPixelNumber and ProcessingPercentageAsOrderAndReliability based on BaseMetricBaseYearBaseManagement---end


    #x = input('Please hit any key to continue 3:')
    #exit()


    #This section mosaics (across tiles) and averages (through runs) for BaseMetricBaseYearBaseManagement---start
    MaximalSimutaneousTask = min(len(Managements)*len(Years)*len(Metrics), UserDefinedMaximumProcessors)
    NumberOfSimutaneousTask = max(min(NumberOfProcessors-2, MaximalSimutaneousTask),1)  
    print("\n\n\nNumberOfSimutaneousTask for mosaics (across tiles) and averages (through runs)=",NumberOfSimutaneousTask)
    F3pool = multiprocessing.Pool(processes=NumberOfSimutaneousTask)
    for Management in [BaseManagement]:  #20230210, surprised it was [Management], so changed to [BaseManagement]. Will see
        for Year in [BaseYear]:
            for Metric in [BaseMetric]:
                if Metric in ContinuousMetrics:
                    FinalMosaicTif = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep + ProjectName + os.sep + Management+"_"+Year+"_"+Metric+"_MosaicCellMean_Win3x3Smoothing.tif"
                if Metric in DiscreteMetrics:
                    FinalMosaicTif = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep + ProjectName + os.sep + Management+"_"+Year+"_"+Metric+"_MosaicCellMode_Win3x3Smoothing.tif"
                if not os.path.exists(FinalMosaicTif):    
                    print(Management,Year,Metric," mosaic started at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
                    #F3pool.apply_async(F3SpatialMosaicAndUncertainty, [mylock,Runs,Tiles,Management,Year,Metric])  ##This is not to include a SpatialMosaicProjectBoundary argument
                    F3pool.apply_async(F3SpatialMosaicAndUncertainty, [mylock,Runs,Tiles,Management,Year,Metric,SpatialMosaicProjectBoundary])   #This is to include a SpatialMosaicProjectBoundary argument
    F3pool.close()
    F3pool.join()
    print("BBB finished at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
    #This section mosaics (across tiles) and averages (through runs) for BaseMetricBaseYearBaseManagement---end

    #x = input('Please hit any key to continue 4:')
    #exit()





    
    #This section process NOT BaseMetricBaseYearBaseManagement---start
    MaximalSimutaneousTask = min(len(Runs)*len(Tiles)*len(Managements)*len(Years)*len(Metrics)-len(Runs)*len(Tiles), UserDefinedMaximumProcessors) 
    NumberOfSimutaneousTask = max(min(NumberOfProcessors-2, MaximalSimutaneousTask),1)  #This defines how many task to be processed simutaneouslly. We can use a fixed number such as "NumberOfSimutaneousTask = 10", but check http://stackoverflow.com/questions/5784389/using-100-of-all-cores-with-python-multiprocessing
    print("\n\n\nNumberOfSimutaneousTask excluding BaseManagement,BaseYear,BaseMetric=",NumberOfSimutaneousTask)
    if NumberOfSimutaneousTask >= 1:
        F3pool = multiprocessing.Pool(processes=NumberOfSimutaneousTask)
        for Run in Runs:
            for Tile in Tiles:
                for Management in Managements:
                    for Year in Years:
                        for Metric in Metrics:
                            if ((Management == BaseManagement) and (Year == BaseYear) and (Metric == BaseMetric)):
                                print("This is BaseManagement,BaseYear,BaseMetric and it should be finished, so we will continue")
                                continue
                            else:
                                if Metric in ContinuousMetrics:
                                    FinalMosaicTif = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep + ProjectName +os.sep+Management+"_"+Year+"_"+Metric+"_MosaicCellMean_Win3x3Smoothing.tif"
                                if Metric in DiscreteMetrics:
                                    FinalMosaicTif = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep + ProjectName +os.sep+Management+"_"+Year+"_"+Metric+"_MosaicCellMode_Win3x3Smoothing.tif"
                                if not os.path.exists(FinalMosaicTif):    
                                    FinalTif = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"Results"+os.sep+Management+"_"+Year+"_"+Metric+".tif"
                                    if not os.path.exists(FinalTif):
                                        print("@@@@@@@@@@@@@@@@@@@@@@",Run,Tile,Management,Year,Metric," started at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
                                        F3pool.apply_async(F3FourSteps, [mylock,Run,Tile,Management,Year,Metric])  
        F3pool.close()
        F3pool.join()
        print("DDD finished at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
    #This section process NOT BaseMetricBaseYearBaseManagement---end

    #x = input('Please hit any key to continue 5:')    #THERE ARE DUPLICATE CALCULATION HERE< PLEASE CHECK
    #exit()





    #This section mosaics (across tiles) and averages (through runs) for BaseMetricBaseYearBaseManagement---start
    MaximalSimutaneousTask = min(len(Managements)*len(Years)*len([k for k in Metrics if "0and1_0_999" in k]), UserDefinedMaximumProcessors)
    NumberOfSimutaneousTask = max(min(NumberOfProcessors-2, MaximalSimutaneousTask),1)  
    print("\n\n\nNumberOfSimutaneousTask for mosaics (across tiles) and averages (through runs)=",NumberOfSimutaneousTask)
    F3pool = multiprocessing.Pool(processes=NumberOfSimutaneousTask)
    for Management in Managements:
        for Year in Years:
            for Metric in Metrics:
                if "0and1_0_999" in Metric:
                    if Metric in ContinuousMetrics:
                        FinalMosaicTif = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep + ProjectName + os.sep + Management+"_"+Year+"_"+Metric+"_MosaicCellMean_Win3x3Smoothing.tif"
                    if Metric in DiscreteMetrics:
                        FinalMosaicTif = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep + ProjectName + os.sep + Management+"_"+Year+"_"+Metric+"_MosaicCellMode_Win3x3Smoothing.tif"
                    if not os.path.exists(FinalMosaicTif):    
                        print("/n/n######################################",Management,Year,Metric," mosaic started at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
                        #F3pool.apply_async(F3SpatialMosaicAndUncertainty, [mylock,Runs,Tiles,Management,Year,Metric])  ##This is not to include a SpatialMosaicProjectBoundary argument
                        F3pool.apply_async(F3SpatialMosaicZeroInflationAndSpeciesConfidence, [mylock,Runs,Tiles,Management,Year,Metric,SpatialMosaicProjectBoundary])   #This is to include a SpatialMosaicProjectBoundary argument
    F3pool.close()
    F3pool.join()
    print("EEE finished at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
    #This section mosaics (across tiles) and averages (through runs) for BaseMetricBaseYearBaseManagement---end

    #x = input('Please hit any key to continue 6:')
    #exit()




    #This section mosaics (across tiles) and averages (through runs) for NOT BaseMetricBaseYearBaseManagement---start
    F3SpatialMosaicAndUncertaintyRatio = 0.4  #This will UserDefinedRatio. If UserDefinedRatio=0.5 and F3SpatialMosaicAndUncertaintyRatio=0.2, then 0.5*0.2=0.1, so let us say 96 cores, we will use 9.6 corse
    MaximalSimutaneousTask = min(len(Managements)*len(Years)*len([k for k in Metrics if "0and1_0_999" not in k]), int(UserDefinedMaximumProcessors*F3SpatialMosaicAndUncertaintyRatio))
    NumberOfSimutaneousTask = max(min(NumberOfProcessors-2, MaximalSimutaneousTask),1)
    print("\n\n\nNumberOfSimutaneousTask for mosaics (across tiles) and averages (through runs)=",NumberOfSimutaneousTask)
    F3pool = multiprocessing.Pool(processes=NumberOfSimutaneousTask)
    for Management in Managements:
        for Year in Years:
            for Metric in Metrics:
                if "0and1_0_999" not in Metric:
                    if ((Management == BaseManagement) and (Year == BaseYear) and (Metric == BaseMetric)):
                        print("This is BaseManagement,BaseYear,BaseMetric and it should be finished, so we will continue")
                        continue
                    else:
                        if Metric in ContinuousMetrics:
                            FinalMosaicTif = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep + ProjectName +os.sep+Management+"_"+Year+"_"+Metric+"_MosaicCellMean_Win3x3Smoothing.tif"
                        if Metric in DiscreteMetrics:
                            FinalMosaicTif = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep + ProjectName +os.sep+Management+"_"+Year+"_"+Metric+"_MosaicCellMode_Win3x3Smoothing.tif"
                        if not os.path.exists(FinalMosaicTif):    
                            print(Management,Year,Metric," mosaic started at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
                            #F3pool.apply_async(F3SpatialMosaicAndUncertainty, [mylock,Runs,Tiles,Management,Year,Metric])  #This is not to include a SpatialMosaicProjectBoundary argumen
                            F3pool.apply_async(F3SpatialMosaicAndUncertainty, [mylock,Runs,Tiles,Management,Year,Metric,SpatialMosaicProjectBoundary])  #This is to include a SpatialMosaicProjectBoundary argument
    F3pool.close()
    F3pool.join()
    print("$$$$$$$$$$$FFFfinished at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
    F3ArcGISProjectCreation_NewFile = os.getcwd() + os.sep + ProjectName + "_ArcProProjectCreation.py"   #THis will create a Python file, which can be run to create ArcPro project file
    F3ArcGISProjectCreationFile = CreatePythonFileForOrganizingF3DataInArcProProject(F3ArcGISProjectCreation_NewFile)
    ProjectAprxFile = os.getcwd()+os.sep+"TilesMosaicRunAverage" + os.sep + ProjectName + os.sep + ProjectName + ".aprx"
    print(F3ArcGISProjectCreationFile," was created and ran to facilate the data check! in ArcPro Please open the file of ",ProjectAprxFile)
    print("FFF finished at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
    #This section mosaics (across tiles) and averages (through runs) for NOT BaseMetricBaseYearBaseManagement---end

    
    #x = input('Please hit any key to continue 7:')
    exit()



    #This section FindWhichPlotsUsedForSpecificPixelImputation---start
    FindWhichPlotsUsedForSpecificPixelImputationCheck = "Yes"  #Options are "Yes" or "No"
    if FindWhichPlotsUsedForSpecificPixelImputationCheck == "Yes":
        MaximalSimutaneousTask = min(len(Runs)*len(Tiles)*1*1*1, UserDefinedMaximumProcessors) #here 1*1*1 indicate BaseManagement,BaseYear,BaseMetric
        NumberOfSimutaneousTask = max(min(NumberOfProcessors-2, MaximalSimutaneousTask),1)  
        print("\n\n\nNumberOfSimutaneousTask for BaseManagement,BaseYear,BaseMetric=",NumberOfSimutaneousTask)
        print("Please check PointsAlbersExample.txt and PointsLongLatExample.txt under the folder of ",EverywherePath," to define the input file for FindWhichPlotsUsedForSpecificPixelImputation")
        PointsTxt = r"F:\CUI\fhaastf3app\RemoteSensingYear2023\TilesMosaicRunAverage\PointsLonLat2.txt"  #As of 20240506, every pixel may take 1.2 hours
        F3pool = multiprocessing.Pool(processes=NumberOfSimutaneousTask)
        for Run in Runs:
            for Tile in Tiles:
                for Management in [BaseManagement]:
                    for Year in [BaseYear]:
                        for Metric in [BaseMetric]:
                            FinalCSV = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"CommonShare"+os.sep+"ZoneImputationSpecificPixels_"+PointsTxt.split(os.sep)[-1].replace(".txt","")+".csv"
                            print("\n\n\nWe want to process ",FinalCSV)
                            F3pool.apply_async(FindWhichPlotsUsedForSpecificPixelImputation, [mylock,Run,Tile,Management,Year,Metric,PointsTxt])   
        F3pool.close()
        F3pool.join()
        AllRunCSV = FindWhichPlotsUsedForSpecificPixelImputationForAllRun(Run,Tile,Management,Year,Metric,PointsTxt)
        print("AllRunCSV=",AllRunCSV)
        print("GGG finished at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
    #This section FindWhichPlotsUsedForSpecificPixelImputation------end


    #x = input('Please hit any key to continue 2AAA:')
    exit()




    #This section process BaseMetricBaseYearBaseManagement and create commonly-shared data---start
    FindWhichPlotsFallenInTheGroupCheck = "Yes"  #Options are Yes or No
    if FindWhichPlotsFallenInTheGroupCheck == "Yes": 
        MaximalSimutaneousTask = min(len(Runs)*len(Tiles)*1*1*1, UserDefinedMaximumProcessors) #here 1*1*1 indicate BaseManagement,BaseYear,BaseMetric
        NumberOfSimutaneousTask = max(min(NumberOfProcessors-2, MaximalSimutaneousTask),1)  
        print("\n\n\nNumberOfSimutaneousTask for BaseManagement,BaseYear,BaseMetric=",NumberOfSimutaneousTask)
        F3pool = multiprocessing.Pool(processes=NumberOfSimutaneousTask)
        for Run in Runs:
            for Tile in Tiles:
                for Management in [BaseManagement]:
                    for Year in [BaseYear]:
                        for Metric in [BaseMetric]:
                            FinalTif = os.getcwd()+os.sep+Run+os.sep+Tile+os.sep+"CommonShare"+os.sep+"ZoneImputationValue.tif"  ##As of 20240506, every image may take 60 hours (2.5 days)
                            if not os.path.exists(FinalTif):
                                print("\n\n\nWe want to process ",FinalTif)
                                F3pool.apply_async(FindWhichPlotsFallenInTheGroup, [mylock,Run,Tile,Management,Year,Metric])   
        F3pool.close()
        F3pool.join()
        print("HHH finished at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
    #This section process BaseMetricBaseYearBaseManagement and create commonly-shared data---end

    #x = input('Please hit any key to continue 2AAA:')
    exit()


    #This section creates landscape scenario mosaic (not spatial mosaic). It has not been tested as of 20230928---start
    LandscapeScenarioMosaic = "No" #Options are "Yes" or "No"
    if LandscapeScenarioMosaic == "Yes":
        ManagementScenarioAOI = ""  #ManagementScenarioAOI is a TIF or Shape file depicting the AOI of each management scenarios
        MaximalSimutaneousTask = min(len(Tiles)*len(Years)*len(Metrics), UserDefinedMaximumProcessors)
        NumberOfSimutaneousTask = max(min(NumberOfProcessors-2, MaximalSimutaneousTask),1)  
        print("\n\n\nNumberOfSimutaneousTask for landscape scenario mosaic=",NumberOfSimutaneousTask)
        F3pool = multiprocessing.Pool(processes=NumberOfSimutaneousTask)
        for Tile in Tiles:
            for Year in Years:
                for Metric in Metrics:
                    FinalPixelTif = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep+"LandscapeScenario"+"_"+str(Year)+"_"+Metric+"_MosaicCellMean_Win3x3Smoothing.tif"
                    if not os.path.exists(FinalPixelTif):
                        print(Tile, Metric, Year, " landscape scenario mosaic started at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"), file=open(F3Log, 'a'))
                        F3pool.apply_async(LandscapeManagementMosaic, [mylock,ManagementScenarioAOI,Tile,Year,Metric])  #This is to include a SpatialMosaicProjectBoundary argument
        F3pool.close()
        F3pool.join()
        print("FFF111 finished at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
        Managements.append("LandscapeScenario")   #20230706: I am not sure how this will affect the subsequent analysis, let us check later
    #This section creates landscape scenario mosaic (not spatial mosaic). It has not been tested as of 20230928 ---end


    #x = input('Please hit any key to continue 5-1:')
    #exit()
    

    #This section calculates time-series PixelWise statistics like arcpy CellStatistics function ---start
    TimeSeriesPixelWiseStatistics = "No" #Options are "Yes" or "No"
    if TimeSeriesPixelWiseStatistics == "Yes":
        MaximalSimutaneousTask = min(len(Managements)*1*len(Metrics), UserDefinedMaximumProcessors)
        NumberOfSimutaneousTask = max(min(NumberOfProcessors-2, MaximalSimutaneousTask),1)  
        print("\n\n\nNumberOfSimutaneousTask for time-series PixelWise statistics=",NumberOfSimutaneousTask)
        F3pool = multiprocessing.Pool(processes=NumberOfSimutaneousTask)
        for Management in Managements:
            for Metric in Metrics:
                FinalPixelTif = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep+Management+"_"+Year[0]+"to"+Years[-1]+"_"+Metric+"_MosaicCellMean_Win3x3Smoothing_PixelWiseMean.tif"
                if not os.path.exists(FinalPixelTif):
                    if Metric in ContinuousMetrics: #added 20231006, because TimeSeriesPixelWiseStatistics is only applicable to ContinuousMetrics
                        print(Management,Metric," PixelWise calculation started at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"), file=open(F3Log, 'a'))
                        F3pool.apply_async(TimeSeriesPixelWiseStatistics, [mylock,Management,Years,Metric])  #This is to include a SpatialMosaicProjectBoundary argument
        F3pool.close()
        F3pool.join()
        print("FFF finished at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
    #This section calculates time-series PixelWise statistics like arcpy CellStatistics function ---end


    #x = input('Please hit any key to continue 6:')
    #exit()



    #This section generate statistic report for polygons (i.e., watershed, NF, counties....) for BaseMetricBaseYearBaseManagement---start
    StatisticsShapeAndFieldPairs = [
                                     os.getcwd()+os.sep+'TilesMosaicRunAverage'+os.sep+"CaliforniaWatershedAlbers.shp||HU_10_NAME"
                                   ]
    MaximalSimutaneousTask = min(1*1*1*len(StatisticsShapeAndFieldPairs), UserDefinedMaximumProcessors)
    NumberOfSimutaneousTask = max(min(NumberOfProcessors-2, MaximalSimutaneousTask),1)  
    print("\n\n\nNumberOfSimutaneousTask for statistic report =",NumberOfSimutaneousTask)
    F3pool = multiprocessing.Pool(processes=NumberOfSimutaneousTask)
    for Management in [BaseManagement]:
        for Year in [BaseYear]:
            for Metric in [BaseMetric]:
                for StatisticsShapeAndFieldPair in StatisticsShapeAndFieldPairs:
                    print("Using https://www.geeksforgeeks.org/how-to-use-glob-function-to-find-files-recursively-in-python/, especially ? pattern")    
                    StatisticsReportCSV = glob.glob(os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep+Management+"_"+Year+"_"+Metric+"_Final_"+StatisticsShapeAndFieldPair.split(os.sep)[-1].replace(".shp||","_*_")+".csv")  
                    print("StatisticsReportCSV=",StatisticsReportCSV)
                    if len(StatisticsReportCSV) == 0:
                        print(Management,Year,Metric," statistic report started at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
                        F3pool.apply_async(StatisticsReportFromRastersAndShapeField, [mylock,Management,Year,Metric,StatisticsShapeAndFieldPair])
    F3pool.close()
    F3pool.join()
    print("GGG finished at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
    #This section generate statistic report for polygons (i.e., watershed, NF, counties....) for BaseMetricBaseYearBaseManagement---end

    #x = input('Please hit any key to continue 7:')    
    #exit()


    #This section generate statistic report for polygons (i.e., watershed, NF, counties....) for NOT BaseMetricBaseYearBaseManagement---start
    #StatisticsShapeAndFieldPairs = [os.getcwd()+os.sep+'TilesMosaicRunAverage'+os.sep+"CaliforniaWatershedAlbers.shp||HU_10_NAME"]
    MaximalSimutaneousTask = min(len(Managements)*len(Years)*len(Metrics)*len(StatisticsShapeAndFieldPairs), UserDefinedMaximumProcessors)
    NumberOfSimutaneousTask = max(min(NumberOfProcessors-2, MaximalSimutaneousTask),1)  
    print("\n\n\nNumberOfSimutaneousTask for statistic report =",NumberOfSimutaneousTask)
    F3pool = multiprocessing.Pool(processes=NumberOfSimutaneousTask)
    for Management in Managements:
        for Year in Years:
            for Metric in Metrics:
                for StatisticsShapeAndFieldPair in StatisticsShapeAndFieldPairs:
                    print("Using https://www.geeksforgeeks.org/how-to-use-glob-function-to-find-files-recursively-in-python/, especially ? pattern")    
                    StatisticsReportCSV = glob.glob(os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep+Management+"_"+Year+"_"+Metric+"_Final_"+StatisticsShapeAndFieldPair.split(os.sep)[-1].replace(".shp||","_*_")+".csv")  
                    print("StatisticsReportCSV=",StatisticsReportCSV)
                    if len(StatisticsReportCSV) == 0:
                        print(Management,Year,Metric," statistic report started at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
                        F3pool.apply_async(StatisticsReportFromRastersAndShapeField, [mylock,Management,Year,Metric,StatisticsShapeAndFieldPair])
    F3pool.close()
    F3pool.join()
    print("HHH finished at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
    #This section generate statistic report for polygons (i.e., watershed, NF, counties....) for NOT BaseMetricBaseYearBaseManagement---end

    #x = input('Please hit any key to continue 8:')    
    #exit()


    #This section merge statistic report for polygons (i.e., watershed, NF, counties....) and create temporal trend figures with uncertainty---start
    MaximalSimutaneousTask = min(len(Metrics), UserDefinedMaximumProcessors)
    NumberOfSimutaneousTask = max(min(NumberOfProcessors-2, MaximalSimutaneousTask),1)  
    print("\n\n\nNumberOfSimutaneousTask for merging statistic report and trend curve =",NumberOfSimutaneousTask, file=open(F3Log, 'a'))
    F3pool = multiprocessing.Pool(processes=NumberOfSimutaneousTask)
    for Metric in Metrics:
        FinalStatisticsReportCSV = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep+Metric +"_FinalStatistic.csv"
        if not os.path.exists(FinalStatisticsReportCSV):
            print(Metric," final statistic report started at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"), file=open(F3Log, 'a'))
            F3pool.apply_async(FinalStatisticsReportForMetricAndTimeSeriesCurve, [mylock,Metric])
    F3pool.close()
    F3pool.join()
    print("III finished at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
    #This section merge statistic report for polygons (i.e., watershed, NF, counties....) and create temporal trend figures with uncertainty---end

    #x = input('Please hit any key to continue 9:')    
    #exit()


    #This section create quicklook images with consistent legend and then produce animation---start
    MaximalSimutaneousTask = min(len(Managements)*1*len(Metrics), UserDefinedMaximumProcessors)
    NumberOfSimutaneousTask = max(min(NumberOfProcessors-2, MaximalSimutaneousTask),1)  
    print("\n\n\nNumberOfSimutaneousTask for [quicklook images with consistent legend and then produce animation] =",NumberOfSimutaneousTask, file=open(F3Log, 'a'))
    F3pool = multiprocessing.Pool(processes=NumberOfSimutaneousTask)
    print("Note Years will be used below", file=open(F3Log, 'a'))
    for Management in Managements:
        for Metric in Metrics:  
            FinalAnimation = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep+Management+"_"+Years[0]+"to"+Years[-1]+"_"+Metric+"_MosaicCellMean_Win3x3Smoothing.gif"  #The gif animation can be opened with a web browser 
            print("FinalAnimation=",FinalAnimation)
            if not os.path.exists(FinalAnimation): 
                print(Management,Year,Metric," [quicklook images with consistent legend and then produce animation] started at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"), file=open(F3Log, 'a'))
                F3pool.apply_async(ManagementYearsMetricAnimation, [mylock,Management,Years,Metric])
    F3pool.close()
    F3pool.join()
    print("JJJ finished at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"), file=open(F3Log, 'a'))
    #This section create quicklook images with consistent legend and then produce animation---end

    #x = input('Please hit any key to continue 10:')
    exit()



    #This section is the crossvalidation for spatial imputation based on baseyear and basemangament. It is not related to temporal assessment---start
    MaximalSimutaneousTask = min(len(Runs)*len(Tiles)*1*1*len(CrossValidationMetric), UserDefinedMaximumProcessors) 
    NumberOfSimutaneousTask = max(min(NumberOfProcessors-2, MaximalSimutaneousTask),1)  #This defines how many task to be processed simutaneouslly. We can use a fixed number such as "NumberOfSimutaneousTask = 10", but check http://stackoverflow.com/questions/5784389/using-100-of-all-cores-with-python-multiprocessing
    print("\n\n\nNumberOfSimutaneousTask for BaseManagement,BaseYear=",NumberOfSimutaneousTask)
    F3pool = multiprocessing.Pool(processes=NumberOfSimutaneousTask)
    for Management in [BaseManagement]:
        for Year in [BaseYear]:
            for Metric in CrossValidationMetric:
                FinalCrossValidationCSV = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep+Management+"_"+Year+"_"+Metric+"_CrossValidation.csv"
                if not os.path.exists(FinalCrossValidationCSV):     
                    FinalCrossValidationCSVFile = open(FinalCrossValidationCSV, 'w')
                    FinalCrossValidationCSVHead = "PlotID,Row,Column,Run,Tile,Management,Year,Metric,MetricType,ObservedValue,ImputedValue,MeanValue,WeightedMeanValue,MeanTimesRatioValue,WeightedMeanTimesRatioValue,AllFourValue,IntegratedValue,ImputedValuePercentage,MeanValuePercentage,WeightedMeanValuePercentage,MeanTimesRatioValuePercentage,WeightedMeanTimesRatioValuePercentage,AllFourValuePercentage,IntegratedValuePercentage,ZoneAndOrder,Modeller,Time" + "\n"
                    FinalCrossValidationCSVFile.write(FinalCrossValidationCSVHead)
                    FinalCrossValidationCSVFile.close()
                    for Run in Runs:
                        for Tile in Tiles:
                            F3pool.apply_async(CrossValidation, [mylock,Run,Tile,Management,Year,Metric])  #The last augument is the cooss-validation percentage from 0.01 to 1.0.  
    F3pool.close()
    F3pool.join()
    for Management in [BaseManagement]:
        for Year in [BaseYear]:
            for Metric in CrossValidationMetric:
                FinalCrossValidationCSV = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep+Management+"_"+Year+"_"+Metric+"_CrossValidation.csv"
                if Metric in ContinuousMetrics:
                    FinalCrossValidationCSVFig = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep+Management+"_"+Year+"_"+Metric+"_CrossValidation_ImputedValue.pdf"
                    if not os.path.exists(FinalCrossValidationCSVFig):
                        CrossValidationGraphicFile = CrossValidationContinuousGraphic(FinalCrossValidationCSV)
                if Metric in DiscreteMetrics:
                    print("The following FinalCrossValidationCSVFig needs revision for discrete metric")
                    FinalCrossValidationCSVFig = os.getcwd()+os.sep+"TilesMosaicRunAverage"+os.sep+Management+"_"+Year+"_"+Metric+"_CrossValidation_ImputedValue.pdf"
                    if not os.path.exists(FinalCrossValidationCSVFig):
                        CrossValidationGraphicFile = CrossValidationDiscreteExcel(FinalCrossValidationCSV)
    print("KKK finished at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
    #This section is the crossvalidation for spatial imputation based on baseyear. It is not related to temporal assessment---end

    #x = input('Please hit any key to continue 11:')
    #exit() 

    
    #This section will create a database to store the infromation of F3 status. If already processed, then the data will be grabbed without processing again---start
    F3DataBaseCSV = os.path.dirname(os.getcwd())+os.sep+"F3DataEveryWhere"+os.sep+"F3DataBase.csv"  #https://stackoverflow.com/questions/2860153/how-do-i-get-the-parent-directory-in-python
    if not os.path.exists(F3DataBaseCSV):
        F3DataBaseCSVFile = open(F3DataBaseCSV, 'w')
        F3DataBaseCSVHead = "GeographicProject,Run,Tile,Management,Year,Metric,BaseYear,BaseMetric,BaseManagement,F3NoDataValue,F3Resolution,Modeller,ProcessingTime" + "\n"
        F3DataBaseCSVFile.write(F3DataBaseCSVHead)
        F3DataBaseCSVFile.close()
    today = date.today()  #https://www.geeksforgeeks.org/get-current-date-using-python/
    F3DataBaseCSVcopy = F3DataBaseCSV.replace(".csv","_"+str(today)+".csv")  #To prevent the damage of this CSV file, we make a copy here
    shutil.copy(F3DataBaseCSV, F3DataBaseCSVcopy)
    F3DataBaseCSVFile = open(F3DataBaseCSV, 'r')
    Lines = F3DataBaseCSVFile.readlines()
    Lines = [i.replace('\n','') for i in Lines]
    Lines = [",".join(i.split(",")[:-1]) for i in Lines]  #removing the last element of "ProcessingTime"
    F3DataBaseCSVFile.close()
    F3DataBaseCSVFile = open(F3DataBaseCSV, 'a')
    GeographicProject = os.getcwd().split(os.sep)[-1]  #This will be the geographic area. For example, maybe like California, Montana, Yellowstone etc). Note F3 cannot make mosaic for very large area, so it is good to divide a large arra into small areas
    Modeller = "Dr. Shengli Huang (shengli.huang@usda.gov)"
    for Run in Runs:
        for Tile in Tiles:
            for Management in Managements:
                for Year in Years:
                    for Metric in Metrics:
                        Content0 = ",".join([GeographicProject,Run,Tile,Management,str(Year),Metric,str(BaseYear),BaseMetric,BaseManagement,str(F3NoDataValue),str(F3Resolution),Modeller])
                        if Content0 not in Lines:   #if already processed, then we will not update
                            Content = Content0 + "," + datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
                            print("Content=",Content)
                            F3DataBaseCSVFile.write(Content)
    F3DataBaseCSVFile.close()
    print("LLL finished at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
    #This section will create a database to store the infromation of F3 status. If already processed, then the data will be grabbed without processing again---end

    #x = input('Please hit any key to continue 12:')
    exit() 


    #This section will create actual annual products (e.g., update Eveg), which is different from traditional F3 annual projections ---start
    if BaseYear == "2022":  #AutomaticAnnualProductCreation will only start when the indicated year is finished. We can change later.
        YearsOfAnnualChange = [*range(2012,2015,1)] + [*range(2015,2075,20)]
        AnnualMetrics = ["SLTSCB"]
        MaximalSimutaneousTask = min(len(AnnualMetrics)*1, UserDefinedMaximumProcessors) 
        NumberOfSimutaneousTask = max(min(NumberOfProcessors-2, MaximalSimutaneousTask),1)  
        print("\n\n\nNumberOfSimutaneousTask for AutomaticAnnualProductCreation=",NumberOfSimutaneousTask)
        F3pool = multiprocessing.Pool(processes=NumberOfSimutaneousTask)
        for Metric in AnnualMetrics:
            MetricFinalFile = os.path.dirname(os.getcwd())+os.sep+"HistoricalAndActualAnnualProducts" + os.sep + "NoMGT_"+str(YearsOfAnnualChange[-1])+"_"+Metric.lower()+".tif"  #Use the last YearsOfAnnualChange to detect if the process has been run
            if not os.path.exists(MetricFinalFile):  
                F3pool.apply_async(AutomaticAnnualProductCreation, [mylock,YearsOfAnnualChange,Metric])   
        F3pool.close()
        F3pool.join()
    print("MMM finished at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
    #This section will create actual annual products (e.g., update Eveg), which is different from traditional F3 annual projections ---end


    #x = input('Please hit any key to continue 13:')
    #exit() 



    #This section will create historical annual products (e.g., going back to 1980s). It is based on traditional F3 annual products with a similar idea of lookup table---start
    #if BaseYear == "2022":  #HistoricalAnnualProductCreation will only start when the indicated year is finished. We can change later.
    #This section will create historical annual products---start
    YearOfInterests = [2019]
    ReferenceYears = [2012,2013,2014]   #20230526: One year may take 3 hours within a tile.
    #ReferencedImg = "D:\\f3app\\RemoteSensingYear2014\\TilesMosaicRunAverage\\HMtest3.tif"   #This is a small tif for testing mainly
    ReferencedImg = os.path.dirname(os.getcwd())+os.sep+"RemoteSensingYear2014"+os.sep+"TilesMosaicRunAverage"+os.sep+"Area_Extent_650215.tif"   #We can change it for the project extent
    HistoricalMetrics = ["SLTSCB"]
    HistoricalMetrics = [i.lower() for i in HistoricalMetrics if i.lower() in Metrics]
    if BaseMetric not in HistoricalMetrics:
        HistoricalMetrics.insert(0,BaseMetric)
    RSbins = [3,4]  #20230526: 3 is the best taking around 3 hours. Higher value more time.  
    MinimumPixelNumber = 10
    StopPercentage = 99
    ReducedTimes = 4    #This must be an integer. If original is 30m, then ReducedTimes = 3 means 90m, which can reduce the computation to 1/9. If we do not use it, the HistoricalAnnualProductCreation may take too long time. 
    print("For historical mapping, resolution is not so imporant, so 150-300 is acceptable. Based on this, ReducedTimes = 5 may be a good option: keep reasonable resolution and computation time is OK")
    MaximalSimutaneousTask = min(len(YearOfInterests)*1, UserDefinedMaximumProcessors) 
    NumberOfSimutaneousTask = max(min(NumberOfProcessors-2, MaximalSimutaneousTask),1)  
    print("\n\n\nNumberOfSimutaneousTask for historical annual products=",NumberOfSimutaneousTask)
    F3pool = multiprocessing.Pool(processes=NumberOfSimutaneousTask)
    for YearOfInterest in YearOfInterests:
        for Metric in [BaseMetric]:
            MetricFinalFile = os.path.dirname(os.getcwd())+os.sep+"HistoricalAndActualAnnualProducts" + os.sep + "NoMGT_"+str(YearOfInterest)+"_"+Metric.lower()+".tif"
            if not os.path.exists(MetricFinalFile):  
                F3pool.apply_async(HistoricalAnnualProductCreation, [mylock,YearOfInterest,ReferenceYears,Metric,ReferencedImg,RSbins,StopPercentage,ReducedTimes])   
    F3pool.close()
    F3pool.join()
    MaximalSimutaneousTask = min(len(YearOfInterests)*len(HistoricalMetrics), UserDefinedMaximumProcessors) 
    NumberOfSimutaneousTask = max(min(NumberOfProcessors-2, MaximalSimutaneousTask),1)  
    print("\n\n\nNumberOfSimutaneousTask for historical annual products=",NumberOfSimutaneousTask)
    F3pool = multiprocessing.Pool(processes=NumberOfSimutaneousTask)
    for YearOfInterest in YearOfInterests:
        for Metric in HistoricalMetrics:
            MetricFinalFile = os.path.dirname(os.getcwd())+os.sep+"HistoricalAndActualAnnualProducts" + os.sep + "NoMGT_"+str(YearOfInterest)+"_"+Metric.lower()+".tif"
            if not os.path.exists(MetricFinalFile):  
                F3pool.apply_async(HistoricalAnnualProductCreation, [mylock,YearOfInterest,ReferenceYears,Metric,ReferencedImg,RSbins,StopPercentage,ReducedTimes])   
    F3pool.close()
    F3pool.join()
    print("NNN finished at ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
    #This section will create historical annual products (e.g., going back to 1980s). It is based on traditional F3 annual products with a similar idea of lookup table---end

    #x = input('Please hit any key to continue 14:')
    exit()

   











                     

    
